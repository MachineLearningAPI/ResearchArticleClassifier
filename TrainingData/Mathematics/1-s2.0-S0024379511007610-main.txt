Linear Algebra and its Applications 436 (2012) 3268–3292

Contents lists available at SciVerse ScienceDirect

Linear Algebra and its Applications
journal homepage: w w w . e l s e v i e r . c o m / l o c a t e / l a a

Spectra of uniform hypergraphs <
Joshua Cooper, Aaron Dutle ∗
Department of Mathematics, University of South Carolina, Columbia, SC, USA

ARTICLE INFO

ABSTRACT

Article history:
Received 27 July 2011
Accepted 10 November 2011
Available online 3 December 2011

We present a spectral theory of uniform hypergraphs that closely
parallels Spectral Graph Theory. A number of recent developments
building upon classical work has led to a rich understanding of “symmetrichyperdeterminants”ofhypermatrices,a.k.a.multidimensional
arrays.Symmetrichyperdeterminantssharemanypropertieswithdeterminants,butthecontextofmultilinearalgebraissubstantiallymore
complicatedthanthelinearalgebrarequiredtoaddressSpectralGraph
Theory (i.e., ordinary matrices). Nonetheless, it is possible to define
eigenvalues of a hypermatrix via its characteristic polynomial as well
as variationally. We apply this notion to the “adjacency hypermatrix”
of a uniform hypergraph, and prove a number of natural analogs of
basic results in Spectral Graph Theory. Open problems abound, and
we present a number of directions for further study.
© 2011 Elsevier Inc. All rights reserved.

Submitted by R.A. Brualdi
AMS classification:
Primary 05C65
Secondary 15A69
15A18
Keywords:
Hypergraph
Spectrum
Resultant
Characteristic polynomial

1. Introduction
Spectral Graph Theory is a widely studied and highly applicable subject in combinatorics, computer
science, and the social sciences. Broadly speaking, one first encodes the structure of a graph in a matrix
M and then pursues connections between graph properties and the eigenvalues or singular values of
M. Work has addressed the “adjacency matrix”, as well as other matrices that come from a graph:
the “(combinatorial) Laplacian”, the “unsigned Laplacian”, the “normalized Laplacian”, the “bipartite
adjacency matrix”, the “incidence matrix”, and others (q.v. [4,11,14,15]). One natural avenue of study
is the generalization of spectral techniques to hypergraphs, though there is a conspicuous paucity
of results known in this vein. There have been attempts in the literature to define eigenvalues for
hypergraphs and study their properties, with varying amounts of success. Notable examples include
[10,16,18,23,27]. Most of this work concerns generalizations of the Laplacian spectrum of a graph, and
has a very different flavor than the subject we discuss in the sequel.
< This work was funded in part by NSF Grant DMS-1001370.
∗ Corresponding author.
E-mail addresses: cooper@math.sc.edu (J. Cooper), dutle@mailbox.sc.edu (A. Dutle).
0024-3795/$ - see front matter © 2011 Elsevier Inc. All rights reserved.
doi:10.1016/j.laa.2011.11.018

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3269

Unfortunately, naïvely attempting to generalize the spectral theory of adjacency matrices to hypergraphs runs into serious obstacles right away. There is no obvious way to define an adjacency matrix
for a hypergraph, since edges are specified by more than two vertices. For a k-uniform hypergraph, one
can obtain a straightforward generalization to an order-k array (essentially, a tensor), but in doing so,
one loses the powerful and sophisticated tools of linear algebra with which to analyze it. Another tack,
which is related to the k-dimensional array strategy, is to consider eigenvalues as the simultaneous
vanishing of a system of equations each containing the parameter λ, where the eigenvalues are those λ
for which the system has a solution. This generalizes the idea that matrix eigenvalues are the vanishing
of linear equations with λ as a parameter.
Recent work [9,17,22,24,26] has provided some of the framework and tools with which to analyze
such higher dimensional arrays, and we employ these developments extensively to define and analyze
our hypergraph eigenvalues. We obtain a number of results closely paralleling results from classical
Spectral Graph Theory, including bounds on the largest eigenvalue, a spectral bound on the chromatic
number, and a sub-hypergraph counting description of the coefficients of the characteristic polynomial. We also describe the spectrum for some natural hypergraph classes and operations, including
disjoint unions, Cartesian products, k-partite graphs, k-cylinders, a generalization of the hypercube,
and complete hypergraphs.
Recent work has used variations of the hypergraph eigenvalues we describe to obtain results about
the maximal cliques in a hypergraph [6], cliques in a graph based on hypergraphs arising from the graph
[7], and connectivity properties for hypergraphs of even uniformity [20]. We add many basic results
about hypergraph eigenvalues to this body of work. Many of our results employ an algebraic characterization of the eigenvalues which has been underutilized in the study of hypergraphs. Furthermore, our
characterizations of the eigenvalues (and, in some cases, eigenvectors) of certain hypergraph classes
gives several classes of hypermatrices for which we now understand the spectrum. We hope that this
work can provide a foundation for further study of the eigenvalues of symmetric hypermatrices.
The remainder of the paper is organized as follows. In Section 2, we give definitions and background
on eigenvalues of symmetric hypermatrices, including both variational and algebraic formulations. In
Section 3, we define the adjacency hypermatrix for a k-uniform hypergraph, and derive hypergraph
generalizations of many of the central results of Spectral Graph Theory. Section 4 explores the spectra
of several “common” hypergraphs: complete graphs, Cartesian products, k-cylinders, etc. Section 5
outlines a surfeit of directions for further study. Finally, Section 6 briefly addresses the computational
aspects of hypergraph spectra.
2. Eigenvalues of symmetric hypermatrices
We begin by defining the array that we will use to encode a k-uniform hypergraph. We denote the
set {1, . . . , n} by [n].
Definition 2.1. A (cubical) hypermatrix A over a set S of dimension n and order k is a collection of nk
elements ai1 i2 ...ik ∈ S where ij ∈ [n].
For the remainder of the present discussion, S

= C.

Definition 2.2. A hypermatrix is said to be symmetric if entries which use the same index sets are the
same. That is, A is symmetric if ai1 i2 ...ik = aiσ (1) iσ (2) ...iσ (k) for all σ ∈ Sk , where Sk is the symmetric
group on [k].
In the case of graphs, i.e., k = 2, cubical hypermatrices are simply square matrices, and symmetric
hypermatrices are just symmetric matrices. It should be noted that some authors use the term tensor
in place of hypermatrix. Strictly speaking, however, a hypermatrix is not simply a tensor: it is a tensor
expressed in a particular basis. It is worth noting that there are several additional departures from
the above nomenclature in the literature. Some authors (e.g., [19]) simply refer to hypermatrices as
“matrices”, while computer scientists often call them “multidimensional arrays”. Also, in order to use

3270

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

“symmetric” to refer to weaker notions of symmetric hypermatrices, some authors use “supersymmetric” to refer to what we term “symmetric”.
An order k dimension n symmetric hypermatrix A uniquely defines a homogeneous degree k polynomial in n variables (a.k.a. a “k-form”) by
n

FA (x)

=

i1 ,i2 ,...,ik =1

ai1 i2 ...ik xi1 xi2

. . . xik .

(1)

Qi [26] and Lim [22] offered several generalizations of the eigenvalues of a symmetric matrix to
the case of higher order symmetric (or even non-symmetric) hypermatrices. We employ the following
definition from [26].
Definition 2.3. Call λ
eigenvector, satisfying

∈ C an eigenvalue of A if there is a non-zero vector x ∈ Cn , which we call an

n
i2 ,i3 ,...,ik =1

for all j

aji2 i3 ...ik xi2

. . . xik = λxjk−1

(2)

∈ [n].

If we write x r for the order r dimension n hypermatrix with i1 , i2 , . . . , ir entry xi1 xi2

. . . xir , and

x [r ] for the vector with ith entry xir , then the expressions above can be written rather succinctly.

Eq. (1) becomes
FA (x )

= Ax k ,

where multiplication is taken to be tensor contraction over all indices. Similarly, the eigenvalue equations (2) can be written as
Ax k−1

= λx [k−1] ,

where contraction is taken over all but the first index of A. We mostly avoid the tensorial nomenclature,
and work instead with polynomials, although we sometimes use the above notation for concision.
With the definitions above (and some generalizations of them), much work has been done using
variational or analytic techniques, including conditions for the function FA (x ) to be positive definite
and Perron–Frobenius-type theorems [9,17,22]. We rely on these results, but draw more from the
algebraic approach suggested by Qi in [26], which uses a construction from algebraic geometry called
the resultant. We give a brief background and some useful properties of this construction.
2.1. The multipolynomial resultant
The resultant of two polynomials in one variable (or alternatively two homogeneous polynomials
in two variables) is a classical construction used to determine if the two polynomials have a common
root. It can be defined and calculated in a number of ways, including the determinant of the so-called
“Sylvester matrix” of the two polynomials. On the other extreme, if we have n linear forms in n variables,
the determinant of the coefficient matrix tells us when these forms have a common non-trivial zero.
The multipolynomial resultant is a construction that unifies both concepts under a single framework.
Readers wishing to learn more about the topic may find a highly algebraic treatment of the resultant
and its generalizations in the text by Gelfand et al. [19]; those looking for a less specialized and more
algorithmic approach may consult the text by Cox et al. [13].
We reproduce two theorems giving some important facts about the resultant. For proofs of these
results, see [19]. First is the existence and (once suitably normalized) uniqueness of the resultant.
Theorem 2.1. Fix degrees d1 , d2 , . . . , dn . For i ∈ [n], consider all monomials x α of total degree di in
x1 , . . . , xn . For each such monomial, define a variable ui,α . Then there is a unique polynomial Res ∈
Z[{ui,α }] with the following three properties:

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3271

(1) If F1 , . . . , Fn ∈ C[x1 , . . . , xn ] are homogeneous polynomials of degrees d1 , . . . , dn , respectively,
then the polynomials have a non-trivial common root in Cn exactly when Res(F1 , . . . , Fn ) = 0.
Here, Res(F1 , . . . , Fn ) is interpreted to mean substituting the coefficient of x α in Fi for the variable
ui,α in Res.
d

(2) Res(x11 , . . . , xndn ) = 1.
(3) Res is irreducible, even in C[{ui,α }].

Next, the resultant is homogeneous in each group of coefficients.
Theorem 2.2. Fix degrees d1 , . . . , dn . Then for i
degree d1 d2 . . . di−1 di+1 . . . dn .

∈ [n], Res is homogeneous in the variables {ui,α } with

Since the equations Ax k−1 are a collection of n homogeneous polynomials in n variables, we can
use them as “input” into the resultant, which leads to the following.
Definition 2.4. The symmetric hyperdeterminant of A, denoted det(A), is the resultant of the polynomials Ax k−1 .
Let I, the identity hypermatrix, have entries

1 if i1

= i2 = · · · = ik

0 otherwise.

Definition 2.5. Let λ be an indeterminate. The characteristic polynomial φA (λ) of a hypermatrix A is
φA (λ) = det(λI − A).
Qi, in [26], determined many properties of the symmetric hyperdeterminant and the characteristic
polynomial, the most crucial being that the roots of the characteristic polynomial are exactly the
eigenvalues of A. From this, we take our generalization of the spectrum of a matrix.
Definition 2.6. The spectrum of a symmetric hypermatrix A, denoted spec(A), is the set (or multiset,
depending on the context) of roots of φA (λ).

3. General hypergraph spectra
In the sequel, we employ standard definitions and notation from hypergraph theory; see, e.g., [3].
A hypergraph H is a pair (V , E ), where E ⊆ P (V ). The elements of V = V (H ) are referred to as vertices
and the elements of E = E (H ) are called edges. A hypergraph H is said to be k-uniform for an integer
2 if, for all e ∈ E (H ), |e| = k. We will often use the term k-graph in place of k-uniform hypergraph.
k
Given two hypergraphs H = (V , E ) and H = (V , E ), if V ⊆ V and E ⊆ E, then H is said to be
a subgraph of H. A set of vertices S ⊂ V (H ) is said to induce the subgraph H [S ] = (S , E ∩ P (S )). A
k-uniform multihypergraph H is a pair (V , E ), where E is a multiset of subsets of V of cardinality k.
Given a hypergraph H = (V , E ) and a multihypergraph H = (V , E ), if (V , E ) is a subgraph of H,
where E is the set of elements of E , then H is said to be a multi-subgraph of H.
Definition 3.1. For a k-graph H on n labeled vertices, the (normalized) adjacency hypermatrix AH is
the order k dimension n hypermatrix with entries
ai1 ,i2 ,...,ik

=

1 if {i1 , i2 , . . . , ik } ∈ E (H )
(k − 1)! 0 otherwise.
1

When dealing with the spectrum of the adjacency hypermatrix of a hypergraph, we often suppress
the hypermatrix, writing spec(H ) for spec(AH ), FH (x ) for FAH (x ), etc.

3272

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

With Definition 3.1, the function FH (x ) and the eigenvalue equations (2) take on a particularly
nice form. For an edge e = {i1 , i2 , . . . , ir } of an r-graph, let xe denote the monomial xi1 xi2 . . . xir .
Recall that the link of a vertex i in H, denoted H (i), is the (k − 1)-graph whose edges are obtained by
removing vertex i from each edge of H containing i. That is, E (H (i)) = {e \ {i} | i ∈ e ∈ E (H )} and
V (H (i)) = E (H (i)). Then
FH (x )

=

e∈H

kxe ,

and the eigenvalue equations (2) become
xe
e∈H (i)

= λxik−1 ,

(3)

for all i ∈ V (H ). The normalization factor (k−11)! in Definition 3.1 is included essentially for aesthetic
reasons. It could easily be absorbed into λ in the eigenvalue equations without altering any of the
calculations. Normalization allows the adjacency hypermatrix to faithfully generalize the adjacency
matrix of a graph while removing a factor of (k − 1)! that would otherwise make an appearance in
some of the results below.
Using the definitions given Section 2, a number of results from basic Spectral Graph Theory can be
generalized to the k-graph case in a natural way. Indeed, some results need only slight modifications
of their standard proofs. Others – particularly those that give results about multiplicities – require the
use of new techniques.
Theorem 3.1. Let H be a k-graph that is the disjoint union of hypergraphs H1 and H2 . Then as sets,
spec(H ) = spec(H1 ) ∪ spec(H2 ). Considered as multisets, an eigenvalue λ with multiplicity m in spec(H1 )
contributes λ to spec(H ) with multiplicity m(k − 1)|H2 | .
We first prove a more general lemma about the resultant of a system of polynomials which can be
viewed as the union of two disjoint systems. The proof of the theorem is then a simple application of
this lemma.
Lemma 3.2. Let F1 , F2 , . . . , Fn ∈ C[x1 , . . . , xn ] be homogeneous polynomials of degrees d1 , . . . , dn ,
and let G1 , G2 , . . . , Gm ∈ C[y1 , . . . , ym ] be homogeneous polynomials of degrees δ1 , . . . , δm . Then
Res(F1 , . . . , Fn , G1 , . . . , Gm )

= Res(F1 , . . . , Fn )

i

δi

Res(G1 , . . . , Gm )

i

di

.

Proof. Instead of considering particular polynomials, we work with “generic” polynomials. We consider each Fi as having a distinct variable ai,α as a coefficient for each monomial xα of degree di in the
x variables (and the corresponding coefficient variables bi,β for Gi , δi , and the y variables).
Then by Theorem 2.1 we can consider Res(F1 , . . . , Fn ) as an irreducible integer polynomial in
C {ai,α } (which is also irreducible in C {ai,α }, {bi,β } ). Similarly Res(G1 , . . . , Gm ) is an irreducible
polynomial in the bi,β variables.
Now consider Res(F1 , . . . , Fn )Res(G1 , . . . , Gm ). It is a polynomial in all of the coefficient variables,
and if we consider Cn+m = Cn × Cm , this polynomial takes value zero precisely when at least one of
the systems {Fi }, {Gi } has a non-trivial solution in its respective space. Thus, any zero of this polynomial
is a setting of the coefficient variables {ai,α , bj,β } so that at least one of the two systems described by
the coefficients has a non-trivial solution.
Similarly, Res(F1 , . . . , Fn , G1 , . . . , Gm ) is an integer polynomial in all of the coefficient variables,
which takes value zero when the entire system has a non-trivial solution in Cn+m . Consequently, this
resultant taking value zero gives that at least one of the systems {Fi }, {Gi } has a non-trivial solution.
Notice, however, that if the system {Fi } has a nontrivial solution, then setting all of the y variables to
zero gives a nontrivial solution to the entire system. Hence Res(F1 , . . . , Fn , G1 , . . . , Gm ) takes value
zero precisely for assignments of the coefficient variables where at least one of the systems {Fi }, {Gi }
described by these coefficients has a non-trivial solution in its respective space.

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3273

Since these two polynomials have exactly the same zeroes, they can only differ (up to a unit) in
the multiplicities of their irreducible factors. Since each of Res(F1 , . . . , Fn ), and Res(G1 , . . . , Gm ) are
already irreducible, we have that for some integers D, > 0, and complex number c = 0,
Res(F1 , . . . , Fn , G1 , . . . , Gm )

= cRes(F1 , . . . , Fn ) Res(G1 , . . . , Gm )D .

Theorem 2.2 gives us that Res(F1 , . . . , Fn ) is homogeneous of degree d2 . . . dn in the coefficients of
F1 , while Res(F1 , . . . , Fn , G1 , . . . , Gm ) is homogeneous of degree d2 . . . dn δ1 . . . δm in the coefficients
= j δj .
of F1 . Since Res(G1 , . . . , Gm ) does not involve any of the ai,α , we may conclude that
Similarly, we have that D = j dj . Finally, property (b) of Theorem 2.1 implies that c = 1.
Proof of Theorem 3.1. Let H , H1 , and H2 be as in the statement of the theorem, and let φH (λ), φH1 (λ),
φH2 (λ) denote their respective characteristic polynomials. To prove the theorem, it suffices to show
|H2 |

φH (λ) = φH1 (λ)(k−1)

|H1 |

φH2 (λ)(k−1)

.

Since H is the disjoint union of two hypergraphs, the polynomials in (3) can be partitioned into two
sets 1 and 2 , where i uses only variables corresponding to vertices of Hi , i = 1, 2. Noting that the
degree of each of these polynomials is k − 1, and that the characteristic polynomial φH is the resultant
of the entire system 1 ∪ 2 , Lemma 3.2 gives the desired result.
3.1. Properties of the largest eigenvalue
We derive some properties of the eigenvalue of a k-graph H with largest modulus, which we denote

λmax = λmax (H ). Although a priori there may be many such eigenvalues with the same modulus, we

show below that there is always a real, positive one. 1 In order to proceed, we begin with a few facts
about eigenvalues associated with positive eigenvectors.
Let H be a k-graph with n vertices, and let
⎧
⎫
n
⎨
⎬
n
k
xi = 1 and xi
0 for i ∈ [n] .
S 0= x∈R
⎩
⎭
i=1

For a vector x, we call the set supp(x ) of all indices of non-zero coordinates of x the support of the
vector. For ease of notation, throughout the sequel we identify coordinate indices of vectors with the
corresponding vertices of the hypergraph under consideration.
Lemma 3.3. If v
components of H.

∈ S

0

maximizes FH (x ) on S

0,

then supp(v ) induces some collection of connected

Proof. Suppose, by way of contradiction, that v maximizes FH (x ), but the support of v is not the
vertex set of a collection of connected components of H. In particular, V (H ) = supp(v ). Define I =
V (H )\ supp(v ), and partition the edges of H as follows. Let F1 be the set of edges of H using only vertices
of supp(v ), let F2 be the set of edges of H using only the vertices of I, and let F3 = E (H ) \ (F1 ∪ F2 ).
Since the support of v does not induce a collection of components, we have F3 = ∅. Let eˆ ∈ F3 be one
such edge.
1/k

s
< s < 1, define δ = 1−
. Note that δ > 0,
|I |
but tends to zero as s tends to 1. Hence we can find s0 with 1/2 < s0 < 1 so that δ
vmin /2 for any s
with s0 < s < 1. Thus for these s, we have

Let vmin be the smallest non-zero entry of v. For 0

δ

vmin /2

svi

for any non-zero entry vi of v .
1

Unless the hypergraph has no edges, in which case all of the eigenvalues are trivially zero.

k

(4)

3274

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Next, let z ∈ Rn be the vector whose support is I, and whose non-zero entries are each 1. Define
the vector y = sv + δ z. A quick verification shows that
n
i=1

=

yik

yik

i∈[n]\I

=

+

yik

i∈I

(svi )k +

i∈I

i∈[n]\I

1 − sk

n

= sk

vik

i=1

+

δk

|I |

i∈I

= sk + (1 − sk ) = 1,
so that y ∈ S 0 . Note that the support of y is all of H.
As v maximizes FH (x ), we have that
FH (v )

FH (y )

=k

ye
e∈H

⎞

⎛

= k⎝

y

e

e∈F1

+

y

e

e∈F2

⎛

⎞

k⎝

k e⎠

s v
e∈F1

+

y

e⎠

e∈F3

+ kyeˆ

= sk FH (v ) + kyeˆ .
Solving this inequality for FH (v ), we see
FH (v )

k(1 − sk )−1 yeˆ

(5)

If we write eˆ = {i1 , i2 , . . . , ik }, then yeˆ
⎧
⎨δ
if ij ∈ I
yij =
⎩
svij otherwise.

= yi1 yi2 . . . yik . By the definition of y, we have

We know that eˆ uses vertices of I and V (H ) \ I. In particular, it has at least one factor svij . Using (4), we
vmin /2 and bound all others factors from below by δ . Thus we have
may write svij
yeˆ

δ k−1

vmin
2

.

Substituting this into (5), we see
FH (v )
where C

=

kvmin
2(1 − sk )
kvmin
2|I |(k−1)/k

δ

k−1

=

kvmin

1 − sk

2(1 − sk )

|I |

(k−1)
k

= C (1 − sk )−1/k

is a constant. Note that the left side is a fixed value, while the right side becomes

arbitrarily large as s tends to 1. Therefore, we have a contradiction.

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3275

From this lemma we can derive the following useful corollary.
Corollary 3.4. If H is a connected k-graph, then it has a strictly positive eigenpair (λ, v ) where λ is the
maximum value of FH (x ) on S 0 .
Proof. Since H is connected, the lemma tells us that the maximum of FH (x ) is obtained by a vector v
with full support. So FH (x ) is maximized on the interior of S 0 . Since this set is compact, and FH (x )
achieves its maximum in the interior, v must be a critical point of FH (x ). The critical points of FH (x )
are exactly the eigenvectors of H, so the maximum happens at an eigenvector. However, on S 0 , if
(λ, v ) is an eigenpair, it is easy to see that FH (v ) = λ. Furthermore, since all entries of v are positive,
λ = FH (v ) > 0.
Once we have the existence of a strictly positive eigenpair, the methods used in [9] allow us show
that the eigenvalue from Corollary 3.4 is actually the largest eigenvalue. We include an adapted proof
for completeness.
Lemma 3.5. If (λ, v ) is a strictly positive eigenpair, and (μ, y ) are non-negative (i.e., y
property that e∈H (i) ye
μyik−1 for each i, then μ λ.
Proof. Since v is strictly positive, we can find a t0 so that (coordinatewise), v
but at least one of the inequalities fails for any t > t0 . From the inequality v
e
each i, we have e∈H (i) ve
e∈H (i) (t0 y) . Thus,

λvik−1 =

ve
e∈H (i)

e∈H (i)

(t0 y)e = t0k−1

ye
e∈H (i)

k−1

t0

= 0) with the

ty for all 0
t
t0 ,
t0 y , it is clear that for

μyik−1 .

Solving for vi , we find
vi

μ
λ

1/(k−1)

t0 yi .

μ 1/(k−1)
t0 y . Since t0 was chosen to be the largest value that
λ
μ 1/(k−1)
1, which gives μ
λ.
makes this inequality hold, we may conclude that λ

As this holds for all i, we see that v

This simple lemma allows us to deduce a few important properties.
Corollary 3.6. If H is a connected k-graph, then the real eigenvalue λ given by Corollary 3.4 is the only
λ.
eigenvalue with a strictly positive eigenvector. If ν is any other eigenvalue of H, then |ν|
Proof. For the first statement, suppose that (λ, v ) and (μ, y ) are both strictly positive eigenpairs.
λ. Switching the roles of μ and λ and applying the same lemma
Applying Lemma 3.5 gives that μ
μ. Thus, the first statement holds.
gives that λ
For the second, suppose that (ν, z) is any eigenpair. If we set μ = |ν| and define y = (|z1 |, |z2 |, . . . ,
|zn |), we see that for each i,

μyik−1 = |ν||zi |k−1 = ν zik−1 =

|z|e =

ze
e∈H (i)

e∈H (i)

Lemma 3.5 then applies to the pair (μ, y ) to show that |ν|
The next theorem summarizes the results on λmax .

ye .
e∈H (i)

λ.

3276

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Theorem 3.7. For any non-empty k-graph H, λmax can be chosen to be a positive real number. If H is
connected, then a corresponding eigenvector x can be chosen to be strictly positive.
Proof. By Theorem 3.1, we see that λmax is obtained as an eigenvalue of some connected component
of H. For each connected component of H, Corollary 3.6 gives that the largest eigenvalue is real. The
second statement is the result of Corollaries 3.4 and 3.6.
The following theorem is an analog of a classical theorem in Spectral Graph Theory, relating λmax
to the average degree and maximum degree of the hypergraph. It also follows quickly from the above
results.
Theorem 3.8. Let H be a k-graph. Let d be the average degree of H, and
d

λmax

be the maximum degree. Then

.

In particular, if we have a regular k-graph, d

= λmax =

.

Proof. We note that Theorem 3.1 allows us to assume that H is connected. By Corollaries 3.4 and 3.6,
FH (x ) for any vector x ∈ S 0 . If we let 1 be the vector with all
and Theorem 3.7, we have that λmax
√
FH (1) = d.
entries equal to 1/ k n, we see that λmax
For the upper bound, let vˆ be a vector achieving λmax . Let vˆ i be the entry of vˆ with largest modulus.
Rescale vˆ to a vector v where vi = 1.
Then the ith eigenvalue equation gives that

λmax vik−1 =

ve .
e∈H (i)

Hence

λmax = |λmax vik−1 | =

|ve |

ve
e∈H (i)

e∈H (i)

e∈H (i)

|vik−1 | =

1

= deg(i)

.

e∈H (i)

Theorem 3.9. If G is a subgraph of H, then

λmax (G)

λmax (H ).

Proof. By Theorem 3.1, we can assume that G and H are both connected. Let FG (x ) and FH (x ) be their
associated homogeneous forms. We note that both have coefficients in {0, k}, and every term in FG (x )
appears in FH (x ). Let v be the vector from the set S 0 that achieves λmax (G). Let u be the same vector,
with zero entries for any vertices that H has, but G lacks. Then we have

λmax (G) = FG (v )

FH (u).

By Theorem 3.7, we have that FH (u)

λmax (H ).

3.2. Chromatic number and the largest eigenvalue
For a hypergraph H, a function f : V (H ) → [r ] is a (weak) proper r-coloring of H if for every edge
e = {v1 , v2 , . . . vk }, there exist i = j so that f (vi ) = f (vj ). Informally, no edge has all of its vertices
colored the same. The (weak) chromatic number of H , denoted χ (H ), is the minimum r such that H
has a proper r-coloring.
Theorem 3.10. For any k-graph, χ (H )

λmax (H ) + 1.

Our proof is a reprise of the classical proof by Wilf in [29], which uses the coloring method described
by Brooks [5].

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3277

Proof. Define an ordering on the vertices of H as follows. Let H (n) = H, and let vn be a vertex of smallest
degree in H (n). Inductively, we let H (m) be the subgraph that remains after deleting vertex vm+1 from
H (m + 1), and let vm be a vertex of smallest degree in H (m). We use the ordering v1 , v2 , . . . , vn as
input to a greedy coloring algorithm, which assigns to vertex vi the smallest natural number so that
H (i) is still properly colored.
λmax (H ) + 1, as we know λmax
0. Inductively, we assume
Now, note that χ (H (1)) = 1
that we have properly colored H (m) with at most λmax (H ) + 1 colors. Note that vertex vm+1 has the
smallest degree of all vertices in H (m + 1). In the worst case, each edge containing vm+1 are, aside
from vm+1 , monochrome, and use the colors {1, 2, . . . , degH (m+1) (vm+1 )}. In this situation, we need
to use color degH (m+1) (vm+1 ) + 1 for vm+1 . Hence, we see that to color vertex vm+1 , we need at most
degH (m+1) (vm+1 ) + 1

= δ(H (m + 1)) + 1
d(H (m + 1)) + 1

λmax (H (m + 1)) + 1
λmax (H ) + 1.
The first inequality above is trivial, as the average degree is always at least the minimum degree, and
the last two inequalities follow from Theorems 3.8 and 3.9, respectively.

By Theorem 3.8, we recover the k-graph analog of Brooks’ bound on the chromatic number.
Corollary 3.11. For any k-graph H, χ (H )

(H ) + 1.

Also implicit in our proof of Theorem 3.10 is that (H ) in Corollary 3.11 can also be replaced by the
degeneracy of the hypergraph, which is maxG⊆H δ(G).
If we consider (H ) tending to infinity and k fixed, Corollary 3.11 can be improved further using
probabilistic methods. Indeed, a simple application of the Lovász Local Lemma [2] gives that

χ (H )

[e(k

(H ) + 1)]1/(k−1) = O

(H )1/(k−1) .

However, if (H )
d(H ), it is possible that λmax is substantially smaller than
3.10 is still a better bound in some cases.

(H ), so that Theorem

3.3. Coefficients of the characteristic polynomial
The characteristic polynomial is defined as the resultant of a certain system of equations, so calculating the characteristic polynomial requires computation of the resultant. In [24], Morozov and
Shakirov give a formula (using somewhat different notation) for calculating det(I − A) using “Schur
polynomials” in the generalized traces of the order k, dimension n hypermatrix A.
Definition 3.2. Define the dth Schur polynomial Pd
d

Pd (t1 , . . . , td )

=

td1

m=1 d1 +···+dm =d
∀i(di >0)

· · · tdm
.
m!

More compactly, one may define the Pd by writing
⎞
⎛
exp ⎝

∞

d=1

td z d ⎠

=

∞

d=1

Pd (t1 , . . . , td )z d .

∈ Z[t1 , . . . , td ] by P0 = 1 and, for d > 0,

3278

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Let fi denote the ith coordinate of Ax k−1 . Define A to be an auxiliary n
variables Aij as entries. For each i, we define the differential operator
fˆi

= fi

× n matrix with distinct

∂
∂
∂
,
,...,
∂ Ai1 ∂ Ai2
∂ Ain

in the natural way. (To be precise, let O be the operator algebra over C generated by the differential operators {∂/∂ Aij }ni,j=1 . Then fˆi is the image of fi (x1 , . . . , xn ) under the homomorphism from C[x1 , . . . , xn ]
to O defined by xj → ∂/∂ Aij for each j ∈ [n].) For d > 0, define the generalized dth trace Trd (A) by
⎛
⎞
d
n
fˆi i
n−1
⎝
⎠ tr(Ad(k−1) ),
Trd (A) = (k − 1)
(
d
(
k
−
1
))!
i
d +d +···+d =d i=1
1

2

n

where tr(·) denotes ordinary matrix trace. The authors prove that
⎞
⎛
∞
Tri (A)
⎠.
⎝
det(I − A) = exp
−
i
i=1
The right hand side of this equation can be expanded as a power series using the Schur polynomials,
where we see
det(I

− A) =

∞

Pi
i=0

−

Tr1 (A)
1

,...,−

Tri (A)
i

.

Morozov and Shakirov note that since we know the degree of the resultant, and since the dth Schur
polynomial in the above expression is homogeneous of degree d in the coefficients of A, the resultant
of A (up to sign) is simply the Schur polynomial of the correct degree in this expression.
We note that this same reasoning tells us that the codegree d coefficient of the characteristic
polynomial of A is the degree d part of the above expression, which is exactly the dth Schur polynomial
in the expression above.
This gives us a concrete way of finding the coefficients of the characteristic polynomial for any
particular hypermatrix. It also gives us a tool to analyze the symmetric hypermatrix with variable
entries ai1 i2 ...ik . Our first application of the technique is to prove that monomials in the symmetric
hyperdeterminant have a very particular form.
Definition 3.3. Let R be any ring, and let
V

= {ai1 i2 ...ik | ij ∈ [n], j ∈ [k], ai1 i2 ...ik = aiσ (1) iσ (2) ...iσ (k) ∀σ ∈ Sk }

be a set of variables. A monomial M in R[V ] is called t-valent (t
2) if every index i appearing in a
subscript of some variable occurring in M appears 0 (mod t ) times in M.
For example, a111 a001 is 2-valent (or “bivalent”), a011 a100 is 3-valent (“trivalent”), while a011 a222 has
no valency.
Theorem 3.12. If A is the order k dimension n symmetric hypermatrix with variable entries, every term of
every coefficient of φA (λ) is k-valent.
Proof. Note that since terms arise from multiplying generalized traces together, it suffices to show
that each generalized trace produces only k-valent terms. Since the traces are sums of terms of the form
⎞
⎛
d
n
fˆi i
⎠ tr Ad(k−1) ,
⎝
(di (k − 1))!
i=1
for some d1 + · · · + dn

= d, it suffices to show that each of these terms produces only k-valent terms.

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3279

We say that a term of tr(Ad(k−1) ) survives an operator if it is nonvanishing under the action of the
operator. For a single term of an operator involving r differentiations and a single term of tr(Ar ), this
amounts to the variables of the trace term being in one-to-one correspondence with the differentiation
variables.
d
If we ignore scalar factors, any single term of D = ni=1 fˆi i consists of the product of d differential
operators, di of them of the form
aij2 ...jk

∂
∂
∂
···
∂ Ai,j2 ∂ Ai,j3
∂ Ai,jk

for each i. When a variable aij2 ...jk is included in such a product arising from the operator Di = fˆi i ,
call i the variable’s primary index, and call the other indices secondary. Clearly, i appears di times as
a primary index in any term of Di . To show that the only monomials that survive D are k-valent, we
show that a term of tr(Ad(k−1) ) that survives must use i exactly di (k − 1) times among the secondary
indices.
Note that if i is a primary index for a variable, then each of the k − 1 partial derivatives that
accompany it have i as the first index of the differentiation variable. Recall that
d

tr(Ar )

=

i1 ,i2 ,...,ir

Ai1 ,i2 Ai2 ,i3

. . . Air−1 ,ir Air ,i1 .

For such a monomial appearing in tr(Ad(k−1) ) to survive, for each i ∈ [n], i must occur as a first index of
some Ast variable di (k − 1) times. Hence, by the form of the trace monomials, it also occurs as a second
index the same number of times. However, the second indices of the differential operator variables
correspond exactly to the secondary indices of the variables ajj2 ...jk from the terms of D. Therefore i
appears exactly di (k − 1) times as a secondary index as well, completing the proof.
Using the methods above, we can fully describe the first few coefficients of the characteristic polynomial for a general k-graph.
Theorem 3.13. For a k-graph H, the codegree 1, 2, . . . , k − 1 coefficients of φH (λ) are zero.
Proof. We consider an adjacency hypermatrix filled with variables whose indices label the possible
edges of a k-graph. Then any monomial in these variables can be thought of as a multi-subgraph of
H. By the previous theorem, we see that the codegree d coefficient is made up of constant multiples
of k-valent monomials of degree d, which correspond to multi-subgraphs; we extend the definition of
k-valency to multihypergraphs in this way. Noting that each variable in a hypergraph monomial uses
k distinct indices, we see that there are no k-valent subgraphs with fewer than k edges, proving our
claim.
Corollary 3.14. For a k-graph, Tri (H )

= 0 for 1

i

< k.

Proof. The proof of Theorem 3.12 tells us that generalized traces only produce k-valent terms, and the
proof of Theorem 3.13 gives that there are no k-valent subgraphs on fewer than k edges.
With a bit more work, we can also characterize the codegree k coefficient in terms of the number
of edges of the k-graph.
Theorem 3.15. For a k-graph H, the codegree k coefficient of φH (λ) is −kk−2 (k − 1)n−k |E (H )|.
Note that setting k = 2 recovers the well-known fact that the codegree 2 coefficient of a graph’s
characteristic polynomial counts the number of edges; for higher uniformity, one obtains a multiple
of the number of edges which depends on the number of vertices as well.

3280

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Proof. First, recall that the codegree k coefficient is
Pk

−

Tr1 (H )
1

,...,−

Trk (H )

.

k

By Corollary 3.14, all but the last parameter of this function are zero. By the definition of Pk , we see
that the desired coefficient is −Trk (H )/k. Recalling the definition of the trace,
⎛
⎞
d
n
Trk (H )
fˆi i
(k − 1)n−1
⎝
⎠ tr(Ak(k−1) ).
=
k
k
(
d
(
k
−
1
))!
i
d +d +···+d =k i=1
1

2

n

We now show that most of the terms in sum in the above expression make no contribution to the
1, and where
trace. Indeed, the only operators that have surviving terms are those with each di
the indices i with di = 1 describe an edge of H. To see this, note that the only k-valent subgraph on k
edges is a single edge repeated k times. From the proof of Theorem 3.12, we see that the only indices

appearing in surviving terms must occur as a primary index in some term of ni=1 fˆi i , and that the
associated coefficient is non-zero only when these indices actually describe an edge.
This lets us further refine our expression for the codegree k coefficient to include only those operators whose coefficients correspond to a bona fide edge. That is,
⎛
⎞
Trk (H )
(k − 1)n−1
⎝
ˆ
=
fi ⎠ tr(Ak(k−1) ).
k
k ((k − 1)!)k e∈H i∈e
d

In fact, we can say substantially more. For a fixed edge e ∈ H, there is only one term of the operator i∈e fˆi that has survivors: the one that arises from multiplying the derivatives whose variables
correspond to the edge e in each fˆi . That is,
⎛
⎞
⎛
⎞
⎜
∂ ⎟
⎟
⎝ fˆi ⎠ tr(Ak(k−1) ) = ⎜
⎜
⎟ tr(Ak(k−1) ).
⎝
⎠
∂
A
i
,
j
i∈e
i,j∈e
i =j

Evidently, this quantity is a constant which only depends on the rows and columns of A that are indexed
by the elements of e, and does not depend upon the particular edge under consideration. So if we let
¯ be the k × k matrix with new variable entries A¯ ij reindexed by their rows and columns, and denote
A
the desired constant by C, we have that
⎛
⎞
C

⎜
⎜
⎝

=⎜

i,j k
i =j

∂ ⎟
⎟
¯ k(k−1) ).
⎟ tr(A
∂ A¯ i,j ⎠

Thus, we can write
Trk (H )
k

=

(k − 1)n−1
C |E (H )|,
k ((k − 1)!)k

and it only remains to determine the value of C.
Recall the form of the trace,

¯ k(k−1) )
tr(A

k

=

i1 ,i2 ,...,ik(k−1) =1

¯ i1 ,i2 A¯ i2 ,i3
A

. . . A¯ ik(k−1)−1 ,ik(k−1) A¯ ik(k−1) ,i1 ,

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3281

and observe that a term of this sum survives the differentiation operator only when it consists of a
¯ . Also note that such a term reduces to 1 if it
permutation of the k(k − 1) non-diagonal elements of A
¯.
survives. Hence C is the number of trace terms that are orderings of the non-diagonal elements of A
To count the number of such terms, consider Dk , the complete labeled directed graph on k vertices.
¯ ij . Then the terms of tr(A¯ k(k−1) ) that we are trying to count are in
Let the edge (i, j) be labeled by A
bijection with Eulerian cycles in Dk where one edge (the first) is distinguished. Hence each Eulerian
cycle in Dk corresponds to exactly k(k − 1) surviving trace terms, by choosing which edge to start from.
Thus C = k(k − 1)(# of Eulerian cycles in Dk ).
Counting Eulerian cycles in a directed graph can be done using so-called “BEST Theorem” [28,1],
which says that the number of such cycles in a directed graph D is given by
tw (G)

v∈D

(deg− (v) − 1)!,

where deg− (v) is the indegree of vertex v (which must equal the outdegree for D to be Eulerian), and

tw (G) is the number of arborescences of D rooted at w. (An arborescence of D at w is a spanning tree
rooted at w, with all edges pointing away from w.) Remarkably, tw (G) does not depend on the choice
of vertex w.
In our case, note that since Dk is complete, every possible (undirected) spanning tree can be realized
as a subgraph, and the requirement that the edges point away from w gives exactly one possible way
of orienting the edges for each such tree. Hence the number of arborescences of Dk is precisely the
number of labeled trees on k vertices, which Cayley’s Formula says is kk−2 [8,25].
Hence we see that
C

= k(k − 1)kk−2 (k − 2)!k ,

so that
Trk (H )
k

(k − 1)n−1
C |E (H )|
k ((k − 1)!)k
(k − 1)n−1
=
k(k − 1)kk−2 (k − 2)!k |E (H )|
k ((k − 1)!)k
= kk−2 (k − 1)n−k |E (H )|,
=

completing the proof.
We can follow a similar procedure (with a less general calculation of the constant) to determine
the next coefficient. Before doing so, we introduce a generalization of the triangle graph, a hypergraph
which appears as the subgraph counted by the codegree k + 1 coefficient.
Definition 3.4. A simplex in a hypergraph is a set of k + 1 vertices where every set of k vertices forms
an edge.
In a graph, the simplex is a triangle. In a 3-uniform hypergraph, the simplex is 4 vertices, each set
of three forming an edge. This hypergraph can be visualized as a tetrahedron in R3 , where the facets
of the tetrahedron are edges of the hypergraph.
Lemma 3.16. The simplex is the only k-uniform k-valent multihypergraph with k + 1 edges.
Proof. Suppose H is a k-uniform k-valent multihypergraph with k + 1 edges. It is clear that H must
have at least k + 1 vertices. Count pairs of the form (vertex, edge) where the vertex lies on the edge.
Since there are k + 1 edges, each containing exactly k vertices, we count k(k + 1) pairs. On the other
hand, if there were more than k + 1 vertices in such a hypergraph, k-valency would imply that there
were strictly more than k(k + 1) such pairs. Hence H has exactly k + 1 vertices.

3282

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Since each edge has k vertices, we can label each edge by the vertex it does not contain. Each
vertex must be used in exactly k edges by k-valency. Hence for each vertex there is a unique edge not
containing that vertex. Every possible k-set of vertices forms an edge, and H is a simplex.

Theorem 3.17. The codegree k + 1 coefficient of the characteristic polynomial of a k-graph H is −C (k −
1)n−k (# of simplices in H ), where C is a constant depending only on k.
Proof. The codegree k + 1 coefficient is
Pk+1

−

Tr1 (H )
1

,−

Tr2 (H )
2

,...,−

Trk+1 (H )

.

k+1

By Corollary 3.14, only the last two parameter values are non-zero. Recalling that monomials in
Pk+1 have indices that sum (with multiplicity) to k + 1, it is easy to see that the only term remaining
in this expression is −
Trk+1 (H )
k+1

Trk+1 (H )
.
k+1

(k − 1)n−1
=
k+1

Applying the definition of this trace,
⎛
⎝
d1 +d2 +...+dn =k+1

Next we show that only terms with each di
showing that any term of D

=

n
ˆdi
i=1 fi

⎞

fˆi

di

n
i=1

((k − 1)di )!

⎠ tr(A(k−1)(k+1) ).

1 can possibly contribute to the sum, again by

that uses some fˆi at least twice can yield no surviving terms.

If fˆi is used twice, then i is used as the first index of a differentiation variable Aij at least 2(k

− 1)

times. Therefore, in order for monomials in tr(A(k−1)(k+1) ) to survive fˆi , i must be used at least 2(k − 1)
times as a second index. Note that i cannot be used as a second index of differentiation in fˆi , since i
and the second indices of differentiation of any term must form an edge of our hypergraph to have a
non-zero coefficient in fˆi . As there are only k − 1 other factors fˆj , some fˆj must use i as a secondary index
at least twice in a single monomial coefficient. However, as noted above, j and the secondary indices
must form an edge to have a nonzero coefficient in fˆj , so i cannot be used twice. Thus we see that any

operator using some fˆi more than once has no survivors, and the only operators that contribute are
those where each exponent is one or zero. That is,
Trk+1 (H )
k+1

=

k+1

(k − 1)(n−1)
(k + 1) [(k − 1)!](k+1)

i1 <i2 <···<ik+1 j=1

fˆij tr(A(k−1)(k+1) ).

Fix vertices i1 , i2 , . . . , ik+1 . By Lemma 3.16, the simplex is the only k-valent (k + 1)-edge k-graph,
k+1

so the only survivors of j=1 fˆij when applied to tr(A(k+1)(k−1) ) arise from a simplex on vertices
i1 , i2 , . . . , ik+1 . Hence, if we let S be the family of all vertex sets of simplices of H,
Trk+1 (H )
k+1

=

(k − 1)(n−1)
(k + 1) [(k − 1)!](k+1)

s∈S v∈s

fˆv tr(A(k−1)(k+1) ).

ˆ

(k−1)(k+1) ) only depends on the rows and columns appearing in s, and so is
independent of the choice of vertices and size of A. Thus v∈s fˆv tr(A(k−1)(k+1) ) = C is a constant

Note that

v∈s fv tr(A

depending on k. So we see that
Trk+1 (H )
k+1

=

(k − 1)(n−1)
(k + 1) [(k − 1)!](k+1)

C

· (# of simplices in H ).

Gathering all of our constants, we find that the codegree k
polynomial of H is

+ 1 coefficient of the characteristic

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3283

−C (k − 1)n−k (# of simplices in H ),
as desired.
Clearly absent from the proof above is the determination of the constants C = Ck . For graphs, it is
well known [4] that the codegree 3 coefficient is −2(# of triangles in G), i.e., C2 = 2.
For k > 2, this constant can be found by computing the codegree k + 1 coefficient of the characteristic polynomial for the simplex, 2 and solving for C in Theorem 3.17. By carrying out such a calculation,
we can show that

=2
= 21
C4 = 588
C5 = 28230.
C2
C3

One can, in principle, perform similar calculations for any fixed uniformity k and fixed codegree d
to determine which k-valent multi-subgraphs on d edges are being counted, and in what multiplicity.
In practice, the calculations become unwieldy for even modest values of uniformity and codegree.
Instead, we hope that a characterization akin to that of the graph case, where the coefficients count
“sesquivalent” subgraphs with coefficients based on their rank [4], can be found for k-graphs. Such a
characterization will almost surely depend on a much better understanding of the symmetric hyperdeterminant.

4. Spectra of special hypergraphs
4.1. General k-partite hypergraphs
A k-graph H is called k-partite, or a k-cylinder, if the vertices of H can be partitioned into k sets
so that every edge uses exactly one vertex from each set. The best known case is that of a 2-cylinder,
a.k.a. a bipartite graph. There are several proofs of the following characterization of bipartite graphs
(q.v. [4,15]).
Theorem 4.1. A graph G is bipartite if and only if its multiset spectrum is symmetric about the origin.
This theorem can be restated as saying that a graph is bipartite if and only if its (multiset) spectrum
is invariant under the action of multiplication by any second root of unity. We generalize this to kcylinders.
Theorem 4.2. The (multiset) spectrum of a k-cylinder is invariant under multiplication by any kth root of
unity.
Of course, this is only one direction of the theorem from the graph case. Unfortunately, the converse
is true not for k > 2. Let H be the unique 3-uniform hypergraph on four vertices with three edges, i.e.,
a tetrahedron with one face removed. It is easy to see that H is not tripartite, but a calculation of the
characteristic polynomial reveals

φH (λ) =λ11 (λ3 − 12)(λ3 − 1 + 2i)3 (λ3 − 1 − 2i)3 ,
whose roots are symmetric under multiplication by any third root of unity.
It is worth mentioning that if one weakens this statement of the theorem to concern the spectrum
as a set instead of a multiset, it be can proved easily using analytic methods.
2

See Section 6 for a more detailed description of this and other computations we employ.

3284

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Proof. Let H be a k-cylinder, and φH (λ) be its characteristic polynomial. We note that φH (λ) (or more
generally, any univariate monic polynomial) has its multiset of roots invariant under multiplication by
0. This
any kth root of unity if and only if φH (λ) = λr f (λk ) for some polynomial f and integer r
condition is equivalent to having every non-zero coefficient of φH (λ) being a term with codegree 0
(mod k).
Suppose that there is a non-zero coefficient for a monomial of φH (λ) with codegree i. Then there
exists a multi-subgraph H of H with |E (H )| = i. By Theorem 3.12, the monomial describing H is also
k-valent. Hence every vertex is used 0 (mod k) times. As H is a k-cylinder, we can count the edges in
H by counting the vertices used in any single partition class. Since each vertex of H is used 0 (mod k)
times, the number of vertices of H in any partition class is also 0 (mod k). Hence i = |E (H )| ≡ 0
(mod k).
4.2. One edge hypergraphs
Finding the (set) spectrum of a single edge is simple. Determining the multiplicities of the eigenvalues is a bit more difficult. Nonetheless, with the help of Theorems 3.15 and 4.2, we can calculate
the characteristic polynomial of a single edge hypergraph for any uniformity.
Theorem 4.3. If H is the k-graph with k vertices and a single edge,
k−1

φH (λ) = λk(k−1)

−kk−1

(λk − 1)k

k−2

.

Proof. Suppose λ = 0 is an eigenvalue of H. Let x be a corresponding eigenvector. If x has a zero entry,
then the eigenvalue equation (2) for a non-zero entry xi gives

λxik−1 =

xj

This contradicts λ
we see
k

λk

i=1

k−1

xi

= 0.

j =i

= 0, so we see x has no zero entries. Multiplying all k of the eigenvalue equations,
k

=

k

xj
i=1 j =i

=

i=1

k−1

xi

.

Hence we see that λk = 1 for any non-zero eigenvalue λ.
H is k-partite, so Theorem 4.2 implies that

φH (λ) = λa (λk − 1)b .

(6)

Since the characteristic polynomial has degree k(k − 1)k−1 , we also have that a + kb = k(k − 1)k−1 .
The codegree k coefficient in (6) is −b, while Theorem 3.15 implies that the codegree k coefficient is
−kk−2 . The formula for φH (λ) follows.
4.3. Cartesian products
Given two hypergraphs G and H, the Cartesian product of G and H is the hypergraph G H with
V (G H ) = V (G) × V (H ) and
E (G H )

= {{v} × e : v ∈ V (G), e ∈ E (H )} ∪ {e × {v} : e ∈ E (G), v ∈ V (H )}.

The following is a natural hypergraph analog of a standard result from Spectral Graph Theory.
Theorem 4.4. If G and H are k-graphs, and λ and μ are eigenvalues for G and H, respectively, then λ + μ
is an eigenvalue for G H .

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3285

Proof. Let G and H be k-graphs on n and m vertices, respectively. Let (λ, u) be an eigenpair for G, and
let (μ, v ) be an eigenpair for H.
Define w ∈ Cnm to be a vector with entries indexed by pairs (a, b) ∈ [n]×[m] so that w(a,b) = ua vb .
We claim that w is an eigenvector of G H with eigenvalue λ + μ. To verify this, we simply check the
eigenvalue equation (2) for an arbitrary vertex (a, b) in G H.
we

w{a}×e

=

e∈(G H )(a,b)

=

{a}×e∈(G H )(a,b)
with e∈H (b)
k−1 e
e∈H (b)

= uka−1
=
=

ua

e∈H (b)

we×{b}

+

e×{b}∈(G H )(a,b)
with e∈G(a)
k−1

v

+

ve

+ vbk−1

e∈G(a)

ue vb

ue
e∈G(a)

k−1
k−1
uka−1 μvb + vb λuka−1
k−1
(λ + μ)w(a,b) .

Since the vertex chosen was arbitrary, each eigenvalue equation holds, so that (λ+μ, w ) is an eigenpair
for G H .
Theorem 4.4 implies that
spec(G H )
Since |spec(G)|
of

⊇ spec(G) + spec(H ).
n−1

= n(k − 1)

nm(k − 1)n+m−2

(7)

and |spec(H )|

nm(k − 1)nm−1

m−1

= m(k − 1)

(as multisets) the multiset-sum consists

= |spec(G H )|

eigenvalues. Equality in the above only occurs when k = 2, so the theorem leaves open the possibility
that there exist more eigenvalues of a Cartesian product than just those arising from sums of eigenvalues from the factor hypergraphs. Unfortunately, the reverse inclusion of (7) is indeed false for k > 2,
as shown in the next section.
4.4. The ultracube
An important and much-studied sequence of graphs are the hypercubes Q d , i.e., the iterated Cartesian product of a single edge with itself. We extend this definition to higher uniformity, and make
some progress in describing its spectrum.
Definition 4.1. Let Ek be the single-edge k-graph. The d-dimension k-uniform ultracube is defined by
Qkd = Ek d .
As an example of Theorem 4.4, first recall that (as a set) spec(E3 )
primitive third root of unity in C. Then Theorem 4.4 yields

= {0, 1, ζ3 , ζ32 }, where ζ3 is a

{−1, 0, 1, 2, ζ3 , 2ζ3 , ζ32 , 2ζ32 , −ζ3 , −ζ32 } ⊆ spec(Q32 ).
On the other hand, a computation of the characteristic polynomial gives that

φQ32 (λ) = (λ3 − 1)18 (λ3 − 2)27 (λ3 + 1)54 λ549 (λ3 − 2)486 .
√
√
√
3
3
3
This reveals three additional eigenvalues { 2, 2ζ3 , 2ζ32 } for Q32 , which shows that the set inclusion

in Theorem 4.4 (i.e., (7)) cannot be turned into an equality. Call the eigenvalues of a cartesian product
that are not given by Theorem 4.4 sporadic eigenvalues of the hypergraph.

3286

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

An eigenvector for the real eigenvalue in this sporadic set of eigenvalues for Q32 is illuminating, so
we describe it explicitly. Let the vertices of Q32 be indexed by pairs (i, j) with i, j ∈ [3]. It is easy to
verify that the vector given by

√
3

x(1,1)

=

2,

x(1,2)

= x(1,3) = x(2,1) = x(3,1) = 1,

x(2,2)

= x(2,3) = x(3,2) = x(3,2) = 0

√
3

is an eigenvector for Q32 corresponding to the eigenvalue 2.
The existence of the other two sporadic eigenvalues can be deduced by the following (simple)
fact.
Lemma 4.5. If G and H are both k-partite k-graphs, then so is G H.
Proof. Let c1 : G → Zk and c2 : H → Zk induce vertex partitions of G and H, respectively. Define
a coloring c : G H → Zk by c ((v, w)) = c1 (v) + c2 (w); it is a simple matter to check that this is a
proper k-partition.
Since E3 is trivially tripartite, the lemma gives that Q32 is tripartite as well. Thus Theorem 4.2 gives
us the other two sporadic eigenvalues.
√
3
The reason that the eigenvector described above for the sporadic eigenvalue 2 of Q32 is interesting
d
is that it can be generalized to give sporadic eigenvalues of Qk for any k > 2 and d > 1. Let the vertices
of Qkd be labeled by (i1 , i2 , . . . , id ) where ij ∈ [k]. Define a vector by
⎧√
k
⎪
d if i1 = i2 = · · · = id = 1
⎪
⎪
⎨
x(i1 ,i2 ,...,id ) = 1
if exactly one ij = 1
⎪
⎪
⎪
⎩
0
otherwise.

√
k

It is again easy to verify that this vector is an eigenvector for λ = d. Hence we obtain a recursive
way to produce eigenvalues of Qkd that gives more eigenvalues than simply applying Theorem 4.4.

= {0} ∪ {ζk }kj=−01 . Then
√
√
√
k
k
d−1
k−1 k
spec(Qkd ) ⊇ (spec(Qk ) + S ) ∪ { d, ζk d, . . . , ζk
d}.
j

Theorem 4.6. Let ζk be a primitive kth root of unity, and define S

d−1

Proof. The first set in the union comes from the facts that Qkd = Qk
Ek and S
Theorem 4.3. The second set are those described in the preceding paragraph.

= spec(Ek ) by

4.5. Complete k-cylinders
In this section, we provide a description of the spectrum of the complete k-cylinder for any uniformity k and any partition sizes.
Let H be a k-cylinder with A1 , . . . , Ak as its partition sets, so that for any choice of v1 ∈ A1 , v2 ∈
A2 , . . . , vk ∈ Ak , we have {v1 , v2 , . . . , vk } ∈ E (H ). We call H a complete k-cylinder.
The eigenvalue equations λx [k−1] = AH x k−1 for such a hypergraph have a particularly simple
form. For each vertex v ∈ Ai , the corresponding equation is
⎛
⎞

λxvk−1 =

⎝
j∈[k]
j =i

w∈Aj

xw ⎠ .

(8)

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3287

Theorem 4.7. Let H be a complete k-cylinder with parts A1 , . . . , Ak , and let ζk−1 be a primitive (k − 1)st
root of unity. Then λ = 0 is an eigenvalue of H if and only if
k

λk =

⎛

⎞k−1

⎝
v∈Ai

i=1

ζk−v 1 ⎠

for some choice of integers

v

(9)

∈ {0, . . . , k − 2} for each v ∈ V (H ).

Proof. To show sufficiency, note that by Theorem 4.2, it suffices to prove that one of the k roots of the
above equation is an eigenvalue. Specifically, for i
fix one of the k values of

1/k
mi .

Then λ
−1/k

=

k
i=1

∈ [k] let mi =

(k−1)/k

mi

v∈Ai

ζk−v 1 , and for each such i, we

is one of the solutions to (9).

. We verify that the vector defined thusly is an eigenvector for λ
For v ∈ Ai , we let xv = ζk−1 mi
by checking the eigenvalue equations (8):
⎛
⎞
⎛
⎞
⎛
⎞
v

⎝
w∈Aj

j∈[k]
j =i

xw ⎠ =

−1/k ⎠

⎝
w∈Aj

j∈[k]
j =i

ζk−w 1 mj

⎛

=

(k−1)/k

j∈[k]
j =i

⎛

=⎝

mj

⎞

k
j=1

=⎝

(k−1)/k ⎠

mj

−1/k ⎝

=
j∈[k]
j =i

k
j=1

mj

w∈Aj

ζk−w 1 ⎠

⎞
(k−1)/k ⎠

mj

−1/k k−1

ζk−v 1 mi

(−k+1)/k

mi

= λxvk−1 .

To establish necessity, let (λ, x ) be an eigenpair for H with λ = 0. Note that for any two vertices in
the same class Ai , the defining eigenvalue equation is the same. Hence we see that xv = ζk−1 xw for
< k − 1 whenever w, v are vertices in the same class. In particular, if x has any zero
some 0
coordinate, it is zero on some entire class Ar . Then v∈Ar xv = 0. An eigenvector has to have some
non-zero coordinate, say xv , whose vertex must then lie in some class As with s = r. If we look at the
defining eigenvalue equation for xv , we see that
⎛
⎞

λxvk−1 =

⎝
j∈[k]
j =s

xw ⎠
w∈Aj

= 0.

Since xvk−1 is non-zero, we conclude that λ = 0, a contradiction. Hence any eigenvector for a non-zero
eigenvalue of H must have all non-zero entries.
As x has full support, we can assume without loss of generality that x1 ∈ A1 with x1 = 1. Let
a1 = 1, and for each partition class Ai , i = 1, choose a vector entry xvi with vi ∈ Ai , and define

= xvi . Then for each entry xv with v ∈ Ai , we have a unique representation xv = ai ζk−v 1 where
v
0
v < k − 1. Now if we let mi =
v∈Ai ζk−1 , we have

ai

xv
v∈Ai

= ai m i .

Note that if mi = 0, our eigenvalue equations would give that any class other than Ai has all corresponding entries in x equal to zero, which contradicts x having full support. Hence mi = 0. From the
eigenvalue equation for x1 , we have

3288

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292
k

λ=

i=2

ai m i .

(10)

For a vertex in class Aj , the eigenvalue equation is

λakj −1 =

ai m i .

i =j

(11)

From (11), we see that
akj

=

aj m j

i =j

ai m i

mj λ

k
i=1 ai mi
mj ki=2 ai mi

=

=

m1
mj

.

If we raise both sides of (10) to the kth power, we find
k

λk =

k

i=2

aki mki

=

i=2

m1
mi

k

mki

=

k−1

i=1

mi

,

completing the proof.
It is worth noting that this argument provides a different proof from the “standard one” for the
spectrum of a complete bipartite graph, although it does lose any information concerning the multiplicities of eigenvalues. To be precise, if we let k = 2, |A1 | = m, |A2 | = n (with m + n > 2), then the
2
gives
only (k − 1)st root of unity is ζk−1 = 1, and so our theorem
√
√ that λ = mn. Therefore, the (set)
spectrum of the complete bipartite graph Km,n is {− mn, 0, mn}.
For k = 3 the theorem also gives a fairly succinct description of the spectrum of a complete tripartite
hypergraph.
Corollary 4.8. Let H be the complete 3-cylinder with partition sizes n1 , n2 , and n3 , and for i
Si = {ni − 2m | m ∈ N and m < ni /2}. Then
spec(H )

= {0} ∪ {ζ3 (s1 s2 s3 )2/3 | 0
j

j

∈ [3], let

< 3 and si ∈ Si }.

4.6. Complete k-graphs
The complete k-graph on n vertices is an obvious next candidate for which to compute the spectrum. We obtain a complete characterization of the (set) spectrum in the first unknown case k = 3.
Unfortunately, our methods do not lead to a complete characterization in cases of uniformity greater
than 3, but they do reveal an interesting connection to the elementary symmetric polynomials.
As in the case of complete k-cylinders, the eigenvalue equations for a complete k-graph have particularly simple form. For any vertex v, the eigenvalue equation is given by

λxvk−1 =

xe .

(12)

[n]\{v}
k−1

e∈(

)
1,

Note, however, that for any r
x

e

[n]\{v}

e∈(

r

)

=

x
e∈(

[n]
r

e

− xv

xe .
[n]\{v}

)

e∈( r −1

)

Applying this identity repeatedly to the eigenvalue equation above, we obtain

λxvk−1 =

xe
[n]

e∈(k−1)

− xv

xe
[n]

e∈(k−2)

+ xv2

xe
[n]

e∈(k−3)

− · · · + (−1)k−1 xvk−1 .

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

3289

e
) x is the sum over all square-free monomials of degree r in n variables, i.e., precisely
the degree r elementary symmetric polynomial in n variables. We denote this polynomial by Er (x )
(letting E0 ≡ 1) and use it to rewrite the eigenvalue equation more succinctly as

Notice that

[n]

e∈(

r

λxvk−1 = Ek−1 (x ) − xv Ek−2 (x ) + xv2 Ek−3 (x ) − · · · + (−1)k−1 xvk−1 .
Theorem 4.9. The complete 3-uniform hypergraph on n vertices has eigenvalues 0, 1,

(13)
n−1
2

, and at most

2n others, which can be found by substituting the roots of one of n/2 univariate quartic polynomials into
a particular quadratic polynomial. In principle, the roots can be obtained from an explicit list of O(n)
formulas.
By “explicit”, we mean that it is indeed possible to write down a list of O(n) expressions involving
O(1) algebraic operations that give the roots in terms of n and which are each O(log n) symbols long.
However, doing so yields absurdly long expressions that are neither useful nor enlightening, so we
omit them.

/ {0, 1} must have the property that x has
Proof. We first claim that any eigenpair (λ, x ) where λ ∈
full support. To see this, let x be an eigenvector without full support; we show λ2 = λ.
Eq. (13) applied to a vertex w so that xw = 0 yields E2 (x ) = 0. Summing Eq. (12) over all vertices
yields
n

λ
Since λ

v=1

= (n − 2)E2 (x ) = 0.

xe
[n]

e∈(

2)

= 0, the sum of the squares of the entries of x is zero. From this, it follows that
2

n
v=1

v

xv

n

=

xv

so that

= (n − 2)

xv2

v=1

xv2

+2

xe
e∈(

[n]
2

= 0,

)

= E1 (x ) = 0. Thus Eq. (13) reduces to

λxv2 = xv2
for each v, from which the claim follows, since there must be some v so that xv = 0.
/ {0, 1}, so that x has full support. Consider the polynomial
Now let (λ, x ) be an eigenpair with λ ∈
g ∈ C[y] given by g (y) = (1 − λ)y2 − yE1 (x ) + E2 (x ). Noting that every coordinate of x is root of
g, we see that x has at most two distinct entries. If all entries are the same, a quick calculation shows
that the corresponding eigenvalue is

n−1
2

. So, assume there are exactly two entries. By rescaling the

vector, we may assume without loss that at least half of the entries are 1, and we denote the other
entry by c. Let t
n/2 be the number of times c appears in x. Then there are only two eigenvalue
equations: one for the entry 1,

λ=

t
2

c2

+ t (n − t − 1)c +

n−t

−1

2

,

(14)

and another for the entry c,

λc 2 =

t

−1
2

c2

+ (t − 1)(n − t )c +

n−t
2

.

(15)

3290

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

Substituting the first into the second yields the quartic polynomial
P (c )

=

t
2

c4

+ t (n − t − 1)c 3 +

− (t − 1)(n − t )c −

n−t
2

n−t
2

−1

−

t

−1
2

c2

.

Then any non-trivial root c0 of P (c ) and the value λ0 obtained by substituting c0 for c in (14) yields
an eigenpair (λ0 , x0 ), where c0 appears t times in x0 and all other entries are 1. As t takes on at
most n/2 values, and each leads to at most 4 eigenvalues, there can be no more than 2n additional
eigenvalues.

5. Conclusion and open problems
Because Spectral Graph Theory has been such a rich font of interesting mathematics, the list of
natural “next” questions about hypergraph spectra is virtually endless. Here we outline a few of those
that we find particularly appealing.
(1) What is the spectrum of the complete k-graph for k > 3? What are the multiplicities for k = 3?
(2) What do the spectra of other natural hypergraph classes look like? For example, one might consider the generalized Erdos–Rényi
˝
random hypergraph, Steiner triple systems, Venn diagrams,
etc.
(3) Fully describe the eigenvalues of Cartesian products – in particular, explain the “sporadic” ones.
Ultracubes are a natural object of study in this vein.
(4) How does one compute the multiplicities of eigenvalues of hypergraphs in general? Is there a
“geometric multiplicity” analogous to the dimension of eigenspaces of matrices which provides
a lower bound for this “algebraic” multiplicity? Perhaps such an invariant can be defined via the
algebraic varieties given by the equations (AH − λI )x k−1 = 0, λ ∈ spec(H ), as in the case of
graphs.
(5) Characterize those hypergraphs whose spectra are invariant under multiplication by kth roots of
unity, i.e., find the appropriate weakening of the hypotheses of Theorem 4.2 to achieve necessity.
(6) How can one compute the spectrum of a hypergraph more efficiently? Our computational experiments have struggled with hypergraphs on as few as six vertices.
(7) How does spec(H ) relate to other hypergraph invariants, such as the domination number,
transversal number, etc.?
(8) Is it true that, for a sequence of k-graphs H on n → ∞ vertices, if the spectrum is “random-like”,
then H is quasirandom in the sense of [12] or [21]? Are “expansion properties” of hypergraphs
related to the size of the second-largest-modulus eigenvalue?

6. A note on computation
As noted in Section 2.1, the characteristic polynomial of a k-graph H is the resultant of the polynok−1
mials Fi = λxi
− e∈H (i) xe where i ∈ [n]. Hence computing the characteristic polynomial reduces
to computing the resultant. For this computation, we use the algorithm described in Chapter 3, Section
4 of [13]. We describe the algorithm here for completeness.

• Compute Res(F1 , F2 , . . . , Fn ) as follows:
Let d = n(k − 1)− n + 1, and let S be the set of all monomials of degree d in the variables x1 , . . . , xn .
(We denote such a monomial xα , where x stands for a variable vector, and α stands for an exponent
vector.) Let

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

S1

= {xα ∈ S | x1k−1 divides xα }

S2

= {xα ∈ S \ S1 | x2k−1 divides xα }

..
.
Sn

⎧
⎨

= xα ∈ S \
⎩

n−1
i=1

Si | xnk−1 divides xα

⎫
⎬
⎭

3291

.

This collection forms a partition of S (by an easy pigeon-hole principle argument). Fix an ordering
on S, and define the |S | × |S | matrix M as follows. The (α, β) entry of M is the coefficient of xβ in the
α
polynomial Fi (x) kx−1 , where i is the unique index such that xα ∈ Si . In particular, any non-zero (α, β)
xi

entry is one of the coefficients of Fi , where i has xα ∈ Si .
k−1
Call a monomial xα ∈ S reduced if there is exactly one i so that xi
divides xα . Form the matrix
M by deleting the rows and columns of M that correspond to reduced monomials. The resultant of
the system is then det(M )/ det(M ), provided that the denominator does not vanish. In our case, each
determinant is actually a characteristic polynomial, so this is never an issue.
Notice that for uniformity k, we have |S |

=

n(k−1)+1
n

. For k

√
= 3, |S| ≈ 4n / n. So the matrix

M has approximately 16n /n entries. We need the characteristic polynomial of this matrix, a computation which is not obviously parallelizable. Hence the space and time demands of computing the
characteristic polynomial of a hypermatrix are high, even for hypergraphs with a small number of
vertices.
We implemented this algorithm using the free and open-source mathematics software system Sage,
and used it for calculating characteristic polynomials, and then by finding the roots, calculating the
spectrum. The implementation we used, including some of the other routines we wrote to produce the
hypermatrices and convert them to and from polynomials, are available at http://www.math.sc.
edu/˜cooper/resultants.html. Running on fairly modest systems (8 core AMD with 8 gigabytes
of RAM), we were unable to compute characteristic polynomials for some 3-graphs on only 9 vertices.
The results we did obtain, including CPU times, are available on the same website.
Acknowledgements
Thank you to Duncan Buell, Fan Chung, David Cox, Andy Kustin and the anonymous referee for
valuable comments and suggestions.
References
[1] T. van Aardenne-Ehrenfest, N.G. de Bruijn, Circuits and trees in oriented linear graphs, Simon Stevin 28 (1951) 203–217.
[2] N. Alon, J.H. Spencer, The Probabilistic Method, third ed., Wiley–Interscience Series in Discrete Mathematics and Optimization,
Wiley–Interscience (John Wiley & Sons), New York, 2008., pp. 67–82.
[3] C. Berge, Hypergraphs, North-Holland Mathematical Library 45, North-Holland, Amsterdam, 1989.
[4] N.L. Biggs, Algebraic Graph Theory, second ed., Cambridge University Press, Cambridge, 1993.
[5] R.L. Brooks, On colouring the nodes of a network, Proc. Camb. Philos. Soc. 37 (1941) 194–197.
[6] S.R. Buló, M. Pelillo, A generalization of the Motzkin–Straus theorem to hypergraphs, Optim. Lett. 3 (2009) 187–295.
[7] S.R. Buló, M. Pelillo, New bounds on the clique number of graphs based on spectral hypergraph theory, in: T. Stützle (Ed.),
Learning and Intelligent Optimization, Springer-Verlag, Berlin, 2009, pp. 45–48.
[8] A. Cayley, A theorem on trees, Q. J. Math. 23 (1889) 376–378.
[9] K.C. Chang, K. Pearson, T. Zhang, Perron–Frobenius theorem for nonnegative tensors, Commun. Math. Sci. 6 (2008) 507–520.
[10] F.R.K. Chung, The Laplacian of a Hypergraph, Expanding Graphs, DIMACS Ser. Disc. Math. Theoret. Comput. Sci. 10, Am. Math.
Soc., Providence, RI, 1993, pp. 21–36.
[11] F.R.K. Chung, Spectral Graph Theory, Regional Conference Series in Mathematics 92, Am. Math. Soc., 1997.
[12] D. Conlon, H. Han, Y. Person, M. Schacht, Weak Quasi-Randomness for Uniform Hypergraphs, preprint, 2011.
[13] D. Cox, J. Little, D. O’Shea, Using Algebraic Geometry, Springer-Verlag, New York, 1998.
[14] D.M. Cvetkovic,
´ M. Doob, I. Gutman, A. Torga¨sev, Recent Results in the Theory of Graph Spectra, North Holland, Amsterdam,
1988.
[15] D.M. Cvetkovic,
´ M. Doob, H. Sachs, Spectra of Graphs, Theory and Application, Academic Press, 1980.
[16] K. Feng, W. Li, Spectra of hypergraphs and applications, J. Number Theory 60 (1) (1996) 1–22.

3292

J. Cooper, A. Dutle / Linear Algebra and its Applications 436 (2012) 3268–3292

[17] S. Friedland, S. Gaubert, L. Han, Perron–Frobenius theorem for nonnegative multilinear forms and extensions, Linear Algebra
Appl., in press, doi:10.1016/j.laa.2011.02.042.
[18] J. Friedman, A. Wigderson, On the second eigenvalue of hypergraphs, Combinatorica 15 (1) (1995) 43–65.
[19] I. Gelfand, M. Kapranov, A. Zelevinsky, Discriminants, Resultants and Multidimensional Determinants, Birkhäuser, Boston, 1994.
[20] S. Hu, L. Qi, Algebraic connectivity of an even uniform hypergraph, J. Comb. Optim., in press, doi:10.1007/s10878-011-9407-1.
[21] Y. Kohayakawa, V. Rödl, J. Skokan, Hypergraphs, quasi-randomness, and conditions for regularity, J. Comb. Theory A 97 (2) (2002)
307–352.
[22] L.-H. Lim, Singular values and eigenvalues of tensors: a variational approach, in: Proceedings of the IEEE International Workshop
on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP ’05), vol. 1, 2005, pp. 129–132.
[23] L. Lu, X. Peng, High-ordered random walks and generalized Laplacians on hypergraphs, in: Proceedings of Algorithms and Models
for the Web-Graph: Eighth International Workshop, WAW 2011, Atlanta, GA, USA, May 27–29, 2011.
[24] A. Morozov, Sh. Shakirov, Analogue of the Identity Log Det = Trace Log for Resultants, arXiv:0804.4632v3 [math.PH], 2008.
[25] H. Prüfer, Neuer Beweis eines Satzes über Permutationen, Arch. Math. Phys. 27 (1918) 742–744.
[26] L. Qi, Eigenvalues of a real supersymmetric tensor, J. Symb. Comput. 40 (2005) 1302–1324.
[27] J.A. Rodríguez, Laplacian eigenvalues and partition problems in hypergraphs, Appl. Math. Lett. 22 (6) (2009) 916–921.
[28] C.A.B. Smith, W.T. Tutte, On unicursal paths in a network of degree 4, Am. Math. Mon. 48 (1941) 233–237.
[29] H.S. Wilf, The eigenvalues of a graph and its chromatic number, J. Lond. Math. Soc. 42 (1967) 330–332.

