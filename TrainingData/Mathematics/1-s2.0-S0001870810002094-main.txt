Advances in Mathematics 225 (2010) 2828–2839
www.elsevier.com/locate/aim

Algebraic methods in discrete analogs of the Kakeya
problem
Larry Guth a , Nets Hawk Katz b,∗
a Department of Mathematics, University of Toronto, Canada
b Department of Mathematics, Indiana University, Bloomington, United States

Received 9 December 2008; accepted 12 May 2010
Available online 11 June 2010
Communicated by Charles Fefferman

Abstract
3

We prove the joints conjecture, showing that for any N lines in R3 , there are at most O(N 2 ) points at
which 3 lines intersect non-coplanarly. We also prove a conjecture of Bourgain showing that given N 2 lines
in R3 so that no N lines lie in the same plane and so that each line intersects a set P of points in at least N
points then the cardinality of the set of points is Ω(N 3 ). Both our proofs are adaptations of Dvir’s argument
for the finite field Kakeya problem.
© 2010 Published by Elsevier Inc.
Keywords: Kakeya problem; Joints; Incidence problem; Bezout’s theorem; Dvir argument

1. Introduction
Various authors have considered the joints problem. It asks, given N lines in space, how many
“joints” can the lines form, where a joint is defined as a point where three lines with linearly
independent directions intersect. Obviously given a

N
3

×

N
3

×

N
3

cube in the integer lattice,

3
2

we get N lines with N√ joints by simply taking all lines in coordinate directions which intersect
3 3
the cube and the lattice. The joints problem is to prove:
* Corresponding author.

E-mail addresses: lguth@math.toronto.edu (L. Guth), nhkatz@indiana.edu (N.H. Katz).
0001-8708/$ – see front matter © 2010 Published by Elsevier Inc.
doi:10.1016/j.aim.2010.05.015

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2829

3

Theorem 1.1. Any set of N lines in R3 form at most O(N 2 ) joints.
The previous best bound in the joints problem is due to Feldman and Sharir [6], who proved
that the number of joints is O(N 1.6232 ). Earlier bounds were reported in [11,10,2]. Bennett,
Carbery, and Tao obtained a result conditioned on the angles at the joints in [1].
At AIM in 2004, Bourgain conjectured the following:
Theorem 1.2. Let L be a set of N 2 lines in R3 and let P be a set of points in R3 . Suppose no
more than N lines of L lie in the same plane and suppose the each line of L contains at least N
points of P . Then |P | = Ω(N 3 ).
The previous best bound in Bourgain’s incidence problem is due to Solymosi and Tóth [12],
who proved that the number of points is Ω(N 11/4 ).
What both conjectures have in common is that they are discrete models of the Kakeya problem. Work of Sharir on joints helped inspire Schlag’s program on Kakeya, see [9]. Bourgain’s
conjecture was posed with the analogy to Kakeya in mind.
In 2008, Dvir [5] solved the finite field version of the Kakeya problem. His technique was to
study the properties of a polynomial which vanishes on the Kakeya set. We adapt this technique,
proving the above theorems through a study of a polynomial which vanishes on the point sets in
question.
The main idea of both proofs is as follows. We find a polynomial of as low degree as possible which vanishes on the set of joints (resp. points) in question. We factorize the polynomial
to irreducibles and find an irreducible factor vanishing on many joints (points). That irreducible
factor will also vanish on many lines. In the event that the gradient, too, vanishes on many lines,
a variant of Bezout’s theorem leads to a contradiction by reducing our irreducible. Otherwise at
each point where such lines intersect, all the lines lie in the tangent plane. In the joints problem
this leads to an immediate contradiction, since intersections must be non-coplanar. In the Bourgain problem, this leads to many flat points of the zero set of the irreducible, which force that
zero set to be a plane. This contradicts the hypothesis of fewer than N lines in a plane. The idea
of planiness, that in Kakeya problems, lines at a given point of intersection lie mainly in a plane,
seems first to have arisen in the work of the second author with Laba and Tao [8]. The idea that
this plane is the tangent space to a polynomial vanishing on the set comes from the work of the
first author on the endpoint multilinear Kakeya problem [7].
We have tried to minimize the amount of algebra background needed for the paper. The small
amount of algebra we use is summarized in the next section with references. The main ingredient
is Bezout’s theorem. In order to minimize the algebra, we focus on irreducible polynomials, and
we use pigeonhole estimates to locate an irreducible polynomial that vanishes on many joints or
points. It is also possible to give a proof using reducible polynomials. Such a proof would need
less pigeonhole estimates, but it would require more algebra.
2. Algebraic preliminaries
In this section, we bring together various algebraic facts that we shall need. Good references
are the books of Cox, Little, and O’Shea [3,4].

2830

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

We recall a fundamental object, the resultant of two polynomials. Given f and g elements of
C[x] having degree l and m respectively, and given as
f (x) = al x l + al−1 x l−1 + · · · + a0
and
g(x) = bm x m + bm−1 x m−1 + · · · + b0 ,
we define the resultant of f and g, namely Res(f, g) as the determinant of the l + m × l + m
matrix whose coefficients cij satisfy cij = aj −i if 1 i m and i j i + l, satisfy cij =
bj −i+m if m + 1 i m + l and i − m j i − m + l and are equal to zero otherwise.
The columns of the matrix cij represent coefficients of the polynomial f multiplied by x j
where j runs from 0 to m − 1 and the coefficients of the polynomial g multiplied by x k where k
runs from 0 to l − 1. The resultant tests whether this set of polynomials is linearly independent.
Linear independence fails exactly when f and g have a common factor. (The resultant was
first defined in this way by Sylvester.) We bring together some basic properties of the resultant
following [4].
Now suppose instead that we work with polynomials f, g ∈ C[x1 , . . . , xn ]. We may view
them as polynomials in x1 with coefficients that are polynomials in x2 , . . . , xn . Then we denote
the resultant, a polynomial in x2 , . . . , xn as Res(f, g; x1 ). In fact, computing resultants is all we
need to do in order to determine whether polynomials in several variables have a common factor.
Theorem 2.1. Let f, g ∈ C[x1 , . . . , xn ] and suppose that both f and g have positive degree when
viewed as polynomials in x1 then f and g have a common factor if and only if Res(f, g; x1 ) is
identically zero.
Theorem 2.1 is §3.6 Proposition 1(ii) in [4].
Proposition 2.2. Let f and g be elements of C[x1 , x2 ] and suppose that f and g have degrees
l and m respectively. Furthermore, assume that f has degree l in x1 and g has degree m in x1 .
Then Res(f, g; x1 ) is a polynomial of x2 of degree at most lm.
Proof. Given two polynomials of one variable,
f (x) = (x − r1 )(x − r2 ) · · · (x − rl )
and
g(x) = (x − s1 )(x − s2 ) · · · (x − sm ),
we have that
l

m

rj − sk .

Res(f, g) =
j =1 k=1

The coefficient ai of f is a symmetric polynomial in the roots of f which is homogeneous of
degree l − i. Similarly, bi is a homogeneous polynomial of degree m − i in the roots of g. We

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2831

therefore assign the variable ai a degree l − i and the variable bi the degree m − i. With respect to
these degrees, the resultant Res(f, g) is a homogeneous polynomial of degree lm. On the other
hand, the coefficient ai is a polynomial in x2 of degree at most l − i and the coefficient bi is
a polynomial in x2 of degree at most m − i. Therefore, Res(f, g; x1 ) is a polynomial of x2 of
degree at most lm. ✷
Proposition 2.2 is the main point in the proof of the celebrated Bezout’s theorem.
Corollary 2.3 (Bezout’s theorem). Let f and g be elements of C[x1 , x2 ] and suppose that f
and g have positive degrees l and m respectively. Suppose there are more than lm points of C2
where f and g both vanish. Then f and g have a common factor.
Proof. We begin by changing coordinates. We may choose x1 and x2 so that f has degree l
in x1 and g has degree m in x1 . We may also guarantee that there are more than lm distinct
values of x2 among the points where f and g both vanish. A generic choice of coordinates
accomplishes these goals. By Proposition 2.2, we see that Res(f, g; x1 ) is a polynomial of x2
with degree at most lm. Since it vanishes at more than lm points, it must vanish identically. An
application of Theorem 2.1 completes the proof. ✷
We shall need a small generalization of Corollary 2.3 that works in C3 when two polynomials
vanish simultaneously on many lines.
Corollary 2.4. Let f and g be elements of C[x1 , x2 , x3 ] and suppose that f and g have positive
degrees l and m respectively. Suppose there are more than lm lines on which f and g simultaneously vanish identically. Then f and g have a common factor.
Proof. Without loss of generality, we may choose x1 so that f and g have positive degree in x1
and x3 so that the x3 = 0 plane is transverse to at least lm + 1 of the lines of vanishing. Then
fixing x3 and apply Bezout’s theorem and Theorem 2.1, we get that Res(f, g; x1 ) vanishes identically as a function of x2 . Since this happens for all values of x3 , we have that Res(f, g; x1 )
vanishes identically and therefore applying Theorem 2.1, we get the desired result. ✷
Finally we prove the real analog of Corollary 2.4. The result below is the one we apply in the
proof of our theorems.
Corollary 2.5. Let f and g be elements of R[x1 , x2 , x3 ], and suppose that f and g have positive
degrees l and m respectively. Suppose that there are more than lm lines on which f and g
simultaneously vanish identically. Then f and g have a common factor.
Proof. We can think of f and g as elements of C[x1 , x2 , x3 ], and they must vanish on more than
lm complex lines in C3 . By Corollary 2.4, f and g must have a common factor h in C[x1 , x2 , x3 ].
We can assume h is irreducible. A priori, the polynomial h may or may not be real. But, if h is
¯ Hence f is divisible
non-real, then the irreducible factorization of f must contain both h and h.
¯
¯
by the real polynomial hh. Similarly, g is divisible by hh. ✷
We take this moment to state an additional algebraic proposition which we will use in what
follows.

2832

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

Proposition 2.6. Let X be a set of N points in R3 . Then there is a nontrivial polynomial in
R[x1 , x2 , x3 ] (a fortiori in C[x1 , x2 , x3 ]) which vanishes on every point of X of degree less than
1
CN 3 , with a universal constant C.
coefficients. Requiring
Proof. A polynomial of three variables and degree d has (d+3)(d+2)(d+1)
6
that a polynomial vanish at a point gives a homogeneous linear equation for the coefficients. Underdetermined systems of homogeneous linear equations always have nontrivial solutions. ✷
3. Geometric preliminaries
In this section, we will recall some basic facts of the extrinsic geometry of irreducible algebraic varieties in R3 .
We let p be a nontrivial irreducible polynomial on R3 of degree d > 0. We consider
S = (x, y, z): p(x, y, z) = 0 .
We say that a point a ∈ S is critical if ∇p(a) = 0. Otherwise, we say that a is regular. (By the
implicit function theorem, S is locally a manifold in a neighborhood of a regular point.) We say
a line l is critical if l ⊂ S and every point of l is critical.
Proposition 3.1. The set S contains no more than d(d − 1) critical lines.
Proof. Suppose not. We apply Corollary 2.5 to p and a nontrivial component of ∇p. This contradicts the irreducibility of p. ✷
Next, we begin to investigate regular points of S. We immediately get the following.
Proposition 3.2. Let a be a regular point of S. Let l be a line contained in S which passes
through a. Then l ⊂ Ta S, where Ta S is the tangent plane to S at a.
Let a be a regular point of S. We would like to investigate the extrinsic curvature of S at a.
That is, we want to understand infinitesimally how the direction of ∇p is changing in a neighborhood of a in S. We define
II(p)(a) = {∇∇p×ej ∇p × ∇p}j =1,2,3 ,
where × is the cross product of vectors and e1 , e2 , e3 are the standard basis vectors in R3 . Clearly
II(p) is a set of three vectors. Thus it has nine components. Each of the components is a polynomial of degree no more than 3d − 4.
We will refer to II(p) as the algebraic second fundamental form of S. (The geometric second
fundamental form is a quadratic form on Tp S obtained by differentiating the unit normal vector
to S along S.) However since the algebraic fundamental form measures the normal component
of the change of ∇p along three directions which span Tp S, it is easy to see that for any regular
point a, all the components of II(p)(a) vanish if and only if the second fundamental form of S
vanishes.
We say a regular point a of S is flat if all the components of II(p)(a) vanish. We give a
sufficient condition for a regular point a to be flat.

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2833

Lemma 3.3. Let a be a regular point of S. Suppose that S contains three distinct lines all of
which intersect at a, then a is a flat point.
Proof. The quadratic surface which most closely approximates S at a contains the three lines.
(This is because the Taylor series of p along the lines vanishes.) However so does Ta S. Thus
since 3 > 2 by Corollary 2.5 the quadratic surface most closely approximating S must contain
Ta S. Therefore, the second fundamental form of S vanishes at a. ✷
We say that a line l is flat if it is contained in S, it is not critical, and every regular point of l
is flat.
Corollary 3.4. Let p be an irreducible polynomial of degree d > 0. Let S be the zero set of p.
Suppose that S contains more than 3d 2 − 4d flat lines, then S is a plane.
Proof. By Corollary 2.5, each component of II(p) has p as a factor. Therefore the direction
of the normal to S at regular points of S does not vary. Therefore S contains a plane. But p is
irreducible so S is a plane. ✷
4. Analytic preliminaries
In the following two sections we will prove “big oh” results by contradiction. Thus we will
make an assumption involving a large constant K. We keep track of anything that depends on K.
However, we ignore constants which are independent of K. Thus we write
A

B

if A and B are quantities and C is a universal constant.
There are two variants of the pigeonhole principle which we will use frequently. The first is
often referred to as the popularity lemma.
Lemma 4.1. Let (X, Y, E) be a bipartite graph with edges E and two sets of vertices X and Y .
Suppose that |E| > ρ|Y |. Let Y be the set of vertices of Y having degree at least μ and let E be
the set of edges in E between Y and X. Then
E > (ρ − μ)|Y |.
Proof. The vertices in Y \Y are incident to at most μ|Y | edges.

✷

We now give the second which we’ll refer to freely as the pigeonhole principle.
Lemma 4.2. Let x1 , . . . , xm be positive quantities and y1 , . . . , ym positive quantities, then there
is an integer 1 k m so that
xk
yk

m
j =1 xj
m
j =1 yj

.

2834

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

Proof. Suppose not. Let ρ =

m
j =1 xj
m
j =1 yj

. Then xk < ρyk for all k. Thus
m

m

xj < ρ
j =1

which is a contradiction.

yj ,
j =1

✷

5. Joints problem
In this section, we prove Theorem 1.1.
We suppose that we are given a set of lines L of cardinality N . Let J be the set of joints
determined by L. We suppose
|J |

3

KN 2 ,

with a large, but universal, constant K.
We create a bipartite, three-colored graph (L, J, R, G, B) between the set of lines and the set
of joints. Each joint is incident to at least three non-coplanar lines. For each joint, we arbitrarily
color one of the incidences red, one green, and one blue. The sets R, G, and B consist of,
respectively, the red, green, and blue incidences.
We will now refine the sets slightly. We let LR be the set of all lines which have at least
1
K
2
1000 N incidences in R. We let JR be the set of joints having a red incidence with a line of LR .
By Lemma 4.1,
|JR |

999
|J |.
1000
1

K
Now we let LG and LB be those lines having respectively at least 1000
N 2 green or blue incidences with joints in JR . We let J denote that set of joints which has red, green, and blue
incidences with lines in LG and LB and by Lemma 4.1, it is easy to show that

J

99
|J |.
100

Our goal now is to produce a polynomial of relatively low degree vanishing on all the points
1
of J . (Any degree which is substantially lower than N 2 will suffice.) We say a line l of LG
or LB meets a line l of LR if l ∩ l is a joint of JR . Each line of LG and each line of LB meets
1
K
N 2 lines of LR . We now take a random subset LR of the lines of LR , picking each
at least 1000
line with probability K1 .
By the law of large numbers, with positive probability, the following events occur: Each line
1
1
of LG and LB meets at least 2000
N 2 lines of LR and
LR

2N
.
K

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2835

1

We make a set of points S by selecting 12 N 2 points on each line of LR . Then
3

N2
.
K

|S|

We find a polynomial p which vanishes on all points of S. By the estimate on the size of S,
1

N2

we may select p with degree d which is

1

. With sufficiently large K, this means that p

K3

must vanish on each line of LR and because of the number of lines of LR that each line of LG
and LB meet, it means that p must vanish identically on each line of LG and LB . Therefore, the
polynomial p must vanish on the entire set J .
Now, it is not necessarily the case that p is irreducible. Thus we factor p into irreducibles
m

p=

pj .
j =1

We denote the degree of the polynomial pj by dj and observe that
1

m

N2

dj

1

.

K3

j =1

We let Jj be the subset of J on which pj vanishes, and we have
m

|Jj |

3

KN 2 .

j =1

Thus by Lemma 4.2, we find j for which
|Jj |

4

K 3 N dj .

From now on, we restrict our attention to Jj .
We denote by LR,j , LG,j , and LB,j those lines in LR , LB , and LG which are incident to at
least dj + 1 elements of Jj , and we let Jj be those element of Jj incident to a line each from
LR,j , LG,j , and LB,j . With K sufficiently large, we have
Jj

999
|Jj |.
1000

We now define LR,j , LG,j , and LB,j as the set of lines which are incident to more than dj + 1
points of Jj . We define Jj to be the set of joints defined by these lines. We have
Jj

99
|Jj |.
100

2836

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

We now break into two cases. In the first case, there are fewer than dj2 lines in each of LR,j ,
LG,j , and LB,j . In this case, we start over again, having a joints problem with fewer lines and
more favorable exponents than the original.
In the second case, we may assume without loss of generality that LR,j contains at least dj2
lines. By the definition of LR,j , LG,j , and LB,j , the polynomial pj vanishes identically on each
line in these sets. However, this implies that each point of Jj is a critical point of pj , because
otherwise it would be impossible for pj to vanish on three, intersecting, non-coplanar lines. But
this implies that each component of the gradient of pj vanishes at each point of Jj . Let q be one
of the components of the gradient which does not vanish identically. Then q has degree at most
dj − 1. Thus, it must vanish on every line of LR,j . But this is a contradiction by Proposition 3.1.
6. Bourgain’s incidence problem
In this section, we prove Theorem 1.2. We suppose we have a set of points X ⊂ R3 of cardi3
nality NK , with K large to be specified later and a set L of N 2 lines so that no N lines lie in the
same plane and so that each line l ∈ L is incident to at least N points of X. We may assume in
what follows that each line is incident to exactly N points by coloring N of its incidences black
and only counting black incidences below.
K
We say that a point x ∈ X is valuable if it is incident to at least 1000
lines. We define v(x)
the value of x to be the number of lines it is incident to. We let Xv be the set of valuable points.
Clearly
1000N 3
,
K

|Xv |
and by Lemma 4.1

999N 3
.
1000

v(x)
x∈Xv

We now perform some dyadic pigeonholing to uniformize the quantity v(x). We define Xj to
be the set of those x ∈ Xv so that
2j −1 K
1000

v(x) <

2j K
.
1000

We define
Vj =

v(x).
x∈Xj

Then note that
∞

Vj =
j =1

v(x)
x∈Xv

999N 3
.
1000

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2837

Note also that
∞
j =1

1
π2
=
< 2.
6
j2

Hence, by the pigeonhole principle, we can fix a positive number j so that
999N 3
.
2000j 2

Vj

(In the argument below, the reader is encouraged to assume that j = 1, since this is indeed the
worst case.)
From this we see that
N3
K2j

N3
.
K2j j 2

|Xj |

Next we find a polynomial p which vanishes on every point of Xj . We may choose p to have
degree d satisfying
N

d

1

.

j

K 323
The polynomial p needs not be irreducible. Thus we factor it
p = p1 p2 . . . pm ,
with pk having degree dk . We let Xj,k be the set of points of Xj on which pk vanishes. Clearly,
we have
N

d1 + d2 + · · · + dm

1

j

,

K 323
while
|Xj,1 | + |Xj,2 | + · · · + |Xj,m |

|Xj |

N3
.
K2j j 2

Thus by the pigeonhole principle, we can fix a k with
N 2 dk

|Xj,k |

2

2j

.

K 3 2 3 j2

We let Y = Xj,k and by the definition of Xj , if I is the number of incidences between L and Y ,
we have
I

1

j

N 2 dk K 3 2 3 j −2

N 2 dk .

2838

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

We let L be the set of lines incident to more than 100dk points of Y and let I be the number of
incidences between L and Y . Then clearly
I

I.

Note that each line of L is in the zero set of pk . Now let Y be the set of points of Y incident
to more than 3 lines of L . Then each point of Y is either a critical point of pk = 0 or else by
Lemma 3.3, it must be a flat point of pk .
We let L be the set of lines in L incident to at least 10dk points of Y . If I is the number of
incidences between lines of L and points of Y , we still have
1

j

N 2 dk K 3 2 3 j −2 .

I

We let Iflat and Icrit be the number of those incidences with flat points and critical points respectively. Note that
Icrit + Iflat

I .

There are two cases. In the first case
1

j

N 2 dk K 3 2 3 j −2 ,

Icrit
1

j

which means that there are at least N dk K 3 2 3 j −2 dk2 lines in the surface pk = 0 on which are
critical. But this is a contradiction in light of Proposition 3.1.
In the second case
1

j

N 2 dk K 3 2 3 j −2 ,

Iflat
1

j

which means that there are at least N dk K 3 2 3 j −2 3dk2 flat lines in the surface pk = 0. In light
of Corollary 3.4 the surface pk = 0 is in fact a plane. But now we have more than N lines of L
lying in a plane which is also a contradiction.
Acknowledgments
The second author would like to thank the University of Toronto and the Fields Institute for
their hospitality which allowed this collaboration to take place. He would also like to thank his
colleague Michael Larsen for a useful conversation about resultants. He is partially supported by
NSF grant DMS 0653763.
References
[1] J. Bennett, A. Carbery, T. Tao, On the multilinear restriction and Kakeya conjectures, Acta Math. 196 (2) (2006)
261–302.
[2] B. Chazelle, H. Edelsbrunner, L. Guibas, R. Pollack, R. Seidel, M. Sharir, J. Snoeyink, Counting and cutting cycles
of lines and rods in space, Comput. Geom. 1 (6) (1992) 305–323.
[3] D. Cox, J. Little, D. O’Shea, Using Algebraic Geometry, Grad. Texts in Math., Springer, 1998.
[4] D. Cox, J. Little, D. O’Shea, Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra, first ed., Undergrad. Texts Math., Springer, 1997.

L. Guth, N.H. Katz / Advances in Mathematics 225 (2010) 2828–2839

2839

[5] Z. Dvir, On the size of Kakeya sets in finite fields, J. Amer. Math. Soc. 22 (4) (2009) 1093–1097.
[6] S. Feldman, M. Sharir, An improved bound for joints in arrangements of lines in space, Discrete Comput. Geom. 33
(2005) 307–320.
[7] L. Guth, The endpoint case of the Bennett–Carbery–Tao multilinear Kakeya conjecture, preprint.
[8] N. Katz, I. Laba, T. Tao, An improved bound on the Minkowski dimension of Besicovitch sets in R3 , Ann. of
Math. 152 (2) (2000) 383–446.
[9] W. Schlag, A geometric inequality with applications to the Kakeya problem in three dimensions, Geom. Funct.
Anal. 8 (3) (1998) 606–625.
[10] M. Sharir, On joints in arrangements of lines in space and related problems, J. Combin. Theory Ser. A 67 (1) (1994)
89–99.
[11] M. Sharir, E. Welzl, Point–line incidences in space, Combin. Probab. Comput. 13 (2) (2004) 203–220.
[12] J. Solymosi, C. Tóth, On a question of Bourgain about geometric incidences, Combin. Probab. Comput. 17 (4)
(2008) 619–625.

