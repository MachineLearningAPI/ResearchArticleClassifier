Expert Systems with Applications 38 (2011) 14336–14345

Contents lists available at ScienceDirect

Expert Systems with Applications
journal homepage: www.elsevier.com/locate/eswa

Review

Review of the main developments in the analytic hierarchy process
Alessio Ishizaka ⇑, Ashraf Labib
University of Portsmouth, Portsmouth Business School, Richmond Building, Portland Street, Portsmouth PO1 3DE, United Kingdom

a r t i c l e

i n f o

Keywords:
AHP
Multicriteria decision making
Review

a b s t r a c t
In this paper the authors review the developments of the analytic hierarchy process (AHP) since its inception. The focus of this paper is a neutral review on the methodological developments rather than reporting its applications that have appeared since its introduction. In particular, we discuss problem
modelling, pair-wise comparisons, judgement scales, derivation methods, consistency indices, incomplete matrix, synthesis of the weights, sensitivity analysis and group decisions. All have been important
areas of research in AHP.
Ó 2011 Elsevier Ltd. All rights reserved.

1. Introduction
The analytic hierarchy process (AHP) is a multi-criteria decision
making (MCDM) method. The oldest reference that we have found
dates from 1972 (Saaty, 1972). Then, a paper in the Journal of
Mathematical Psychology (Saaty, 1977) precisely described the
method. The vast majority of the applications still use AHP as described in this ﬁrst publication and are unaware of successive
developments. This paper provides a sketch of the major directions
in methodological developments (as opposed to a discussion of
applications) and further research in this important ﬁeld.
AHP has been inspired by several previous discoveries. The use
of pair-wise comparisons (called paired comparisons by psychologists), the essence of AHP, instead of direct allocation of weights
has been used long time before by psychologists, e.g. (Thurstone,
1927; Yokoyama, 1921). The hierarchic formulation of the criteria,
a major feature of AHP, was ﬁrst proposed by Miller in his 1966
doctoral dissertation (Miller, 1966) and applied in Miller (1969)
and Miller (1970). The 1–9 scale is based on psychological observations (Fechner, 1860; Stevens, 1957). The number of items in each
level is inspired by Miller (1956), who recommends seven plus or
minus two items.
Since its introduction, AHP has been widely used, for example in
banks (Haghighi, Divandari, & Keimasi, 2010; Seçme, Bayrakdaroglu,
& Kahraman, 2009), manufacturing systems (Iç & Yurdakul, 2009; Li
& Huang, 2009; Yang, Chuang, & Huang, 2009), operators evaluation
(Sen & ÇInar, 2010), drugs selection (Vidal, Sahin, Martelli, Berhoune,
& Bonan, 2010), site selection (Önüt, Efendigil, & Soner Kara, 2009),
software evaluation (Cebeci, 2009; Chang, Wu, & Lin, 2009), evaluation of website performance (Liu & Chen, 2009), strategy selection

⇑ Corresponding author.
E-mail addresses: Alessio.Ishizaka@port.ac.uk (A. Ishizaka), Ashraf.Labib@port.
ac.uk (A. Labib).
0957-4174/$ - see front matter Ó 2011 Elsevier Ltd. All rights reserved.
doi:10.1016/j.eswa.2011.04.143

(Chen & Wang, 2010; Li & Li, 2009; Limam Mansar, Reijers, & Ounnar,
2009; Wu, Lin, & Lin, 2009), supplier selection (Chamodrakas, Batis,
& Martakos, 2010; Labib, 2011; Wang, Che, & Wu, 2010; Wang &
Yang, 2009), selection of recycling technology (Hsu, Lee, & Kreng,
2010), ﬁrms competence evaluation (Amiri, Zandieh, Soltani, &
Vahdani, 2009), weapon selection (Dagdeviren, Yavuz, & KilInç,
2009), underground mining method selection (Naghadehi, Mikaeil,
& Ataei, 2009) and its sustainability evaluation (Su, Yu, & Zhang,
2010), software design (Hsu, Kao, & Wu, 2009), organisational performance evaluation (Tseng & Lee, 2009), staff recruitment (Celik,
Kandakoglu, & Er, 2009; Khosla, Goonesekera, & Chu, 2009), construction method selection (Pan, 2009), warehouse selection (Ho &
Emrouznejad, 2009), technology evaluation (Lai & Tsai, 2009), route
planning (Niaraki & Kim, 2009), project selection (Amiri, 2010), customer requirement rating (Li, Tang, & Luo, 2010; Lin, Chen, & Tzeng,
2010), energy selection (Kahraman & Kaya, 2010), university evaluation (Lee, 2010) and many others. Several papers have compiled the
AHP success stories (Forman & Gass, 2001; Golden, Wasil, & Harker,
1989; Ho, 2008; Kumar & Vaidya, 2006; Liberatore & Nydick, 2008;
Omkarprasad & Sushil, 2006; Saaty & Forman, 1992; Shim, 1989;
Sipahi & Timor, 2010; Vargas, 1990; Zahedi, 1986). However AHP
has also received strong criticisms. Despite the predicted demise
by some researchers, there has been a strong response leading to
steady increase in its usage.

2. The AHP method
AHP is a multi-criteria decision making (MCDM) method helping decision-maker facing a complex problem with multiple conﬂicting and subjective criteria (e.g. location or investment
selection, projects ranking, etc). Several MCDM methods have
been developed (e.g. ELECTRE, MacBeth, SMART, PROMETHEE,
UTA, . . . see (Belton & Stewart, 2002; Figueira, Greco, & Ehrgott,
2005)) and all are based on four steps: problem modelling, weights

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

valuation, weights aggregation and sensitivity analysis. In the next
sections we will review these four steps used by AHP and its
evolutions.
2.1. Problem modelling
As with all decision-making processes, the facilitator will sit a
long time with the decision-maker(s) to structure the problem.
AHP has the advantage of permitting a hierarchical structure of
the criteria (Fig. 1), which provides users with a better focus on
speciﬁc criteria and sub-criteria when allocating the weights. This
step is important, because a different structure may lead to a different ﬁnal ranking. Several authors (Pöyhönen, Hamalainen, &
Salo, 1997; Stillwell, von Winterfeldt, & John, 1987; Weber,
Eisenführ, & von Winterfeldt, 1988) have observed that criteria
with a large number of sub-criteria tend to receive more weight
than when they are less detailed. Brugha (2004) has provided a
complete guideline to structure a problem hierarchically. A book
(Saaty & Forman, 1992) compiling hierarchies in different applications has been written. When setting up the AHP hierarchy with a
large number of elements, the decision maker should attempt to
arrange these elements in clusters so they do not differ in extreme
ways (Ishizaka, 2004a; Ishizaka, 2004b; Saaty, 1991).
2.2. Pair-wise comparisons
Psychologists argue that it is easier and more accurate to express one’s opinion on only two alternatives than simultaneously
on all the alternatives. It also allows consistency cross checking between the different pair-wise comparisons (see Section 2.5). AHP
uses a ratio scale, which, contrary to methods using interval scales
(Kainulainen, Leskinen, Korhonen, Haara, & Hujala, 2009), requires
no units in the comparison. The judgement is a relative value or a
quotient a/b of two quantities a and b having the same units
(intensity, meters, utility, etc). The decision maker does not need
to provide a numerical judgement; instead a relative verbal appreciation, more familiar in our daily lives, is sufﬁcient. Comparisons
are recorded in a positive reciprocal matrix (1). In special cases,
such as in currencies exchanges, not reciprocal matrices can be
used (Hovanov, Kolari, & Sokolov, 2008).

2

1

6a
6 21
A¼6
4 ...
an1

a12

a1n

3

...

aij

aji ¼ 1=aij

...

... 7
7
7
... 5

...

...

1

ð1Þ

where aij is the comparison between element i and j.
If the matrix is perfectly consistent, then the transitivity rule (2)
holds for all comparisons:

aij ¼ aik Á akj

14337

ð2Þ

For example, if team A beats team B two-zero and team B beats
team C three-zero, then it is expected with the transitivity rule
(2) that team A beats team C six-zero (3 Á 2 = 6). However, this is seldom the case because our world is inconsistent by nature. As a minimal consistency is required to derive meaningful priorities, a test
must be done (see Section 2.5). Webber, Apostolou, and Hassell
(1996) state that the order in which the comparisons are entered
in the matrix may affect the successive judgments.
2.3. Judgement scales
One of AHP’s strengths is the possibility to evaluate quantitative
as well as qualitative criteria and alternatives on the same preference scale. These can be numerical, verbal (Table 1) or graphical.
The use of verbal responses is intuitively appealing, user-friendly
and more common in our everyday lives than numbers. It may also
allow some ambiguity in non-trivial comparisons. This ambiguity
in the English language has also been criticised (Donegan, Dodd,
& McMaster, 1992). Due to its pair-wise comparisons AHP needs
ratio scales. Barzilai (2005) claims that preferences cannot be represented with ratio scales, because in his opinion an absolute zero
does not exists, as with temperature or electrical tension. Saaty
(1994) states that ratio scales are the only possible measurement
if we want to be able to aggregate measurement, as in a weighted
sum. Dodd and Donegan (1995) have criticised the absence of a
zero in the preference scale.
To derive priorities, the verbal comparisons must be converted
into numerical ones. In Saaty’s AHP the verbal statements are converted into integers from one to nine. Theoretically there is no reason to be restricted to these numbers and verbal gradation.
Although the verbal gradation has been little investigated, several
other numerical scales have been proposed (Table 2). Harker and
Vargas (1987) have evaluated a quadratic and a root square scale
in only one simple example and argued in favour of Saaty’s 1–9
scale. However, one example seems not enough to conclude the
superiority of the 1–9 linear scale. Lootsma (1989) argued that
the geometric scale is preferable to the 1–9 linear scale. Salo and
Hamalainen (1997) point out that the integers from one to nine
yield local weights, which are unevenly dispersed, so that there
is lack of sensitivity when comparing elements, which are preferentially close to each other. Based on this observation, they propose a balanced scale where the local weights are evenly
dispersed over the weight range [0.1, 0.9]. Earlier Ma and Zheng
(1991) have calculated a scale where the inverse elements x of
the scale 1/x are linear instead of the x in the Saaty scale. Donegan
et al. (1992) have proposed an asymptotic scale avoiding the
boundary problem, e.g. if the decision-maker enters aij = 3 and

Fig. 1. Example of a hierarchy (Akarte, Surendra, Ravi, & Rangaraj, 2001).

14338

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

(1) Add the elements of the columns: (1.75; 7; 3.5).
(2) Normalize the columns:

Table 1
The 1–9 fundamental scale.
Intensity of importance

Deﬁnition

1
2
3
4
5
6
7
8
9

Equal importance
Weak
Moderate importance
Moderate plus
Strong importance
Strong plus
Very strong or demonstrated importance
Very, very strong
Extreme importance

a
b
c

a

b

c

0.57
0.14
0.29

0.57
0.14
0.29

0.57
0.14
0.29

(3) Calculate the mean of the rows: (a = 0.57; b = 0.14; c = 0.29).
The result can be veriﬁed simply:

ajk = 4, s/he is forced to an intransitive relation (2) because the
upper limit of the scale is 9 and s/he cannot enter aik = 12. Ji and
Jiang (2003) propose a mixture of verbal and geometric scale.
The possibility to integrate negative values in the scale has been
also explored (Millet & Schoner, 2005; Saaty & Ozdemir, 2003).
Among all the proposed scales, the linear scale with the integers
one to nine and their reciprocals has been used by far the most often
in applications. Saaty (1980,1991) advocates it as the best scale to
represent weight ratios. However, the cited examples deal with
objective measurable alternatives such as the areas of ﬁgures,
whereas AHP mainly treats decision processes as subjective issues.
We understand the difﬁculty of verifying the effectiveness of scales
through subjective issues. Salo and Hamalainen (1997) demonstrate
the superiority of the balanced scale when comparing two elements.
The choice of the ‘‘best’’ scale is a very heated debate. Some scientists
argue that the choice depends on the person and the decision problem (Harker & Vargas, 1987; Pöyhönen et al., 1997).
2.4. Priorities derivation
The goal is to ﬁnd a set of priorities p1,. . .,pn such that pi/pj
match the comparisons aij in a consistent matrix and when slight
inconsistencies are introduced, priorities should vary only slightly.
Different methods have been developed to derive priorities. Psychologists using pair-wise matrices before Saaty used the mean
of the row. This old method is based on three steps (see example
1):
P
(1) Sum the elements of each column j: ni¼1 aij 8i; j
a
(2) Divide each value by its column sum: a0ij ¼ Pnij
a
Pn 0
i¼1 ij
aij
(3) Mean of row i: pi ¼ j¼1
n

8i; j

Example 1. Consider the following comparison matrix:

a
b
c

a

b

c

1

4
1
2

2
1/2
1

1=

4

½

– 0.57 % 4 Á 0.14, which is equivalent to the entered comparison
a=4Áb
– 0.57 % 2 Á 0.29, which is equivalent to a = 2 Á c
– 0.14 % 0.5 Á 0.29, which is equivalent to b = 0.5 Á c.
In the case of the introduction of small inconsistency, we can
decently think that it induces only a small distortion. Based on this
idea, Saaty (1977) uses the perturbation theory to justify the use of
the principal eigenvector p as the desired priorities vector (3). He
argues that slight variations in a consistent matrix imply slight
variations of the eigenvector and the eigenvalue.

AÁp¼kÁp

ð3Þ

where A is the comparison matrix; p is the priorities vector; k is the
maximal eigenvalue.
Only two years later after the publication of the original AHP,
Johnson, Beine, and Wang (1979) show a rank reversal problem
for scale inversion with the eigenvalue method. The solution of
the eigen Eq. (3) gives the right eigenvector p, which is not necessary the same as the left eigenvector p0 , solution of p0 T A = k p0 T
() AT p0 = k p0 . The solution depends on the formulation of the
problem. This right and left inconsistency (or asymmetry) arises
only for inconsistent matrices with a dimension higher than three
(Saaty & Vargas, 1984a).
In order to avoid this problem, Crawford and Williams (1985)
have adopted another approach in minimizing the multiplicative
error (4):

aij ¼

pi
eij
pj

ð4Þ

where aij is the comparison between object i and j; pi is the priority
of object i; eij is the error.
The multiplicative error is commonly accepted to be log normal
distributed (similarly the additive error would be assumed to be
normal distributed). The geometric mean (5) will minimize the
sum of these errors (6).

Pi ¼

rﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Yn
n
a
j¼1 ij

ð5Þ

The method ‘‘mean of row’’ derives the priorities as follow:

Table 2
Different scales for comparing two alternatives (for the comparison of A and B, c = 1 indicates A = B; c > 1 indicates A > B; when A < B, the reciprocal values 1/c are used).
Scale type

Deﬁnition

Parameters

Linear (Saaty, 1977)
Power (Harker & Vargas, 1987)
Geometric (Lootsma, 1989)
Logarithmic (Ishizaka, Balkenborg, & Kaplan, 2010)
Root square (Harker & Vargas, 1987)
Asymptotical (Dodd & Donegan, 1995)

c=a Á x
c = xa
c = axÀ1
c = log a(x + (a À 1))
pﬃﬃﬃ
c¼ ax
pﬃﬃ

À1
3ðxÀ1Þ
c ¼ tanh
14

a > 0; x = {1, 2, . . . ,
a > 1; x = {1, 2, . . . ,
a > 1; x = {1, 2, . . . ,
a > 1; x = {1, 2, . . . ,
a > 1; x = {1, 2, . . . ,
x = {1, 2, . . . , 9}

Inverse linear (Ma & Zheng, 1991)
Balanced (Salo & Hamalainen, 1997)

c ¼ 9=ð10 À xÞ
c ¼ w=ð1 À wÞ

x = {1, 2, . . ., 9}
w = {0.5, 0.55, 0.6, . . . , 0.9}

9}
9}
9} or x = {1, 1.5, . . . , 4} or other step
9}
9}

14339

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

min

n X
n
X
i¼1

lnðaij Þ À ln

j¼1

pi
pj

!!2
ð6Þ

The geometric mean (also sometimes known as logarithmic least
squares method) can be easily calculated by hand (see Example 2)
and has been supported by a large segment of the AHP community
(Aguarón & Moreno-Jiménez, 2000; Aguarón & Moreno-Jiménez,
2003; Barzilai, 1997; Barzilai & Lootsma, 1997; Budescu, 1984;
Escobar & Moreno-Jiménez, 2000; Fichtner, 1986; Leskinen &
Kangas, 2005; Lootsma, 1993; Lootsma, 1996). Its main advantage
is the absence of rank reversals due to the right and left inconsistency: in fact geometric mean of rows and columns provide the
same ranking (which is not necessarily the case with the eigenvalue
method).
Example 2. The priorities derived with the geometric mean (5)
from the matrix of the Example 1 are:

ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
p
3
P1 ¼ 1 Á 4 Á 2 ¼ 2;

rﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
3 1
Á 1 Á ¼ 0:5;
p2 ¼
4
2

rﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
3 1
p3 ¼
Á2Á1¼1
2

Normalizing, we obtain: ~
p ¼ ð0:57; 0:14; 0:29Þ.
If mathematical evidences testify clearly for the geometric
mean over the eigenvalue method, there is no clear differences between these two methods when simulations are applied (Budescu,
Zwick, & Rapoport, 1986; Cho & Wedley, 2004; Golany & Kress,
1993; Herman & Koczkodaj, 1996; Ishizaka & Lusti, 2006; Jones &
Mardle, 2004; Mikhailov & Singh, 1999), apart from special cases
(Bajwa, Choo, & Wedley, 2008). Perhaps in the light of this lack
of practical evidence, Saaty’s group has always supported the
eigenvalue method (Harker & Vargas, 1987; Saaty, 2003; Saaty &
Hu, 1998; Saaty & Vargas, 1984a; Saaty & Vargas, 1984b).
Other methods have been proposed, each one based either on
the idea of the distance minimisation (like the geometric mean)
or on the idea that small perturbation inducing small errors (like
the eigenvalue method or the arithmetic mean of rows). Cho and
Wedley (2004) have enumerated 18 different methods, which are
effectively 15 because three are equivalent to others (Lin, 2007).

Table 3
Random indices from (Saaty, 1977).
n

3

4

5

6

7

8

9

10

RI

0.58

0.9

1.12

1.24

1.32

1.41

1.45

1.49

cover contradictory judgements and correct them (Ishizaka & Lusti,
2004; Wang, Chin, & Luo, 2009).
Several other methods have been proposed to measure consistency. Peláez and Lamata (2003) describe a method based on the
determinant of the matrix. Crawford and Williams (1985) prefer
to sum the difference between the ratio of the calculated priorities
and the given comparisons in the Geometric Consistency Index
(GCI):

GCI ¼

2
P 
2 i<j log aij À log ppi
j

ðn À 1Þðn À 2Þ

ð9Þ

Aguarón and Moreno-Jiménez (2003) determines a threshold that
provides an interpretation of the inconsistency threshold analogous
to the CR = 10%: GCI = 0.3147 for n = 3, GCI = 0.3526 for n = 4 and
GCI = 0.370 for n > 4.
The transitivity rule (2) has been used by Salo and Hamalainen
(1997) and later by Ji and Jiang (2003) in another formulation:

vﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
uPnÀ1 Pn
u i¼1 j¼iþ1 ðaij À log pi Þ
pj
t
nðn À 1Þ=2

ð10Þ

Alonso and Lamata (2006) have computed a regression of the random indices and propose the formulation:

kmax < n þ 0:1ð1:7699n À 4:3513Þ

ð11Þ

Stein and Mizzi (2007) use the normalised column of the comparison matrix.
For all consistency checking, some questions remain: what is
the cut-off rule to declare my matrix inconsistent? Should this rule
depend on the size of the matrix? How should I adapt my consistency deﬁnition, when I use another judgement scale?

2.5. Consistency
2.6. Incomplete pair-wise matrix
As priorities make sense only if derived from consistent or near
consistent matrices, a consistency check must be applied. Saaty
(1977) has proposed a consistency index (CI), which is related to
the eigenvalue method:

CI ¼

kmax À n
nÀ1

ð7Þ

where n is the dimension of the matrix; kmax is maximal eigenvalue.
The consistency ratio, the ratio of CI and RI, is given by:

CR ¼ CI=RI;

ð8Þ

where RI is the random index (the average CI of 500 randomly ﬁlled
matrices).
If CR is less than 10%, then the matrix can be considered as having an acceptable consistency.
Saaty (1977) calculated the random indices shown in Table 3:
Other researchers have run simulations with different numbers
of matrices (Aguarón & Moreno-Jiménez, 2003; Alonso & Lamata,
2006; Lane & Verdini, 1989; Tummala & Wan, 1994) or incomplete
matrices (Forman, 1990). Their random indices are different but
close to Saaty’s.
This consistency index has been criticised because it allows
contradictory judgements in matrices (Bana e Costa & Vansnick,
2008; Kwiesielewicz & van Uden, 2004) or rejects reasonable
matrices (Karapetrovic & Rosenbloom, 1999). Techniques based
on the transitivity rule (2) have been developed in order to dis-

The number of pair-wise comparisons requested can be very
high: (n2–n)/2 for n alternatives/criteria. For example 8 alternatives
and 6 criteria request 183 entries. This high number of questions
can quickly become overwhelming and comparisons may be entered with a small reﬂexion time due in order to speed up the process. Therefore it has been proposed to enter fewer comparisons,
which are well evaluated, than the whole number of comparisons,
which may be approximate evaluation. Another reason for incomplete comparisons matrix is that the decision-maker may not have
formed a strong opinion on a particular judgement and rather that
forcing him to give an often wild guess or to have the entire process slowed down due to one comparison; one can simply skip this
question. In a Monte-Carlo simulation study, where comparisons
are deleted from large matrices (rank 10, 15 and 20), it has been
discovered that one can randomly delete as much as 50% of the
comparisons without signiﬁcantly reducing the results (Carmone,
Kara, & Zanakis, 1997). The minimal number of comparisons required is n À 1, one for each row or column of the pariwise comparison matrix. The other comparisons are redundant and only
necessary to check consistency and possibly improve accuracy.
They can be calculated by the transitivity rule (2). This transitivity
rule can be extended:

aij ¼ aik Á akm Á . . . Á av j :

ð12Þ

14340

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

The literature related to incomplete comparisons falls into three
categories: calculation of missing comparisons, starting rules and
stopping rules.

 Ordinal rank will not be reversed whatever further comparison
is entered. This stopping criteria is not effective if two alternatives have almost equivalent priorities.

2.6.1. Calculation of missing comparisons
A natural way to ﬁll in the missing matrix element is to take the
geometric average of all the indirectly calculated missing comparisons with the extended transitivity rule (12) (Harker, 1987). The
drawback of this method is that the number of indirect comparisons grows with the number of alternatives n in such a way that
the calculation requires a long processing time.
In order to overcome this problem, eigenvector can be derived
directly without estimating unknown comparisons (Harker,
1987b). If we consider the matrix A with missing comparisons,
the method to calculate the priorities has two steps:

Wedley (1993) has simulated several matrices with different
degrees of inconsistency and then used then to develop regressions
equations that predict consistency ratio at each step beyond n
comparisons. This method is satisfying only if the decision-maker
does not enter a too inconsistent comparison. Alternatively, the
consistency index can be calculated only based upon the entered
comparisons (Harker, 1987b): the priority vector (pi, i = 1,2, . . . ,n)
is calculated (see Section 2.6.1) which in turn is used to calculate
estimates missing values (pi/pj, i = 1,2, . . . ,n; j = 1,2, . . . ,n). Since
these estimates are based only on the known comparisons, the
consistency index tends to underestimate the true degree of inconsistency that would occur if all redundant comparisons were
entered. In order to correct this bias, new random indexes were
calculated (Forman, 1990). This method is used in expert choice,
the leading supporting software of AHP, to estimate the consistency ratio for incomplete matrices.
Lim and Swenseth (1993) have proposed to stop the process
when one alternative becomes dominant to such a degree that
regardless of the effects of the remaining comparisons to evaluate,
it cannot be overtaken as the preferred choice. In fact, in a scenario
with n criteria, if the difference between the cumulative scores for
the two best alternatives, after considering r criteria, is greater
than the remaining total eigenscores of the n–r remaining criteria,
the best alternative is identiﬁed. The drawback of this method is
that only the best choice is identiﬁed and the decision-maker must
use a top-down sequence for establishing priorities.

(i) A new matrix B is created from the incomplete matrix A:
– bij = aij if aij is a real number > 0
– = 0 otherwise
– bii = the number of unanswered questions in the row i
(ii) The eigenvalue method is applied on the matrix B = A + I,
where I is the identity matrix.
Other methods have been proposed to decrease the number of
comparisons:
 To use clusters and pivots (Ishizaka, 2008; Shen, Hoerl, &
McConnell, 1992). Objects are divided into several clusters such
that all these clusters have one common object: the pivot. Then,
pair-wise comparisons are performed for each cluster and priorities are calculated. Finally, the global priority is derived by
using the pivot and priorities of each cluster.
 To make comparisons for a node that has an overall high impact
on the ﬁnal priorities and froze node with a very low global
weight (Millet & Harker, 1990).
2.6.2. Starting rule
As only n À 1 comparisons are required, the question is which
one should we estimate? Harker (1987a) used random selection.
Ishizaka and Lusti (2004) prefers the ﬁrst upper diagonal of the
comparison matrix as all items are compared exactly same number
of time: two. They prefer to reject a common row or column approach because they felt that it compromised the psychological
independence of the comparisons. Wedley, Schoner, and Tang
(1993) investigated starting rules for the selection of the ﬁrst
n À 1 comparisons in an experiment with 144 business students
for a problem with known answer. The students have to estimate
the proportions of ﬁve distinct colours in a rectangular area. Six
different referents were considered for the n À 1 initial comparisons: ﬁrst column, bottom row, upper diagonal, lowest ranked
item, median ranked item and highest ranked item. The lowest
ranked item for the ﬁrst n À 1 comparisons proved to be statistically more accurate than any of the other starting methods. However instead of imposing a starting rule, it may be preferable to
leave the choice to the decision-maker, who can select the comparisons (s)he is the most comfortable to evaluate.
2.6.3. Stopping rule
Harker (1987b) uses a gradient procedure to select the next
comparison which will have the greatest impact on the priorities.
He suggested three different stopping criteria:
 Subjective satisfaction of the user with the priorities.
 Tolerance percentage change in absolute attribute weights from
one question to another.

2.7. Aggregation
The last step is to synthesize the local priorities across all criteria in order to determine the global priority. The historical AHP approach (called later distributive mode) adopts an additive
aggregation with normalisation of the sum of the local priorities
to unity:

pi ¼

X

wj Á lij

ð13Þ

j

where pi is the global priority of the alternative i; lij is local priority;
wj is weight of the criterion j.
The distributive mode is subject to rank reversal, a phenomenon
that has been extensively discussed in the literature. In particular,
a memorable debate has appeared ﬁrst in Omega and then in
Management Science and in the Journal of the Operational Society.
The saga in Omega has four episodes. The ﬁrst article (Belton &
Gear, 1983) came as a bombshell. It describes an example where
the introduction of a copy of an alternative changes the ranking.
The rank reversal is due to the modiﬁcation of the relative values
between the local priorities (which is a different and independent
cause of the rank reversal due to the right and left inconsistency
described in the Section 2.4). As the sum of the local priorities to
unity changes with the introduction of a new alternative, the local
priorities are also modiﬁed when normalised and therefore the global priorities may be reversed. The rank reversal phenomenon is
therefore independent of the consistency of the matrix and the
derivation method of the priorities. As this phenomenon is not unique to AHP but to all additive models (Triantaphyllou, 2001; Wang
& Luo, 2009), Belton and Gear, inspired by the weighted sum model, suggested using a normalisation by dividing the score of each
alternative only by the score of the best alternative under each
criteria. This normalisation will be called later in the literature
B–G normalisation or ideal mode. In the second article of the saga,
Saaty and Vargas (1984c) provided a counter-example to show that

14341

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

the ideal mode is also subject to rank reversal. In this case, they
introduce an alternative, which is a copy on only two of three criteria. On the last criterion, the new alternative has the largest value, which implies different normalisation and priorities. In the
third episode, Belton and Gear (1985) responded that if a new
alternative is introduced, then the weight criteria should also be
modiﬁed. This contradicts the AHP philosophy of independence
of weights and alternatives. In the fourth episode, Vargas (1985)
claims that a method must not be applied only because it gives
the results we want (i.e. preserve ranks). He argued that the process used if one has a set of alternatives and adds or deletes some
alternatives should be the same if when starting from scratch. The
same remark applies to the work of Wang and Elhag (2006), which
propose a normalisation by the sum of all priorities with the exception of the new added one. Later, Schoner and Wedley (1989),
showed a tangible example (i.e. all criteria are monetary measurable), that a weight change is required to preserve ranks. In a successive paper, Schoner, Wedley, and Choo (1993) proposed the
linking pin AHP. The local priorities of a speciﬁc alternative is normalised to unity. The rank is preserved because the normalisation
is always the same. However the ﬁnal solution depends on which
alternative is selected to link across criteria.
This phenomenon, appearing also for near identical copy (Dyer,
1990b) or when a copy is removed (Troutt, 1988), has then been
debated in Management Science, in the Journal of the Operational
Society and in the European Journal of Operational Research where
one side has criticised the rank reversal phenomenon (Dyer,
1990a; Dyer, 1990b; Holder, 1990; Holder, 1991; Stam & Duarte
Silva, 2003) and the other has legitimized it (Harker & Vargas,
1987; Harker & Vargas, 1990; Pérez, 1995; Saaty, 1986; Saaty,
1990; Saaty, 1991; Saaty, 1994; Saaty, 2006).
Millet and Saaty (2000) gave some guidance on which normalisation to use. However, due to the absence of a causal effect demonstration, we believe that the occasional rank reversals are more
side-effects of the procedure rather than credible results of the
modelling procedure.
The multiplicative aggregation (14) has been proposed to prevent the rank reversal phenomenon (Barzilai & Lootsma, 1997;
Lootsma, 1993).

pi ¼

Y

w

lij j

ð14Þ

j

The multiplicative aggregation has non-linearity properties allowing a superior compromise to be select, which is not the case with
the additive aggregation (Ishizaka, Balkenborg, & Kaplan, 2010;
Stam & Duarte Silva, 2003). However, Vargas (1997) showed that
additive aggregation is the only way to retrieve exact weights of
known objects.

2.8. Sensitivity analysis
The last step of the decision process is the sensitivity analysis,
where the input data are slightly modiﬁed in order to observe
the impact on the results. As complex decision models may be
inherently unstable, it allows the generation of different scenarios,
which may results in other rankings and further discussion may be
needed to reach a consensus. If the ranking does not change, the results are said to be robust otherwise it is sensitive. In AHP, the sensitivity analysis can be done on three levels: weights, local
priorities and comparisons.
The sensitivity analysis in expert choice allows the variation the
weights of the criteria only as input data. Its interactive graphical
interface allows a better visualization of the impact of the changes
(Fig. 2). A sensitivity analysis to single and multiple changes of lo-

cal priorities has also been studied (Chen & Kocaoglu, 2008; Huang,
2002; Masuda, 1990) but not yet implemented in a software.
Armacost and Hosseini (1994), inspired from the dual questioning approach attribute (DQDA), have described the way to calculate
the most determinant criteria. In fact, it is not necessarily the most
weighted criterion that is the most critical; the weight must be
multiplied by the difference of the local priorities of the alternatives. Triantaphyllou and Sánchez (1997) have deﬁned a sensitivity
coefﬁcient of the weights and local priorities. It is calculated with
the minimum change of the current weight/local priority such as
the ranking of two alternatives is reversed.
The sensitivity coefﬁcient of criterion ck is given by:

Sensitivityðck Þ ¼ 1=Dk ;

ð15Þ

where Dk is the smallest percent amount by which the current value
must change such that the ranking is reversed:

Dk ¼ min rk;i;j

for all k; i; j

ð16Þ

where k is the criterion k; i, j is alternative i, jand the perturbation
rk,i,j is given by:

X

¼ ðpj À piÞ=ðli j À lii Þ and

rk;i;j

wj

ð17Þ

k;i;j

where pi is the global priority of the alternative i; lij is local priority
of alternative i on the weight j.
The same paper (Triantaphyllou & Sánchez, 1997) contains also
the formulas for the most sensitive weight and criteria for the multiplicative AHP. These parameters are critical and careful attention
should be given to them.
A sensitivity analysis at a micro level has been developed to calculate the interval a single comparison can vary without changing
the rank of the alternatives (Aguarón & Moreno-Jiménez, 2000) and
to remain in an acceptable inconsistency index (Aguarón & Moreno-Jiménez, 2003) for AHP using the geometric mean.
3. AHP in group decision making
As a decision affects often several persons, the standard AHP has
been adapted in order to be applied in group decisions. Consulting
several experts avoids also bias that may be present when the
judgements are considered from a single expert. There are four
ways to combine the preferences into a consensus rating (Table 4).
The consensus vote is used, when we have a synergistic group
and not a collection of individuals. In this case, the hierarchy of
the problem must be the same for all decision-makers. On the
judgements level, this method requires the group to reach an
agreement on the value of each entry in a matrix of pair-wise comparisons. A consistent agreement is usually difﬁcult to obtain with
increasing difﬁculty with the number of comparison matrices and
related discussions. In order to bypass this difﬁculty, the consensus
vote can be postponed after the calculation of the priorities of each
participant. O’Leary (1993) recommends this version because an
early aggregation could result ‘‘in a meaningless average performance measure’’. An aggregation after the calculation of priorities
allows to detect decision-makers from different boards and to discuss further any disagreement.
If a consensus is difﬁcult to achieve (e.g. with a large number of
persons or distant persons), a mathematical aggregation can be
adopted. Two synthesizing methods exist and provide the same results in case of perfect consistency of the pair-wise matrices (Saaty
& Vargas, 2005). In the ﬁrst method, the geometric mean of individual evaluations are used as elements in the pair-wise matrices
and then priorities are computed. The geometric mean method
(GMM) must be adopted instead of the arithmetical mean in order
to preserve the reciprocal property (Aczél & Saaty, 1983). For

14342

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

Fig. 2. An example of four possible graphical sensitivity analyses in expert choice.

Table 4
Four ways to combine preferences.
Mathematical aggregation

Aggregation on:

Judgements
Priorities

Yes

No

Geometric mean
on judgements
Weighted arithmetic
mean on priorities

Consensus vote
on judgements
Consensus vote
on priorities

example, if person A enters a comparison 9 and person B enters 1/9,
qﬃﬃﬃﬃﬃﬃﬃﬃﬃ
then by intuition the mathematical consensus should be 9 Á 19 ¼ 1,
which is a geometric mean and not ð9 þ 1=9Þ=2 ¼ 4:56, which is an
arithmetic mean. Ramanathan and Ganesh (1994) give an example
where the Pareto optimality (i.e. if all group members prefer A to B,
then the group decision should prefer A) is not satisﬁed with the
GMM. Van den Honert and Lootsma (1997) argue that this violation could be expected because the pair-wise assessments are a
compromise of all the group members’ assessments and therefore
it is a compromise that does not represent any opinion of the group
member. Madu and Kuei (1995), Bryson (1996) and then Saaty and
Vargas (2007) introduce a measure of the dispersion of the judgements (or consensus indicator) in order to avoid this problem. If
the group is not homogenous, further discussions are required to
reach a consensus.
In the second method, decision-makers constitute the ﬁrst level
below the goal of the AHP hierarchy. Priorities are computed and
then aggregated using the weighted arithmetic mean method
(WAMM). Applications can be found in (Labib & Shah, 2001; Labib,
Williams, & O’Connor, 1996). Arbel and Orgler (1990) have introduced a further level above the stakeholders’ level representing

the several economics scenarios. This extra level determines the
priorities (weights) of the stakeholders.
In a compromised method individual’s derived priorities can be
aggregated at each node. However according to Forman and Peniwati (1998), this method is ‘‘less meaningful and not commonly
used’’. Aggregation methods with linear programming (Mikhailov,
2004) and Bayesian approach (Altuzarra, Moreno-Jiménez, & Salvador, 2007) have been proposed in order to take a decision even
when comparisons are missing, for example when a stakeholder
does not feel to have the expertise to judge a particular comparison. Uncertainty has also been taken into account in proposing several ranking with an attached probability (Escobar & Morenojiménez, 2007; Van den Honert, 1998).
Group decision may be skewed because of collusion or distortion of the judgements in order to advantage its preferred outcome.
As individual identities are lost with an aggregation, we prefer to
avoid an early aggregation. Condon, Golden, and Wasil (2003) have
developed a programme in order to visualise the decision of each
participant, which facilitate the detection of outliers.

4. Conclusion and future developments
Decisions that need support methods are difﬁcult by deﬁnition
and therefore complex to model. A trade-off between prefect modelling and usability of the model should be achieved. It is our belief
that AHP has reached this compromise and will be useful for many
other cases as it has been in the past. In particular, AHP has broken
through the academic community to be widely used by practitioners. This widespread use is certainly due to its ease of applicability and the structure of AHP which follows the intuitive way in
which managers solve problems. The hierarchical modelling of
the problem, the possibility to adopt verbal judgements and the

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

veriﬁcation of the consistency are its major assets. Expert Choice,
the user-friendly supporting software, has certainly largely contributed to the success of the method. It incorporates intuitive
graphical user interfaces, automatic calculation of priorities and
inconsistencies and several ways to process a sensitivity analysis
(Ishizaka & Labib, 2009). Today, several other supporting software
packages have been developed: Decision Lens, HIPRE 3+, RightChoiceDSS, Criterium, EasyMind, Questfox, ChoiceResults, AHPProject, 123AHP. . . not to mention that a template in Excel could also
be easily generated. Along with its traditional applications, a new
trend, as compiled by the work of Ho (2008), is to use AHP in conjunction with others methods: mathematical programming techniques like linear programming, data envelopment analysis
(DEA), fuzzy sets, house of quality, genetic algorithms, neural networks, SWOT-analysis and so on. There is little doubt that AHP will
be more and more frequently adopted.
AHP still suffers from some theoretical disputes. The rank reversal is surely the most debated problem. This phenomenon is still
not fully resolved and maybe it will never be because the aggregation of preferences transposed from scales of different units is not
easily interpretable and even questionable according to the French
school (Roy, 1996).
The assumption of criteria independence (no correlation) may
be sometimes a limitation of AHP (and other MCDM methods).
The Analytic Network Process (ANP), a generalisation of AHP with
feed-backs to adjust weights, may be a solution. However the decision-maker must answer a much larger number of questions,
which may be quite complex: e.g. ‘‘Given an alternative and a criterion, which of the two alternatives inﬂuences the given criterion
more and how much more than another alternative’’ (Saaty &
Takizawa, 1986). A simpliﬁed ANP, while still keeping its proprieties, would be beneﬁcial for a wider adoption of the method.
Another direction of the research will probably be on a more soft
side. The choice of a hierarchy and a judgement scale is important
and difﬁcult. Problem structuring methods could help in the construction of AHP hierarchies, which is its less formalised aspect
(Petkov & Mihova-Petkova, 1997; Petkov, Petkova, Andrew, &
Nepal, 2007).

References
Aczél, J., & Saaty, T. (1983). Procedures for synthesizing ratio judgements. Journal of
Mathematical Psychology, 27, 93–102.
Aguarón, J., & Moreno-Jiménez, J. (2000). Local stability intervals in the analytic
hierarchy process. European Journal of Operational Research, 125, 113–132.
Aguarón, J., & Moreno-Jiménez, J. (2003). The geometric consistency index:
approximated thresholds. European Journal of Operational Research, 147,
137–145.
Akarte, M., Surendra, N., Ravi, B., & Rangaraj, N. (2001). Web based casting supplier
evaluation using analytical hierarchy process. Journal of the Operational Research
Society, 52, 511–522.
Alonso, J., & Lamata, T. (2006). Consistency in the Analytic Hierarchy Process: a New
Approach. International Journal of Uncertainty, Fuzziness and Knowledge-Based
Systems, 14, 445–459.
Altuzarra, A., Moreno-Jiménez, J., & Salvador, M. (2007). A Bayesian priorization
procedure for AHP-group decision making. European Journal of Operational
Research, 182, 367–382.
Amiri, M., Zandieh, M., Soltani, R., & Vahdani, B. (2009). A hybrid multi-criteria
decision-making model for ﬁrms competence evaluation. Expert Systems with
Applications, 36, 12314–12322.
Amiri, M. P. (2010). Project selection for oil-ﬁelds development by using the AHP
and fuzzy TOPSIS methods. Expert systems with applications, Uncorrected Proof,
doi: 10.1016/j.eswa.2010.1002.1103.
Arbel, A., & Orgler, Y. (1990). An application of the AHP to bank strategic planning:
The mergers and acquisitions process. European Journal of Operational Research,
48, 27–37.
Armacost, R., & Hosseini, J. (1994). Identiﬁcation of determinant attributes using the
analytic hierarchy process. Journal of the Academy of Marketing Science, 22,
383–392.
Bajwa, G., Choo, E., & Wedley, W. (2008). Effectiveness analysis of deriving priority
vectors from reciprocal pairwise comparison matrices. Asia-Paciﬁc Journal of
Operational Research, 25, 279–299.

14343

Bana e Costa, C., & Vansnick, J. (2008). A critical analysis of the eigenvalue method
used to derive priorities in AHP. European Journal of Operational Research, 187,
1422–1428.
Barzilai, J. (1997). Deriving weights from pairwise comparisons matrices. Journal of
the Operational Research Society, 48, 1226–1232.
Barzilai, J. (2005). Measurement and preference function modelling. International
Transactions in Operational Research, 12, 173–183.
Barzilai, J., & Lootsma, F. (1997). Power relation and group aggregation in the
multiplicative AHP and SMART. Journal of Multi-Criteria Decision Analysis, 6,
155–165.
Belton, V., & Gear, A. (1983). On a shortcoming of Saaty’s method of analytical
hierarchies. Omega, 11, 228–230.
Belton, V., & Gear, A. (1985). The legitimacy of rank reversal – A comment. Omega,
13, 143–144.
Belton, V., & Stewart, T. J. (2002). Multiple criteria decision analysis: An integrated
approach. Boston: Kluwer Academic Publishers.
Brugha, C. (2004). Structure of multi-criteria decision-making. Journal of the
Operational Research Society, 55, 1156–1168.
Bryson, N. (1996). Group decision-making and the analytic hierarchy process:
Exploring the consensus-relevant information content. Computers and
Operations Research, 23, 27–35.
Budescu, D. (1984). Scaling binary comparison matrices: A comment on
Narasimhan’s proposal and other methods. Fuzzy Sets and Systems, 14, 187–192.
Budescu, D., Zwick, R., & Rapoport, A. (1986). A comparison of the eigenvalue
method and the geometric mean procedure for ratio scaling. Applied
Psychological Measurement, 10, 69–78.
Carmone, F., Kara, A., & Zanakis, S. (1997). A Monte Carlo investigation of
incomplete pairwise comparison matrices in AHP. European Journal of
Operational Research, 102, 538–553.
Cebeci, U. (2009). Fuzzy AHP-based decision support system for selecting ERP
systems in textile industry by using balanced scorecard. Expert Systems with
Applications, 36, 8900–8909.
Celik, M., Kandakoglu, A., & Er, D. (2009). Structuring fuzzy integrated multi-stages
evaluation model on academic personnel recruitment in MET institutions.
Expert Systems with Applications, 36, 6918–6927.
Chamodrakas, I., Batis, D., & Martakos, D. (2010). Supplier selection in electronic
marketplaces using satisﬁcing and fuzzy AHP. Expert Systems with Applications,
37, 490–498.
Chang, C.-W., Wu, C.-R., & Lin, H.-L. (2009). Applying fuzzy hierarchy multiple
attributes to construct an expert decision making process. Expert Systems with
Applications, 36, 7363–7368.
Chen, H., & Kocaoglu, D. (2008). A sensitivity analysis algorithm for hierarchical
decision models. European Journal of Operational Research, 185, 266–288.
Chen, M. K., & Wang, S.-C. (2010). The critical factors of success for information
service industry in developing international market: Using analytic hierarchy
process (AHP) approach. Expert Systems with Applications, 37, 694–704.
Cho, E., & Wedley, W. (2004). A common framework for deriving preference values
from pairwise comparison matrices. Computers and Operations Research, 31,
893–908.
Condon, E., Golden, B., & Wasil, E. (2003). Visualizing group decisions in the analytic
hierarchy process. Computers and Operations Research, 30, 1435–1445.
Crawford, G., & Williams, C. (1985). A note on the analysis of subjective judgement
matrices. Journal of Mathematical Psychology, 29, 387–405.
Dagdeviren, M., Yavuz, S., & KilInç, N. (2009). Weapon selection using the AHP and
TOPSIS methods under fuzzy environment. Expert Systems with Applications, 36,
8143–8151.
Dodd, F., & Donegan, H. (1995). Comparison of priotization techniques using
interhierarchy mappings. Journal of the Operational Research Society, 46,
492–498.
Donegan, H., Dodd, F., & McMaster, T. (1992). A new approach to AHP decisionmaking. The Statician, 41, 295–302.
Dyer, J. (1990a). A clariﬁcation of ‘‘remarks on the analytic hierarchy process’’.
Management Science, 36, 274–275.
Dyer, J. (1990b). Remarks on the analytic hierarchy process. Management Science, 36,
249–258.
Escobar, M., & Moreno-Jiménez, J. (2000). Reciprocal distributions in the
analytic hierarchy process. European Journal of Operational Research, 123,
154–174.
Escobar, M., & Moreno-jiménez, J. (2007). Aggregation of individual preference
structures in Ahp-group decision making. Group Decision and Negotiation, 16,
287–301.
Fechner, G. (1860). Elemente der psychophysik (Vol. 2). Breitkopf und Härtel.
Fichtner, J. (1986). On deriving priority vectors from matrices of pairwise
comparisons. Socio-Economic Planning Sciences, 20, 341–345.
Figueira, J., Greco, S., & Ehrgott, M. (2005). Multiple criteria decision analysis: State of
the art surveys. New York: Springer-Verlag.
Forman, E. (1990). Random indices for incomplete pairwise comparison matrices.
European Journal of Operational Research, 48, 153–155.
Forman, E., & Gass, S. (2001). The analytic hierarchy process – An exposition.
Operations Research, 49, 469–486.
Forman, E., & Peniwati, K. (1998). Aggregating individual judgments and priorities
with the analytic hierarchy process. European Journal of Operational Research,
108, 165–169.
Golany, B., & Kress, M. (1993). A multicriteria evaluation of the methods for
obtaining weights from ratio-scale matrices. European Journal of Operational
Research, 69, 210–220.

14344

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345

Golden, B., Wasil, E., & Harker, P. (1989). The analytic hierarchy process: Applications
and studies. Heidelberg: Springer-Verlag.
Haghighi, M., Divandari, A., & Keimasi, M. (2010). The impact of 3D e-readiness on
e-banking development in Iran: A fuzzy AHP analysis. Expert Systems with
Applications, 37, 4084–4093.
Harker, P. (1987). Incomplete pairwise comparisons in the analytic hierarchy
process. Mathematical and Computer Modelling.
Harker, P., & Vargas, L. (1987). The theory of ratio scale estimation: Saaty’s analytic
hierarchy process. Management Science, 33, 1383–1403.
Harker, P., & Vargas, L. (1990). Reply to ‘‘Remarks on the Analytic Hierarchy
Process’’. Management Science, 36, 269–273.
Harker, P. T. (1987a). Alternative modes of questioning in the analytic hierarchy
process. Mathematical Modelling, 9, 353–360.
Harker, P. T. (1987b). Incomplete pairwise comparisons in the analytic hierarchy
process. Mathematical Modelling, 9, 837–848.
Herman, M., & Koczkodaj, W. (1996). A Monte Carlo study of pairwise comparison.
Information Processing Letters, 57, 25–29.
Ho, W. (2008). Integrated analytic hierarchy process and its applications – A
literature review. European Journal of Operational Research, 186, 211–228.
Ho, W., & Emrouznejad, A. (2009). Multi-criteria logistics distribution network
design using SAS/OR. Expert Systems with Applications, 36, 7288–7298.
Holder, R. (1990). Some comment on the analytic hierarchy process. Journal of the
Operational Research Society, 41, 1073–1076.
Holder, R. (1991). Response to holder’s comments on the analytic hierarchy process:
Response to the response. Journal of the Operational Research Society, 42,
914–918.
Hovanov, N., Kolari, J., & Sokolov, M. (2008). Deriving weights from general pairwise
comparisons matrices. Mathematical Social Sciences, 55, 205–220.
Hsu, S. H., Kao, C.-H., & Wu, M.-C. (2009). Design facial appearance for roles in video
games. Expert Systems with Applications, 36, 4929–4934.
Hsu, Y.-L., Lee, C.-H., & Kreng, V. B. (2010). The application of Fuzzy Delphi Method
and Fuzzy AHP in lubricant regenerative technology selection. Expert Systems
with Applications, 37, 419–425.
Huang, Y.-F. (2002). Enhancement on sensitivity analysis of priority in analytic
hierarchy process. International Journal of General Systems, 31, 531–542.
Iç, Y. T., & Yurdakul, M. (2009). Development of a decision support system for
machining center selection. Expert Systems with Applications, 36, 3505–
3513.
Ishizaka, A. (2004a). The Advantages of Clusters in AHP. In 15th Mini-Euro conference
MUDSM. Coimbra.
Ishizaka, A. (2004b). Développement d’un système tutorial intelligent pour dériver des
priorités dans l’AHP. Berlin: http://www.dissertation.de.
Ishizaka, A. (2008). A Multicriteria approach with AHP and clusters for supplier
selection. In 15th international annual EurOMA conference. Groningen.
Ishizaka, A., Balkenborg, D., & Kaplan, T. (2010). Inﬂuence of aggregation and
measurement scale on ranking a compromise alternative in AHP. Journal of the
Operational Research Society, 62, 700–710.
Ishizaka, A., & Labib, A. (2009). Analytic hierarchy process and expert choice:
Beneﬁts and limitations. OR Insight, 22, 201–220.
Ishizaka, A., & Lusti, M. (2004). An expert module to improve the consistency of AHP
matrices. International Transactions in Operational Research, 11, 97–105.
Ishizaka, A., & Lusti, M. (2006). How to derive priorities in AHP: A comparative
study. Central European Journal of Operations Research, 14, 387–400.
Ji, P., & Jiang, R. (2003). Scale transitivity in the AHP. Journal of the Operational
Research Society, 54, 896–905.
Johnson, C., Beine, W., & Wang, T. (1979). Right-left asymmetry in an eigenvector
ranking procedure. Journal of Mathematical Psychology, 19, 61–64.
Jones, D., & Mardle, S. (2004). A distance-metric methodology for the derivation of
weights from a pairwise comparison matrix. Journal of the Operational Research
Society, 55, 869–875.
Kahraman, C., & Kaya, I. (2010). A fuzzy multicriteria methodology for selection
among energy alternatives. Expert Systems with Applications, Corrected Proof,
doi: 10.1016/j.eswa.2010.1002.1095.
Kainulainen, T., Leskinen, P., Korhonen, P., Haara, A., & Hujala, T. (2009). A statistical
approach to assessing interval scale preferences in discrete choice problems.
Journal of the Operational Research Society, 60, 252–258.
Karapetrovic, S., & Rosenbloom, E. (1999). A quality control approach to
consistency paradoxes in AHP. European Journal of Operational Research, 119,
704–718.
Khosla, R., Goonesekera, T., & Chu, M.-T. (2009). Separating the wheat from the
chaff: An intelligent sales recruitment and benchmarking system. Expert
Systems with Applications, 36, 3017–3027.
Kumar, S., & Vaidya, O. (2006). Analytic hierarchy process: An overview of
applications. European Journal of Operational Research, 169, 1–29.
Kwiesielewicz, M., & van Uden, E. (2004). Inconsistent and contradictory
judgements in pairwise comparison method in AHP. Computers and Operations
Research, 31, 713–719.
Labib, A.W. (2011). A supplier selection model: A comparison of fuzzy logic and the
analytic hierarchy process, International Journal of Production Research, 49, in
press.
Labib, A., & Shah, J. (2001). Management decisions for a continuous improvement
process in industry using the analytical hierarchy process. Journal of Work Study,
50, 189–193.
Labib, A., Williams, G., & O’Connor, R. (1996). Formulation of an appropriate
productive maintenance strategy using multiple criteria decision making.
Maintenance Journal, 11, 66–75.

Lai, W.-H., & Tsai, C.-T. (2009). Fuzzy rule-based analysis of ﬁrm’s technology
transfer in Taiwan’s machinery industry. Expert Systems with Applications, 36,
12012–12022.
Lane, E., & Verdini, W. (1989). A consistency test for AHP decision makers. Decision
Sciences, 20, 575–590.
Lee, S.-H. (2010). Using fuzzy AHP to develop intellectual capital evaluation model
for assessing their performance contribution in a university. Expert Systems with
Applications, Corrected Proof, doi: 10.1016/j.eswa.2009.1012.1020.
Leskinen, P., & Kangas, J. (2005). Rank reversal in multi-criteria decision analysis
with statistical modelling of ratio-scale pairwise comparisons. Journal of the
Operational Research Society, 56, 855–861.
Li, S., & Li, J. Z. (2009). Hybridising human judgment, AHP, simulation and a fuzzy
expert system for strategy formulation under uncertainty. Expert Systems with
Applications, 36, 5557–5564.
Li, T.-S., & Huang, H.-H. (2009). Applying TRIZ and Fuzzy AHP to develop innovative
design for automated manufacturing systems. Expert Systems with Applications,
36, 8302–8312.
Li, Y., Tang, J., & Luo, X. (2010). An ECI-based methodology for determining the ﬁnal
importance ratings of customer requirements in MP product improvement.
Expert Systems with Applications, Uncorrected Proof, doi: 10.1016/
j.eswa.2010.1002.1100.
Liberatore, M., & Nydick, R. (2008). The analytic hierarchy process in medical and
health care decision making: A literature review. European Journal of Operational
Research, 189, 194–207.
Lim, K., & Swenseth, S. (1993). An iterative procedure for reducing problem size in
large scale AHP problems. European Journal of Operational Research, 67, 64–74.
Limam Mansar, S., Reijers, H., & Ounnar, F. (2009). Development of a decisionmaking strategy to improve the efﬁciency of BPR. Expert Systems with
Applications, 36, 3248–3262.
Lin, C.-L., Chen, C.-W., & Tzeng, G.-H. (2010). Planning the development strategy for
the mobile communication package based on consumers’ choice preferences.
Expert Systems with Applications, Corrected Proof, doi: 10.1016/
j.eswa.2009.1011.1009.
Lin, C. (2007). A revised framework for deriving preference values from pairwise
comparison matrices. European Journal of Operational Research, 176, 1145–1150.
Liu, C.-C., & Chen, S.-Y. (2009). Prioritization of digital capital measures in recruiting
website for the national armed forces. Expert Systems with Applications, 36,
9415–9421.
Lootsma, F. (1989). Conﬂict resolution via pairwise comparison of concessions.
European Journal of Operational Research, 40, 109–116.
Lootsma, F. (1993). Scale sensitivity in the multiplicative AHP and SMART. Journal of
Multi-Criteria Decision Analysis, 2, 87–110.
Lootsma, F. (1996). A model for the relative importance of the criteria in the
multiplicative AHP and SMART. European Journal of Operational Research, 94,
467–476.
Ma, D., & Zheng, X. (1991). 9/9-9/1 Scale method of AHP. In Second international
symposium on AHP (Vol. 1, pp. 197–202). Pittsburgh.
Madu, C., & Kuei, C.-H. (1995). Stability analyses of group decision making.
Computers and Industrial Engineering, 28, 881–892.
Masuda, T. (1990). Hierarchical sensitivity analysis of priority used in analytic
hierarchy process. International Journal of Systems Science, 21, 415–427.
Mikhailov, L. (2004). Group prioritization in the AHP by fuzzy preference
programming method. Computers and Operations Research, 31, 293–301.
Mikhailov, L., & Singh, M. G. (1999). Comparison analysis of methods for deriving
priorities in the analytic hierarchy process. In IEEE international conference on
systems, man, and cybernetics (Vol. 1, pp. 1037–1042). Tokyo.
Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on
our capacity for processing information. Psychological Review, 63, 81–97.
Miller, J. (1966). The assessment of worth: A systematic procedure and its experimental
validation. MIT.
Miller, J. (1969). Assessing alternative transportation systems. In Memorandum RM5865-DOR. The RAND Corporation.
Miller, J. (1970). Professional decision-making: A procedure for evaluation complex
alternatives. New York: Praeger Publishers.
Millet, I., & Harker, P. (1990). Globally effective questioning in the analytic hierarchy
process. European Journal of Operational Research, 48, 88–97.
Millet, I., & Saaty, T. (2000). On the relativity of relative measures-accommodating
both rank preservation and rank reversals in the AHP. European Journal of
Operational Research, 121, 205–212.
Millet, I., & Schoner, B. (2005). Incorporating negative values into the analytic
hierarchy process. Computers and Operations Research, 32, 3163–3173.
Naghadehi, M. Z., Mikaeil, R., & Ataei, M. (2009). The application of fuzzy analytic
hierarchy process (FAHP) approach to selection of optimum underground
mining method for Jajarm Bauxite Mine, Iran. Expert Systems with Applications,
36, 8218–8226.
Niaraki, A. S., & Kim, K. (2009). Ontology based personalized route planning system
using a multi-criteria decision making approach. Expert Systems with
Applications, 36, 2250–2259.
O’Leary, D. (1993). Determining differences in expert judgment: Implications for
knowledge acquisition and validation. Decision Sciences, 24, 395–408.
Omkarprasad, V., & Sushil, K. (2006). Analytic hierarchy process: An overview of
applications. European Journal of Operational Research, 169, 1–29.
Önüt, S., Efendigil, T., & Soner Kara, S. (2009). A combined fuzzy MCDM approach for
selecting shopping center site: An example from Istanbul, Turkey. Expert
Systems with Applications, Uncorrected Proof, doi: 10.1016/j.eswa.2009.
1006.1080.

A. Ishizaka, A. Labib / Expert Systems with Applications 38 (2011) 14336–14345
Pan, N. (2009). Selecting an appropriate excavation construction method based on
qualitative assessments. Expert Systems with Applications, 36, 5481–5490.
Peláez, P., & Lamata, M. (2003). A new measure of consistency for positive reciprocal
matrices. Computers and Mathematics with Applications, 46, 1839–1845.
Pérez, J. (1995). Some comments on Saaty’s AHP. Management Science, 41,
1091–1095.
Petkov, D., & Mihova-Petkova, O. (1997). The analytic hierarchy process and
systems thinking. In 13th international MCDM conference (Vol. 465, pp. 243–
252). Cape Town Springer.
Petkov, D., Petkova, O., Andrew, T., & Nepal, T. (2007). Mixing multiple criteria
decision making with soft systems thinking techniques for decision support in
complex situations. Decision Support Systems, 43, 1615–1629.
Pöyhönen, M., Hamalainen, R., & Salo, A. (1997). An experiment on the numerical
modelling of verbal ratio statements. Journal of Multi-Criteria Decision Analysis,
6, 1–10.
Ramanathan, R., & Ganesh, L. (1994). Group preference aggregation methods
employed in AHP: An evaluation and an intrinsic process for deriving members’
weightages. European Journal of Operational Research, 79, 249–265.
Roy, B. (1996). Multicriteria methodology for decision analysis. Dordrecht: Kluwer
Academic Publishers.
Saaty, T. (1972). An eigenvalue allocation model for prioritization and planning. In
Working paper, Energy Management and Policy Center: University of
Pennsylvania.
Saaty, T. (1977). A scaling method for priorities in hierarchical structures. Journal of
Mathematical Psychology, 15, 234–281.
Saaty, T. (1980). The analytic hierarchy process. New York: McGraw-Hill.
Saaty, T. (1986). Axiomatic foundation of the analytic hierarchy process.
Management Science, 32, 841–855.
Saaty, T. (1990). An exposition of the AHP in reply to the paper ‘‘Remarks on the
Analytic Hierarchy Process’’. Management Science, 36, 259–268.
Saaty, T. (1991). Response to holder’s comments on the analytic hierarchy process.
Journal of the Operational Research Society, 42, 909–929.
Saaty, T. (1994). Highlights and critical points in the theory and application of the
analytic hierarchy process. European Journal of Operational Research, 74,
426–447.
Saaty, T. (2003). Decision-making with the AHP: Why is the principal eigenvector
necessary? European Journal of Operational Research, 145, 85–91.
Saaty, T. (2006). Rank from comparisons and from ratings in the analytic hierarchy/
network processes. European Journal of Operational Research, 168, 557–570.
Saaty, T., & Forman, E. (1992). The Hierarchon: A dictionary of hierarchies (Vol. V).
Pittsburgh: RWS Publications.
Saaty, T., & Hu, G. (1998). Ranking by eigenvector versus other methods in the
analytic hierarchy process. Applied Mathematics Letters, 11, 121–125.
Saaty, T., & Ozdemir, M. (2003). Negative priorities in the analytic hierarchy process.
Mathematical and Computer Modelling, 37, 1063–1075.
Saaty, T., & Takizawa, M. (1986). Dependence and Independence: From Linear
Hierarchies to Nonlinear Networks. European Journal of Operational Research, 26,
229–237.
Saaty, T., & Vargas, L. (1984a). Comparison of eigenvalue, logarithmic least squares
and least squares methods in estimating ratios. Mathematical Modeling, 5,
309–324.
Saaty, T., & Vargas, L. (1984b). Inconsistency and rank preservation. Journal of
Mathematical Psychology, 28, 205–214.
Saaty, T., & Vargas, L. (1984c). The legitimacy of rank reversal. Omega, 12, 513–516.
Saaty, T., & Vargas, L. (2007). Dispersion of group judgments. Mathematical and
Computer Modelling, 46, 918–925.
Saaty, T. L., & Vargas, L. G. (2005). The possibility of group welfare functions.
International Journal of Information Technology and Decision Making, 4, 167–176.
Salo, A., & Hamalainen, R. (1997). On the measurement of preference in the analytic
hierarchy process. Journal of Multi-Criteria Decision Analysis, 6, 309–319.
Schoner, B., & Wedley, W. (1989). Ambiguous criteria weights in AHP:
Consequences and solutions. Decision Sciences, 20, 462–475.
Schoner, B., Wedley, W., & Choo, E. (1993). A uniﬁed approach to AHP with linking
pins. European Journal of Operational Research, 64, 384–392.
Seçme, N. Y., Bayrakdaroglu, A., & Kahraman, C. (2009). Fuzzy performance
evaluation in Turkish banking sector using analytic hierarchy process and
TOPSIS. Expert Systems with Applications, 36, 11699–11709.
Sen, C. G., & ÇInar, G. (2010). Evaluation and pre-allocation of operators with
multiple skills: A combined fuzzy AHP and max–min approach. Expert Systems
with Applications, 37, 2043–2053.
Shen, Y., Hoerl, A., & McConnell, W. (1992). An incomplete design in the analytic
hierarchy process. Mathematical and Computer Modelling, 16, 121–129.
Shim, J. (1989). Bibliography research on the analytic hierarchy process (AHP).
Socio-Economic Planning Sciences, 23, 161–167.
Sipahi, S., & Timor, M. (2010). The analytic hierarchy process and analytic network
process: An overview of applications. Management Decision, 48, 775–808.

14345

Stam, A., & Duarte Silva, P. (2003). On multiplicative priority rating methods for
AHP. European Journal of Operational Research, 145, 92–108.
Stein, W., & Mizzi, P. (2007). The harmonic consistency index for the analytic
hierarchy process. European Journal of Operational Research, 177, 488–497.
Stevens, S. (1957). On the psychophysical law. Psychological Review, 64, 153–181.
Stillwell, W., von Winterfeldt, D., & John, R. (1987). Comparing hierarchical and nonhierarchical weighting methods for eliciting multiattribute value models.
Management Science, 33, 442–450.
Su, S., Yu, J., & Zhang, J. (2010). Measurements study on sustainability of China’s
mining
cities.
Expert
Systems
with
Applications,
doi:
10.1016/
j.eswa.2010.1002.1140.
Thurstone, L. (1927). A law of comparative judgments. Psychological Review, 34,
273–286.
Triantaphyllou, E. (2001). Two new cases of rank reversals when the AHP and some
of its additive variants are used that do not occur with the multiplicative AHP.
Journal of Multi-Criteria Decision Analysis, 10, 11–25.
Triantaphyllou, E., & Sánchez, A. (1997). A sensitivity analysis approach for some
deterministic multi-criteria decision-making methods. Decision Sciences, 28,
151–194.
Troutt, M. (1988). Rank reversal and the dependence of priorities on the underlying
MAV function. Omega, 16, 365–367.
Tseng, Y.-F., & Lee, T.-Z. (2009). Comparing appropriate decision support of human
resource practices on organizational performance with DEA/AHP model. Expert
Systems with Applications, 36, 6548–6558.
Tummala, V., & Wan, Y. (1994). On the mean random inconsistency index of the
analytic hierarchy process (AHP). Computers and Industrial Engineering, 27,
401–404.
Van den Honert, R. (1998). Stochastic group preference modelling in the
multiplicative AHP: A model of group consensus. European Journal of
Operational Research, 110, 99–111.
Van Den Honert, R., & Lootsma, F. (1997). Group preference aggregation in the
multiplicative AHP The model of the group decision process and Pareto
optimality. European Journal of Operational Research, 96, 363–370.
Vargas, L. (1985). A Rejoinder. Omega, 13, 249.
Vargas, L. (1990). An overview of the analytic hierarchy process and its applications.
European Journal of Operational Research, 48, 2–8.
Vargas, L. (1997). Comments on Barzilai and Lootsma why the multiplicative AHP is
invalid: A practical counterexample. Journal of Multi-Criteria Decision Analysis, 6,
169–170.
Vidal, L.-A., Sahin, E., Martelli, N., Berhoune, M., & Bonan, B. (2010). Applying AHP to
select drugs to be produced by anticipation in a chemotherapy compounding
unit. Expert Systems with Applications, 37, 1528–1534.
Wang, H. S., Che, Z. H., & Wu, C. (2010). Using analytic hierarchy process and particle
swarm optimization algorithm for evaluating product plans. Expert Systems with
Applications, 37, 1023–1034.
Wang, T.-Y., & Yang, Y.-H. (2009). A fuzzy model for supplier selection in quantity
discount environments. Expert Systems with Applications, 36, 12179–12187.
Wang, Y., Chin, K.-S., & Luo, Y. (2009). Aggregation of direct and indirect judgements
in pairwise comparison matrices with a re-examination of the criticisms by
Bana e Costa and Vansnick. Information Sciences, 179, 329–337.
Wang, Y., & Elhag, T. (2006). An approach to avoiding rank reversal in AHP. Decision
Support Systems, 42, 1474–1480.
Wang, Y., & Luo, Y. (2009). On rank reversal in decision analysis. Mathematical and
Computer Modelling, 49, 1221–1229.
Webber, S., Apostolou, B., & Hassell, J. (1996). The sensitivity of the analytic
hierarchy process to alternative scale and cue presentations. European Journal of
Operational Research, 96, 351–362.
Weber, M., Eisenführ, F., & von Winterfeldt, D. (1988). The effects of spitting
attributes on weights in multiattribute utility measurement. Management
Science, 34, 431–445.
Wedley, W. (1993). Consistency prediction for incomplete AHP matrices.
Mathematical and Computer Modelling, 17, 151–161.
Wedley, W., Schoner, B., & Tang, T. (1993). Starting rules for incomplete
comparisons in the analytic hierarchy process. Mathematical and Computer
Modelling, 17, 93–100.
Wu, C.-R., Lin, C.-T., & Lin, Y.-F. (2009). Selecting the preferable bancassurance
alliance strategic by using expert group decision technique. Expert Systems with
Applications, 36, 3623–3629.
Yang, C.-L., Chuang, S.-P., & Huang, R.-H. (2009). Manufacturing evaluation system
based on AHP/ANP approach for wafer fabricating industry. Expert Systems with
Applications, 36, 11369–11377.
Yokoyama, M. (1921). The Nature of the affective judgment in the method of paired
comparison. The American Journal of Psychology, 32, 357–369.
Zahedi, F. (1986). The analytic hierarchy process: A survey of the method and its
applications. Interface, 16, 96–108.

