Expert Systems with Applications 37 (2010) 1784‚Äì1789

Contents lists available at ScienceDirect

Expert Systems with Applications
journal homepage: www.elsevier.com/locate/eswa

Grey system theory-based models in time series prediction
Erdal Kayacan a,*, Baris Ulutas b, Okyay Kaynak a
a
b

Bogazici University, Electric and Electronics Engineering Department, Bebek, 34342 Istanbul, Turkey
University of Victoria, Department of Mechanical Engineering, P.O. Box 3055, Stn. CSC, Victoria, BC, V8W 3P6 Canada

a r t i c l e

i n f o

Keywords:
Grey models
Error corrected grey models
Time series prediction
GM(1,1)

a b s t r a c t
Being able to forecast time series accurately has been quite a popular subject for researchers both in the
past and at present. However, the lack of ability of conventional analysis methods to forecast time series
that are not smooth leads the scientists and researchers to resort to various forecasting models that have
different mathematical backgrounds, such as artiÔ¨Åcial neural networks, fuzzy predictors, evolutionary
and genetic algorithms. In this paper, the accuracies of different grey models such as GM(1,1), Grey Verhulst model, modiÔ¨Åed grey models using Fourier Series is investigated. Highly noisy data, the United
States dollar to Euro parity between the dates 01.01.2005 and 30.12.2007, are used to compare the performances of the different models. The simulation results show that modiÔ¨Åed grey models have higher
performances not only on model Ô¨Åtting but also on forecasting. Among these grey models, the modiÔ¨Åed
GM(1,1) using Fourier series in time is the best in model Ô¨Åtting and forecasting.
√ì 2009 Elsevier Ltd. All rights reserved.

1. Introduction
A time series is a collection of data points which are generally
sampled equally in time intervals. Time series prediction refers
to the process by which the future values of a system is forecasted
based on the information obtained from the past and current data
points. Generally, a pre-deÔ¨Åned mathematical model is used to
make accurate predictions. Time series prediction models are
widely used in Ô¨Ånancial area, such as predicting stock price indexes, foreign currency exchange rates (FX rates) and so on. The
ability to do prediction with a reasonable accuracy can change
the economic policy of large companies and governments and ensure a more reasonable behavior by the Ô¨Ånancial actors.
Statistical and artiÔ¨Åcial intelligence (soft computing) based approaches are the two main techniques for time series prediction
seen in the literature. While AR (Auto Regressive), MA (Moving
Average), ARMA (Auto Regressive Moving Average), ARIMA (Auto
Regressive Integrated Moving Average) and Box‚ÄìJenkins models
(Box & Jenkins, 1976) can be mentioned as statistical models, neural network (NN) based models (Quah & Srinivasan, 1999; Rabiner,
1989; Roman & Jameel, 1996) are widely used as an artiÔ¨Åcial intelligence-based approach, back propagation being the most widely
used technique for updating the parameters of the model. However, not only are the statistical models not as accurate as the neural network-based approaches for nonlinear problems, they may be
too complex to be used in predicting future values of a time series.
* Corresponding author. Tel.: +90 535 418 0975; fax: +90 212 287 2465.
E-mail addresses: erdal.kayacan@ieee.org (E. Kayacan), bulutas@uvic.ca (B.
Ulutas), okyay.kaynak@boun.edu.tr (O. Kaynak).
0957-4174/$ - see front matter √ì 2009 Elsevier Ltd. All rights reserved.
doi:10.1016/j.eswa.2009.07.064

One major criticism about the NN model is that it demands a great
deal of training data and relatively long training period for robust
generalization (Jo, 2003). Other intelligent approaches seen in the
literature for the analysis of time series include Linear regression,
Kalman Ô¨Åltering (Ma & Teng, 2004), fuzzy systems (Kandel,
1991), hidden markov models (Rabiner, 1989) and the support vector machines (Cao, 2003). Some hybrid models are also seen in the
literature: in Versace, Bhatt, Hinds, and Shiffer (2004), a combination of genetic algorithms and neural networks has been proposed.
In Huang and Tsai (2009), support vector regression (SVR) and a
self-organizing feature map (SOFM) technique have been hybridized to reduce the cost of training time and to improve prediction
accuracies. High-order fuzzy logical relationships and genetic-simulated annealing techniques are combined in Lee, Wang, and Chen
(2008) for temperature prediction and the Taiwan futures exchange (TAIFEX) forecasting, where genetic-simulated annealing
techniques have been used to adjust the length of each interval
in the universe of discourse to increase the forecasting accuracy.
FX rates are highly nonlinear, stochastic and highly non-stationary Ô¨Ånancial time series, and as such, it is very difÔ¨Åcult to Ô¨Åt a model to them by the use conventional linear statistical methods or
artiÔ¨Åcial neural networks. In this paper, the use of grey prediction
theory is proposed to alleviate the problem.
Grey system theory is an interdisciplinary scientiÔ¨Åc area that
was Ô¨Årst introduced in early 1980s by Deng (1982). Since then,
the theory has become quite popular with its ability to deal with
the systems that have partially unknown parameters. As a superiority to conventional statistical models, grey models require only a
limited amount of data to estimate the behavior of unknown
systems (Deng, 1989).

E. Kayacan et al. / Expert Systems with Applications 37 (2010) 1784‚Äì1789

During the last two decades, the grey system theory has been
developed rapidly and caught the attention of many researchers.
It has been widely and successfully applied to various systems such
as social, economic, Ô¨Ånancial, scientiÔ¨Åc and technological, agricultural, industrial, transportation, mechanical, meteorological, ecological, hydrological, geological, medical, military, etc., systems.
Some research studies in Ô¨Ånancial area are as follows: In one study
(Wang, 2002), the combination of fuzziÔ¨Åcation techniques and the
grey system theory (GM(1,1) model with adaptive stepsize) is proposed to predict stock prices and it is shown that the approach is
very efÔ¨Åcient. In another study, the moving average autoregressive
exogenous (ARX) prediction model is combined with grey predictors for time series prediction in Huang and Jane (2009), and it is
proved that the hybrid method has a greater forecasting accuracy
than the GM(1,1) method. Another study (Chang & Tsai, 2008)
introduces a support vector regression grey model (SVRGM) which
combines support vector regression (SVR) learning algorithm and
grey system theory to obtain a better approach to time series prediction. In these studies and the others, it is seen that grey system
theory-based approaches can achieve good performance characteristics when applied to real-time systems, since grey predictors
adapt their parameters to new conditions as new outputs become
available. Because of this reason, grey predictors are more robust
with respect to noise and lack of modeling information when compared to conventional methods.
The spread of this new theory has taken place as follows: In
early 1990s, some universities located in Australia, China, Japan,
Taiwan, USA, have started offering courses on grey system theory. Chinese Grey System Association (CGSA) was established
in 1996. A conference on grey system theory and applications
is held by CGSA every year. For dissemination of research results,
an academic periodical; ‚Äò‚ÄòThe Journal of Grey System‚Äù is started
to be published in England in 1989. Additionally, more than
300 different academic periodicals accept and publish the grey
system related articles in the world (Liu & Lin, 1998). When
all the literature above is investigated, it can be seen that grey
system theory has aroused the interest of the scientists mostly
from the far eastern countries since it was introduced into the
scientiÔ¨Åc arena. Almost all the journal and conference papers
have been published by eastern scientists; the scientists from
the Western world have, to date, given only a limited attention
to this theory. Although a number of academic books and lecture
notes written in eastern languages can be found in the literature,
there are only two books in English which are also written by
eastern scientists.
In systems theory, a system can be deÔ¨Åned with a color that
represents the amount of clear information about that system.
For instance, a system can be called as a black box if its internal
characteristics or mathematical equations that describe its dynamics are completely unknown. On the other hand if the description
of the system is, completely known, it can be named as a white system. Similarly, a system that has both known and unknown information is deÔ¨Åned as a grey system. In real life, every system can be
considered as a grey system because there are always some uncertainties. Due to noise from both inside and outside of the system of
our concern (and the limitations of our cognitive abilities!), the
information we can reach about that system is always uncertain
and limited in scope (Lin & Liu, 2004).
There are many situations in which the difÔ¨Åculty of incomplete
or insufÔ¨Åcient information is faced. Even a simple motor control
system always contains some grey characteristics due to the
time-varying parameters of the system and the measurement difÔ¨Åculties. Similarly, it is difÔ¨Åcult to forecast the electricity consumption of a region accurately because of the various kinds of social
and economic factors. These factors are generally random and
make it difÔ¨Åcult to obtain an accurate model.

1785

2. Fundamental concepts of grey system theory
2.1. Grey system based prediction
Grey models predict the future values of a time series based
only on a set of the most recent data depending on the window size
of the predictor. It is assumed that all data values to be used in grey
models are positive, and the sampling frequency of the time series
is Ô¨Åxed. From the simplest point of view, grey models which will be
formulated below can be viewed as curve Ô¨Åtting approaches.
2.2. Generations of grey sequences
The main task of grey system theory is to extract realistic
governing laws of the system using available data. This process
is known as the generation of the grey sequence (Liu & Lin,
1998).
It is argued that even though the available data of the system,
which are generally white numbers, is too complex or chaotic, they
always contain some governing laws. If the randomness of the data
obtained from a grey system is somehow smoothed, it is easier to
derive any special characteristics of that system.
For instance, the following sequence that represents the price of
a product might be given:

X √∞0√û ¬º √∞820; 840; 835; 850; 890√û:
It is obvious that the sequence does not have a clear regularity.
If accumulating generation suggested in grey system theory is applied to this sequence, X √∞1√û is obtained which has a clear growing
tendency.

X √∞1√û ¬º √∞820; 1660; 2495; 3345; 4235√û:
2.3. GM(n,m) model
In grey systems theory, GM(n,m) denotes a grey model, where n
is the order of the difference equation and m is the number of variables. Although various types of grey models can be mentioned,
most of the previous researchers have focused their attention on
GM(1,1) models in their predictions because of its computational
efÔ¨Åciency. It should be noted that in real time applications, the
computational burden is the most important parameter after the
performance.
2.4. GM(1,1) model
GM(1,1) type of grey model is the most widely used in the literature, pronounced as ‚Äò‚ÄòGrey Model First Order One Variable‚Äù. This
model is a time series forecasting model. The differential equations
of the GM(1,1) model have time-varying coefÔ¨Åcients. In other
words, the model is renewed as the new data become available
to the prediction model.
The GM(1,1) model can only be used in positive data sequences
(Deng, 1989). In this paper, since all the primitive data points are
positive, grey models can be used to forecast the future values of
the primitive data points.
In order to smooth the randomness, the primitive data obtained
from the system to form the GM(1,1) is subjected to an operator,
named Accumulating Generation Operator (AGO) (Deng, 1989).
The differential equation (i.e. GM(1,1)) is solved to obtain the
n-step ahead predicted value of the system. Finally, using the predicted value, the Inverse Accumulating Generation Operator
(IAGO) is applied to Ô¨Ånd the predicted values of original data.
Consider a time sequence X √∞0√û that denotes the price of a
product in USD (see Fig. 1)

The price of a product (USD)

1786

E. Kayacan et al. / Expert Systems with Applications 37 (2010) 1784‚Äì1789
1

890

dx √∞t√û
√æ ax√∞1√û √∞t√û ¬º b:
dt

880

In above, ¬Ωa; b¬äT is a sequence of parameters that can be found as
follows:

870

√∞7√û

¬Ωa; b¬äT ¬º √∞BT B√û√Ä1 BT Y;
860

where

850
840

X=X(0)

830
820

√∞8√û

1

2

3

4

5

Y ¬º ¬Ωx√∞0√û √∞2√û; x√∞0√û √∞3√û; . . . ; x√∞0√û √∞n√û¬äT ;
3
2 √∞1√û
√Äz √∞2√û 1
6 √Äz√∞1√û √∞3√û 1 7
7
6
7
6
7
6
√Å
√Å
7:
B¬º6
7
6
√Å
√Å
7
6
7
6
4
√Å
√Å5
According to Eq. (7), the solution of x√∞1√û √∞t√û at time k:

Fig. 1. The original data set.

xp√∞1√û √∞k √æ 1√û ¬º x√∞0√û √∞1√û √Ä
n P 4;

√∞1√û

where X √∞0√û is a non-negative sequence and n is the sample size of
the data. When this sequence is subjected to the Accumulating Generation Operation (AGO), the following sequence X √∞1√û is obtained. It
is obvious that X √∞1√û is monotonically increasing (see Fig. 2).

X √∞1√û ¬º √∞x√∞1√û √∞1√û; x√∞1√û √∞2√û; . . . ; x√∞1√û √∞n√û√û;

n P 4;

√∞2√û

where

x√∞1√û √∞k√û ¬º

x√∞0√û √∞i√û;

k ¬º 1; 2; 3:::::; n:

!
b √Äak b
e √æ :
a
a

√∞11√û

To obtain the predicted value of the primitive data at time
(k + 1), the IAGO is used to establish the following grey model.
√∞0√û
x√∞0√û
p √∞k √æ 1√û ¬º x √∞1√û √Ä

!
b √Äak
e √∞1 √Ä ea √û
a

√∞12√û

and the predicted value of the primitive data at time (k + H):
√∞0√û
x√∞0√û
p √∞k √æ H√û ¬º x √∞1√û √Ä

k
X

√∞10√û

√Äz√∞1√û √∞n√û 1

Time(days)

X √∞0√û ¬º √∞x√∞0√û √∞1√û; x√∞0√û √∞2√û; . . . ; x√∞0√û √∞n√û√û;

√∞9√û

!
b √Äa√∞k√æH√Ä1√û
√∞1 √Ä ea √û:
e
a

√∞13√û

√∞3√û

i¬º1

2.5. The grey Verhulst model

The generated mean sequence Z √∞1√û of X √∞1√û is deÔ¨Åned as:

Z √∞1√û ¬º √∞z√∞1√û √∞1√û; z√∞1√û √∞2√û; . . . ; z√∞1√û √∞n√û√û;

√∞4√û

where z√∞1√û √∞k√û is the mean value of adjacent data, i.e.

z√∞1√û √∞k√û ¬º 0:5x√∞1√û √∞k√û √æ 0:5x√∞1√û √∞k √Ä 1√û;

k ¬º 2; 3; . . . ; n:

√∞5√û

The least square estimate sequence of the grey difference equation of GM(1,1) is deÔ¨Åned as follows (Deng, 1989):

x√∞0√û √∞k√û √æ az√∞1√û √∞k√û ¬º b:

√∞6√û

The price of a product(USD)

The whitening equation is therefore, as follows:

The Verhulst model was Ô¨Årst introduced by a German biologist
Pierre Franois Verhulst. The main purpose of Velhulst model is to
limit the whole development for a real system and it is effective
in describing some increasing processes, such as an S-curve which
has a saturation region.
The Grey Verhulst model can be deÔ¨Åned as (Wen & Huang,
2004):
√∞1√û

dx
√æ ax√∞1√û ¬º b√∞x√∞1√û √û2 :
dx

√∞14√û

Grey difference equation of Eq. (14) is

x√∞0√û √∞k√û √æ az√∞1√û √∞k√û ¬º b√∞z√∞1√û √∞k√û√û2 ;

√∞15√û

x√∞0√û √∞k√û ¬º √Äaz√∞1√û √∞k√û √æ b√∞z√∞1√û √∞k√û√û2 :

√∞16√û

4500

Similar to the GM(1,1) model

4000

¬Ωa; b¬äT ¬º √∞BT B√û√Ä1 BT Y;

3500

where

Y ¬º ¬Ωx√∞0√û √∞2√û; x√∞0√û √∞3√û; . . . ; x√∞0√û √∞n√û¬äT ;
3
2
√Äz√∞1√û √∞2√û √∞z√∞1√û √∞2√û√û2
7
6 √∞1√û
6 √Äz √∞3√û √∞z√∞1√û √∞3√û√û2 7
7
6
7
6
√Å
√Å
7
6
B¬º6
7:
7
6
√Å
√Å
7
6
7
6
√Å
√Å
5
4
2
√∞1√û
√∞1√û
√Äz √∞n√û √∞z √∞n√û√û

3000
2500

X=X(1)

2000
1500
1000
500
1

2

3

Time (days)
Fig. 2. The accumulated data set.

√∞17√û

4

5

√∞18√û

√∞19√û

The solution of x√∞1√û √∞t√û at time k:

xp√∞1√û √∞k √æ 1√û ¬º

ax√∞0√û √∞1√û
√∞0√û

√∞0√û

bx √∞1√û √æ √∞a √Ä bx √∞1√û√ûeak

:

√∞20√û

1787

E. Kayacan et al. / Expert Systems with Applications 37 (2010) 1784‚Äì1789

Applying the IAGO, the solution of x√∞0√û √∞t√û at time k:

Eq. (25) can be rewritten as follows:

√∞0√û

x√∞0√û
p √∞k√û ¬º

ax√∞0√û √∞1√û√∞a √Ä bx √∞1√û√û
√∞0√û

√∞0√û

√∞bx √∞1√û √æ √∞a √Ä bx
√É

√∞1 √Ä ea √ûea√∞k√Ä2√û
√∞0√û

√∞0√û Ô¨É PC

√∞1√û√ûea√∞k√Ä1√û √û

√∞0√û

√∞bx √∞1√û √æ √∞a √Ä bx √∞1√û√ûea√∞k√Ä2√û √û

√∞26√û

P and C matrixes can be deÔ¨Åned as follows:

√∞21√û

:

As can be seen, in Eq. (21), if a < 0, then

a
lim x√∞1√û
p √∞k √æ 1√û ! :
b

√Ä √Å
√Ä √Å
√Ä
√Å
√Ä
√Å
1=2 cos 2 2Tp sin 2 2Tp cos 2 2pT 2 sin 2 2pT 2
√Ä
√Å
√Ä
√Å
√Ä
√Å
√Ä
6 1=2 cos 3 2p sin 3 2p cos 3 2p2 sin 3 2p2√Å
6
T
T
T
T
P ¬º6
4 √Å√Å√Å
√Å√Å√Å
√Å√Å√Å
√Å√Å√Å
√Å√Å√Å
√Ä 2p√Å
√Ä 2p√Å
√Ä 2p2√Å
√Ä 2p2√Å
1=2 cos n T sin n T cos n T sin n T
2

√Ä
√Å
√Ä
√Å3
√Å√Å√Å cos 2 2Tpz sin 2 2Tpz
√Ä 2pz√Å
√Ä 2pz√Å 7
√Å√Å√Å cos 3 T sin 3 T 7
7;
5
√Å√Å√Å
√Å√Å√Å
√Å√Å√Å
√Ä 2pz√Å
√Ä 2pz√Å
√Å√Å√Å cos n T sin n T
√∞27√û

k!1

It means that the saturation point in Eq. (20) is ba which limits
√∞0√û
the prediction value. It is also the saturation point of xp √∞k√û (Wen
& Huang, 2004).
√∞1√û
√∞1√û
When k is sufÔ¨Åciently large, xp √∞k √æ 1√û and xp √∞k√û will be very
close. Because of this feature of grey Verhulst model, it is commonly used to describe and to predict processes with a saturation
region.

T

C ¬º ¬Ω a0 a1 b1 a2 b2 √Å√Å√Å an bn ¬ä :

One can use least-squares method to solve the Eq. (26), and calculate the matrix C:

C Ô¨É √∞PT P√û√Ä1 PT √∞0√û :

√∞29√û

Fourier series correction can be obtained as follows:
√∞0√û
√∞0√û
x√∞0√û
pf √∞k√û ¬º xp √∞k√û √Ä p √∞k√û;

2.6. GM(1,1) rolling model
GM(1,1) rolling model is based on the forward data of sequence
to build the GM(1,1). For instance, using x√∞0√û √∞k√û; x√∞0√û √∞k √æ 1√û; x√∞0√û
√∞k √æ 2√û and x√∞0√û √∞k √æ 3√û, the model predicts the value of the next
point x√∞0√û √∞k √æ 4√û. In the next steps, the Ô¨Årst point is always shifted
to the second. It means that x√∞0√û √∞k √æ 1√û; x√∞0√û √∞k √æ 2√û; x√∞0√û √∞k √æ 3√û and
x√∞0√û √∞k √æ 4√û are used to predict the value of x√∞0√û √∞k √æ 5√û. This procedure is repeated till the end of the sequence and this method is
called rolling check (Wen, 2004).
GM(1,1) rolling model is used to predict the long continuous
data sequences such as the outputs of a system, price of a speciÔ¨Åc
product, trend analysis for Ô¨Ånance statements or social parameters.

√∞28√û

k ¬º 2; 3; . . . n √æ 1:

√∞30√û

3.2. ModiÔ¨Åcation of GM(1,1) model using fourier series in time
In order to denote the residual time series, the difference be√∞0√û
tween the real time k and the model Ô¨Åtted kp √∞k√û is obtained as follows (Guo et al., 2005):

q√∞0√û ¬º √∞q√∞0√û √∞2√û; q√∞0√û √∞3√û; . . . q√∞0√û √∞n√û√û;

√∞31√û

where
√∞0√û

q√∞0√û √∞k√û ¬º k √Ä kp √∞k√û;
√∞0√û

kp √∞k√û ¬º 1 √Ä
3. Error modiÔ¨Åcation of grey models

1
ln
a

k ¬º 2; 3 . . . n;

√∞0√û
xp √∞k√û
√Ç
√É
x√∞0√û √∞1√û √Ä ba √∞1

√Ä ea √û

√∞32√û

!
;

k ¬º 2; 3 . . . n:

√∞33√û

Eq. (32) can be expressed in the Fourier series as follows:
In order to improve the modeling accuracy of grey models, several remedies have been discussed in the literature (Tan & Chang,
1996; Tan & Lu, 1996; Guo, Song, & Ye, 2005). In this study, fourier
series have been used to modify the grey models.

q√∞0√û √∞k√û Ô¨É

3.1. ModiÔ¨Åcation of GM(1,1) model using fourier series of error
residuals

Similar to the derivations in Section 3.2, Fourier series correction in time domain can be obtained as follows (Guo et al., 2005):

Consider the X √∞0√û sequence in Eq. (1) and the predicted values
given by the GM(1,1):

kpf √∞k√û ¬º k √Ä q√∞0√û √∞k√û;

√∞0√û
x√∞0√û
p √∞k √æ 1√û ¬º x √∞1√û √Ä

!
b √Äak
e √∞1 √Ä ea √û
a

√∞22√û

√∞23√û

where

√∞0√û √∞k√û ¬º x√∞0√û √∞k√û √Ä x√∞0√û
p √∞k√û;

k ¬º 2; 3 . . . ; n:

√∞24√û

The error residuals in (24) can be expressed in Fourier series as
follows:

√∞0√û √∞k√û Ô¨É




!
z
X
1
2pi
2p i
ai cos
a0 √æ
k √æ bi sin
k ;
2
T
T
i¬º1



n√Ä1
T ¬º n √Ä 1 and z ¬º
√Ä 1:
2

¬º 2; 3 . . . n:

√∞0√û

k
√∞34√û

k ¬º 2; 3; . . . n:

√∞35√û

4. Simulation results
4.1. The data

then, the error sequence of X √∞0√û can be deÔ¨Åned as:

√∞0√û ¬º √∞√∞0√û √∞2√û; √∞0√û √∞3√û; . . . ; √∞0√û √∞n√û√û;




!
z
X
1
2pi
2pi
ai cos
a0 √æ
k √æ bi sin
k ;
2
T
T
i¬º1

k ¬º 2; 3 . . . n;

The prediction of the foreign currency exchange rates (FX rates)
is a very important topic in Ô¨Ånancial area. The estimated daily trading volume of FX rates is about 1 trillion US dollars (Hussain,
Knowles, Lisboa, & El-Deredy, 2008) On the other hand, it is very
difÔ¨Åcult to develop good mathematical models and thus make
accurate predictions for FX rates, because of the fact that the statistical properties of the data change over time (Magdon-ismail, Nicholson, & Abu-mustafa, 1998).
Time series prediction in Ô¨Ånancial area is generally very difÔ¨Åcult
because of the factors listed below (Hussain et al., 2008):

√∞25√û

It is obvious that T will be an integer number and z will be selected as an integer number (Guo et al., 2005).

1. The statistical properties of the data change over time
(Nonstationary).
2. It is difÔ¨Åcult to use mathematical prediction models with linear
parameters (Nonlinearity).
3. Random, day-to-day variations (Highly noisy).

1788

E. Kayacan et al. / Expert Systems with Applications 37 (2010) 1784‚Äì1789

Eqs. (37)‚Äì(39) are the three accuracy evaluation standards that
are used to examine the accuracy of the models in this study.

1.5
1.45

 ¬º x√∞0√û √∞k√û √Ä x√∞0√û
p √∞k√û;
j√∞k√ûj

2007

Euro to Dolar parity

1.4

RPE ¬º

x√∞0√û √∞k√û

1.35

ARPE ¬º

2006

1.3
1.25

1
n√Ä1

n
X
k¬º2

√∞38√û

j√∞k√ûj
;
x√∞0√û √∞k√û

√∞39√û

4.4. The different grey models used in this study

1.15

In order to test the accuracies of different grey models, various
models are formed in this paper:
0

50

100

150

200

250

300

day

 GM(1,1): GM(1,1) model.
 EFGM: ModiÔ¨Åed GM(1,1) model using modeling errors and Fourier series.
 TFGM: ModiÔ¨Åed GM(1,1) model at time domain using Fourier
series.
 GVM: Grey Verhulst model.
 EFGVM: ModiÔ¨Åed Grey Verhulst model using modeling errors
and Fourier series.
 TFGVM: ModiÔ¨Åed Grey Verhulst model at time domain using
Fourier series.

Fig. 3. The data set.

Fig. 3 shows Euro to the United States dollar parity between the
dates 01.01.2005 and 30.12.2007. The time series have been
formed using the daily rates which are the data points at the end
of the each day. It can be seen that the data are highly nonlinear
and nonstationary.
4.2. Moving Average Filter (MAF)
MAF is the most common Ô¨Ålters in signal processing in order to
reduce the random noise because of its simple structure. In this
study, a MAF with different window sizes is used to make the
primitive data smoother. By this way, the effect of MAFs on different grey models are investigated. The impulse response of the Ô¨Ålter
used in this study is as follows:

h¬Ωn¬ä ¬º

100%;

where ; RPE and ARPE represent the error, the relative percentage
error and the average relative percentage error, respectively.

2005

1.2

1.1

√∞37√û

1
1
1
1
1
d¬Ωn¬ä √æ d¬Ωn √Ä 1¬ä √æ d¬Ωn √Ä 2¬ä √æ d¬Ωn √Ä 3¬ä √æ d¬Ωn √Ä 4¬ä:
5
5
5
5
5

4.5. Simulation results
Table 1 shows that GM(1,1) model is better on both interpolation and extrapolation when compared to GVM model without
using a Ô¨Ålter. ModiÔ¨Åed GM(1,1) models, TFGM(1,1) and EFGM(1,1),
are giving better performances when compared to GM(1,1) model
as expected. However, the performance of interpolation has increased more than the performance of extrapolation.
Tables 2 and 3 show that while the performances of GM(1,1)
models are decreasing, the performances of GVM models are
increasing when a moving average Ô¨Ålter (MAF) has been used.
However, when the window size of the MAF is increased, the performance of GM(1,1) models has been decreased dramatically. This
is because while GVM models give better performances S-type

√∞36√û

4.3. Model accuracy examination
To demonstrate the accuracy of the proposed forecasting mod√∞0√û
els, the actual value x√∞0√û √∞k√û and the forecasted value xp √∞k√û can be
compared.

Table 1
The accuracy of the models with GM and GVM window size = 5.
The dates

The standards

GM

EFGM

TFGM

GVM

EFGVM

TFGVM

01.01.2005‚Äì01.01.2006

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.1517
0.5396

0.0804
0.5110

0.0804
0.5110

1.5634
29.8774

0.8625
28.9847

0.1682
4.9612

01.01.2006‚Äì01.01.2007

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.1285
0.4386

0.0699
0.4207

0.0699
0.4206

2.5034
12.2847

1.4239
12.1073

0.1418
6.0883

01.01.2007‚Äì01.01.2008

ARPE(%) (Int.)
ARPE (%) (Ext.)

0.0972
0.3439

0.0543
0.3242

0.0543
0.3241

2.9236
15.2324

1.8276
14.5963

0.1052
5.1995

Table 2
The accuracy of the models MAF window size = 4 and GM and GVM window size = 5.
The dates

The standards

GM

EFGM

TFGM

GVM

EFGVM

TFGVM

01.01.2005‚Äì01.01.2006

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.3413
0.6105

0.1038
0.7297

0.3378
0.5770

2.1249
4.3561

1.8136
6.3879

0.3497
0.9807

01.01.2006‚Äì01.01.2007

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.2741
0.4806

0.0870
0.5961

0.2699
0.4549

1.1888
4.1610

0.9265
4.2929

0.2793
1.7863

01.01.2007‚Äì01.01.2008

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.2175
0.3903

0.0672
0.4762

0.2165
0.3687

0.7365
8.9730

0.5162
8.5258

0.2201
2.6013

1789

E. Kayacan et al. / Expert Systems with Applications 37 (2010) 1784‚Äì1789
Table 3
The accuracy of the models MAF window size = 10 and GM and GVM window size = 5.
The dates

The standards

GM

EFGM

TFGM

GVM

EFGVM

TFGVM

01.01.2005‚Äì01.01.2006

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.5997
0.8207

0.1153
0.8099

0.5969
0.8113

1.094
6.5260

0.2767
6.6278

0.6050
1.7241

01.01.2006‚Äì01.01.2007

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.4657
0.6284

0.0949
0.6143

0.4632
0.6196

0.5979
3.0732

0.1812
2.9493

0.4643
1.2397

01.01.2007‚Äì01.01.2008

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.4117
0.5609

0.0763
0.5101

0.4105
0.5534

0.8473
1.9357

0.3287
1.5517

0.4143
1.1361

Table 4
The accuracy of the models MAF window size = 10 and GM and GVM window size = 20.
The dates

The standards

GM

EFGM

TFGM

GVM

EFGVM

TFGVM

01.01.2005‚Äì01.01.2006

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.7098
1.0977

0.0817
1.1850

0.7205
1.0369

0.8640
1.7255

0.0961
1.7582

0.7252
1.4868

01.01.2006‚Äì01.01.2007

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.5702
0.9002

0.0590
0.9476

0.5637
0.8018

0.7281
1.5701

0.0760
1.5638

0.5671
1.0448

01.01.2007‚Äì01.01.2008

ARPE (%) (Int.)
ARPE (%) (Ext.)

0.4851
0.7733

0.0480
0.8030

0.4893
0.6669

0.5725
1.2067

0.0596
1.2309

0.4908
0.7326

data, GM(1,1) models are good at monotonically increasing data
sets.
Table 4 is used to check the performances of GVM models when
the Ô¨Ålter and prediction window size are increased. In this situation, GMV models give satisfactory performances both in interpolation and extrapolation. On the other hand, GM(1,1) models give
dramatically unsuccessful results.
5. Conclusion and future works
This paper compares the performances of the various modiÔ¨Åed
grey models in time series prediction. It is shown that the performance of the grey predictors can be further improved by taking
into account the error residuals. Highly noisy data, the United
States dollar to Euro parity, are used to show the efÔ¨Åciency of the
various error corrected grey models for this purpose. The model
accuracy examination results show that GM(1,1) model is able to
make accurate predictions for forecasting of the monotonous type
of processes. However, the model GM(1,1) cannot give the same
performance when the primitive data sequence increases like as
in an S-curve (like the data with a MAF used in this project) or it
has a saturation region. The simulation results show that modiÔ¨Åed
grey models have higher performances not only on model Ô¨Åtting
but also on forecasting. Among these grey models, the modiÔ¨Åed
GM(1,1) using Fourier series in time is the best in model Ô¨Åtting
and forecasting.
References
Box, G. E. P., & Jenkins, G. M. (1976). Time series analysis: Forecasting and control. San
Fransisco, CA: Holden Day.
Cao, L. (2003). Support vector machines experts for time series forecasting.
Neurocomputing, 51, 321‚Äì339.
Chang, B. R., & Tsai, H. F. (2008). Forecast approach using neural network adaptation
to support vector regression grey model and generalized auto-regressive
conditional heteroscedasticity. Expert Systems with Applications, 34, 925‚Äì934.
Deng, J. (1982). Control problems of grey system. Systems & Control Letters, 1,
288‚Äì294.
Deng, J. L. (1989). Introduction to grey system theory. The Journal of Grey System, 1,
1‚Äì24.
Guo, Z., Song, X., & Ye, J. (2005). A Verhulst model on time series error corrected for
port throughput forecasting. Journal of the Eastern Asia Society for Transportation
Studies, 6, 881‚Äì891.

Huang, K. Y., & Jane, C. J. (2009). A hybrid model for stock market forecasting and
portfolio selection based on ARX, grey system and RS theories. Expert Systems
with Applications, 36, 5387‚Äì5392.
Huang, C. L., & Tsai, C. Y. (2009). A hybrid SOFM‚ÄìSVR with a Ô¨Ålter-based feature
selection for stock market forecasting. Expert Systems with Applications, 36,
1529‚Äì1539.
Hussain, A. J., Knowles, A., Lisboa, P. J. G., & El-Deredy, W. (2008). Financial time
series prediction using polynomial pipelined neural networks. Expert Systems
With Applications, 35, 1186‚Äì1199.
Jo, T. C., 2003. The effect of virtual term generation on the neural based approaches
to time series prediction. In Proceedings of the IEEE fourth conference on control
and automation, Montreal, Canada (Vol. 3, pp. 516‚Äì520).
Kandel, A. (1991). Fuzzy expert systems. Florida, USA: CRC Press.
Lee, L. W., Wang, L. H., & Chen, S. M. (2008). Temperature prediction and TAIFEX
forecasting based on high-order fuzzy logical relationships and genetic
simulated annealing techniques. Expert Systems with Applications, 34, 328‚Äì
336.
Lin, Y., & Liu, S. (2004). A historical introduction to grey systems theory. In
Proceedings of IEEE international conference on systems, man and cybernetics, The
Netherlands (Vol. 1, pp. 2403‚Äì2408).
Liu, S. F., & Lin, Y. (1998). An introduction to grey systems. PA, USA: IIGSS Academic
Publisher.
Ma, J., & Teng, J. F. (2004). Predict chaotic time-series using unscented Kalman Ô¨Ålter.
In Proceedings of the third international conference on machine learning and
cybernetics, Shanghai, China (Vol. 1, pp. 867‚Äì890).
Magdon-ismail, M., Nicholson, A., & Abu-mustafa, Y. S. (1998). Financial markets:
Very noisy information processing. IEEE Special Issue on Information Processing,
86, 2184‚Äì2195.
Quah, T. S., & Srinivasan, B. (1999). Improving returns on stock investment through
neural network selection. Expert Systems with Applications, 17, 295‚Äì301.
Rabiner, L. R. (1989). A tutorial on hidden markov models and selected applications
in speech recognition. Proceedings of the IEEE, 77, 257‚Äì286.
Roman, J., & Jameel, A. (1996). Backpropagation and recurrent neural networks in
Ô¨Ånancial analysis of multiple stock market returns. In Proceedings of IEEE system
sciences proceedings of the 29th Hawaii international conference, Hawaii, USA (Vol.
2, pp. 454‚Äì460).
Tan, C. L., & Chang, S. P. (1996). Residual correction method of fourier series to
GM(1,1) model. In Proceedings of the Ô¨Årst national conference on grey theory and
applications, Kauhsiung, Taiwan (pp. 93‚Äì101).
Tan, C. L., & Lu, B. F. (1996). Grey markov chain forecasting model. In Proceedings of
the Ô¨Årst national conference on grey theory and applications, Kauhsiung, Taiwan
(pp. 157‚Äì162).
Versace, M., Bhatt, R., Hinds, O., & Shiffer, M. (2004). Predicting the exchange traded
fund DIA with a combination of genetic algorithms and neural networks. Expert
Systems with Applications, 27, 417‚Äì425.
Wang, Y. F. (2002). Predicting stock price using fuzzy grey prediction system. Expert
Systems with Applications, 22, 33‚Äì39.
Wen, K. L., & Huang, Y. F. (2004). The development of grey Verhulst toolbox and the
analysis of population saturation state in taiwan‚Äìfukien. In Proceedings of IEEE
international conference on systems, man and cybernetics, The Netherlands (Vol. 6,
pp. 5007‚Äì5012).
Wen, K. L. (2004). Grey systems. Tucson, USA: Yang‚Äôs ScientiÔ¨Åc Press.

