Working Papers
ECAI-­‐2012 Workshop on

Weighted Logics for Artificial Intelligence
WL4AI
Edited by

Lluís Godo
(IIIA, CSIC, Sp.)

and

Henri Prade
(IRIT, CNRS, Fr.)

20th European Conference on Artificial Intellligence
Montpellier, France, August 28, 2012

Technical Report-­‐IIIA-­‐2012-­‐04

Working Papers
of the
ECAI-2012 Workshop on
Weighted Logics for Artificial
Intelligence
— Reasoning about uncertain beliefs,
preferences, partial truth
and other graded notions —

WL4AI

August 28, 2012 - Montpellier (France)

Preface

Logics provide a formal basis for the study and development of applications and systems in Artificial Intelligence. In the last decades there has
been an explosion of logical formalisms capable of dealing with a variety
of reasoning tasks that require an explicit representation of quantitative or
qualitative weights associated with classical or modal logical formulas (in a
form or another).
The semantics of the weights refer to a large variety of intended meanings: belief degrees, preference degrees, truth degrees, trust degrees, etc.
Examples of such weighted formalisms include probabilistic or possibilistic
uncertainty logics, preference logics, fuzzy description logics, diﬀerent forms
of weighted or fuzzy logic programs under various semantics, weighted argumentation systems, logics handling inconsistency with weights, logics for
graded BDI agents, logics of trust and reputation, logics for handling graded
emotions, etc. The underlying logics range from fully compositional systems,
like systems of many-valued or fuzzy logic, to non-compositional ones like
modal-like epistemic logics for reasoning about uncertainty, as probabilistic
or possibilistic logics, or even some combination of them.
The aim of the one-day ECAI 2012 workshop WL4AI has been to bring
together researchers to discuss about the diﬀerent motivations for the use
of weighted logics in AI, the diﬀerent types of calculi that are appropriate
for these needs, and the problems that arise when putting them at work.
As a result, we are very happy to gather in this proceedings volume a very
interesting set of contributions on diﬀerent logical formalisms that we believe
are representative of the richness of the area.
Finally, we would like to express our gratitude to:
• Dr. Thomas Vetterlein for having accepted to give an invited talk at
this workshop.
• Our programme committee members for their commitment to the
success of this event and for their work (each paper received 2 reviews).
• The participants of WL4AI for the quality of their contributions.
• Our sponsor institutions, namely the IRIT laboratory in Toulouse
and the IIIA-CSIC in Barcelona (in particular to Tito Cruz for his
help with the web site, and Nuria Castellote and Daniel Polak for
their help with these proceedings).

Lluis Godo and Henri Prade, Montpellier (France), August 28, 2012.

Program Committee

Teresa Alsinet,
Leila Amgoud
Salem Benferhat
Jonathan Ben Naim
Carlos Ches˜
nevar
Laurence Cholvy
Petr Cintula
Martine De Cock
Didier Dubois
Francesc Esteva
Tommaso Flaminio
Angelo Gilio
Gabriele Kern-Isberner
Joe Halpern
Anthony Hunter
Manfred Jaeger
Souhila Kaci
J´erˆ
ome Lang
Churn-Jung Liau
Emiliano Lorini
Thomas Lukasiewicz
Enrico Marchioni
Vil´em Nov´
ak
Zoran Ognjanovi´c
Manuel Ojeda-Aciego
Nicola Olivetti
Guilin Qi
Emad Saad
Steven Schockaert
Guillermo Simari
Umberto Straccia
V.S. Subrahmanian
Thomas Vetterlein

University of Lleida, Spain
IRIT, France
Univeristy of Artois, France
IRIT, France
Universidad Nacional del Sur, Argentine
ONERA, France
CSAV, Czech Republic
Ghent University, Belgium
IRIT, France
IIIA - CSIC, Spain
IIIA - CSIC, Spain
University of Roma, Italy
Dortmund University, Germany
Cornell University, USA
University College London, UK
Aalborg University, Denmark
University Montpellier, France
Paris-Dauphine University, France
Academia Sinica,Taiwan
IRIT, France
Oxford University, UK
IIIA - CSIC, Spain
University of Ostrava, Czech Republic
Mathematical Institute SANU, Serbia
University of Mlaga, Spain
University Paul Czanne, France
Southeast University, China
Advanced Intelligence Research, Egypt
Cardiff University, UK
Universidad Nacional del Sur, Argentine
CNR, Italy
University of Maryland, USA
University of Linz, Austria

Workshop Programme
8.30 - 9.00 Welcome and introduction (L. Godo and H. Prade)
9.00 - 9.50 Invited talk: On graded logical approaches to formalising
medical decision support
Thomas Vetterlein
Session 1: Probability logics
9.50 - 10.15 Hierarchies of probability logics
N. Ikodinovi´c, Z. Ognjanovi´c, A. Perovi´c, M. Raˇskovi´c
10.15 - 10.40 Conditional p-adic probability logic
A. Ili´c Stepi´c, Z. Ognjanovi´c, N. Ikodinovi´c
Coffee Break 10.40 – 11.00
Session 2: Belief functions & Fuzzy logic
11.00 - 11.25 Combination of dependent evidential bodies sharing common knowledge
T. Nakama, E. Ruspini
11.25 - 11.50 Logics for belief functions on MV-algebras
T. Flaminio, L. Godo, E. Marchioni
11.50 - 12.15 NP-completeness of fuzzy answer set programming
under Lukasiewicz semantics
M. Blondeel, S. Schockaert, M. De Cock, D. Vermeir
12.15 - 12.40 Undecidability of fuzzy description logics
with GCIs under Lukasiewicz semantics
M. Cerami, U. Straccia
Lunch Break 12.40 – 14.00
Session 3: Argumentation & Similarity
14.00 - 14.25 Postulates for logic-based argumentation systems
L. Amgoud
14.25 - 14.50 On arguments and conditionals
E. Weydert
14.50 - 15.20 A logic for approximate reasoning
with a comparative connective
T. Vetterlein
Coffee Break 15.20 – 15.40
Session 4: Incomplete information & Preferences
15.40 - 16.05 Borderline vs. unknown: a comparison between
three-valued valuations, partial models, and possibility distributions
D. Ciucci, D. Dubois, J. Lawry
16.05 - 16.30 Handling partially ordered preferences in possibilistic logic
- A survey discussion D. Dubois, H. Prade, F. Touazi
16.30 - 16.55 Strong possibility and weak necessity as a basis for a logic of desires
E. Lorini, H. Prade
16.55 - 17.15 Closing discussion

Table of Contents

Weighted logics for Artificial Intelligence: an introductory discussion
D. Dubois, L. Godo, H. Prade

1

Hierarchies of probability logics
N. Ikodinovi´c, Z. Ognjanovi´c, A. Perovi´c, M. Raˇskovi´c

9

Conditional p-adic probability logic
A. Ili´c Stepi´c, Z. Ognjanovi´c, N. Ikodinovi´c

17

Combination of dependent evidential bodies sharing common knowledge
T. Nakama, E. Ruspini

25

Logics for belief functions on MV-algebras
T. Flaminio, L. Godo, E. Marchioni

33

NP-completeness of fuzzy answer set programming under Lukasiewicz semantics
M. Blondeel, S. Schockaert, M. De Cock, D. Vermeir

43

Undecidability of fuzzy description logics with GCIs under Lukasiewicz semantics
M. Cerami, U. Straccia

51

Postulates for logic-based argumentation systems
L. Amgoud

59

On arguments and conditionals
E. Weydert

69

A logic for approximate reasoning with a comparative connective
T. Vetterlein

77

Borderline vs. unknown: a comparison between three-valued valuations,
partial models, and possibility distributions
D. Ciucci, D. Dubois, J. Lawry

83

Handling partially ordered preferences in possibilistic logic - A survey discussion D. Dubois, H. Prade, F. Touazi

91

Strong possibility and weak necessity as a basis for a logic of desires
E. Lorini, H. Prade

99

ECAI-2012 Workshop WL4AI

Weighted Logics for Artificial Intelligence:
an Introductory Discussion
Didier Dubois1 and Llu´ıs Godo2 and Henri Prade3
Abstract. We present a brief, structured introductory overview of a
landscape of weighted logics (in a general sense) that can be found in
the literature on Artificial Intelligence, highlighting their fundamental differences and application areas.

1

aspect may lead to insufficiently expressive frameworks and lead to
confusion. Such naturally gradual notions are reviewed below.

2.1

Truth is a key notion in the philosophy of knowledge that is often
viewed as Boolean in essence. Yet in the scope of information storage
and management, this absolute view becomes questionable. Representing knowledge requires a language whose primitives are Boolean
or not. Indeed, as claimed quite early by De Finetti [19] commenting
Łukasiewicz logic, deciding that a proposition is an entity that can
only be true or false is a matter of convention, as it is a matter of
choosing the range of a (propositional) variable. In this sense truth is
an ontic notion, as one participating to the definition of a proposition.
One may take into account the idea that in some contexts the truth of
a proposition (understood as its conformity with a precise description
of the state of affairs) is a matter of degree. For instance, if the height
of John is known one might consider that the proposition “John is
tall” is not always just true or false. This is the view held by fuzzy
logic [5].
If the truth set contains intermediary truth degrees, one issue is
whether we can keep or not the truth-functionality assumption which
is the key feature of classical logic. Mathematically, the answer is
yes as demonstrated by the large set of multiple-valued logics that
are now available. However there are a lot of unresolved issues about
many-valued logics and their applications to artificial intelligence
such as

Introduction

In the last decades there has been an explosion of logical formalisms
capable of dealing with a variety of reasoning tasks that require an
explicit representation of quantitative or qualitative weights associated with classical or modal logical formulas (in one form or another). The semantics of the weights refer to a large variety of intended meanings: belief degrees, preference degrees, truth degrees,
trust degrees, etc. Examples of such weighted formalisms include
probabilistic or possibilistic uncertainty logics, preference logics,
fuzzy description logics, different forms of weighted or fuzzy logic
programs under various semantics, weighted argumentation systems,
logics handling inconsistency with weights, logics for graded BDI
agents, logics of trust and reputation, logics for handling graded emotions, etc.
The underlying logics range from fully compositional systems,
like systems of many-valued or fuzzy logic, to non-compositional
ones like modal-like epistemic logics for reasoning about uncertainty, probabilistic or possibilistic logics, or even some combination
of them. Sometimes the weights are not explicit and the formalisms
use total or partial orderings instead.
In this short paper we present an introductory discussion organizing a landscape of weighted logics (in a general sense) that can be
found in the literature, highlighting their differences and application
areas. In particular we overview the main approaches in AI to deal
with graded notions of uncertainty, truth, preferences and similarity,
we discuss what are the logical issues behind them, and finally we
also point out new emerging areas for graded settings.
We would like to remark that our aim is not to provide a full and
exhaustive overview of graded formalisms in AI, but rather an informed discussion of the main general issues and approaches.

2

• Why are there so few papers using multiple-valued logics as a
representation of gradual properties in artificial intelligence?
• How to choose among the many available systems?
• Does truth-functionality always make sense?
• How does the notion of many-valued truth articulate with studies
of vagueness [16]?
Finally, the most popular many-valued logics in AI seem to be
those with 3 (Kleene [57]), 4 (Belnap [6]) or 5 (equilibrium logic
[69]) truth values, with a view to handle epistemic notions such as
ignorance, contradiction, negation as failure or default knowledge,
following a long tradition dating back to Łukasiewicz and Kleene
[39]. However, these approaches are questionable as such epistemic
notions are closer to ideas of uncertainty while truth is an ontic notion. For instance, Kleene suggested that the third truth value could
mean “unknown”, and this view has been taken for granted by many.
However, “unknown” can be opposed to “certainly true” and “certainly false”, not to true and false. This has led to confusing debates
that cannot be solved without letting the representation of uncertainty
enter the picture [25].

Typical graded notions

One heavily entrenched tradition in Artificial Intelligence, especially
in knowledge representation and reasoning is to rely on Boolean
logic. However, many epistemic notions in commonsense reasoning
are perceived as gradual rather than all-or-nothing. Neglecting this
1
2
3

Graded Truth

IRIT - CNRS, Toulouse, France. Email: didier.dubois@irit.fr
IIIA - CSIC, Bellaterra, Spain. Email: godo@iiia.csic.es
IRIT - CNRS, Toulouse, France. Email: henri.prade@irit.fr

1

ECAI-2012 Workshop WL4AI

2.2

Uncertainty

to belief leads to reasoning with imprecise probabilities [85] which
explicitly attach degrees of belief and degrees of plausibility to
propositions. Such degrees are graded versions of necessity and possibility modalities, and possibility distributions can encode special
cases of convex probability families [30].
A nice by-product of reconciling probability, and epistemic or possibilistic logics is to offer a logical handling of conditioning: pushing
probability down to the Boolean context, in de Finetti style, leads to
the three-valued logic of conditional objects [31], that is also a semantics for non-monotonic logics; adding weights to this construction bridges the gap between logical representations of belief and
both probability and possibility theories [8].
It remains the issue of choosing a proper scale for grading beliefs
in a given application context, namely how much numerical is it useful to be? A unified framework for reasoning about uncertainty leaves
us the choice between various graded representations: ordinal, qualitative (with a finite value scale), integer-based (as with Spohn kappa
functions [78]) or real-valued.

Uncertainty modeling pertains to the representation of an agent’s beliefs. There are several kinds of reasons for uncertainty
• The random variation of a class of repeatable events leaves an
agent unable to predict the occurrence of the next similar event.
• The sheer lack of information may imply an agent being uncertain
about the answer to a question.
• The presence of inconsistent pieces of information due to too
many sources may equally prevent an agent from asserting the
truth or the falsity of a statement.
There are two traditions in AI for representing uncertainty, that
still need to be reconciled
• The non-graded Boolean tradition of (monotonic) epistemic logics
that rely on the modal formalism, and includes some exceptiontolerant non-monotonic logics.
• The graded tradition typically relying on degrees of probability.
Measures of uncertainty aim at formalizing the strength of our
beliefs in the truth (occurrence) of some propositions (events) by
assigning to those propositions a degree of belief [51].

2.3

Preferences

Preferences clearly are not Boolean most of the time. Artificial Intelligence has developed a Boolean framework for decision-making
problems based on constraint propagation and satisfaction. While
many problems are amenable to a constraint-based formulation, it
makes little sense to ignore the gradual nature of preferences.
The tradition in preference modeling has been to use either order
relations (total or partial) or numerical utility functions, albeit with
little attention to the issue of preference representation in practice.
On the contrary, Artificial Intelligence has focused on compact logical or graphical representations of preferences on multi-dimensional
(often Boolean domains) [23]. In this situation, an interpretation represents an option described by Boolean attributes. For instance, CPnets have exploited an analogy with Bayes nets to design a graphical structure encoding ordinal preferences when local decision variables are Boolean. However CP-nets are far from capturing all possible ordering relations between possible worlds. More general logical
languages where a preference relation between formulas appears in
the language have been used, that are more expressive. However the
question of the meaning of comparing two logical formulas in terms
of its consequences on a preference ordering between interpretations
is not obvious, and several proposals exist that are at odds with each
other. For instance do we mean that all models of the preferred formula should be preferred to all models of the other formula? Or just
their best models? See, e.g. [53].
One alternative is to use weights attached to Boolean formulas.
Such a weight may reflect the imperativeness of the satisfaction of
the associated proposition, then viewed as a goal to reach (a prioritized constraint). This weight penalizes interpretations that violate
the formula and can be viewed as a lower bound of a necessity measure [9]. However, other approaches exist, e.g., [35, 14], where the
weight is a reward when satisfying the formula, and [59] where desires or preferences have a utilitarian semantics. More generally at
the semantic level one may focus on the least preferred interpretations that violate the formula or the best preferred that satisfy it. Or
on the contrary, an interpretation may be considered all the better
(resp. worse) as the sum of the rewards (resp. penalties) attached to
formulas it satisfies (resp. violates) is higher (resp. smaller). An alternative to the use of weights is the introduction of a preference
relation inside the representation language, as in, e.g., [84, 80, 10].
In the above preference representation framework, neither the

Whatever the tradition, it must be stressed that belief is a higher order
notion w.r.t. truth, that is, a statement pertaining to belief encapsulates a Boolean proposition inside a belief qualifier: the truth degree
of the statement “I believe p” does not refer to the truth of p, but to
the belief itself: it is the degree of belief in p, irrespectively of p being
true or not. From the mathematical point of view, a measure of uncertainty is a function that assigns to each event (understood here as
a formula in a specific logical language) a value from a given scale,
usually the real unit interval [0, 1], under some suitable constraints.
A well-known example is given by probability measures which try
to capture our degree of confidence in the occurrence of events by
additive [0, 1]-valued assignments. It can be shown that an uncertainty calculus cannot be compositional with respect to all logical
connectives [32]. For instance, probabilities are only compositional
with respect to negation, while we have seen that degrees of truth can
be truth-functional.
It is not easy to reconcile the probabilistic and the logical view
of beliefs. At the most elementary level a set of Boolean formulas
is often interpreted as a belief base containing propositions an agent
believes. In the probabilistic tradition, information is represented by
a single probability distribution on possible worlds, possibly encoded
as a Bayes net. The two approaches are at odds beyond the choice of
Boolean vs. gradual representations of belief:
• The logical approach leaves room for incomplete information.
• The Bayesian approach [70] seems to be very information demanding as the lack of belief in a proposition is always equated
with the belief in its negation.
In fact the natural graded extension of the elementary logical approach is captured by possibilistic logic [33] where degrees of uncertainty may be captured by means of a mere total ordering of possible
worlds and some propositions can be more believed than others. This
plausibility ordering can be encoded as a numerical possibility distribution if needed.
The use of a modal language enables the syntactic expression of
partial ignorance, and explicit patterns of reasoning from it, which
does not fit with the numerical tradition of representing beliefs.
Putting together the probabilistic and the epistemic logic approaches

2

ECAI-2012 Workshop WL4AI

(or proximity) relation between the interpretations gives birth to a
graded consequence relation, which is the basis for a logic of similarity dedicated to interpolation [26], and captures fuzzy logic-based
approximate reasoning. In a similar spirit, a logic allowing to reason
about the similarity with respect to specific sets of prototypes has
been recently proposed [82].
In the above approaches, similarity is graded. More qualitative approaches have been proposed, using comparative relations. The logic
CSL [77] is based on a modal binary operator that is used for denoting the set of interpretations that are closer to p than to q. The underlying distance-based semantics can be restated in terms of preferential structures using a ternary relation expressing that all the points in
a region z are at least as close to region x than to region y [2].
Another qualitative approach, without any grade, relies at the semantic level on the conceptual spaces framework [43] where the possibility of expressing spatial-like localization such as “being in between” (by means of a ternary relation), or “parallelism” (by means
of a quaternary relation) provides a basis for capturing interpolative
and extrapolative reasoning respectively [75]. This proposal comes
close to logical reasoning with analogical proportions [71], which
are quaternary statements of the form “a is to b as c is to d”, but
remains more cautious.
Lastly, let us also mention that apart reasoning about similarity,
what may be termed reasoning with similarity has been also proposed as a semantic basis in information updating (which relies on
ternary comparative closeness relation)[55], or in distance-based information fusion, where, e.g., Hamming distances are computed with
respect to set of interpretations [58]. Another view of information fusion, recently proposed in [76], relies on the idea that inconsistency
can be often resolved by enlarging the sets of models of the information to be fused, thanks to similarity relations.

presence of several criteria nor the possibility of uncertainty is considered. In this case, there may be two kinds of weights
• Weights expressing preferences of options over other options.
• Weights expressing the likelihood of events or importance of
groups of criteria.
In the case of decision under uncertainty, one way out is to use two
sets of formulas, one for the knowledge base, one for the preference
base, and to articulate some kind of inference technique exploiting
both bases so as to encode the optimization of a given criterion mixing uncertainty and utility. This approach looks more problematic
on multiple criteria decision-making where value scales may not be
commensurate, and importance weights are yet another kind of evaluation.

2.4

Similarity

The use of the idea of similarity in reasoning may refer two different
points of view: either one does not want to differentiate inside a set of
objects that are found to be similar, or one wants to take advantage
of the closeness of objects with respect to others. In the first case,
we perform a granulation of the universe of discourse, while in the
second case we are interested in extrapolation or interpolation.
Similarity is often a graded notion, especially when it is related
to the idea of distance. It may refer to a physical space as in spatial
reasoning, or to an abstract space used for describing situations, as
e.g., in case-based reasoning.
The representation of spatial relations between regions often relies
on first order theories based on a family of partial preorders between
regions, called mereologies. Although the term “mereology” usually
refers to the idea of parthood as a basic notion, the idea of connection
may be also used as a primitive notion. There are eight basic relations
between regions known as RCC relations (RCC stands for “Region
Connection Calculus”) [18]. One may even start with a fuzzy connection relation (which might be defined from a distance or a pointwise
closeness relation), and then define a “part of”, or an “overlap” fuzzy
relation between regions for instance, and obtain a graded extension
of RCC calculus [74]. Modal logics are also used for representing
spatial information. Spatial interpretations of modalities have been
provided for capturing various spatial concepts qualitatively with a
topological or geometric flavor such as nearness or distance, for example. See [36] for a review of the logic-based representations of
mereotopologies in classical or modal logics, and in fuzzy and rough
sets settings, as well as modal logic representations of geometries.
Spatial regions are viewed as a whole, where one does not distinguish between their points. Rough sets provide a formal setting for
the “granulation” of a universe of discourse partitioned into equivalence classes of elements that are found indistinguishable (because
they share exactly the same properties among the ones that are considered). Modal logics have been proposed for reasoning with lower
and upper approximations of sets of models in such a setting [38, 22].
Clearly the equivalence relation may be turned into a fuzzy relation,
giving birth to a graded calculus [29].
Extrapolation and interpolation reasoning are based on the idea
of closeness between interpretations. Thus, for instance, if the set of
models of a proposition p fails to be included in the set of models of
a proposition q, but remains included in the set of interpretations that
are close to models of q, one may say that p → q is “close to be true”.
This has been advocated by different authors [73, 56] (and contrasts
with nonmonotonic reasoning where one requires that the preferred
/ normal models of p be included in the models of q). The closeness

3

Logical Issues

In this section our aim is to lay bare the main distinguishing aspects
of logical formalisms dealing with graded uncertainty and graded
truth.
Let us assume an agent is to reason about what the world and assume first that each of the possible states of the world is described
by a complete Boolean truth evaluation of a given (finite) set of
atomic propositions V ar. So let Ω denote the set of Boolean truthevaluations w : L → {0, 1} of formulas from a propositional language L built from the finite set of variables V ar and with the usual
connectives ∧, ∨, → and ¬. It is well known that the connectives ∧,
∨ and ¬ endow L, modulo logical equivalence, with a structure of a
Boolean algebra.
We start considering the case where the agent has complete information about the world, so he knows that the actual worlds is
w0 ∈ Ω. In this case there is no uncertainty at all, in fact, knowing in
which world the agent is, he is able to ascertain the truth status of every possible proposition. This corresponds to consider agent’s epistemic state as being represented by the pair (Ω, E) where E = {w0 }.
A first form of uncertainty appears when the agent’s information
only allows him to know for certain that the actual world w0 is in
some given subset E ⊆ Ω. This is the typical case where the agent
has a theory T (a set of formulas) describing what he knows about the
world. The epistemic state of the agent is then represented as (Ω, E)
where E is a non-empty subset of interpretations, indeed the set of
models of T , and the agent is only able to determine the truth status
of some propositions, but not for some others. Indeed, a proposition
ϕ is known to be true if E |= ϕ (or equiv. T � ϕ ), it is known to be

3

ECAI-2012 Workshop WL4AI

is graded in nature (ϕ can be more or less believed, probable, necessary, etc.). In this way, the truth-degree of Bϕ can be taken as,
e.g., the probability (or necessity) degree of ϕ, and then these graded
atoms are combined using the rules of a suitable fuzzy logic.
Indeed, formalisms that cope with graded truth (fuzzy logics) radically departs from the formalisms for uncertainty reasoning [32, 27].
By neglecting the bivalence principle and adopting a truth scale (usally the unit real interval [0, 1]) with intermediate degrees between 0
(false) and 1 (true) leads to a number of many-valued truth-functional
systems with connectives extending the classical ones. The most relevant formal systems of fuzzy logic systems are the so-called t-norm
based fuzzy logics [46]. These correspond to logical calculi with the
real interval [0, 1] as set of truth-values and defined by a conjunction & and an implication → interpreted respectively by a continuous t-norm ∗ and its residuum ⇒, and where negation is defined as
¬ϕ = ϕ → 0, with 0 being the truth-constant for falsity. In this
framework, each continuous t-norm ∗ uniquely determines a semantical (propositional) calculus P C(∗) over formulas defined in the
usual way from a countable set of propositional variables, connectives ∧, & and → and truth-constant 0 (further connectives, like ϕ∧ψ
as ϕ&(ϕ → ψ), can also be defined). Evaluations of propositional
variables are mappings e assigning to each propositional variable p
a truth-value e(p) ∈ [0, 1], which extend univocally to compound
formulas as follows:

false when E |= ¬ϕ and it is unknown otherwise, i.e. when E �|= ϕ
and E �|= ¬ϕ. Therefore in this setting, propositions may be in three
different status.
A more refined representation is when the agent may associate
weights to interpretations related to the likelihood of each interpretation of describing the actual world. In this case, the epistemic state
can be an represented as a pair (Ω, π), where µ : Ω → [0, 1] attaches a weight to each Boolean interpretation or possible world. In
the probabilistic model (see e.g. early�
works by Nilsson [68]), π is a
probability distribution on Ω, hence {p(w) | w ∈ Ω} = 1, that
allows to rank the likelihood of any proposition
of being true accord�
ing to its probability measure P (ϕ) = {p(w) | w ∈ Ω, w |= ϕ}.
When π(w) ∈ {0, 1} for all w ∈ Ω, then the epistemic state defined
by π corresponds to the previously considered three-valued setting
with E = {w | π(w) = 1}.
In the possibilistic setting [28], π is a possibilty distribution, where
π(w) means that is totally possible that w = w0 , π(w) = 0
means that it is discarded that w = w0 . Then propositions are
weighted according to the corresponding dual necessity and possibility measures (although other measures can also be used): N (ϕ) =
1 − min{π(w) | w |= ¬ϕ}, and Π(ϕ) = max{π(w) | w |= ϕ}.
Again, when π(w) ∈ {0, 1} for all w ∈ Ω, then the epistemic state
defined by π corresponds to the previously considered three-valued
setting with E = {w | π(w) = 1}.
More generally, one may consider graded epistemic states of the
form (Ω, µ), where µ : 2Ω → [0, 1] is an uncertainty measure in
general, attaching likelihood weights to subsets of interpretations, in
such a way that every proposition ϕ can be attached a likelihood
or belief degree of being true as the measure w.r.t. µ of the set of
models of ϕ, i.e. of µ({w ∈ Ω | w(ϕ) = 1}). This representation
generalizes the previous probabilistic or possibilistic models, to other
more general ones like for instance those defined by belief functions,
upper and lower probabilities or imprecise probabilities (see e.g. [49,
50] for a general approach encompassing many uncertainty models
in a modal logic setting).
From a syntactical point of view, a number of formalisms coping with graded uncertainty have been proposed in the literature.
Most of them use a modality, either explicit or implicit, referring
to graded belief. For illustration purposes, we mention three kinds
of languages. For instance, in Halpern’s probability logic [50] formulas express constraints among the probabilities of ϕ1 , . . . , ϕk as
linear inequalities of the form a1 �(ϕ1 ) + ... + ak �(ϕk ) ≥ b, with
a1 , . . . , ak , b being real numbers. The same language is used to reason about other kinds of uncertainty measures like plausibility measures, belief functions, etc. In the Serbian school (Markovic, Ognjanovic and colleagues) on probability logics [24, 67, 72], they use
graded modalities of the form P≥a ϕ, declaring that the probability of
ϕ is at least a, these probabilistic atoms are then combined by means
of classical connectives. A similar approach is Lukasiewicz’s probabilistic logic [64] uses expressions of the form (ϕ)[l, u] to denote
that the probability of ϕ lies in the interval [l, u], as well as van der
Hoek and Meyer’s approach [81] on graded probabilistic modalities.
On the other hand, in Dubois-Prade’s possibilistic logic [28, 33], formulas are pairs (ϕ, α), stating that the necessity of ϕ is at least α. Recently, this language has also been generalized to deal with Boolean
combinations of possibilistic atoms N≥α ϕ, in a similar way to the
previous probabilistic logic language.
A different approach by H´ajek and colleagues [47, 46, 44] has
also been proposed where the modality B used to denote graded belief (probability, necessity, etc.) is graded itself, that is, even if ϕ is
Boolean, the atomic modal expression Bϕ, read as “ϕ is believed”,

e(ϕ ∧ ψ)

=

min(e(ϕ), e(ψ))

e(ϕ&ψ)

=

e(ϕ → ψ)

=

e(ϕ) ∗ e(ψ)

e(ϕ) ⇒ e(ψ)

A formula ϕ is a said to be a 1-tautology of P C(∗) if e(ϕ) = 1
for each evaluation e. The set of all 1-tautologies of P C(∗) will be
denoted as T AU T (∗). Main axiomatic systems of fuzzy logic, like
Łukasiewicz logic (Ł), G¨odel logic (G) or Product logic (Π), syntactically capture different sets of T AU T (∗) for different choices of the
t-norm ∗, see e.g. [48, 46, 45, 17]. Indeed one has:
ϕ is provable in Ł

iff

ϕ is provable in G

iff

ϕ is provable in Π

iff

ϕ ∈ T AU T (∗Ł )

ϕ ∈ T AU T (∗G )
ϕ ∈ T AU T (∗Π )

where x ∗Ł y = max(0, x + y − 1), x ∗G y) = min(x, y) and
x ∗Π y = x · y.
It is worth noticing that, in contrast with classical logic, the algebraic structures of the set of formulas modulo logical equivalence
in these systems of fuzzy logic are no longer Boolean algebras but
weaker structures like MV-algebras, prelinear Heyting algebras, etc.
It is worth noticing that in all these systems, the implication
captures the truth-ordering, since if ⇒ is the residuum of a leftcontinuous t-norm ∗ (i.e., x ⇒ y = max{z ∈ [0, 1] | x ∗ z ≤ y}),
then x ⇒ y = 1 iff x ≤ y, and hence e(ϕ → ψ) = 1 iff
e(ϕ) ≤ e(ψ). Therefore, a formula ϕ → ψ actually represents that
ψ is at least as true as ϕ, this is to say, t-norm based fuzzy logics are
logics of comparative truth. To explicitly deal with truth-degrees in
the reasoning, one may introduce truth-constants r, e.g. for all rational values in r ∈ [0, 1]. Then a formula r → ϕ expresses that the
truth-degree of ϕ is at least r (see e.g. [37]).
From an epistemic point of view, in a fuzzy logic setting, the states
of the world are described by complete [0, 1]-evaluations of atomic
formulas. Let Ω� be the set of these evaluations, i.e. Ω� = {w | w :
V ar → [0, 1]}. Note that the set Ω of Boolean interpretations is
indeed a subset of Ω� . Because of truth-functionality, a completely

4

ECAI-2012 Workshop WL4AI

(but also trust, permission, obligation, desires, etc.) that may require
a graded treatment. In particular, the basic difference between graded
truth and other graded notions has been highlighted. While the former implies a change at the ontic level (from two truth values to multiple truth-values), without any reference to epistemic knowledge or
ignorance, the latter relates to intensional notions that (usually) apply to Boolean propositions, like their epistemic (belief) status, or
how they compare to other propositions in terms of preference, utility, similarity, etc. This is reflected on the kind of formal models that
support these graded notions, many-valued truth-functional models
in the former case, Kripke-like models and graded modalities in the
latter case.
Actually, many-valued logics have been seriously criticized at the
philosophical level because of the confusion between truth-values on
the one hand and degrees of belief, or various forms of incomplete
information, on the other hand, a confusion that even goes back to
pioneers including Łukasiewicz (e.g., the idea of possible as a third
truth-value). Actually, due to this issue and the numerical flavor of
fuzzy logic, there is a long tradition of mutual distrust between Artificial Intelligence and fuzzy logic. A possibility to remedy this gap
is to show how reasoning about knowledge and uncertainty can also
be defined on top of fuzzy/gradual propositions by augmenting fuzzy
logic with epistemic modalities. Recent works along this line may be
considered as first steps towards a reconciliation between possibility theory and other theories of belief as well with fuzzy logic (in the
sense of a rigorous symbolic setting to reason about gradual notions),
see e.g. [11, 41].
Finally, we would like to mention that, although we have mainly
focused on logical issues, many of the concerns discussed here have
also echoes in closely related areas like logic programming and answer set programming when they come to handle uncertainty, preferences or fuzziness, see for instance [65, 52, 66, 4] for a variety of
approaches coping with graded uncertainty and/or truth.

informed scenario thus corresponds now to a precise many-valued
truth-value assignment w0 ∈ Ω� to all propositional variables. Analogously to the Boolean case, different kinds of incomplete information about the world translates here to different many-valued generalizations of epistemic states. In general they are of the form (Ω� , µ� ),
�
where µ� : [0, 1]Ω → [0, 1] is a generalized uncertainty measure
over fuzzy sets of interpretations (see e.g. [41, 40] for some logical
formalisms that are able to deal with uncertainty over non-Boolean
(fuzzy) events).

4

New areas for graded settings

Beyond the handling of the ideas of truth, uncertainty, preferences,
and similarity that may require graded settings for a proper handling,
the field of deontic reasoning is another area where one encounters
basic notions whose strengths may be needed to be compared, stratified into layers, or even graded: one may think of graded obligations,
or permissions for instance [60, 20]. One may distinguish between
weak and strong permissions [54]. Priorities, or preference relations
among worlds, aiming at ordering worlds from the most ideal ones
to the least ideal ones, may help solving dilemmas [15].
Besides, there are several domains of active research in artificial
intelligence nowadays where several of the basic notions mentioned
above can be encountered, possibly with other notions which also
need to be graded. Let us review them briefly.
• So called BDI agents [12] are supposed to have beliefs about the
world, desires, from which they elicitate intentions that are feasible desires. Clearly beliefs may be pervaded with uncertainty,
desires may be modeled as collections of goals with different priority levels, feasibility may be a matter of cost, leading to ordered
/ graded intentions, see, e.g. [13].
• Modeling the trust that can be associated with information sources
or agents, as well as related notions such as distrust or reputation,
is an important issue in practice. Many proposals exist - modal
or numerical - where gradedness has been introduced in various
ways [63] [21][83] [7]. Still, there is not yet a fully clear view of
how graded trust may relate to beliefs and uncertainty.
• Argumentation is another area where the idea of strength seems
naturally associated with arguments [3], as recently investigated
[34][42]. However, it is likely that a uniform view of strength is
not applicable here, since the strength of an argument may refer
to the uncertainty pervading the pieces of information on which it
is based and on the reliability of the source(s) of the argument, as
well as on the rhetoric form of the argument (e.g. its length); moreover the argument itself may refer to a gradual view of truth (when
stating for instance that “ the higher the fever the more certain the
child should remain in bed”). The handling of such strengths may
also depend on the kind of problem to which argumentation is applied: persuasion, negotiation, or deliberation, for instance.
• Emotions, such as surprise, fear etc. have been recently modeled
by means of modal definitions [1]. It seems natural here again,
to have these modalities complemented with grades, leading to
hybrid notions that might be a compound of more basic notions
such as uncertainty, preference, or similarity [79][62][61].

5

REFERENCES
[1] C. Adam, A. Herzig, and D. Longin, ‘A logical formalization of the
OCC theory of emotions’, Synthese, 168(2), 201–248, (2009).
[2] R. Alenda, N. Olivetti, and C. Schwind, ‘Comparative concept similarity over minspaces: Axiomatisation and tableaux calculus’, in Proc.
18th Inter. Conf. Automated Reasoning with Analytic Tableaux and Related Methods (TABLEAUX’09), Oslo, July 6-10, eds., M. Giese and
A. Waaler, volume 5607 of LNCS, pp. 17–31. Springer, (2009).
[3] L. Amgoud, C. Cayrol, and D. Le Berre, ‘Comparing Arguments using
Preference Orderings for Argument-based Reasoning’, in IEEE Inter.
Conf. on Tools with Artificial Intelligence (ICTAI’96), Toulouse, Nov.
16-19, pp. 400–403, (1996).
[4] K. Bauters, S. Schockaert, M. De Cock, and D. Vermeir, ‘Possibilistic answer set programming revisited’, in Proc. 26th Conf. on Uncertainty in Artificial Intelligence (UAI’10), Catalina Island, July 8-11,
eds., P. Gr¨unwald and P.Spirtes, pp. 48–55. AUAI Press, (2010).
[5] R. E. Bellman and L. A. Zadeh, ‘Local and fuzzy logics’, in Modern
Uses of Multiple-Valued Logic, eds., J. M. Dunn and G. Epstein, pp.
103–165. D. Reidel, Dordrecht, (1977).
[6] N. D. Belnap, ‘A useful four-valued logic’, in Modern Uses of MultipleValued Logic, eds., J. M. Dunn and G. Epstein, pp. 7–37. D. Reidel,
Dordrecht, (1977).
[7] J. Ben-Naim and H. Prade, ‘Evaluating trustworthiness from past performances: interval-based approaches’, Ann. Math. Artif. Intell., 64(23), 247–268, (2012).
[8] S. Benferhat, D. Dubois, and H. Prade, ‘Possibilistic and standard probabilistic semantics of conditional knowledge bases ’, J. of Logic and
Computation, 9(6), 873–895, (1999).
[9] S. Benferhat, D. Dubois, and H. Prade, ‘Towards a possibilistic logic
handling of preferences’, Applied Intelligence, 14, 303–317, (2001).
[10] M. Bienvenu, J. Lang, and N.Wilson, ‘From preference logics to preference languages, and back’, in Proc. 12th Inter. Conf. on Principles of

Conclusions

In this paper we have briefly discussed several logical issues of the
main approaches at work to represent and reason with fundamental
notions in AI, such as truth, uncertainty, preferences, or similarity

5

ECAI-2012 Workshop WL4AI

[11]

[12]
[13]
[14]

[15]
[16]
[17]
[18]
[19]
[20]

[21]
[22]
[23]
[24]
[25]
[26]
[27]

[28]
[29]

[30]
[31]
[32]

[33]
[34]

plexity results’, Artificial Intelligence, 175, 457–486, (2011).
[35] F. Dupin de Saint Cyr - Bannay, J. Lang, and T. Schiex, ‘Penalty
logic and its link with Dempster-Shafer theory’, in Proc. Conf. on
Uncertainty in Artificial Intelligence (UAI), Seattle, July 29-31, eds.,
R. Lopez de Mantaras and D. Poole, pp. 204–211. Morgan Kaufmann
Publ., (1994).
[36] F. Dupin de Saint-Cyr, O. Papini, and H. Prade, ‘An exploratory survey of logic-based formalisms for spatial information’, in Methods for
Handling Imperfect Spatial Information, eds., R. Jeansoulin, O. Papini,
H. Prade, and S. Schockaert, volume 256 of Studies in Fuzziness and
Soft Computing, 133–163, Springer, (2010).
[37] F. Esteva, J. Gispert, L. Godo, and C. Noguera, ‘Adding truth-constants
to logics of continuous t-norms: Axiomatization and completeness results’, Fuzzy Sets and Systems, 158(6), 597–618, (2007).
[38] L. Fari˜nas del Cerro and E. Orlowska, ‘DAL - A logic for data analysis’, Theor. Comput. Sci., 36, 251–264, (Corrigendum 47, 345, 1986),
(1985).
[39] M. Fitting, ‘Kleene’s three-valued logics and their children’, Fundamenta Informaticae, 20, 113–131, (1994).
[40] T. Flaminio and L. Godo, ‘A logic for reasoning about the probability
of fuzzy events’, Fuzzy Sets and Systems, 158(6), 625–638, (2007).
[41] T. Flaminio, L. Godo, and E. Marchioni, ‘On the logical pormalization of possibilistic counterparts of states over n-valued Lukasiewicz
events’, J. Log. Comput., 21(3), 429–446, (2011).
[42] D. M. Gabbay, ‘Introducing equationals emantics for argumentation
networks’, in Proc. 11th Europ. Conf. on Symbolic and Quantitative
Approaches to Reasoning with Uncertainty (ECSQARU’11), Belfast,
June 29-July 1, ed., W.r. Liu, volume 6717 of LNCS, pp. 19–35.
Springer, (2011).
[43] P. G¨ardenfors, Conceptual Spaces: The Geometry of Thought, MIT
Press, 2000.
[44] L. Godo, P. H´ajek, and F. Esteva, ‘A fuzzy modal logic for belief functions’, in Proc. 17th Inter. Joint Conf. on Artificial Intelligence (IJCAI’01), Seattle, Aug. 4-10, ed., B. Nebel, pp. 723–732. Morgan Kaufmann, (2001).
[45] S. Gottwald, A treatise on many-valued logics, volume 9 of Studies in
Logic and Computation, Research Studies Press, Baldock, 2001.
[46] P. H´ajek, Metamathematics of fuzzy logic, volume 4 of Trends in
Logic—Studia Logica Library, Kluwer Academic Publishers, Dordrecht, 1998.
[47] P. H´ajek, L. Godo, and F. Esteva, ‘Fuzzy logic and probability’, in Proc.
of the 11th Annual Conf. on Uncertainty in Artificial Intelligence (UAI
’95), Montreal, Aug. 18-20, 1995, eds., P. Besnard and S. Hanks, pp.
237–244. Morgan Kaufmann, (1995).
[48] P. H´ajek, L. Godo, and F. Esteva, ‘A complete many-valued logic with
product-conjunction’, Archive for Mathematical Logic, 35, 191–208,
(1996).
[49] J. Y. Halpern, ‘Plausibility measures: A general approach for representing uncertainty’, in Proc. 17th Inter. Joint Conf. on Artificial Intelligence (IJCAI’01), Seattle, Aug. 4-10, ed., B. Nebel, pp. 1474–1483.
Morgan Kaufmann, (2001).
[50] J. Y. Halpern, Reasoning About Uncertainty, MIT Press, Cambridge,
MA, 2003.
[51] F. Huber and C. Schmidt-Petri, eds., Degrees of Belief, volume 342 of
Synthese Library, Springer, 2009.
[52] J. Janssen, S. Schockaert, D. Vermeir, and M. De Cock, ‘General fuzzy
answer set programs’, in Proc. 8th Inter. Workshop on Fuzzy Logic and
Applications (WILF’09), Palermo, June 9-12, eds., V. Di Ges`u, S. K.
Pal, and A. Petrosino, volume 5571 of LNCS, pp. 352–359. Springer,
(2009).
[53] S. Kaci and L. van der Torre, ‘Reasoning with various kinds of preferences: Logic, non-monotonicity and algorithms’, Annals of Operations
Research, 163(1), 89–114, (2008).
[54] S. Kaci and L. W. N. van der Torre, ‘Permissions and uncontrollable
propositions in DSDL3: Non-monotonicity and algorithms’, in Deontic
Logic and Artificial Normative Systems, Proc. 8th Inter. Workshop on
Deontic Logic in Computer Science (DEON’06), Utrecht, July 12-14,
eds., L. Goble and J.-J. Ch. Meyer, volume 4048 of LNCS, pp. 161–
174. Springer, (2006).
[55] H. Katsuno and A. O. Mendelzon, ‘On the difference between updating a knowledge base and revising it’, in Proc. of the 2nd Inter. Conf.
on Principles of Knowledge Representation and Reasoning (KR’91),
Cambridge, April 22-25, eds., J. F. Allen, R. Fikes, and E. Sandewall,
pp. 387–394. Morgan Kaufmann, (1991).

Knowledge Representation and Reasoning (KR 2010), Toronto, May 913, eds., F.z. Lin, U; Sattler, and M. Truszczynski. AAAI Press, (2010).
M. Blondeel, S. Schockaert, M. De Cock, and D. Vermeir, ‘Fuzzy autoepistemic logic: Reflecting about knowledge of truth degrees’, in
Proc. 11th Europ. Conf. Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’11), Belfast, June 29-July 1, ed.,
W.r. Liu, volume 6717 of LNCS, pp. 616–627. Springer, (2011).
M. E. Bratman, Faces of Intention, Cambridge University Press, 1999.
A. Casali, L. Godo, and C. Sierra, ‘A graded BDI agent model to represent and reason about preferences’, Artificial Intelligence, 175, 1468–
1478, (2011).
Y. Chevaleyre, U. Endriss, and J. Lang, ‘Expressive power of weighted
propositional formulas for cardinal preference modeling’, in Proc. 10th
Inter. Conf. on Principles of Knowledge Representation and Reasoning,
Lake District, UK, June 2-5, eds., P. Doherty, J. Mylopoulos, and C. A.
Welty, pp. 145–152, (2006).
L. Cholvy and C. Garion, ‘An attempt to adapt a logic of conditional
preferences for reasoning with contrary-to-duties’, Fundam. Inform.,
48(2-3), 183–204, (2001).
P. Cintula, C. G. Ferm¨uller, L. Godo, and P. H´ajek, eds., Understanding
Vagueness - Logical, Philosophical, and Linguistic Perspectives, College Publications, 2011.
P. Cintula, P. H´ajek, and C. Noguera, eds., Handbook of Mathematical
Fuzzy Logic, 2 volumes, volume 37 and 38 of Studies in Logic. Mathematical Logic and Foundation, College Publications, 2011.
A. G. Cohn, B. Bennett, J. Gooday, and N. M. Gotts, ‘Qualitative spatial representation and reasoning with the region connection calculus’,
GeoInformatica, 1(3), 275–316, (1997).
B. de Finetti, ‘La logique des probabilit´es’, in Congr`es International de
Philosophie Scientifique, pp. 1–9, Paris, (1936). Hermann et Cie.
P. Dellunde and L. Godo, ‘Introducing grades in deontic logics’, in
Proc. of 9th Intl. Conf. on Deontic Logic in Computer Science, DEON
2008, Luxembourg, July 15-18, 2008., eds., R. van der Meyden and
L. van der Torre, volume 5076 of Lecture Notes in Computer Science,
pp. 248–262, (2008).
R. Demolombe, ‘Graded trust’, in Proc. 12th. AAMAS Inter. Workshop
on Trust in Agent Societies (TRUST’09), Budapest, May 12, (2009).
S. P. Demri and E. Orlowska, Incomplete Information: Structure, Inference, Complexity, Springer, 2002.
C. Domshlak, E. H¨ullermeier, S. Kaci, and H. Prade, ‘Preferences in
AI: An overview’, Artifificial Intelligence, 175, 1037–1052, (2011).
R. S. Dordevic, M. Raskovic, and Z. Ognjanovic, ‘Completeness theorem for propositional probabilistic models whose measures have only
finite ranges’, Arch. Math. Log., 43(4), 557–564, (2004).
D. Dubois, ‘On ignorance and contradiction considered as truthvalues’, Logic Journal of the IGPL, 16(2), 195–216, (2008).
D. Dubois, F. Esteva, P. Garcia, L. Godo, and H. Prade, ‘A logical approach to interpolation based on similarity relations’, Int. J. of Approximate Reasoning, 17, 1–36, (1997).
D. Dubois, F. Esteva, L. Godo, and H. Prade, ‘Fuzzy-set based logics An history-oriented presentation of their main developments’, in Handbook of The History of Logic, eds., D. M. Gabbay and J. Woods, volume 8 of The Many Valued and Nonmonotonic Turn in Logic, 325–449,
Elsevier, (2007).
D. Dubois, J. Lang, and H. Prade, ‘Possibilistic logic’, in Handbook of
logic in artificial intelligence and logic programming, Vol. 3, Oxford
Sci. Publ., 439–513, Oxford Univ. Press, New York, (1994).
D. Dubois and H. Prade, ‘Putting rough sets and fuzzy sets together’, in
Intelligent Decision Support Handbook of Applications and Advances
of the Rough Sets Theory, ed., R. Slowinski, 203–232, Kluwer Academic Publ., (1992).
D. Dubois and H. Prade, ‘When upper probabilities are possibility measures’, Fuzzy Sets and Systems, 49, 65–74, (1992).
D. Dubois and H. Prade, ‘Conditional objects as nonmonotonic consequence relationships’, IEEE Trans. on Systems, Man and Cybernetics,
24(12), 1724–1740, (1994).
D. Dubois and H. Prade, ‘Possibility theory, probability theory and
multiple-valued logics: a clarification’, Annals of Mathematics and Artificial Intelligence, 32(1-4), 35–66, (2001). Representations of uncertainty.
D. Dubois and H. Prade, ‘Possibilistic logic: a retrospective and
prospective view’, Fuzzy Sets and Systems, 144(1), 3–23, (2004).
P. E. Dunne, A. Hunter, P. McBurney, S. Parsons, and M. Wooldridge,
‘Weighted argument systems: Basic definitions, algorithms, and com-

6

ECAI-2012 Workshop WL4AI

[81] W. van der Hoek and J.-J. Ch. Meyer, ‘Graded modalities in epistemic
logic’, in Proc. 2nd Inter. Symp. Logical Foundations of Computer Science, Tver, July 20-24, eds., A. Nerode and M. A. Taitslin, volume 620
of LNCS, pp. 503–514. Springer, (1992).
[82] T. Vetterlein, ‘A logic of the similarity with prototypes and its relationship to fuzzy logic’, in Proc. 7th Conf. of the Europ. Soc. for Fuzzy
Logic and Tech. (EUSFLAT-LFA’11), Aix-Les-Bains, Jul. 18-22, pp.
196–202, (2011).
[83] P. Victor, C. Cornelis, M. De Cock, and E. Herrera-Viedma, ‘Practical
aggregation operators for gradual trust and distrust’, Fuzzy Sets and
Systems, 184, 126–147, (2011).
[84] G. H. von Wright, The Logic of Preference, Edinburgh University Press,
1963.
[85] P. Walley, Statistical Reasoning with Imprecise Probabilities, Chapman
and Hall, 1991.

[56] F. Klawonn and J. L. Castro, ‘Similarity in fuzzy reasoning’, Mathware
& Soft Computing, 2(3), (1995).
[57] S. C. Kleene, Introduction to Metamathematics, North Holland, 1952.
[58] S. Konieczny and R. Pino P´erez, ‘Merging information under constraints: a logical framework’, J. of Logic and Computation, 12,
773808, (2002).
[59] J. Lang, L. W. N. van der Torre, and E. Weydert, ‘Utilitarian desires’,
Autonomous Agents and Multi-Agent Systems, 5(3), 329–363, (2002).
[60] C.-J. Liau, ‘A semantics for logics of preference based on possibility
theory’, in Proc. of the 7th Inter. Fuzzy Systems Assoc. World Cong.,
Prague, June 25-29, pp. 243–248, (1997).
[61] P. Livet, ‘Rational choice, neuroeconomy and mixed emotions’, Phil.
Trans. R. Soc. B, 365, 259–269, (2010).
[62] E. Lorini, ‘A dynamic logic of knowledge, graded beliefs and graded
goals and Its application to emotion modelling’, in LORI-III Workshop
on Logic, Rationality and Interaction, Guangzhou, Oct. 10-13, eds.,
H. van Ditmarsch, J. Lang, and S. Ju, volume 6953 of LNAI, pp. 165–
178. Springer-Verlag, (2011).
[63] E. Lorini and R. Demolombe, ‘From binary trust to graded trust in information sources: A logical perspective’, in Revised Selected and Invited Papers of the 11th AAMAS Inter. Workshop Trust in Agent Societies (TRUST’08), Estoril, May 12-13, eds., R. Falcone, K. S. Barber,
J. Sabater-Mir, and M. P. Singh, volume 5396 of LNCS, pp. 205–225.
Springer, (2008).
[64] T. Lukasiewicz, ‘Weak nonmonotonic probabilistic logics’, Artificial
Intelligence, 168(1-2), 119–161, (2005).
[65] T. Lukasiewicz and U. Straccia, ‘Description logic programs under
probabilistic uncertainty and fuzzy vagueness’, Int. J. Approx. Reasoning, 50(6), 837–853, (2009).
[66] N. Madrid and M. Ojeda-Aciego, ‘On coherence and consistence in
fuzzy answer set semantics for residuated logic programs’, in Proc. 8th
Inter. Workshop on Fuzzy Logic and Applications (WILF’09), Palermo,
June 9-12, volume 5571 of LNCS, pp. 60–67. Springer, (2009).
[67] M. Milosevic and Z. Ognjanovic, ‘A first-order conditional probability
logic’, Logic Journal of the IGPL, 20(1), 235–253, (2012).
[68] N. J. Nilsson, ‘Probabilistic logic’, Artificial Intelligence, 28, 71–88,
(1986).
[69] D. Pearce, ‘Equilibrium logic’, Annals of Mathematics and Artificial
Intelligence, 47, 3–41, (2006).
[70] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of
Plausible Inference, Morgan Kaufmann Publ., San Mateo, CA, 1988.
[71] H. Prade and G. Richard, ‘Multiple-valued logic interpretations of analogical, reverse analogical, and paralogical proportions’, in Proc. 40th
IEEE Inter. Symp. on Multiple-Valued Logic (ISMVL’10), Barcelona,
26-28 May, pp. 258–263. IEEE Computer Society, (2010).
[72] M. Raskovic, Z. Ognjanovic, and Z. Markovic, ‘A logic with conditional probabilities’, in Proc. 9th Europ. Conf. on Logics in Artificial Intelligence (JELIA’04), Lisbon, Portugal, Sept. 27-30, eds., J. J. Alferes
and J. A. Leite, volume 3229 of LNCS, pp. 226–238. Springer, (2004).
[73] E. H. Ruspini, ‘On the semantics of fuzzy logic’, Int. J. Approx. Reasoning, 5, 45–88, (1991).
[74] S. Schockaert, M. De Cock, and E. E. Kerre, Reasoning about Fuzzy
Temporal and Spatial Information from the Web, World Scientific,
2010.
[75] S. Schockaert and H. Prade, ‘Qualitative reasoning about incomplete
categorization rules based on interpolation and extrapolation in conceptual spaces’, in Proc. 5th Inter. Conf. on Scalable Uncertainty Management (SUM’11), Dayton, Oct. 10-13, eds., S. Benferhat and J. Grant,
volume 6929 of LNCS, pp. 303–316. Springer, (2011).
[76] S. Schockaert and H. Prade, ‘Solving conflicts in information merging
by a flexible interpretation of atomic propositions’, Artificial Intelligence, 175, 1815–1855, (2011).
[77] M. Sheremet, D. Tishkovsky, F. Wolter, and M. Zakharyaschev, ‘A logic
for concepts and similarity’, J. Log. Comput., 17(3), 415–452, (2007).
[78] W. Spohn, ‘Ordinal conditional functions: A dynamic theory of epistemic states’, Causation in Decision, Belief Change, and Statistics, 2,
105–134, (1988).
[79] B. R. Steunebrink, M. Dastani, and J.-J. Ch. Meyer, ‘A formal model of
emotions: Integrating qualitative and quantitative aspects’, in Proc. 18th
Europ. Conf. on Artificial Intelligence (ECAI’08), Patras, July 21-25,
eds., M. Ghallab, C. D. Spyropoulos, N. Fakotakis, and N. M. Avouris,
pp. 256–260. IOS Press, (2008).
[80] J. van Benthem and F. Liu, ‘Dynamic logic of preference upgrade’, J.
of Applied Non-Classical Logics, 17(2), 157–182, (2007).

7

ECAI-2012 Workshop WL4AI

8

ECAI-2012 Workshop WL4AI

Hierarchies of probability logics
Nebojˇsa Ikodinovi´c1 and Zoran Ognjanovi´c2 and Aleksandar Perovi´c3 and Miodrag Raˇskovi´c4
Abstract. Our aim is to present what we call the lower and the upper hierarchies of the real valued probability logics with probability
operators of the form P s and QF , where s ∈ [0, 1]Q = [0, 1] ∩ Q
and F is a recursive subset of [0, 1]Q . The intended meaning of P s α
is that the probability of α is at least s, while the intended meaning
of QF α is that the probability of α is in F .

1

to express that the conditional probability of p given q is at least 1/3.
Over the course of two decades we have developed various probability logics with the mentioned types of probability operators - an
extensive survey including a uniform notation for logics is presented
in [17]. The aim of this paper is to put the certain class of probability
logics into the wider context of mathematical phenomenology - to
compare mathematical concepts according to some natural criterion
(expressive power, class of models, consistency strength and so on).
Here we will focus on the classification of two sorts of probability
Fr(n)
logics: LP P2,P,Q,O logics introduced in [12] and LP P2
logics
introduced in [3, 13, 17, 20, 24] (L for logic, the first P for propositional, and the second P for probability). Independently, several authors in [4, 6] have developed the fuzzy logics F P (Łn ) that extend
Fr(n)
Łukasiewicz logic. The LP P2
logics can be embedded into those
logics. For the LP P2,P,Q,O logics we introduce the comparison criFr(n)
terion with respect to the classes of models, while the LP P2
logics we compare in terms of the interpretation method. We show
that both criteria can be joined in a single one. Thus we have obtained
the hierarchy of probability logics where the lattice of LP P2,P,Q,O
Fr(n)
logics.
logics is the end extension of the lattice of LP P2
The rest of the paper is organized as follows: in Section 2 we
present some definitions and theorems from [12] that are needed
afterwards. In Section 3 we introduce the upper hierarchy of
LP P2,P,Q,O logics, prove the characterization theorem and show
that the upper hierarchy is a non-atomic non-modular lattice. In SecFr(n)
logics, prove
tion 4 we introduce the lower hierarchy of LP P2
the characterization theorem and show that the lower hierarchy is an
atomic non-modular lattice. Due to the characterization theorems 4
and 10, both hierarchies can be naturally merged into a single hierarchy, where the upper hierarchy is an end extension of the lower
hierarchy. Concluding remarks are in the final section.

Introduction

The modern probability logics arose from the work of Jerome Keisler
on generalized quantifiers and hyperfinite model theory in the mid
seventies of the twentieth century [8].
Another branch of research that was involved with automatization
of reasoning under uncertainty have led to development of numerous
Hilbert style formal systems with modal like probability operators,
see for instance [5, 2, 11, 13, 14, 17, 18, 20, 23, 24]. The simplest
form of such representation of uncertainty does not allow iteration of
probability operators, so formulas are Boolean combinations of the
basic probability formulas, i.e. formulas of the form
ProbOp(α1 , . . . , αn ),
where α1 , . . . , αn are classical (propositional or predicate) formulas
and ProbOp is an n-ary probability operator. Weighted probability
formulas used by Fagin, Halpern and Megiddo in [2] can be treated
as n-ary probability operators. For instance,
w(α) + 3w(β) − 5w(γ)

1

is example of a ternary probability operator.
The vast majority of those formal systems have unary or binary
probability operators. The unary operators are used for statements
about probability of classical formulas: for example we use
P

3/4 (p

∨ q)

2 LP P2,P,Q,O logics

to express “the probability of p ∨ q is at least 3/4”, while
n
Q{ n+1

| n∈N} (p

In [12] we have introduced a class of LP P2,P,Q,O logics as probability logics with the new type of probability operators - namely the QF
operators as the natural generalization of the basic probability operators P s . Here O ranges over recursive families of recursive subsets
of the set of rational numbers from the real unit interval (denoted by
[0, 1]Q ).
The subscript 2, P, Q, O has the following meaning: 2 denotes the
fact that any LP P2,P,Q,O logic is an extension of LP P2 logic; P
and Q stand for two type of probability operators P r and QF ; O is
a recursive family of recursive subsets of [0, 1]Q .
As it was shown in [12], an LP P2,P,Q,O logic needs not to be
recursive. However, the cardinality of O has a minor impact on
the completion technique (instead of ω-iterations there would be κiterations, where κ is the cardinality of the set of formulas) and no
impact on the properties of the hierarchy, so decidable O’s nicely re-

∨ q)

in our notation reads “the probability of p ∨ q is an element of the
n
set { n+1
| n ∈ N}”. The binary operators are usually used for the
expression of conditional probability: for instance, we use
CP
1
2
3
4

1/3 (p, q)

University of Belgrade, Faculty of Mathematics, email: ikodinovic@matf.bg.ac.rs
Mathematical Institute of Serbian Academy of Sciences and Arts, email:
zorano@mi.sanu.ac.rs
University of Belgrade, Faculty of Transportation and Traffic Engineering,
email: pera@sf.bg.ac.rs
Mathematical Institute of Serbian Academy of Sciences and Arts, email:
miodragr@mi.sanu.ac.rs

9

ECAI-2012 Workshop WL4AI

An LP P2,P,Q,O -theory T (T is a set of LP P2,P,Q,O -formulas) is
satisfiable iff there is an LP P2,P,Q,O -structure M such that M |= φ
for all φ ∈ T ; T is finitely satisfiable iff every finite subset of T is
satisfiable. A probability formula φ is satisfiable iff {φ} is satisfiable;
φ is valid iff M |= φ for each LP P2,P,Q,O -structure M .
Furthermore, M(φ) is the set of all M ∈ M such that M |= φ.
Similarly, M(T ) is the set of all M ∈ M such that M |= T .

flect the general case. In addition, we prefer to have recursive syntax
whenever this restriction is not deterring in logical sense.
In this section we will state some definitions and facts regarding
LP P2,P,Q,O logics that are necessary for development of the hierarchy.

2.1

Syntax and semantics

Theorem 1 Compactness theorem fails for LP P2,P,Q,O , i.e., there
is a finitely satisfiable LP P2,P,Q,O -theory T which is not satisfiable.

By V ar we will denote a countably infinite set of propositional letters; variables for propositional letters are p and q, indexed if necessary. The set of all propositional formulas built over the set of propositional letters will be denoted by F orC (C stands for “classical”,
so F orC reads “classical formulas”). Variables for classical propositional formulas are α, β and γ, indexed if necessary.
The basic probability formulas are P s α and QF α. Here s ∈
[0, 1]Q and F ∈ O, where O is a recursive family of recursive subsets
of [0, 1]Q . In the sequel, O is an arbitrary but fixed family. Probability formulas are Boolean combinations of basic probability formulas.
Note that iterations of probabilistic operators in formulas are not allowed. Variables for probability formulas are φ, ψ and θ, indexed
if necessary. The set of all probability formulas will be denoted by
F or(P, Q, O).
In order to simplify notation we introduce the operators P s , P>s ,
P<s and P=s as follows:
•
•
•
•

Proof. Let T = {P>0 p} ∪ {P<10−n p | n ∈ N}. We will show
that T is finitely satisfiable and that it is not satisfiable. Indeed, to
see that T is not satisfiable, let M = (W, H, v, µ) be an arbitrary
LP P2,P,Q,O -structure. If µ[p] = 0, then M |= P>0 p. If µ[p] > 0,
then, since R is an Archimedean field, there is a positive integer m
such that µ[p] > 10−m . By the definition of |=, it follows that M |=
P<10−m p.
It remains to show that T is finitely satisfiable. Let T0 be an arbitrary nonempty finite subset of T and let n be the maximal nonnegative integer such that the operator P<10−n appears in at least one
formula from T0 . Note that in order to satisfy T0 it is sufficient to
satisfy the formula
n

P>0 p ∧

P s α is P 1−s (¬α);
P>s α is ¬(P s α);
P<s α is ¬(P s α);
P=s α is P s α ∧ P s α.

Let us define f, g : V ar −→ {0, 1} by
f (p0 ) = 1 iff p0 = p and g(p0 ) = 1 iff p0 = p, p0 ∈ V ar.

A model, or an LP P2,P,Q,O -structure is a tuple

Furthermore, let W = {f, g}, H = P(W ), v(f, α) = 1 iff f |= α,
v(g, α) = 1 iff g |= α, and let µ(∅) = 0, µ(W )=1, µ({f }) =
10−n−1 and µ({g}) = 1 − 10−n−1 .
Clearly, M = (W, H, v, µ) is an LP P2,P,Q,O -structure. Furthermore, it is obvious that [p] = {f }, so µ [p] = 10−n−1 , which implies that M |= P>0 p ∧ n
i=0 P<10−i p. Consequently, M |= T0 .

M = W, H, v, µ
with the following properties:
• W is a nonempty set whose elements are traditionally called
worlds;
• v : W × F orC −→ {0, 1}; v(w, α) = 1 means that α is satisfied in w, while v(w, α) = 0 means that α is not satisfied in
w. In addition, v is compatible with the standard truth tables of
propositional connectives;
• H is a subalgebra of the Boolean algebra (P(W ), ∩, ∪,c , ∅, W )
such that for each α ∈ F orC the set

2.2

is in H;
• µ : H −→ [0, 1] is a finitely additive probability measure.

•
•
•
•

W, H, v, µ
W, H, v, µ
W, H, v, µ
W, H, v, µ
ψ.

|= P s α iff µ[α] s;
|= QF α iff µ[α] ∈ F ;
|= ¬φ iff W, H, v, µ |= φ;
|= φ ∧ ψ iff W, H, v, µ |= φ and W, H, v, µ |=

Axioms and inference rules of LP P2,P,Q,O

The LP P2,P,Q,O logic is a Hilbert style formal system with the following three groups of axioms (propositional axioms, bookkeeping
axioms and probability axioms) and three inference rules (modus ponens, the Archimedean rule and the QF -rule). All axioms and inference rules are listed below:
Propositional axioms

[α] = {w ∈ W | v(w, α) = 1}

Though LP P2,P,Q,O -structures form a proper class, without any
loss of generality we can consider only LP P2,P,Q,O -structures with
classical evaluations as worlds and classical satisfiability as valuation
v : W × F orC −→ {0, 1}. Therefore, the class M of all such
LP P2,P,Q,O -structures is actually a set.
The satisfiability relation |= between LP P2,P,Q,O -structures and
F or(P, Q, O) is defined inductively as follows:

P<10−i p.
i=0

A1 Substitutional instances of classical tautologies;
Bookkeeping axioms
A2 P s α → P>r α, r < s;
A3 P>s α → P s α;
Probability axioms
A4
A5
A6
A7
A8

10

P 0 α;
P=1 α, α is a tautology;
(P s α ∧ P r β ∧ P 1 (¬α ∨ ¬β)) → P min(1,s+r) (α ∨ β);
(P s α ∧ P<r β) → P min(1,s+r) (α ∨ β);
P=s α → QF α, s ∈ F .

ECAI-2012 Workshop WL4AI

Inference rules

Definition 2.2 Let F ⊆ [0, 1]Q . The set
1 − F = {1 − s : s ∈ F }.

R1 (modus ponens) From φ and φ → ψ infer β;
R2 (Archimedean rule) From φ → P s−1/k α, for every positive integer k 1/s, infer β → P s α;
R3 (QF -rule) From P=s α → φ, for all s ∈ F , infer QF α → φ.

is the quasi complement of F .
For example, if F =
inition 2.2,

As we have mentioned before, LP P2,P,Q,O -theories are
nonempty sets of formulas. Notice that R2 and R3 are infinitary inference rules, so the classical notion of deduction should be modified
accordingly.

1−F =

•
•
•
•

2i − 1
: i = 1, 2, . . . .
2i

1 − (F ∩ G) = (1 − F ) ∩ (1 − G),
1 − (F ∪ G) = (1 − F ) ∪ (1 − G),
1 − (F \ G) = (1 − F ) \ (1 − G) and
1 − (1 − F ) = F .

These properties, as well as the properties of ∪, ∩ and \, guarantee
that an arbitrary expression on the language {∪, ∩, \, 1−} can be
rewritten in a normal form as a finite union of finite intersections of
differences between sets and quasi complements of sets.

As it is usual, T φ reads “φ is deducible from T ”, “φ is a syntactical consequence of T ” and so on. Instead of ∅ φ we write φ.
Any formula φ such that φ will be called a theorem. A theory T is
consistent if there is a formula φ such that T φ; T is complete if it
is consistent and, for all φ, either T φ or T ¬φ.

Definition 2.3 Let O1 and O2 be recursive families of recursive subsets of [0, 1]Q . Let F1 ∈ O1 . F1 is representable in O2 if it is equal to
a finite union of finite intersections of sets, differences between sets
and quasi complements of sets from O2 and sets [r, s], [r, s), (r, s]
and (r, s), where r and s are rational numbers from [0, 1]. The family
of sets O1 is representable in O2 if each set F1 ∈ O1 is representable
in O2 .

Note on additivity

Strictly speaking, we cannot formally express the additivity condition
µ[α ∨ β] = µ[α] + µ[β]

As an example, consider a positive integer k > 0, the sets

for disjoint formulas α and β (i.e. α∧β is a contradiction). However,
axioms A6 and A7 completely describe finite additivity.
Indeed, suppose that we have defined the notion of a model without the finite additivity condition for µ. By A6, the lower bound of
µ[α ∨ β] cannot be lesser than µ[α] + µ[β] for disjoint α and β. By
A7, the upper bound of µ[α ∨ β] cannot be greater than µ[α] + µ[β].
Since µ : H −→ [0, 1], it must be µ[α ∨ β] = µ[α] + µ[β] for
disjoint α and β.

2.4

: i = 1, 2, . . . , then, following the def-

It is easy to see that the quasi complement has the following properties:

Definition 2.1 Let T be an LP P2,P,Q,O -theory and φ an
LP P2,P,Q,O -formula. Then T φ means that there exist a sequence
ψ0 , . . . , ψλ+1 (λ is finite or countable ordinal) of LP P2,P,Q,O formulas, such that ψλ+1 = φ and for all i
λ + 1, ψi is an
axiom-instance, or ψi ∈ T , or ψi can be derived by some inference
rule applied on some previous members of the sequence.

2.3

1
2i

i

F1 = { 21i : i = k, k + 1, . . .} ∪ { 3 3−1
: i = k, k + 1, . . .},
i
F2 = { 21i : i = 1, 2, . . .},
F3 = { 31i : i = 1, 2, . . .},
and the family O2 = {F2 , F3 }. By Definition 2.3, F1 is reprek
sentable in O2 because F1 = (F2 ∩ [0, 21k ]) ∪ ((1 − F3 ) ∩ [ 3 3−1
k , 1]).
On the other hand, the set
F4 =

Some important properties of LP P2,P,Q,O
logics

1
: i = 1, 2, . . .
22i

is not representable in O2 .

We will start with a list of important model and proof theoretical
properties of the LP P2,P,Q,O logics. Then, we will define the notion
of a quasi complement and state some facts about recursive families
of recursive subsets of [0, 1]Q that are essential for the main topic
of this work. The proofs or theorems and facts listed below can be
found in [12].
Facts:

Theorem 2 Let O1 and O2 be recursive families of recursive subsets of [0, 1]Q . Let F1 ∈ O1 be representable in O2 . Then, for an arbitrary formula α ∈ F orC , there is a formula φ ∈ F or(P, Q, O2 )
such that M(QF1 α) = M(φ), i.e. QF1 α and φ have the same models.
Definition 2.4 Let O1 and O2 be recursive families of recursive subsets of [0, 1]Q , and L1 and L2 be the corresponding LP P2,P,Q,O logics. The logic L2 is more expressive than the logic L1 (L1 L2 )
if for every formula φ ∈ F or(P, Q, O1 ) there is a formula ψ ∈
F or(P, Q, O2 ) such that M(φ) = M(ψ).

1. (soundness) If T φ, then T |= φ;
2. If α is equivalent with β, then φ(. . . , α, . . .) → φ(. . . , β, . . .);
3. P=1 (α → β) → (P s α → P s β). As a consequence, equivalent formulas have the same probabilities;
4. (deduction theorem) T φ → ψ iff T, φ ψ;
5. (strong completeness) Every consistent theory is satisfiable;
6. (undecidability) There exists a recursive family O of recursive
subsets of [0, 1]Q such that the LP P2,P,Q,O -logic is undecidable.

Theorem 3 Let O1 and O2 be recursive families of recursive rational subsets of [0, 1], and L1 and L2 be the corresponding
LP P2,P,Q,O -logics. The family O1 is representable in the family O2
iff L1 L2 .

11

ECAI-2012 Workshop WL4AI

2.5

Theorem 4 Let O1 and O2 be different families from O∗ . Then
O1 O2 iff O1 ⊆ O2 .

Note on decidability

There are recursive families O of recursive subsets of [0, 1]Q so that
the corresponding probability logics are decidable. For instance, such
is the family Ofin of all nonempty finite subsets of [0, 1]Q . Indeed, for
arbitrary F ∈ Ofin we have that
QF α ↔

Proof. The statement is an immediate consequence of the corresponding definitions.

P=s α,
Theorem 5 The structure (O∗ , ) is a lattice.

s∈F

so LPP,Q,Ofin is a conservative extension of the probability logic
LP P2 (see [17], pages 45–56), which is decidable.
The main difficulty with decidability of certain LP P2,P,Q,O logic
is the following one: satisfiability of any LP P2,P,Q,O -formula can
be equivalently reduced to satisfiability of finite disjunction of arithmetical predicates of the form
n

∃¯
x ∈ [0, 1]2Q

k

Φ(¯
x) ∧

l

xij ∈ Fνj ∧
j=1

Proof. Since ⊆ is a partial ordering, by Theorem 4, the relation
defined on O∗ is a partial ordering, too. Moreover, any two elements
of (O∗ , ) posses both the least upper bound, and the greatest lower
bound. Suppose O1 , O2 ∈ O∗ . Let O3 = O1 ∪ O2 . Obviously,
O1
O3 , and O2
O3 . Suppose that there is an O4 ∈ O∗ , such
that O1
O4 and O2
O4 . But then, by Theorem 4, O1 ⊆ O4 ,
O2 ⊆ O4 , and O1 ∪ O2 ⊆ O4 . It follows that O3
O4 . Hence,
O1 ∪ O2 is the least upper bound of {O1 , O2 }. Similarly, the greatest lower bound of {O1 , O2 } is O1 ∩ O2 . Since (O∗ , ) is a partially ordered set such that any two elements posses both a least upper bound, and a greatest lower bound, it is a lattice.

xmj ∈
/ Fξj

,

j=1

where Φ(¯
x) is a system of linear inequalities in variables
n
n
x1 , . . . , x2n containing 2i=1 xi = 1 and 2i=1 xi 0; such predicates need not to be recursive. In fact, the existential fragment of the
first order theory of the rational field is unknown to be decidable (it
is known that the whole theory is not).

3

The meet (·) and join (+) operations can be defined as usual:
• O1 · O2 = O1 ∩ O2 , and
• O1 + O2 = O1 ∪ O2 .

The upper hierarchy

Since every set that is representable both in O1 and in O2 , is representable in O1 ∩ O2 , we have O1 ∩ O2 = O1 ∩ O2 , and O1 · O2 =
O1 ∩ O2 . On the other hand, note that the join operation and the set
union do not coincide, because for some O1 , O2 ∈ O∗ , it can be
O1 ∪ O2 = O1 ∪ O2 .

Theorem 3 correlates the relations of ’being more expressive’ between the LP P2,P,Q,O -logics, and ’being representable in’ between
the corresponding families of sets. In the sequel we investigate the
later relation having in mind the former one. The relation ’being
more expressive’ describes the hierarchy of expressiveness of the
LP P2,P,Q,O -logics.

Theorem 6 The lattice (O∗ , ) is non-modular.

Definition 3.1 Let O be a recursive family of recursive subsets of
[0, 1]Q . The family of all recursive subsets of [0, 1]Q that are representable in O is denoted by O.

Proof. We can find a counter example for the modularity law: if
O2
O1 , then (O1 · (O2 + O3 )) = (O2 + (O1 · O3 )). Let
P rim = {k1 , k2 , . . .} denote the set of all prime numbers. Then,
consider the sets: F1 = { 211 : i = 1, 2, . . .}, F2 = { 2k1i : i =
1
1, 2, . . .}, and F3 = F1 \ { k2i−1
: i = 1, 2, . . .}, and the fam-

It is easy to see, using Definition 2.3, that a family O is closed under finite union, finite intersection, quasi complement and difference
of sets. Each family O contains all finite rational subsets of [0, 1].
Since the operations of union and intersection satisfy the commutative, associative, absorption and distributive laws, every family O
with the standard set operations is a distributive lattice. Note that,
if the complement of a set F is understood as [0, 1] \ F , then O is
not a Boolean algebra since [0, 1] \ F ∈
/ O. On the other hand, if
[0, 1]Q ∈ O, and complement is understood as [0, 1]Q \ F , then O
becomes a Boolean algebra.

2

ilies O1 , O2 , O3 ∈ O∗ , such that O1 = {F1 , F2 }, O2 = {F2 },
and O2 = {F3 }. Obviously, O2 ⊆ O1 , and O2
O1 . Since
F1 = F2 ∪ F3 , F1 is representable in O2 + O3 , and also in
O1 · (O2 + O3 ). On the other hand, F1 is neither representable in
O2 nor in O3 . Thus, F1 is not representable in O2 + (O1 · O3 ), and
the modularity law does not hold.
Theorem 7 ∅ is the smallest element of (O∗ , ).

Definition 3.2 Let O1 and O2 be recursive families of recursive subsets of [0, 1]Q . The binary relation ∼ is defined such that O1 ∼ O2
iff O1 = O2 .

Proof. ∅ contains all the finite subsets of [0, 1]Q only. Since an
arbitrary O ∈ O∗ contains these sets, ∅ ⊆ O and ∅ O.
Let F1 = {r0 , r1 , . . .} be a recursive subset of [0, 1]Q with only
one accumulation point. Let O1 = {F1 }, O2 ∈ O∗ , and O2
O1 .
Note that a set F2 ∈ O2 can be either a finite set, or an infinite set
such that symmetric difference of either F1 and F2 , (F1 \ F2 ) ∪
(F2 \ F1 ), or 1 − F1 and F2 is finite. If all the sets from O2 are finite,
then O2 = 0. Suppose that there is an infinite set F2 ∈ O2 that is
representable in O1 . F2 differs from F1 (or 1 − F1 ) in finitely many
elements. It follows that F1 is representable in O2 , O1
O2 , and
O1 = O2 . Hence, O1 is an atom of (O∗ , ). Suppose that a family
O ∈ O∗ contains a recursive set F with finitely many accumulation

The relation ∼ is an equivalence relation on the set O of all recursive families of subsets of [0, 1]Q . We use O/∼ to denote the
corresponding quotient set. Each equivalence class o ∈ O/∼ contains a unique maximal family Oo such that Oo = Oo . For such an
equivalence class o and the corresponding family Oo we say that Oo
represents o. Let the set {Oo : o ∈ O/∼ } be denoted by O∗ . Clearly,
O and O∗ are countable.
Definition 3.3 Let O1 and O2 be different families from O∗ . Then
O1 O2 iff O1 is representable in O2 .

12

ECAI-2012 Workshop WL4AI

points. For every F1 ⊆ F with only one accumulation point, and
O1 = {F1 } holds O1
O. Finally, let us consider a family which
contains a set with infinitely many accumulation points. Suppose that
a recursive set F0 is dense in (a0 , b0 ) ⊆ [0, 1], and O0 = {F0 }. We
can obtain two sequences a0 < a1 < a2 < . . . and b0 > b1 >
b2 > . . . such that ai < bj for every i and j, a sentence of sets F0 ⊃
F1 ⊃ F2 ⊃ . . . that are dense in (a1 , b1 ) ⊆ [0, 1], (a2 , b2 ) ⊆ [0, 1],
. . . , respectively, and an infinite sentence of families O1 = {F1 },
O2 = {F2 }, . . . , such that 0 . . . O2
O1
O0 . Obviously,
there is no atom in this sequence.
In particular, we have the following theorems:

A2 P s α → P>r α, r < s;
A3 P>s α → P s α;
Probability axioms
A4
A5
A6
A7
A8

P 0 α;
P=1 α, α is a tautology;
(P s α ∧ P r β ∧ P 1 (¬α ∨ ¬β)) → P min(1,s+r) (α ∨ β);
(P s α ∧ P<r β) → P min(1,s+r) (α ∨ β);
n
k=0 P= k α.
n

Inference rules
Theorem 8 A necessary and sufficient condition that an O ∈ O∗ be
an atom is that O = {F }, where F is a recursive set with only one
accumulation point. The lattice (O∗ , ) is non-atomic.

R1 (modus ponens) From φ and φ → ψ infer ψ.
Note that A8 imposes range restrictions on probability functions, i.e.
the range of any probability function that verifies A1–A8 is a subset
of the set F r(n) = 0, n1 , n2 , . . . , n−1
,1 .
n
We shall define the lower hierarchy in the same manner as the
upper one (see Definition 2.4).

Theorem 9 There is no greatest element in (O∗ , ). Consequently,
the lattice O∗ is σ-incomplete.
Proof. Since the family of all recursive subsets of [0, 1]Q is not
recursive, for each recursive family O of recursive subsets of [0, 1]Q
there is a recursive F ⊆ [0, 1]Q non-representable by O. Hence, there
is no greatest element in O∗ .
In particular, σ-incompleteness is an immediate consequence of
the fact that O∗ is a countable ordering without upper bounds.

Fr(n)

Definition 4.1 Let L1 and L2 be arbitrary LP P2
-logics. We say
that the logic L2 is more expressible than L1 and write L1 L2 iff
for each L1 -formula φ exists an L2 formula ψ such that M(φ) =
M(ψ) (i.e. φ and ψ have the same models).

Thus, we can define a hierarchy of the LP P2,P,Q,O -logics, so that
a logic L1 is less expressive than a logic L2 (L1
L2 ) iff the corresponding families O1 and O2 of subsets of [0, 1]Q satisfy a similar
requirement (O1
O2 ). The hierarchy of the probability logics is
isomorphic to O∗ , . For instance, the probability logic LP P2 is
the minimum of the hierarchy of the LP P2,P,Q,O -logics and corresponds to the 0-element of O∗ , .
As we have seen, for all LP P2,P,Q,O -logics L1 and L2 , L1 L2
iff O1 ⊆ O2 . The natural maximum of O∗ ,
would be the minimal extension of all LP P2,P,Q,O logics. Such logic can be obtained
as follows:

It is easy to see that the introduced relation is reflexive and transiF r(n)
-formula φ, an LP P2 -formula
tive. Furthermore, for any LP P2
ψ defined by
n

ψ =def φ ∧

s α, QF α

| s ∈ [0, 1]Q , α ∈ F orC , F ⊆ [0, 1]Q is recursive}

Fr(n)

Theorem 10 Suppose that L1 and L2 are arbitrary LP P2
logics. Then, L1 L2 if and only if Fr(n1 ) ⊆ Fr(n2 ).

that is closed for Boolean connectives;
2. axioms and inference rules are the same as for any LP P2,P,Q,O
logic.

-

Proof. Suppose that Fr(n1 ) ⊆ Fr(n2 ) and let φ be an arbitrary
L1 -formula. As above, we define an L2 -formula ψ by

That logic will be denoted by LP P2,P,Q,all . Here “all” stands for
the family of all recursive subsets of [0, 1]Q . Though the set of
LP P2,P,Q,all -formulas is not recursive, from now on we will assume that LP P2,P,Q,all is also an LP P2,P,Q,O -logic. The strong
completeness of LP P2,P,Q,all can be straightforwardly derived from
the corresponding argumentation for LP P2,P,Q,O -logics that is presented in [12].

4

n

have the same models as φ (here F orC (φ) is the set of all classical
propositional formulas appearing in φ), so we can naturally consider
the upper hierarchy as an end-extension of the lower hierarchy.
We shall show that the characterization theorem for the upper hierarchy (Theorem 4) has the natural counterpart in the lower hierarchy.

1. the set of LP P2,P,Q,O -formulas is the smallest superset of the set
{P

P= k α
α∈F orC (φ) k=0

n1

ψ =def φ ∧

P=
α∈F orC (φ) k=0

k
n1

α.

Clearly, φ and ψ have the same models, so L1 L2 .
Conversely, let Fr(n1 ) ⊆ Fr(n2 ). Then, we can chose s ∈
Fr(n1 ) \ Fr(n2 ). Let p be an arbitrary propositional letter. Then,
P=s p is satisfiable as L1 -formula, while by A8, L2 ¬P=s p. Hence,
L1 L2 .

The lower hierarchy

Fr(1)

Since F r(1) ⊆ F r(n) for all positive integers n, the LP P2
logic is the minimum of the lower hierarchy. Moreover, F r(n) is
a proper subset of F r(2n) for all positive integers n, so the lower
hierarchy has no maximal elements.
Note that logics L1 and L2 are incomparable if and only if the
symmetric difference of Fr(n1 ) and Fr(n2 ) is nonempty. Thus, the
hierarchy contains incomparable elements (for instance, Fr(2) =
{0, 21 , 1} and Fr(3) = {0, 13 , 32 , 1}).

Fr(n)

In this section we will study the hierarchy of LP P2
logics. For
Fr(n)
the given positive integer n the corresponding LP P2
logic has
the following axioms and inference rules:
Propositional axioms
A1 Substitutional instances of classical tautologies;
Bookkeeping axioms

13

ECAI-2012 Workshop WL4AI

Another immediate consequence of Theorem 10 is the fact that
the lower hierarchy is a lattice. Namely, the greatest lower bound of
L1 and L2 is determined by Fr(n1 ) ∩ Fr(n2 ) = Fr(GCD(n1 , n2 )),
while the least upper bound of L1 and L2 is determined by Fr(n1 ) ∪
Fr(n2 ) = Fr(LCM(n1 , n2 )). Notice that L1
L2 iff n1 |n2 (n1
divides n2 ).

nice classification criterion, which is of interest on its one right due
to the general trend of classification of mathematical concepts, which
may be seen as the central theme of the research in mathematics.
Undecidability of LP P2,P,Q,O logics might be seen as a major
obstacle with respect to potential applications. One possible way to
overcome this is to use different types of sets in the operators QF .
For instance, for any semialgebraic subset of Rn we can introduce
the n-ary probability operator QF , where the intended meaning of
QF (α1 , . . . , αn ) is that (µ[α1 ], . . . , µ[αn ]) ∈ F . In this way we can
obtain a decidable probability logic with probability operators of all
positive arities. Notice that decidability is a consequence of the fact
that each semialgebraic set is a finite union of solution sets of some
systems of polynomial inequalities. Hence the satisfiability problem
for probability formulas is reducible to the problem of solvability
for systems of polynomial inequalities, which is PSPACE-complete
in the most general case. Such a logic could be easily developed by
modification of the methodology presented for LP P2,P,Q,O logics.

Theorem 11 The lower hierarchy is atomic and non-modular.
Proof. Concerning non-modularity, it is well known that any lattice
is non-modular iff the pentagon lattice N5 can be embedded into it. In
particular, we can embed N5 into the lower hierarchy in the following
way:

Acknowledgements
The authors are partially supported by Serbian ministry of education and science through grants III044006, III041103, ON174062
and TR36001.
Figure 1.

N5 lattice embedded into the lower hierarchy

Moreover, by Theorem 10, the logics L1 and L2 are incomparable
iff Fr(n1 )
Fr(n1 ) = ∅ ( is the symmetric difference of sets).
As a consequence, atoms of the lower hierarchy are determined by
Fr(n), where n is a prime number.
As we have mentioned earlier, it is quite natural to merge the upper and the lower hierarchy into the single hierarchy of probability
f r(n)
-logic
logics due to the same definiton of . Since each LP P2
can be embedded into any LP P2,P,Q,O -logic in the same manner as
we have demonstrated for the LP P2 logic, the upper hierarchy is an
end-extension of the lower hierarchy.

Figure 2.

5

Hierarchies of probability logics

Conclusion

From a theoretical point of view, the introduced hierarchy (the merge
of the upper and the lower hierarchy) of probability logics gives us a

REFERENCES
[1] R. Djordjevi´c, M. Raˇskovi´c, Z. Ognjanovi´c. Completeness theorem
for propositional probabilistic models whose measures have only finite
ranges. Archive for Mathematical Logic 43, 557 –563, 2004.
[2] R. Fagin, J. Halpern, N. Megiddo. A logic for reasoning about probabilities. Information and Computation 87(1–2), pp 78–128, 1990.
[3] M. Fattorosi-Barnaba and G. Amati. Modal operators with probabilistic
interpretations I. Studia Logica 46(4), 383–393, 1989.
[4] T. Flaminio, L. Godo. A logic for reasoning about the probability of
fuzzy events. Fuzzy Sets and Systems, 158(6): 625638, 2007.
[5] L. Godo, E. Marchioni. Coherent conditional probability in a fuzzy logic
setting. Logic Journal of the IGPL, Vol. 14 No. 3, pp 457–481, 2006.
[6] P. Hajek, L. Godo, F. Esteva, Fuzzy Logic and Probability. In Proc. of
UAI95, Morgan-Kaufmann, 237–244, 1995.
[7] N. Ikodinovi´c,, M. Raˇskovi´c, Z. Markovi´c, Z. ognjanovi´c. Measure logic.
ECSQARU 2007: 128–138.
[8] H. J. Keisler. Probability quantifiers. In J. Barwise and S. Feferman,
editors, Model–Theoretic Logics, Perspectives in Mathematical Logic,
Springer–Verlag 1985.
[9] H. J. Keisler. Elementary calculus. An infinitesimal approach. 2nd edition, Prindle, Weber and Schmidt, Boston, Massachusets, 1986.
[10] D. Lehmann, M. Magidor. What does a conditional knowledge base
entail? Artificial Intelligence, 55, 1–60, 1992.
[11] N. Nilsson. Probabilistic logic. Artif. Intell. 28, 71–78, 1986.
[12] Z. Ognjanovi´c, M. Raˇskovi´c. Some probability logics with new types
of probability operators, J. Logic Computat., Vol 9 No. 2, pp 181–195,
1999.
[13] Z. Ognjanovi´c, M. Raˇskovi´c. Some first-order probability logics. Theoretical Computer Science 247(1–2), pp 191–212, 2000.
[14] Z. Ognjanovi´c, Z. Markovi´c, M. Raˇskovi´c. Completeness Theorem for
a Logic with imprecise and conditional probabilities. Publications de
L’Institute Matematique (Beograd), ns. 78 (92) 35 - 49, 2005.
[15] Z. Ognjanovi´c. Discrete linear-time probabilistic logics: completeness,
decidability and complexity. J. Log. Comput. 16(2), pp 257–285, 2006.
[16] Z. Ognjanovi´c, A. Perovi´c, M. Raˇskovi´c. Logics with the qualitative
probabilty operator. Logic journal of the IGPL 16(2), 105–120, 2008.
[17] Z. Ognjanovi´c, M. Raˇskovi´c, Z. Markovi´c. Probability Logics. Zbornik
radova. Logic in Computer Science (edited by Z. Ognjanovi´c), 12(20),
35–111, Mathematical Institute of Serbian Academy of Sciences and
Arts, 2009. http://elib.mi.sanu.ac.rs/files/journals/zr/20/n020p035.pdf
[18] Z. Ognjanovi´c, M. Raˇskovi´c, Z. Markovi´c, and A. Perovi´c, On probability logic, The IPSI BgD Transactions on Advanced Research, 2– 7,
Volume 8 Number 1, 2012. (ISSN 1820-4511)

14

ECAI-2012 Workshop WL4AI

[19] A. Perovi´c, Z. Ognjanovi´c, M. Raˇskovi´c, Z. Markovi´c. A probabilistic
logic with polynomial weight formulas. FoIKS 2008, pp 239–252.
[20] M. Raˇskovi´c. Classical logic with some probability operators. Publications de l’institut mathematique, Nouvelle s´erie, tome 53(67), 1–3, 1993.
[21] M. Raˇskovi´c, Z. Ognjanovi´c. A first order probability logic LPQ . Publications de l’institut mathematique, Nouvelle s´erie, tome 65(79), pp 1–7,
1999.
[22] M. Raˇskovi´c, Z. Ognjanovi´c, Z. Markovi´c. A logic with Conditional
Probabilities. In J. Leite and J. Alferes, editors, 9th European Conference
Jelia’04 Logics in Artificial Intelligence, volume 3229 of Lecture notes
in computer science, pages 226–238, Springer-Verlag 2004.
[23] M. Raˇskovi´c, Z. Ognjanovi´c, Z. Markovi´c. A logic with approximate
conditional probabilities that can model default reasoning. Int. J. Approx.
Reasoning 49(1): 52–66, 2008.
[24] W. van der Hoek. Some considerations on the logic PF D: a logic combining modality and probability. Journal of Applied Non-Classical Logics, 7(3), 287–307, 1997.

15

ECAI-2012 Workshop WL4AI

16

ECAI-2012 Workshop WL4AI

Conditional p-adic probability logic
Angelina Ili´c Stepi´c 1 and Zoran Ognjanovi´c 2 and Nebojˇsa Ikodinovi´c 3
Abstract. This paper presents the proof-theoretical approach to a
p-adic valued conditional probabilistic logic CP LQp . In this logic
formulas are built from the finite set of propositional letters. We propose a class of probabilistic models and corresponding infinitary axiomatization for which we prove strong completeness theorem. Decidability of the presented logic is proved.

1

when it is not possible to compare the probability of two events.
Another benefit of p-adic access is the possibility of negative values for the probability. Following the concepts of Khrennikov’s approach to probability [14, 15, 16], in [12] the authors developed a
propositional probability logic LQp which is an extension of classical propositional logic with modal-like operators Kr,ρ , where the
intended meaning of Kr,ρ α is that the probability of α is in the ball
K[r, ρ] = {a ∈ Qp : |r − a|p ≤ ρ}. As the corresponding semantics, probability Kripke like models are introduced, and the range of
probability functions is restricted on balls of finite diameters. The paper [12] gives a formal system which is sound and strongly complete
with respect to the corresponding semantics. Also, the decidability
of the logic LQp is proved.
Now, we introduce the probabilistic logic CP LQp by extending
classical propositional logic with a list of conditional probability operators of the form CKr,ρ . The intended meaning of CKr,ρ α, β is
that the conditional probability of truthfulness of α given β is in the
ball K[r, ρ]. One of the essential conditions for the p-adic measure
is the boundedness condition: If F is a field of subsets of some set Ω
then, for every A ∈ F

Introduction

There are strong historical links between probability theory and
mathematical logic. In the last decades more and more areas of these
subjects have been very closely connected in investigations of logical systems called probabilistic logics with a broad range of possible application areas (learning from data [20], causal reasoning
[22, 26], multi-agent systems [7], robotics [27], logic programming
[13], among other fields). There are numerous proposals for probabilistic logics [2, 5, 6, 17, 21, 23]. Many of them are based on the
standard Kolmogorov’s (measure theoretical) approach to the probability, but there is an increasing number of those based on an alternative approach. Many of alternative approaches share the same
basic ideas: omission of the condition of σ-additivity and consideration of probabilities of a different range. In this paper, as well
as in [10, 11, 12, 24], we develop a logic that is based on one of
the mentioned approaches. Let us also mention the coherence-based
approach adopted in recent years by many authors, that, differently
from the approach used in this paper, allows direct use of conditional
probabilities, with no need of representing them as ratios of unconditional probabilities (for more details see, for instance [4]).
In [16] Khrennikov gives a detailed and inspiring presentation on
p-adic probability theory and discuss its applications in physics (especially quantum mechanics). It is well known that any non-trivial
norm on the field of rational numbers Q is equivalent to either the
usual real absolute value or a p-adic norm | · |p , for some prime
p. Therefore, by completing the field of rational numbers we obtain the field of real numbers or some field Qp . On the other hand,
values of relative frequencies of random experiments are rational
numbers. Therefore, to calculate the probability of the corresponding event we can take limes of these frequencies in the field of real
numbers, as we used to, but we can also calculate limes in the field
Qp , for some prime number p. If we choose Qp as the range of
probability we obtain two new features compared to the real access. Field of p-adic numbers cannot be turned into an ordered field,
it is possible to construct several partial orders. Thus, p-adic approach gives the opportunity to work with probabilities in situations

sup{|µ(B)|p : B ∈ F, B ⊂ A} < ∞
In [12] this condition is ensured by reducing the range of probabilities to an arbitrarily large (but fixed) ball K[0, pM ], where M is some
fixed integer. When handling conditional probabilities there is a need
for multiplying p-adic numbers. Since arbitrary ball K[0, pM ] is not
closed for multiplication, these balls are no longer useful for the logic
CP LQp . Here we might proceed in two ways. We can choose unit
ball K[0, 1] as a range of probability, which is closed for multiplication. Second way, which is presented in this paper, is to built formulas from the finite set of propositional letters, but to retain Qp as
a range of probability. In this way we compute supremum of finitely
many numbers of the form pn , n ∈ Z, which is again a finite number. Thus, logic CP LQp has two key differences with respect to the
logic LQp : the set of propositional letters is finite and the range of
probability functions is the whole Qp .
In this paper we present the proof-theoretical approach to
CP LQp , while a discussion of its possible application is left for a
future work. Namely, the logic CP LQp may be useful to analyze the
relationship between the conditional probabilities and the notion of
implication since the former notion is a natural generalization of the
later one [1, 8, 18, 19, 25, 24].
The rest of the paper is organized as follows: in Section 2 we
present syntax and semantics of CP LQp ; Section 3 presents axioms and inference rules of CP LQp ; in Section 4 we prove the
corresponding soundness and completeness theorems; in Section 5
we discuss decidability of CP LQp ; concluding remarks are given in
Section 6.

University of Belgrade, Faculty of Mathematics, Belgrade, Serbia, email:
angelina@matf.bg.ac.rs
2 Mathematical Institute of Serbian Academy of Sciences and Arts, Belgrade,
Serbia, email: zorano@mi.sanu.ac.rs
3 University of Belgrade, Faculty of Mathematics, Belgrade, Serbia, email:
ikodinovic@matf.bg.ac.rs
1

17

ECAI-2012 Workshop WL4AI

2

Syntax and semantics

finitely many numbers of the form pn , n ∈ Z, which is again a finite
number.
Definition 2 Let M = �W, H, µ, v� be a CP LZp -model. The
satisfiability relation is inductively defined as follows:

Let p be a fixed prime number. We define the function | · |p : Q →
{pn |n ∈ Z} ∪ {0} in the following way:
• If n ∈ N, then n can be represented as a product of prime numbers, n = 2t2 3t3 . . . ptp . . . sts . We define |n|p = p−tp , putting
|0|p = 0.
• If n ∈ Z, n < 0 then |n|p = | − n|p .
|n|
n
n
∈ Q, m �= 0, we put | m
|p = |m|pp .
• Finally, if m

• If α ∈ F orCl then M |= α iff v(w, α) = true for every w ∈ W .
• If α, β ∈ F orCl then M |= CKr,ρ α, β iff:
– µ([β]) = 0 and |r − 1|p ≤ ρ or

− r|p ≤ ρ.
– µ([β]) �= 0 and | µ([α∧β])
µ([β])

• If ϕ ∈ F orCP , then M |= ¬ϕ iff it is not M |= ϕ.
• If ϕ, ψ ∈ F orCP then M |= ϕ ∧ ψ iff M |= ϕ and M |= ψ.

The field Qp of p-adic numbers can be constructed as a completion
of the field of rational numbers Q with respect to p-adic norm. For a
more detailed insight into the p-adic numbers we suggest [3].
We introduce the following set:

According to Definition 2, µ(W ) = 1. Therefore, from Definition
2 we obtain M |= CKr,ρ α, � iff | µ([α])
− r|p ≤ ρ i.e. iff |µ([α]) −
1
r|p ≤ ρ. In the sequel, we will denote CKr,ρ α, � by Kr,ρ α.
Note that for arbitrary ρ ∈ R, r ∈ Q1 , M |= CKr,ρ α, β means
that the quotient µ([α∧β])
which represents conditional probability of
µ([β])
α given β, belongs to the p-adic ball with the center r and the radius
ρ. Particularly, M |= Kr,ρ α means that µ[α] belongs to the p-adic
ball with the center r and the radius ρ. If ρ = 0, then we obtain that
the (conditional) probability is equal to r.

1. R = {pn |n ∈ Z} ∪ {0}.
Suppose that V ar = {p1 , . . . , pn } is a finite set of propositional
letters. By F orCl we will denote the set of all propositional formulas
over V ar. Propositional formulas will be denoted by α, β and γ,
indexed if necessary. The set F orCP of all probabilistic formulas is
defined as the least set satisfying the following conditions:
• If α, β ∈ F orCl , r ∈ Q, ρ ∈ R then CKr,ρ α, β is a probabilistic
formula;
• If ϕ, φ are probabilistic formulas then (¬ϕ), (ϕ ∧ φ) are probabilistic formulas.
Probabilistic formulas will be denoted by ϕ, φ and θ, indexed if necessary. The set F or of all CP LQp -formulas is the union of F orCl
and F orCP . Formulas will be denoted by A, B and C, indexed if
necessary. The other classical connectives (∨, ⇒, ⇔) can be defined
as usual. We denote both α∧¬α and ϕ∧¬ϕ by ⊥, letting the context
to determine the meaning. Also, we use � for α ∨ ¬α and ϕ ∨ ¬ϕ.
Definition 1 A CP LQp -model is a structure M = �W, H, µ, v�
where:
• W is a nonempty set of elements called worlds;
• H is an algebra of subsets of W ;
• µ : H −→ Qp is a measure (additive function) such that
µ(W ) = 1;
• v : W × V ar −→ {true, f alse} is a valuation which associated with every world w ∈ W a truth assignment v(w, ·) on
propositional letters; the valuation v(w, ·) is extended to classical propositional formulas as usual.
If M is a CP LQp -model, by [α]M we will denote the set of
all worlds w such that v(w, α) = true. We will omit M from
the subscript whenever the context is clear. An CP LQp -model
M = �W, H, µ, v� is measurable if [α]M ∈ H for every formula
α ∈ F orCl . In this paper we focus on the class of all measurable
CP LQp -models. Thus, when we write ”CP LQp -model” we mean
”measurable CP LQp -model”.
In terms of sets [α], the boundedness condition can be formulated
as:
sup{|µ([β])|p : [β] ∈ H, [β] ⊂ [α]} < ∞.

3

Axiomatization

The axiom system AXCP LZp of the logic CP LZp contains the following axioms and inference rules:
Axioms
A1.
A2.
A3.
A4.
A5.
A6.

Substitutional instances of tautologies;
Kr1 ,ρ1 α∧Kr2 ,ρ2 β ∧K0,0 (α∧β) ⇒ Kr1 +r2 ,max(ρ1 ,ρ2 ) (α∨β);
CKr,ρ α, β ⇒ CKr,ρ� α, β, whenever ρ� ≥ ρ;
CKr1 ,ρ1 α, β ⇒ ¬CKr2 ,ρ2 α, β, if |r1 − r2 |p > max(ρ1 , ρ2 );
CKr1 ,ρ α, β ⇒ CKr2 ,ρ α, β, if |r1 − r2 |p ≤ ρ;
Kr1 r2 ,ρ1 (α∧β)∧Kr2 ,ρ2 β ⇒ CK max{ρ1 ,|r1 |p ·ρ2 } α, β, r2 �=
r1 ,

|r2 |p

0, |r2 |p > ρ2
A7. CKr,ρ α, β ∧Kr1 ,ρ1 β ⇒ Kr·r1 ,max{|r1 |p ·ρ,|r|p ·ρ1 } α∧β, if r1 �=
0, |r1 |p > ρ1 ;
A8. K0,0 β ∧ Kr,ρ (α ∧ β) ⇒ CK1,0 α, β;
Inference rules
R1. From A and A ⇒ B infer B. Here A and B are either both propositional, or both probabilistic formulas;
R2. From α infer K1,0 α;
R3. If n ∈ Z, from ϕ ⇒ ¬Kr,pn α for every r ∈ Q, infer ϕ ⇒⊥;
R4. From α ⇒⊥, infer K0,0 α;
R5. If r ∈ Q, from γ ⇒ CKr,pn α, β for every n ∈ Z, infer γ ⇒
CKr,0 α, β;
R6. From (α ⇔ β) infer (Kr,ρ α ⇔ Kr,ρ β);
Axiom A2 corresponds to the additivity of measures and it also reflects property of p-adic norm (strong triangle inequality). Axiom A3
corresponds to the obvious property of p-adic balls: a ball of smaller
radius is contained in a ball of larger radius provided the balls are not
disjoint. Axiom A4 provides that the conditional probability (corresponding quotient of measures) cannot belong to two disjoint balls.
Axiom A5 says that any point of a p-adic ball can be it’s center. Axioms A6 -A8 express the definition of the conditional probability. In
the axioms A6 and A7 we estimate the conditional probability of α
given β using the ball with the appropriate center, precisely with the
center that is obtained as quotient r/r where µ([α ∧ β]) belongs to

If the set V ar of propositional letters if finite, then, for every
propositional formula α over V ar, there exist finitely many logical
inequivalent formulas β, such that β ⇒ α is tautology, ie. such that
[β] ⊂ [α]. Thus, if we allowed µ([β]) to be arbitrary p-adic number,
then in the above boundedness condition, we compute supremum of

18

ECAI-2012 Workshop WL4AI

the ball with the center r and µ([β]) belongs to the ball with the center r. Precisely, since µ([α ∧ β]) belongs to the ball with the center
r1 · r2 and µ([β]) belongs to the ball with the center r2 , we have to
restrict | µ([α∧β])
− r1 |p with the appropriate radius. Using the propµ([β])

c−k+1 p−k+1 . . . c−n p−n then r ∈ Q and µ([α]) − r =
c−n+1 p−n+1 + c−n+2 p−n+2 + . . .. Therefore |µ([α]) − r|p ≤
pn−1 < pn so M |= Kr,pn α. Since M |= ϕ ⇒ ¬Kr,pn α it follows
that M |= ¬ϕ and therefore M |= ϕ ⇒⊥.
Theorem 2 (Deduction theorem) Let T be a set of formulas and A
and B both classical or both propositional formulas. Then, T, A � B
implies T � A ⇒ B.
Proof We use transfinite induction on the length of the proof of
B form T ∪ {A}. For instance, we consider Rule R5. Assume that
B = (ϕ ⇒ CKr,0 α, β) is obtained using rule R5. Then:
T, A � ϕ ⇒ CKr,pn α, β for every n ∈ Z T � A ⇒ (ϕ ⇒
CKr,pn α, β) for every n ∈ Z, by the induction hypothesis,
T � (A ∧ ϕ) ⇒ CKr,pn α, β for every n ∈ Z,
T � (A ∧ ϕ) ⇒ CKr,0 α, β by Rule R5
T � A ⇒ (ϕ ⇒ CKr,0 α, β).
Theorem 3 Every consistent set can be extended to a maximal
consistent set.
Proof
Let T be a consistent theory (set of formulas), T the set of all classical formulas that are consequences of T , α0 , α1 , . . . an enumeration of all formulas from F orCl , and ϕ0 , ϕ1 , . . . an enumeration of
all formulas from F orCP . Let f : N → Z × N be any bijection
(i.e., f is of the form f (i) = (π1 (i), π2 (i))). We define a sequence
of theories Ti in the following way:

1 ,ρ2 }
erties of | · |p , we obtain the radius max{ρ
(for details see the
|r2 |p
proof of the Theorem 4). In the case of Axiom A7, we apply similar
considerations.
Rule R2 can be considered as the rule of necessitation in modal
logic. Rule R3 provides that for every classical formula α and every
radius ρ there must be some r ∈ Q such that the measure of α belongs to the ball K[r, ρ]. Rule R4 guaranties that a contradiction has
the measure 0. Rule 5 express the next property: if the quotient of
measures, µ([α ∧ β]) and µ([β]),(which corresponds to the conditional probability ) is arbitrary close to some rational number r, then
this quotient is equal to r. Finally, Rule R6 says that equivalent classical formulas have the same measures. Note that the rules R3 and
R5 are infinitary.
A formula A is deducible from the set T of formulas (denoted
T � A) if there is a sequence (called a proof) of formulas A0 , A1
. . . ,A such that every Ai is either an instance of some axiom, or it
is a formula from the set T , or it can be derived from the preceding
formulas by some inference rule. The length of a proof is a successor
ordinal. A formula A is a theorem (� A) iff it is deducible from
the empty set. A set of formulas T is consistent if there are α ∈
F orCl and ϕ ∈ F orCP such that neither T � α or T � ϕ holds. A
consistent set T of formulas is said to be maximal consistent if it has
the following properties:

1. T0 = T ∪ T ∪ {K1,0 α|α ∈ T };
2. For every i ≥ 0,

(a) If T2i ∪ {ϕi } is consistent then T2i+1 = T2i ∪ {ϕi };

• For every α ∈ F orCl , if T � α, then both α and K1,0 α are in T ;
• For every ϕ ∈ F orCP either ϕ ∈ T or ¬ϕ ∈ T .

(b) Otherwise, if T2i ∪ {ϕi } is inconsistent then:

(i) If ϕi = (ψ ⇒ CKr,0 α, β) then T2i+1 = T2i ∪ {¬ϕi , ψ ⇒
¬CKr,pn α, β} for some n ∈ Z such that T2i+1 is consistent,

A set of formulas T is deductively closed if for every A ∈ F or, if
T � A then A ∈ T .

4

(ii) Otherwise T2i+1 = T2i ∪ {¬ϕi };

3. For every i ≥ 0, T2i+2 = T2i+1 ∪ {Kr,pπ1 (i) απ2 (i) } for some
r ∈ Q such that T2i+2 is consistent.

Soundness and completeness

Theorem 1 (Soundness) The axiomatic system AXCP LZp is sound
with respect to the class of CP LZp -models.
Proof We will show that every instance of an axiom schemata
holds in every world of every CP LZp -model, while the inference
rules preserve validity. For instance, we present validity of axiom A6
and rule R3.
Axiom A6. Suppose that for some model M |= Kr1 ·r2 ,ρ1 (α ∧
β) ∧ Kr2 ,ρ2 β, r2 �= 0 and |r2 |p > ρ2 . Then |µ([α ∧ β]) − r1 ·
1
r2 |p ≤ ρ1 . Therefore,| µ([α∧β])
− r1 |p = | µ([α∧β])−µ([β])·r
|p =
µ([β])
µ([β])

We show that for every i, Ti is consistent. The set T0 is consistent
since it contains consequences of a consistent set. The sets obtained
by the steps 2a are obviously consistent. The step 2b (ii) produces
consistent sets, too. Really, if T2i , ϕi �⊥, by Deduction Theorem we
have T2i � ¬ϕi , and, since T2i is consistent, the same holds for
T2i ∪ {¬ϕi }.
Let us consider the step 2b(i). Suppose that ϕi = (ψ ⇒
CKr,0 α, β) , T2i ∪ {ϕi } is inconsistent and that for every n ∈ Z,
T2i ∪ {¬(ψ ⇒ CKr,0 α, β), ψ ⇒ ¬CKr,pn α, β} is inconsistent.
Then:
T2i , ¬(ψ ⇒ CKr,0 α, β), ψ ⇒ ¬CKr,pn α, β �⊥ for every n ∈
Z
T2i , ¬(ψ ⇒ CKr,0 α, β) � ¬(ψ ⇒ ¬CKr,pn α, β) for every
n ∈ Z, by Deduction theorem
T2i , ¬(ψ ⇒ CKr,0 α, β) � ψ ⇒ CKr,pn α, β for every n ∈ Z,
by the classical tautology ¬(α ⇒ ¬β) ⇒ (α ⇒ β)
T2i , ¬(ψ ⇒ CKr,0 α, β) � ψ ⇒ CKr,0 α, β by Rule R5
T2i � ¬(ψ ⇒ CKr,0 α, β) ⇒ (ψ ⇒ CKr,0 α, β) by Deduction
theorem T2i � ψ ⇒ CKr,0 α, β.
Since T2i ∪ {ψ ⇒ CKr,0 α, β} is not consistent, from T2i � ψ ⇒
CKr,0 α, β it follows that T2i is not consistent, a contradiction.
Next, consider the step 3. Suppose that for every r ∈ Q the
set T2i+1 ∪ {Kr,pπ1 (i) απ2 (i) } is inconsistent. Let T2i+1 = T0 ∪
+
+
T2i+1
, where T2i+1
is set of all formulas from F orCP which

|µ([α∧β])−r1 ·r2 +r1 ·r2 −µ([β])·r1 |p
.
|µ([β])|p

Since M |= Kr2 ,ρ2 β it follows
that |µ([β]) − r2 |p ≤ ρ2 and therefore |µ([β])|p = |µ([β]) − r2 +
r2 |p = max{|µ([β])−r2 |p , |r2 |p } = |r2 |p because |µ([β])−r2 |p ≤
ρ2 < |r2 |p . Now, |µ([α ∧ β]) − r1 · r2 + r1 · r2 − µ([β]) · r1 |p
≤ max{|µ([α ∧ β]) − r1 · r2 |p , |r1 |p · |r2 − µ([β])|p } ≤ max
max{ρ1 ,|r1 |p ·ρ2 }
, i.e.
− r1 |p ≤
{ρ1 , |r1 |p · ρ2 }. Therefore | µ([α∧β])
µ([β])
|r2 |p
M |= CK max{ρ1 ,|r1 |p ·ρ2 } α, β.
r1 ,

|r2 |p

Note that µ([β]) �= 0, because from µ([β]) = 0 and Definition
2 it follows that M |= K0,0 β. Therefore, since M |= Kr2 ,ρ2 β,
according to axiom A4 we have |r2 − 0| ≤ max{0, ρ2 }, which is
inconsistent with the requirement |r2 | > ρ2 .
Rule R3. Let M be arbitrary model and let M |= ϕ ⇒
¬Kr,pn α for every r ∈ Q. Suppose that µ([α]) = c−k p−k +
c−k+1 p−k+1 . . . c−n p−n + c−n+1 p−n+1 + . . .. If r = c−k p−k +

19

ECAI-2012 Workshop WL4AI

were added to T0 in the previous steps of the construction. Then:
+
T0 , T2i+1
, Kr,pπ1 (i) απ2 (i) �⊥ for every r ∈ Q
+
T0 , T2i+1
� ¬Kr,pπ1 (i) απ2 (i) for every r ∈ Q, by Deduction
theorem �
T0 � ( ϕ∈T + ϕ) ⇒ ¬Kr,pπ1 (i) απ2 (i) for every r ∈ Q, by

Next we define a canonical model. Let MT ∗ = �W, H, µ, v�,
where:
• W = {w|w |= T } contains all classical propositional interpretations that satisfy the set T of all classical consequences of the set
T,
• H = {[α] : α ∈ F orCl }
• µ : H → Zp : Let r(α) = (rn )n∈N . Then

2i+1

Deduction�theorem
T0 � ( ϕ∈T + ϕ) ⇒⊥ by Rule R3.
2i+1

Therefore T�
2i+1 �⊥, a contradiction.
Let T ∗ = i<ω Ti . It remains to show that T ∗ is maximal and
consistent. The steps 1 and 2 of the above construction guarantees
that T ∗ is maximal. We continue by showing that T ∗ is deductively
closed set which does not contain all formulas, and, as a consequence, that T ∗ is consistent.
First we show that T ∗ does not contain all formulas. Let α ∈
F orCl . According to the construction of T0 , α and ¬α cannot be
simultaneously in T0 . Suppose that ϕ ∈ F orCP . Then for some i, j,
ϕ = ϕi and ¬ϕ = ϕj . Since Tmax(2i,2j)+1 is consistent, T ∗ cannot
contain both ϕ and ¬ϕ.
Next we show that T ∗ is deductively closed. If α ∈ F orCl and
∗
T � α then by the construction of T0 , α ∈ T ∗ and K1,0 α ∈ T ∗ .
Let ϕ ∈ F orCP . Notice that if ϕ = ϕj and Ti � ϕj , it must be ϕ ∈
T ∗ because Tmax(i,2j)+1 is consistent. Suppose that the sequence
ϕ1 , ϕ2 , . . . ϕ forms the proof of ϕ from T ∗ . If the sequence is finite,
there must be a set Ti such that Ti � ϕ. Then, similarly as above,
ϕ ∈ T ∗ . Thus suppose that the sequence is countably infinite.We
can show that for every i, if ϕi is obtained by an application of an
inference rule, and all premises belong to T ∗ , then there must be
ϕi ∈ T ∗ . If the rule is a finitary one, then there must be a set Tj
which contains all premises and Tj � ϕi . Reasoning as above, we
conclude that ϕi ∈ T ∗ . So, let us now consider the infinitary rules.
For instance, we consider rule R3, while rule R5 follows similarly.
Suppose that ϕi = (ψ ⇒⊥) is obtained from the set of premises
{ϕr = (ψ ⇒ ¬Kr,pn α)|r ∈ Q}, by Rule R3 and for some α ∈
F orCl , n ∈ Z. By the induction hypothesis ϕr ∈ T ∗ for every
r ∈ Q. By the step 3 of the construction there must be some r � and
some l such that ψ ⇒ Kr� ,pn α belongs to Tl . Since all premises
belong to T ∗ , for some k, ψ ⇒ ¬Kr� ,pn α ∈ Tk . If m = max(l, k)
then
ψ ⇒ ¬Kr� ,pn α, ψ ⇒ Kr� ,pn α ∈ Tm

µ([α]) =

�

if Kr,0 α ∈ T ∗
otherwise

r
limpn→∞ rn

• for every world w and every propositional letter p ∈ V ar,
v(w, p) = true iff w |= p.
First note that µ([α]) is well defined: by Axiom A4 it cannot happen that Kr1 ,0 α, Kr2 ,0 α, ∈ T ∗ , r1 �= r2 .
Theorem 4 Let MT ∗ = �W, H, µ, v� be defined as above. Then
for every α, β ∈ F orCl the following holds:
1.
2.
3.
4.

if [α] = [β] then µ([α]) = µ([β]);
if [α] ∩ [β] = ∅ then µ([α ∨ β]) = µ([α]) + µ([β]);
µ(W ) = 1 and therefore µ(∅) = 0;
µ([¬α]) = 1 − µ([α]).

Proof For instance, we will prove property (1). Other cases follow similarly. Let [α] = [β]. Then {w|v(w, α) = true} =
{w|v(w, β) = true}. Therefore, for every world w, v(w, α ⇔ β) =
true so α ⇔ β ∈ T , i.e. α ⇔ β ∈ T ∗ . Then T ∗ � α ⇔ β. Let
µ([α]) = r.
(a) Suppose that Kr,0 α ∈ T ∗ . Then:
T ∗ � Kr,0 α
T∗ � α ⇔ β
T ∗ � Kr,0 α ⇔ Kr,0 β by Rule R6 T ∗ � Kr,0 α ⇒ Kr,0 β
T ∗ � Kr,0 β by Rule R1.
Therefore Kr,0 β ∈ T ∗ so µ([β]) = r.
(b) Suppose that Kr,0 α ∈
/ T ∗ . Then limpn→∞ rn = r, where
(rn )n∈N = r(α). Then, reasoning as above, for every element
of this sequence, from T ∗ � α ⇔ β and T ∗ � Krn ,p−n α we
obtain T ∗ � Krn ,p−n β.
Therefore, for every n, Krn ,p−n β ∈ T ∗ and using Lemma 4,
µ([β]) = limpn→∞ rn = r.

Thus Tm � ψ ⇒ Kr� ,pn α and Tm � ψ ⇒ ¬Kr� ,pn α so Tm �
ψ ⇒⊥. Then, in the same way as above, we have ψ ⇒⊥∈ T ∗ .
Let T ∗ be a maximal consistent set obtained from a consistent set
T by the construction from Theorem 4. According to the step (3),
T ∗ has the next property: For every formula α ∈ F orCl and every
m ∈ N there is at least one r ∈ Q such that Kr,p−m α ∈ T ∗ .
Since T ∗ is deductively closed, using axiom A5, we can obtain
countably many rational numbers r� ∈ Q such that Kr� ,p−m α ∈ T ∗ .
Now, for each formula α ∈ F orCl we make a sequence of rational
numbers rm in the following way:

Theorem 5[Strong completeness] A set of formulas T is consistent
iff it has an CP LZp -model.
The proof can be found in the Appendix.

5

Decidability

In this section we prove decidability of the satisfiability problem
for CP LZp -formulas. Since there is a procedure for deciding satisfiability of classical propositional formulas, we will consider only
F orCP -formulas.
Let ϕ ∈ F orCP . If p1 , . . . , pn are all propositional letters appearing in ϕ, then an atom of a formula ϕ is a formula of the form
±p1 ∧ . . . ∧ ±pn , where ±pi is either pi or ¬pi . It can be shown,
using classical propositional reasoning, that ϕ is equivalent to a formula of the form DN F (ϕ) =

• For every m ∈ N we arbitrarily chose any number r such that
Kr,p−m α ∈ T ∗ and this r will be the m-th number of the sequence, i.e., rm = r.
In this way we obtain the sequence r(α) = r0 , r1 , . . . , where
Krj ,p−j α ∈ T ∗ .
Notice that it is possible that rm = rk , for some m �= k.
Lemma 1 Let r(α) be defined as above. Then, r(α) is a Cauchy
sequence with respect to the p-adic norm. It can be proved that the
limes of r(α) does not depend on the choice of rk ’s.

�

i=1,m

20

((

�

j=1,ki

±Kri,j ,pni,j αi,j ) ∧ (

�

l=1,si

±CKri,l ,pni,l αi,l , βi,l ))

ECAI-2012 Workshop WL4AI

where ±Kri,j ,pni,j αi,j (±CKri,l ,pni,l αi,l , βi,l ) denotes either
Kri,j ,pni,j αi,j or ¬Kri,j ,pni,j αi,j (CKri,l ,pni,l αi,l , βi,l or
¬CKri,l ,pni,l αi,l , βi,l ). ϕ is satisfiable iff at least one disjunct from
DN F (ϕ) is satisfiable.
Let
Di = (

�

j=1,ki

±Kri,j ,pni,j αi,j ) ∧ (

�

l=1,si

 �
yt
at ∈αi,s ∩βi,s

n�
i

� i
|
− rsi |p ≤ p si


y
t

at ∈βi,s

i



if ±CK
n� αi,si , βi,si = CK
n� αi,si , βi,si


rsi ,p si
rsi ,p si
Ls i =
�


yt

at ∈α
∩β
n�


| � i,si i,si − rsi |p > p si

yt


at ∈βi,s

i

 if ±CK
n� αi,s , βi,s = ¬CK
n� αi,s , βi,s

±CKri,l ,pni,l αi,l , βi,l )

be a disjunct from DN F (ϕ). Every propositional formula α is
equivalent to the full disjunctive normal form, denoted F DN F (α).
If |= (α ⇔ β), then according to Rule R6, for every model M
and every r ∈ Q, ρ ∈ R, M |= Kr,ρ α iff M |= Kr,ρ β. Similarly,
if |= (α ⇔ γ) and |= (β ⇔ δ), then |= (α ∧ β) ⇔ (γ ∧ δ) so
µ([α ∧ β]) = µ([γ ∧ δ]) and µ([β]) = µ([δ]). Therefore, for every
model M and every r ∈ Q, M |= CKr,ρ α, β iff M |= CKr,ρ γ, δ.
Thus, Di is satisfiable iff formula
(

�

j=1,ki

(

�

rsi ,p si

The inequality
|

�

|
yt = 1
iff

t=1

 �
| at ∈α yt − r1 |p ≤ pn1


i,1


 if ±Kr1 ,pn1 αi,1 = Kr1 ,pn1 αi,1
J1 =
�


| at ∈α yt − r1 |p > pn1

i,1



i

rk ,p
i

i

(

n�

r1 ,p 1

αi,1 , βi,1 = ¬CK

n�

r1 ,p 1

yt − r|p ≤ pn

at ∈α

�

=

r−k and

�

yt )−k+1

=

r−k+1 and

�

yt )−n−1

=

r−n−1

at ∈α

(
and (

�

�

..
.

at ∈α
at ∈α

yt )−j = 0 for j < −k. In the case that pk ≤ pn then
|

�

at ∈α

yt − r|p ≤ pn

iff ( at ∈α yt )−j = 0 for j < −n.
For inequalities of the form |y −a|p > pn we use following result:
Lemma 2 Let a ∈ Q, j ∈ Z, a = a−k p−k + a−k+1 p−k+1 +
. . . and n = max{k, j + 1}. Then inequality |y − a|p > pj has a
solution iff it has a solution yf such that |yf |p = pn .
Proof Let |y − a|p > pj . Then, for some m ≥ j + 1, y − a =
c−m p−m + . . . c−j+1 p−j+1 + c−j p−j +. . . .

i

 �
yt
�
at ∈αi,1 ∩βi,1


| �
− r1 |p ≤ p n1


y
t

at ∈βi,1




 if ±CKr1 ,pn�1 αi,1 , βi,1 = CKr1 ,pn�1 αi,1 , βi,1
L1 =
�


yt

�
at ∈αi,1 ∩βi,1


| �
− r1 |p > p n1

yt


at ∈βi,1


if ±CK

�

at ∈α

at ∈α

..
.

i

yt − r|p ≤ pn

yt )−k

(

if ±Kr1 ,pn1 αi,1 = ¬Kr1 ,pn1 αi,1

 �
| at ∈α
yt − rki |p ≤ pnki


i,ki



 if ±Krki ,pnki αi,ki = Krki ,pnki αi,ki
=
�


| at ∈α
yt − rki |p > pnki

i,ki


 if ±K
nk αi,k = ¬K
nk αi,k

�

means that at ∈α yt and r have a common initial piece. More precisely, if pk > pn then

n

i

i

r = r−k r−k+1 . . . r−n−1 r−n r−n+1 . . .

±CKri,l ,pni,l F DN F (αi,l ), F DN F (βi,l ))

rk ,p

i

In the sequel, we will also use the short p-adic representation

is satisfiable. Since for different atoms ai and aj , [ai ] ∩ [aj ] = ∅,
µ[ai ∨ aj ] = µ[ai ] + µ[aj ]. Hence, Di is satisfiable iff the following
system Si is satisfiable:

Jki

rsi ,p si

r = r−k p−k + . . . + r−n−1 p−n−1 + r−n p−n + r−n+1 p−n+1 + . . .

±Kri,j ,pni,j F DN F (αi,j ))

2
�

i

where at ∈ αi,j denote that the atom at appears in F DN F (αi,j ),
while at ∈ αi,j ∩ βi,j denote that the atom at appears in
F DN F (αi,j ) and in F DN F (βi,j ), and yt = µ([at ]).
In order to check satisfiability of the previous system we will consider the above inequalities. Let

∧

l=1,si

i

1. Suppose that j + 1 ≥ k, i.e. n = j + 1. Then y = c−m p−m +
. . . c−j−1 p−j−1 + . . . +(c−k + a−k )p−k + . . . (or eventually y =
c−m p−m + . . . +(c−j−1 + a−k )p−j−1 + (c−j + a−j )p−j . Let
yf = c−j−1 p−j−1 + . . . +(c−k +a−k )p−k + . . . (yf = (c−j−1 +
a−k )p−j−1 + (c−k + a−j )p−j + . . . ). Thus, anyhow |yf − a|p =
pj+1 > pj .

αi,1 , βi,1

..
.

21

ECAI-2012 Workshop WL4AI

for all variables appearing in the system. We enumerate these representations (potential solutions) by R1 ,R2 . . . Rp( D−M +1)(2n −1) .
More precisely:

2. k > j + 1, n = k.
−m

−k

(a) k ≤ m. Thus, y = c−m p + . . . +(c−k + a−k )p +
. . . +(c−j−1 + a−j−1 )p−j−1 + (c−j + a−j )p−j + . . . . Then,
for yf = (c−k + a−k )p−k + . . . +(c−j−1 + a−j−1 )p−j−1 +
. . . , |yf − a|p = pk ≥ pj+j > pj . Particularly, if k = m,
y = (c−m + a−k )p−k + (c−k+1 + a−k+1 )p−k+1 +. . . and
yf = y.

• the representation R1 is denoted by
000 . . . 0, 000 . . . 0, . . . 000 . . . 0

(b) k > m. In that case y = a−k p−k +. . . +(c−m +
a−m )p−m +. . . +(c−j−1 +a−j−1 )p−j−1 +. . . . Then, for yf =
y, |yf − a|p = pk > pj+1 > pj .

which means that (yji )k = 0 for all i, j, k,
• the representation R2 is denoted by
100 . . . 0, 000 . . . 0, . . . 000 . . . 0

The other direction is obvious. Thus, if we want to find y such that
|y − a|p > pj it is enough to find y of the form y = y−m p−m . . .
for any m ≥ n.

�2n−1

n

which means that (y11 )−D = 1, while all the others (yji )k are
equal to 0, etc.

Replacing y 2 with 1 − t=1 yt in the system Si we obtain that
ϕ is satisfiable iff the following system S is satisfiable:
J1 =

� �
|

|

y1
t t

� or1
t

−

r1�� |p

≤p

Thus, we assign the potential solution R1 to the variables and check
whether the system is satisfiable. If R1 does not satisfy the system,
we can try with R2 and so on. Finally, after a finite number of steps,
we will find a representation which satisfies the system, or we can
conclude that no representation satisfies the system S. Note that each
Ri that satisfies the system is a ”finite part” of infinitely many solutions, thus it is actually particular solution.
Remark If |z|p = pk and z = xy where |x|p = pm+k , |y|p = pm

n1

yt − r1�� |p > pn1
..
.

 �
 | t ytk − rk�� |p ≥ pnk

m

then ppm xy = z |pm x|p , |pm y|p ≤ pk . Thus, if we want to obtain z
which p-adic representation begins with position −k it is enough to
x and y such that their representations begin with any j ≤ −k. We
use this fact when we check satisfiability of inequalities that include
fractions.

or
 | � y k − r�� | > pnk
k p
t t
�

±
y 11 +1∗
�

 | �t t11 ∗ − r1 |p ≤ pn1

 ± t yt +1
or
L1 =
 ± � y11 +1∗

�

 | �t t11 ∗ − r1 |p > pn1
Jk =

±

t

6

yt +1

In this paper we have defined several p-adic valued conditional probabilistic logics (one for each set of propositional letters). The corresponding strongly complete axiomatizations have been given. Decidability of the logics have been proven.
One of the possible applications of the presented logics concerns
interesting connections with the various systems developed for modelling reasoning with uncertainty, especially non-monotonic reasoning. The standard approach to modelling uncertainty is probability
theory. As mentioned in the introduction, researchers have introduced a number of generalizations and alternatives to probabilities. A
very general approach has been presented in the paper [9] where the
authors has introduced so-called plausibility measures and showed
that almost all approaches for dealing with uncertainty can be viewed
as plausibility measures. Drawing on this work, one can see that the
monotonicity is an essential property in reasoning with uncertainty.
A plausibility space is a tuple (W, H, P l), where H is an algebra of
subsets of W , and P l is a plausibility measure on W , i.e., a function
P l : H → D that maps sets in H to elements in some partially ordered set (D, ≤D ), and satisfies the only one condition: if A ⊆ B,
then P l(A) ≤D P l(B). Some special types of CP LZp -models can
be viewed as plausibility spaces and, therefore, be used in appropriate
context. Although there are several possibilities to restore a plausibility space from a special p-adic probability space, we mention only
one. A p-adic probability measure µ : H → Zp is | · |p -monotone if
A ⊆ B implies |µ(A)|p ≤ |µ(B)|p . A CP LZp -model is monotone
if its measure is | · |p -monotone. More detailed considerations of this
and the other possible applications are left for a companion paper
which will follow.

..
.

Ls =

�

� s1 ∗

±
y +1
�

�t ts1 ∗ − rs |p ≤ pns
|


y +1
 ±
t

t

or
�


±
y s1 +1∗
�

 | �t ts1 ∗ − rs |p > pns
±

yk
t t

t

yt +1

∗

�

�

Where ±
+ 1 denotes 1 − t ytk or t ytk . Now, ri are
arbitrary rational numbers and nj (from pnj ) are from Z.
Let n1 , . . . , na appearing in inequalities with ≤ pni , while
m1 , . . . , mb are from inequalities with > pmj . Suppose that
r, r ∈ {r1�� , . . . , rk�� , r1 , . . . , rs } and that r have maximal p-adic
norm (among all ri ), while r have minimal p-adic norm. Let r =
pk ,r = ps , D = max{0, k, n1 . . . na , m1 + 1, . . . mb + 1},
M = min{0, s, n1 . . . na , m1 , . . . mb }. We put 0 in these estimations because 1 appears in inequalities.
Since each (yjt )k
∈
{0, 1, . . . , p − 1}, there are
D−M +1
p
possibilities for each representation of the form
y = y−D y−D+1 . . . y−M −1 y−M (it is assumed that yj = 0
for j < −D).
The system S has at most 2n − 1 variables yjt so there are at most
p(D−M +1)(2

n

Conclusion

−1)

ways to chose representations of the form
y = y−D y−D+1 . . . y−M −1 y−M

22

ECAI-2012 Workshop WL4AI

7

Acknowledgement

[27] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics, MIT Press,
Cambridg, 2005.

The authors are partially supported by Serbian Ministry of education
and science through the grants III044006, ON174026, III041013 and
TR36001.

8

Appendix

We give the proof of Theorem 5.
(⇐) This direction follows from the soundness of the above axiomatic system (Theorem 4).
(⇒) In order to prove this direction we construct MT ∗ =
(W, H, µ, v) as above, and show, by induction on complexity of formulas, that for every formula A, MT ∗ |= A iff A ∈ T ∗ .

REFERENCES
[1] E. W. Adams, The logic of Conditional, Dordrecht, Reidel, 1975.
[2] F. Bacchus, ‘Lp, a logic for representing and reasoning with statistical
knowledge’, Computational Intelligence, 6, 209–231, (1990).
[3] A. J. Baker, An Introduction to p-adic numbers and p-adic analysis, Department of mathematics, University of Glasgow, Glasgow G12 8QW,
Scotland, 2002.
[4] S. Coletti and R. Scozzafava, Probabilistic logic in a coherent setting,
Kluwer, Doredrecht, 2002.
[5] R. Fagin and J. Halpern, ‘Reasoning about knowledge and probability’,
Journal of the ACM, 41(2), 340–367, (1994).
[6] R. Fagin, J. Halpern, and Megiddo N., ‘A logic for reasoning about
probabilities’, Information and Computation, 87(1/2), 78–128, (1988).
[7] R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi, Reasoning About
Knowledge, MIT Press, Cambridge, 2003.
[8] T. Flaminio and F. Montagna, ‘A logical and algebraic treatment of conditional probability’, Proceedings of IPMU ’04, 493–500, (2004).
[9] N. Friedman and J. Halpern, ‘Plausibility measures and default reasoning’, Journal of the ACM, 48(6), 648–685, (2001).
[10] N. Ikodinovi´c, M. Raˇskovi´c, Z. Markovi´c, and Z. Ognjanovi´c, ‘Logics
with generalized measure operators’, Journal of Multiple-Valued Logic
and Soft Computing. Accepted for publication.
[11] N. Ikodinovi´c, M. Raˇskovi´c, Z. Ognjanovi´c, and Z. Markovi´c, ‘Measure
logic’, Proceedings of the 9th European Conference on Symbolic and
Quantitative Approaches to Reasoning with Uncertainty, ECSQARU,
128138, (2007).
[12] A Ili´c-Stepi´c, Z. Ognjanovi´c, N. Ikodinovi´c, and A. Perovi´c, ‘A p-adic
probability logic’, Mathematical Logic Quarterly. Accepted for publication.
[13] K. Kersting and L. D. Raedt, Bayesian logic programming: Theory and
tool. In Getoor, L. and Taskar, B., editors, Introduction to Statistical
Relational Learning, MIT Press, Cambridge, 2007.
[14] A. Yu. Khrennikov, ‘Mathematical methods of the non-archimedean
physics’, Uspekhi Mat.Nauk, 45(4), 79–110, (1990).
[15] A. Yu. Khrennikov, p-adic valued distibutions in mathematical physics,
Kluwer Academic Publishers, Dordrecht, 1994.
[16] A. Yu. Khrennikov, Interpretations of probability, Walter de Gruyter,
Berlin, Germany, 2009.
[17] D. Lehmann, ‘Generalized qualitative probability: Savage revisited’,
In Proceedings of 12th Conference on Uncertainty in Artificial Intelligence (UAI-96), 381388, (1996).
[18] E. Marchioni and L. Godo, ‘A logic for reasoning about coherent
conditional probability: A modal fuzzy logic approach’, In Proc. of
the JELIA’04, Lecture notes in artificial intelligence, 3229, 213–225,
(2004).
[19] Z. Markovi´c, M. Raˇskovi´c, and Z. Ognjanovi´c, ‘Completeness theorem
for a logic with imprecise and conditional probabilities’, Publications
de L’Institute Matematique, 78, 35–49, (2005).
[20] R. E. Neapolitan, Probabilistic Reasoning in Expert Systems, Wiley,
New York, 1990.
[21] Z. Ognjanovi´c, M. Raˇskovi´c, and Z. Markovi´c, ‘Probability logics’, in
Zbornik radova, subseries Logic in computer science, 12(20), 35–111,
(2009).
[22] J. Pearl, Probabilistic Reasoning in Intelligent Systems, Morgan Kaufmann, San Francisco, 1988.
[23] M Raˇskovi´c and R. Djordjevi´c, Probability Quantifiers and Operators,
VESTA, Belgarde, 1996.
[24] M. Raˇskovi´c, Z. Markovi´c, and Z. Ognjanovi´c, ‘A logic with approximate conditional probabilities that can model default reasoning’, International Journal of Approximate Reasoning, 49, 52–66, (2008).
[25] M. Raˇskovi´c, Z. Ognjanovi´c, and Z. Markovi´c, ‘A logic with conditional probabilities’, In 9th Euroean conference JELIA’04 Logics in
Artificial Intelligence, Lecture notes in artificial intelligence, 226–238,
(2004).
[26] P. Spirtes, C. Glymour, and V. Scheines, Causation, Prediction, and
Search, Springer, New York, 1993.

• Let A = α ∈ F orCl . If α ∈ T ∗ , then α ∈ T and for every
w ∈ W , w |= α, i.e., MT ∗ |= α. Conversely, if MT ∗ |= α then
by the completeness of classical propositional logic, α ∈ T , and
α ∈ T ∗.
• For technical reasons we especially consider formulas of the form
Kr,ρ α. Let A = Kr,ρ α for some r ∈ Q, ρ ∈ R and α ∈ F orCl .
Suppose that Kr,ρ α ∈ T ∗ . First we assume that ρ > 0 and ρ =
p−t for some t ∈ N. Choose r(α) such that rt = r. Let r(α) =
(rn )n∈N and µ([α]) = limpn→∞ rn . Thus
(∀ε)(∃n0 )(∀n)(n ≥ n0 → |rn − µ([α])|p ≤ ε).
Let ε = p−t . If t ≥ n0 then |rt − µ([α])|p ≤ p−t and therefore
MT ∗ |= Krt ,p−t α, i.e., MT ∗ |= Kr,p−t α. Suppose that t < n0
and consider some k ≥ n0 . Then Krk ,p−k α ∈ T ∗ and |rk −
µ([α])|p ≤ p−t . Thus:
T ∗ � Krt ,p−t α
T ∗ � Krk ,p−k α
T ∗ � Krk ,p−k α ⇒ Krk ,p−t α by Axiom A3 since p−t > p−k
T ∗ � Krk ,p−t α
T ∗ � Krt ,p−t α ∧ Krk ,p−t α.
If |rt − rk | > p−t then by Axiom A4, T ∗ � Krt ,p−t α ⇒
¬Krk ,p−t α and therefore T ∗ � ¬Krk ,p−t α, which contradicts
the consistency of T ∗ . Thus |rt − rk | ≤ p−t and
|rt − µ([α])|p = |(rt − rk ) + (rk − µ([α]))|p ≤
max{|rt − rk |p , |rk − µ([α])|p } ≤ p−t
so MT ∗ |= Kr,p−t α.
If ρ = pt , t > 0, i.e., Kr,pt α ∈ T ∗ , then, for some rt ,
Krt ,p−t α ∈ T ∗ . Therefore, according to A3 Krt ,pt α ∈ T ∗ ,
and also by A4, |r − rt |p ≤ pt . Based on what we just showed,
M |= Krt ,p−t α, and since pt ≥ p−t , M |= Krt ,pt α. Thus,
|µ([α]) − rt |p ≤ pt and therefore, using |r − rt |p ≤ pt we obtain
|µ([α]) − r|p ≤ pt , i.e. M |= Kr,pt α.
Furthermore, suppose that ρ = 0, that is Kr,0 α ∈ T ∗ . Then,
according to the definition of µ in the model M = �W, P rob, v�,
we have µ([α]) = r. Therefore |µ([α]) − r|p = 0 so MT ∗ |=
Kr,0 α.
For the converse implication, suppose that MT ∗ |= Kr,ρ α and
r(α) = (rm )m∈N . Notice that for every m ∈ N, Krm ,p−m α ∈
T ∗ . Assume that ρ = pt for some t ∈ Z. In that case
|µ([α]) − r|p ≤ pt where µ([α]) = limm→∞ rm . Let ε = pt .
Then (∃m0 )(∀m)(m ≥ m0 → |rm − µ([α])|p ≤ ε). Let
m ≥ max{−t, m0 }. Thus p−m ≤ pt and |rm − µ([α])|p ≤ pt .
Since |µ([α]) − r|p ≤ pt we have
|rm − r|p = |(rm − µ([α])) + (µ([α]) − r)|p ≤

23

ECAI-2012 Workshop WL4AI

- ρ �= 0, r �= 0. Let r(α ∧ β) = (an )n∈N and r(β) = (bn )n∈N .
If a �= 0, choose ε and n�0 such that ε < min{|a|p , |b|p ·
|b| ·ρ
ρ, |b|p , |a|pp } and for n ≥ n�0 , |an − a|p ≤ ε and |bn − b|p ≤
ε. Then for n ≥ n�0 we have |an |p = |(an − a) + a|p =
max{|an − a|p , |a|p } = |a|p , because |an − a|p ≤ ε < |a|p .
In the same way we conclude that |bn | = |b|p .
n ·a
Further, for such n: | abnn − ab |p
=
| an ·b−b
|p
bn ·b

max{|rm − µ([α])|p , |µ([α]) − r|p } ≤ pt .
Hence:
T ∗ � Krm ,p−m α
T ∗ � Krm ,p−m α ⇒ Krm ,pt α, by Axiom A3, since pt ≥ p−m
T ∗ � Krm ,pt α by Rule R1
T ∗ � Krm ,pt α ⇒ Kr,pt α, by Axiom A5, since |rm − r|p ≤ pt
T ∗ � Kr,pt α by Rule R1
and since T ∗ is deductively closed, Kr,pt α ∈ T ∗ .
If ρ = 0 then MT ∗ |= Kr,0 α, that is |µ([α]) − r|p = 0. Let n
be an arbitrary nonnegative integer. Then |µ([α]) − r|p ≤ p−n
and hence MT ∗ |= Kr,p−n α. Therefore, according to the above
considerations for every n ∈ N, Kr,p−n α ∈ T ∗ . Then, according
to Rule R5, T ∗ � Kr,0 α, i.e. Kr,0 α ∈ T ∗ .
• Let A = CKr,ρ α, β for some r ∈ Q, ρ ∈ R and α, β ∈ F orCl .
Suppose that CKr,ρ α, β ∈ T ∗ . Let µ([β]) = b and r(β) =
(bn )n∈N (b = limpn→∞ bn and Kbn ,p−n β ∈ T ∗ for every n ∈
N). First assume that b �= 0 and under this assumption consider
the following cases:

=
≤
≤

and since p−n < |bn |p using Axiom A6 and Rule R1,
we obtain T ∗ � CK max{|bn |p ·ρ,|r|p p−n } α, β, i.e., T ∗ �
r,

it follows that |r|p · p−n < |bn |p · ρ. There−n

��

− r|p } ≤ ρ. Let n��0 be such that p−n0 < min{|b|p ·
|b|p ·ρ
ρ, |b|p , |r|p } and let n0 ≥ max{n�0 , n��0 }. Then, for n ≥ n0 ,
|an − bn · r|p ≤ |bn |p · ρ and therefore
|a−bn ·r|p ≤ max{|a−an |p , |an −bn ·r|p } ≤ max{ε, |bn |p ·
ρ} = |bn |p · ρ, which means that MT ∗ |= Kbn ·r,|bn |p ·ρ (α ∧
β) and therefore T ∗ � Kbn ·r,|bn |p ·ρ (α ∧ β). Thus T ∗ �
Kbn ·r,|bn |p ·ρ (α ∧ β) ∧ Kbn ,p−n β
a
| ,|a
b p b

|b| ·ρ

|bn |p ·ρ
|r|p

max{|an −a|p ·|b|p ,|bn −b|p ·|a|p }
|b|2
p
ε·|a|p
ε
max{ |b|p , |b|p } ≤ ρ.

|(an ·b−a·b)+(a·b−bn ·a)|p
|b|2
p
max{ε·|b|p ,ε·|a|p }
≤
|b|2
p

If a = 0 choose ε < min{|b|p · ρ, |b|p } and n�0 such that for
n ≥ n�0 , |an |p ≤ ε and |bn − b|p ≤ ε. Again |bn |p = |b|p and
| abnn − 0b |p = | abn |p ≤ ρ.
Thus, in both cases:
| abnn − r|p = |( abnn − ab ) + ( ab − r)|p ≤ max{| abnn −

- r �= 0 and ρ �= 0. Let ε < min{ |r|pp , |b|p } and choose n�0
such that for n ≥ n�0 |b − bn |p ≤ ε. Then, |bn |p = |(bn −
b) + b|p = max{|bn − b|p , |b|p } = |b|p , since |bn − b|p ≤
��
|b| ·ρ
ε < |b|p . Select n��0 such p−n0 < min{ |r|pp , |b|p } and let
n0 = max{n�0 , n��0 }. For every n ≥ n0 the following holds:
T ∗ � CKr,ρ α, β ∧Kbn ,p−n β, where |bn |p �= 0, and therefore,
by axiom A7, T ∗ � Kr·bn ,max{|bn |p ·ρ,|r|p ·p−n } (α ∧ β). Since
p−n <

n ·a)
| (an ·b−a·b)+(a·b−b
|p =
bn ·b

CKr,ρ α, β.

∗

|bn |p

fore, max{|bn |p · ρ, |r|p · p } = ρ · |bn |p and hence T �
Kr·bn ,ρ·|bn |p (α∧β). Thus, |µ([α∧β])−r·bn |p ≤ ρ·|bn |p and
therefore |µ([α ∧ β]) − r · µ([β])|p = |(µ([α ∧ β]) − r · bn ) +
(r · bn − r · µ([β]))|p ≤ max{ρ · |bn |p , |r|p · |bn − µ([β])|p } =
ρ·|b |
ρ · |bn |p because |bn − µ([β])|p ≤ ε < |r|np p . Hence,

– If r = 0 proof is different insofar as we choose n��0 such
��
that p−n0 < min{|bn |p · ρ, |bn |p }. Applying Axiom A6,
under the same hypotheses as before, we obtain T ∗ �
max{|bn |p ·ρ,0}
CK0 ,
, that is T ∗ � CK0,ρ α, β.
|bn |p

- r = 0. In this case we conclude as above with the difference
��
that we choose ε and n��0 such that ε < |b|p and n��0 p−n0 <
|b|p . Further, using previous considerations we obtain
T ∗ � Kr·bn ,max{|bn |p ·ρ,|r|p ·p−n } (α ∧ β)
that is, T ∗ � K0,ρ·|bn |p (α ∧ β) because |r|p = 0 and
p−n < |bn |p . Thus |µ([α ∧ β])|p ≤ ρ · |bn |p and therefore
| µ([α∧β])
| ≤ ρ i.e. MT ∗ |= CK0,ρ α, β.
µ([β]) p

and hence | µ([α∧β])
− r|p ≤ p−n for every n ∈ N, that is
µ([β])
MT ∗ |= CKr,p−n α, β for every n ∈ N. Based on what we
have just shown, T ∗ � CKr,p−n α, β for every n ∈ N and
hence, using Rule R5, we obtain T ∗ � CKr,0 α, β.
Finally, suppose that b = 0. Then, according to Definition 2,
|r − 1|p ≤ ρ. On the other hand, from µ([β]) = 0, it follows
that T ∗ � K0,0 β and therefore using Axiom A8, we obtain
T ∗ � CK1,0 α, β. Since ρ ≥ 0, according to Axiom A3, T ∗ �
CK1,ρ α, β. Finally, from |r − 1|p ≤ ρ, applying Axiom A5
we obtain T ∗ � CKr,ρ α, β.

− r|p ≤ ρ,
|µ([α ∧ β]) − r · µ([β])|p ≤ ρ · |bn |p so | µ([α∧β])
µ([β])
∗
i.e. MT |= CKr,ρ α, β.

- Let ρ = 0. Since MT ∗ |= CKr,0 α, β, | µ([α∧β])
− r|p = 0
µ([β])

- r �= 0 i ρ = 0. Since T ∗ � CKr,0 α, β, using axiom A3,
we conclude that for every n ∈ N, T ∗ � CKr,p−n α, β.
Therefore, using what we just proved, for every n ∈ N,
MT ∗ |= CKr,p−n α, β that is | µ([α∧β])
− r|p ≤ p−n for every
µ([β])

• Let A = ¬B, B ∈ F or. Then MT ∗ |= ¬B iff it is not MT ∗ |= B
iff B ∈
/ T ∗ iff ¬B ∈ T ∗ .
• Let A = (B ∧ C), B, C ∈ F or. Then MT ∗ |= (B ∧ C) iff
MT ∗ |= B and MT ∗ |= C iff B ∈ T ∗ and C ∈ T ∗ iff (B ∧ C) ∈
T ∗ (the last conclusion is an elementary consequence of A1 and
the fact that T ∗ is deductively closed).

n ∈ N. Thus, there is no n ∈ Z such that | µ([α∧β])
− r|p =
µ([β])
pn so according to definition of p-adic norm, it follows that
| µ([α∧β])
− r|p = 0. Hence, MT ∗ |= CKr,0 α, β.
µ([β])

Now, suppose that b = 0, i.e. |µ([β])|p = 0. Then
MT ∗ � K0,0 β and therefore, according to Axiom A8, T ∗ �
CK1,0 α, β, so by axiom A4, it must hold |r − 1|p ≤ ρ.
Therefore, according to definition 2, we conclude that MT ∗ |=
CKr,ρ α, β.
In the opposite direction, assume that MT ∗ |= CKr,ρ α, β. Let
µ([α ∧ β]) = a, µ([β]) = b. Let b �= 0. We distinguish the
following cases.

24

ECAI-2012 Workshop WL4AI

Combination of Dependent Evidential Bodies Sharing
Common Knowledge
Takehiko Nakama1 and Enrique Ruspini 2
Abstract. In this study, we examine how to combine dependent
evidential bodies that share common knowledge. For a given set on
which evidence is to be established, it is assumed that each of multiple evidential bodies is formed not on the whole set but on its subset
and that there is an overlap among the subsets. Common knowledge
is formed on the overlapping subset, and it introduces dependencies among the evidential bodies. We derive a formula for combining
the dependent evidential bodies assuming their conditional independence given the shared knowledge. We extend Ruspini’s epistemic
logic formulation of the calculus of evidence to establish the combination formula. The resulting formula extends the Dempster-Shafer
combination formula to evidence fusion of dependent evidential bodies in a mathematically rigorous manner, without resorting to heuristics or to unclear assumptions.

1

lems (see, for instance, Feller [4,5], Sutton and Barto [14], Ross [10],
Thrun et al. [15]).
We derive our combination formula by extending Ruspini’s (
[11,12]) epistemic logic framework of the calculus of evidence. Ruspini [11] established a probability-theoretic formulation of logical
foundations of evidential reasoning. His methodology is based on the
logical foundations of probability developed by Carnap [2]. In these
frameworks, knowledge is characterized probabilistically. In his formulation, Ruspini fully utilizes epistemic logics, which were introduced by Hintikka [6] and have been developed to effectively deal
with not only the state of the real world but also the state of knowledge about it. Epistemic logics have been successfully applied to artificial intelligence (e.g., Moore [7], Rosenschein and Kaelbling [9]).
Ruspini’s approach led to several important theoretical results. For
instance, it established connections between the interval probability
bounds derived from the Dempster-Shafer theory (Shafer [13]) and
the classical (probability-theoretic) notions of upper and lower probabilities.
In this study, we extend Ruspini’s formulation of evidential reasoning to the process of combining dependent partial evidential bodies sharing common knowledge. His formulation offers two main advantages in analytically investigating evidence fusion. One of them
is that the epistemic logics incorporated in his approach allow us to
properly formulate or characterize essential concepts in evidential
reasoning, such as the state of a real system, the state of knowledge
possessed by rational agents, and effects of information about the
knowledge. As described by Ruspini [11, 12], the acquisition of evidence does not alter the actual state of the world itself but changes
the state of knowledge about it, and his epistemic formulation properly models both states. The other main advantage is that his approach allows us to establish a mathematically rigorous formulation
of evidence fusion based on probability theory. In Ruspini’s framework, evidential bodies are represented by probability spaces that reflect their epistemic states and uncertainties. Our formula extends the
Dempster-Shafer combination formula to evidence fusion of dependent evidential bodies in a mathematically rigorous manner, without
resorting to heuristics or to unclear assumptions.
The remainder of this paper is organized as follows. In Section 2,
we provide an overview of our framework and formulation. In Section 3, we review basic concepts in epistemic logics and in Ruspini’s
formulation of evidential reasoning. In Section 4, we establish probability spaces that represent evidential bodies. Using the representations, we formulate the process of combining dependent partial evidential bodies sharing common knowledge based on conditioning
in Section 5. We provide a simple example that illuminates various
aspects of our combination formula in Section 6. In Section 7, we
examine several issues associated with the evidence fusion described

Introduction and Summary

In the classical Dempster-Shafer theory (Shafer [13]), it is assumed
that evidential bodies that are to be combined are independent, but
clearly there are many cases in which it is inadequate to make the independence assumption. To our knowledge, the process of evidence
fusion in those cases has not been formulated in a mathematically
satisfactory manner. In this study, we examine how to combine evidential bodies that are dependent due to shared common knowledge.
For a given set on which evidence is to be established, it is assumed
that each of multiple evidential bodies is formed not on the whole
set but on its subset and that there is an overlap among the subsets.
As described in Section 2, this assumption should be made in addressing many real-world problems; if multiple agents are available
to form evidential bodies on a set that is too large for any one agent
to process, then each of them will be designated to form evidence
on a subset of the entire set. Thus, we describe the evidential bodies
that are to be combined as partial evidential bodies. It is also reasonable to assume in many practical situations that there is some overlap
among the assigned subsets. We assume that the evidence established
on the overlapping subset is shared by all the partial evidential bodies. The shared evidence on the overlap will be described as common
knowledge. This shared common knowledge introduces dependencies among partial evidential bodies. Roughly speaking, our combination formula shows how to combine such dependent partial evidential bodies when they are conditionally independent given the common knowledge. See Section 2 for more details. Conditional independence has been assumed in solving a variety of real-world prob1
2

European
Center
for
hiko.nakama@softcomputing.es
European
Center
for
rique.ruspini@softcomputing.es

Soft
Soft

Computing,
Computing,

email:
email:

takeen-

25

ECAI-2012 Workshop WL4AI

agents 1 and 2, form partial evidential bodies regarding Ω and that
agent 1 is provided with only Ω1 × Ωc whereas agent 2 is provided
with only Ω2 × Ωc . Thus agent 1 does not form any evidence on Ω2
whereas agent 2 does not form any evidence on Ω1 . This depicts a
rather realistic situation in forming evidence by employing multiple
agents; in practice, a sample space can be too large for any one agent
to process, and when multiple agents are available, each of them will
be responsible for gaining knowledge on a portion of the entire set.
It is also reasonable to assume in many practical situations that there
is some overlap among the assigned portions.
Let (Ω1 , σ(Ω1 ), P1 ) and (Ω2 , σ(Ω2 ), P2 ) denote the resulting evidential bodies developed by agents 1 and 2, respectively. They will
be described as partial evidential bodies 1 and 2, as shown in Figure 1. Partial evidential body 1 contains no evidential knowledge
about Ω2 , whereas partial evidential body 2 contains no evidential
knowledge about Ω1 . (Hence these evidential bodies are considered
partial.) The evidence formed on Ωc (i.e., the marginal probability
distribution on Ωc ) is assumed to be shared by the two agents, and
it introduces dependencies among the partial evidential bodies. We
will describe this shared evidence as common knowledge.
How can we combine these dependent partial evidential bodies
in order to establish evidence on the whole sample space Ω? The
resulting combined evidence, which is shown at the bottom of Figure 1, is considered ideal if it faithfully reflects the total evidence
(Ω, σ(Ω), P ). (See Section 4 for details.) Notice that the sample
space Ωc is part of both partial evidential bodies. Due to the shared
common knowledge, the independence between the two evidential
bodies cannot be assumed, so it is not appropriate to combine them
using the classical Dempster-Shafer formula, which assumes the independence. In this study, we formulate a mathematically rigorous
procedure for combining the dependent partial evidential bodies by
assuming their conditional independence given the common knowledge so that the resulting combined evidence faithfully reflects the
total evidence.

in Section 5.

2

Overview

We will use Figure 1 to provide an overview of our framework
and formulation. As described in Section 1, evidence is considered
Total evidence

X

Par0al eviden0al body 1

X

Par0al eviden0al body 2

Combined evidence

Figure 1. Formulation overview. In the process of establishing evidence on
the sample space Ω = Ω1 × Ω2 × Ωc , two partial evidential bodies are
created. Partial evidential body 1 contains no evidential knowledge about Ω2
whereas partial evidential body 2 contains no evidential knowledge about
Ω1 . The evidence on Ωc (called common knowledge) is assumed to be
shared by the partial evidential bodies, and it introduces dependencies
among them. We formulate a procedure for combing the dependent partial
evidential bodies by assuming their conditional independence given the
common knowledge so that the resulting combined evidence faithfully
reflects the total evidence, which represents the most refined evidence on Ω.

3
probabilistic knowledge in our framework (see Carnap [2], Ruspini [11,12]), and each evidential body is represented by a probability
space. Our probability-theoretic formulation of epistemic evidential
bodies is described in Sections 3–4. This approach allows us to establish a mathematically rigorous formulation of evidence fusion based
on probability theory.
Consider establishing evidence or knowledge on a sample space
Ω. In our formulation, we express Ω as a direct product Ω1 × Ω2 ×
· · · × Ωn × Ωc . Note that there is no loss of generality in expressing
a sample space as a direct product; even if the original sample space
is not a direct product, we can imbed one in it (see, for instance,
Billingsley [1] and Chung [3]). It will become clear that the directproduct representation allows us to clearly see important elements
associated with our evidence fusion formula based on conditioning.
Our results are valid for any n, but, for concreteness, we consider
n = 2; thus Ω = Ω1 × Ω2 × Ωc . See Figure 1.
The probability space (Ω, σ(Ω), P ), which is described as total
evidence in Figure 1, represents the most refined evidence that can be
established regarding the whole sample space Ω. Here σ(Ω) denotes
a σ-field in Ω. Thus the whole sample space (and any information
associated with it) must be available in forming the total evidence.
To intuitively explain the process of establishing evidential bodies,
we consider rational agents creating them. Suppose that two agents,

Preliminaries

As described in Section 1, we closely follow and extend the epistemic
framework and formulation established by Ruspini [11, 12]. In this
section, we describe basic concepts that are essential in our study.

3.1

Epistemic Logic

Let A denote a finite alphabet. Its elements are called symbols. We
define sentences as follows:
•
•
•
•
•

(S1) Each symbol is a sentence.
(S2) If E and F are sentences, then so are E ∧ F and E ∨ F.
(S3) If E is a sentence, then so is ¬E.
(S4) If E is a sentence, then so is KE.
(S5) If E and F are sentences, then E → F is a sentence.

If E is a sentence that does not include the unary operator K, then it
is called an objective sentence. We denote the set of all well-formed
sentences by S and call it a sentence space. Each sentence is assigned
a truth value, which is either T (true) or F (false). We assume that S
contains a symbol, denote it by Θ, that is always true and that it also
contains a symbol, denote it by ϕ, that is always false.

26

ECAI-2012 Workshop WL4AI

3.2

Epistemic Worlds

states where the most specific objective sentence known to be true is
E: For each E ∈ Φ(S),

Let VE denote the truth value of E ∈ S. Then an interpretation W of
S is defined by

e(E) := {W ∈ U(S) | KE is true in W, and

if KF is true, then E ⇒ F } .

W := {(E, VE ) | E ∈ S}.

This mapping is essential in establishing probability spaces for evidential bodies. We call it the epistemic mapping associated with
Φ(S).
As in the framework of Ruspini [11, 12], we represent each evidential body by a probability space. Its sample space is U (S) for
some sentence set S, and we consider a σ-field whose generating
class can be expressed as GS := {e(E) | E ∈ Φ(S)}. We let σ(GS )
denote the σ-field generated by GS ; hence σ(GS ) is the intersection
of all the σ-fields containing GS (see, for instance, Billingsley [1]
and Chung [3]). Thus the probability space is of the form

Hence W can be considered a mapping from S to {T, F}. We say that
a sentence E is true in W if and only if W maps E to T; otherwise it
is false in W.
An interpretation W is called a possible epistemic world (or simply a possible world) of S if the following axioms are satisfied in
W:
•
•
•
•
•
•

(M1) The axioms of ordinary propositional logic hold.
(M2) If KE is true, then E is true.
(M3) If KKE is true, then KE is true.
(M4) If K(E → F ) is true, then KE → KF is true.
(M5) If E is an axiom, then KE is true.
(M6) If ¬KE is true, then K¬KE is true.

(U (S), σ(GS ), P ),

4

Implication

Epistemic Equivalence

Two possible worlds W1 and W2 for S are said to be epistemically
equivalent if for any E ∈ S, the sentence KE is true if and only if it
is also true in W2 . We denote the equivalence by W1 ∼ W2 . This
relation is indeed an equivalence relation.

3.5

Evidential Bodies

We establish a probability-theoretic formulation of the process of obtaining combined evidence from partial evidential bodies that are
dependent due to shared common knowledge, as described in Section 2. We provide details for combining two partial evidential bodies, which will be referred to as PEB 1 and PEB 2. The formulation
can be easily extended to more than two partial evidential bodies. To
explain the process intuitively, we consider two rational agents creating the two partial evidential bodies; agents 1 and 2 create PEB 1
and PEB 2, respectively.
In addition to the two evidential bodies, we consider two other
bodies of evidence in our formulation: total evidence and combined
evidence. Total evidence represents knowledge about all the possible worlds presented to agents 1 and 2, and it specifies a probabilistic
structure that must be taken into account when the two partial evidential bodies are combined. On the other hand, combined evidence is
formed by integrating the two partial evidential bodies based on the
total evidence. Typically, it is ensured that the resulting combined
evidence does not contain any contradiction.
In Section 4.1, we describe the sentence spaces and the epistemic
spaces associated with the four evidential bodies. In Section 4.2, we
describe the probability spaces that represent them.

A sentence E is said to imply a sentence F if F is shown to be true
whenever E is true on the basis of (M1)–(M6) and by the rules of
deduction, regardless of the truth values of the other sentences that
could be possibly true or false (i.e., not necessarily true or false).
We denote the implication by E ⇒ F . Therefore, if E ⇒ F, then
E → F in every possible world, and the converse also holds. Hence
it follows from (M5) that if E ⇒ F , then K(E → F ) is true in every
possible world. Two sentences E and F are said to be equivalent if
E ⇒ F and F ⇒ E. The equivalence will be denoted by E ⇔ F .

3.4

(2)

where P is a probability measure on σ(GS ). In our framework, evidence is considered probabilistic knowledge on σ(GS ) (see Carnap [2], Ruspini [11, 12]).

The set of axiom schemata used here is an enhancement (by addition
of (M6)) of that originally developed by Moore [7], and the resulting
logical system is equivalent to the modal logic system S5. As described by Ruspini [11, 12], this system allows rigorous probabilitytheoretic derivations of lower and upper probabilities (belief and
plausibility) based on epistemic logics. See Ruspini [11, 12] for details.

3.3

(1)

4.1

Spaces for Evidential Bodies

Let S1 , S2 , and Sc denote three sentence spaces, and let K1 , K2 , and
Kc denote the unary operators of S1 , S2 , and Sc , respectively. We denote the alphabets of S1 , S2 , and Sc by A1 , A2 , and Ac , respectively.
Also we let e1 , e2 , and ec denote the epistemic mappings associated
with Φ(S1 ), Φ(S2 ), and Φ(Sc ), respectively (see (1)). Total evidence
will be formed from U (S1 ) × U(S2 ) × U(Sc ), and the two evidential
bodies PEB 1 and PEB 2 will be derived from U (S1 ) × U(Sc ) and
U (S2 ) × U(Sc ), respectively. Notice that U(Sc ) is part of both PEB
1 and PEB 2. As described in Sections 1–2, shared common knowledge will be formed on U(Sc ), and it will introduce dependencies
between the two partial evidential bodies. Also note that U (S1 ) will
not be a part of PEB 2 whereas U(S2 ) will not be a part of PEB 1.

Spaces

We let U (S) denote the quotient space of the set of all possible
worlds for S resulting from the equivalence relation ∼ described in
Section 3.4. This quotient space will be called the epistemic space
of S, and each element of U(S) will be called an epistemic state.
The quotient space of the set of objective sentences that results from
the equivalence relation ⇔ will be denoted by Φ(S) and called the
frame of discernment of S. To facilitate our exposition, we describe
each element in Φ(S) as an objective sentence.
We define a mapping e : Φ(S) → 2U (S) (2U (S) denotes the power
set of U (S)) such that for each E ∈ Φ(S), e(E) is the set of epistemic

27

ECAI-2012 Workshop WL4AI

form their partial evidential bodies, they are not provided with all
of U(S1 ) × U (S2 ) × U (Sc )—agents 1 and 2 are provided with
U(S1 ) × U(Sc ) and U (S2 ) × U(Sc ), respectively. Thus agent 1 remains completely ignorant about U (S2 ), and agent 2 remains completely ignorant about U (S1 ). As described in Section 2, this formulation applies to realistic situations; in many real-world problems,
the set of all possible worlds is too large for any one agent to process,
and multiple agents, who each gain knowledge only on a manageable
portion of the entire set, must be employed. It is also reasonable to
assume in many practical situations that there is some overlap among
the assigned portions. Define

After describing the evidential bodies, we will explain why we use
the direct products.
We consider the following sentence space, S1 ⊗ S2 ⊗ Sc , which
will be used to represent combined evidence.
• (TS1) The alphabet of S1 ⊗ S2 ⊗ Sc is A1 ∪ A2 ∪ Ac .
• (TS2) The axioms (S1)–(S5) in Section 3.1 hold for S1 ⊗ S2 ⊗ Sc .
We will refer to S1 ⊗ S2 ⊗ Sc as the combined sentence space. Each
possible world W of S1 ⊗ S2 ⊗ Sc is a mapping from the combined
sentence space to {T, F} satisfying the following properties:
• (TU1) If E is an objective sentence in S1 ⊗ S2 ⊗ Sc , then E is true
if and only if there exist sentences E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ) and
Ec ∈ Φ(Sc ) such that E1 , E2 and Ec are each true in W and that
E1 ∧ E2 ∧ Ec ⇒ E.
• (TU2) For each E ∈ S1 ⊗ S2 ⊗ Sc , KE is true if and only if there
exist sentences E1 ∈ S1 , E2 ∈ S2 and Ec ∈ Sc such that KE1 ,
KE2 and KEc are each true in W and that E1 ∧ E2 ∧ Ec ⇒ E.
• (TU3) The axioms (M1)–(M6) in Section 3.2 hold.

GS1 ×Sc :={(e1 (E1 ), ec (Ec )) | E1 ∈ Φ(S1 ), Ec ∈ Φ(Sc )},
GS2 ×Sc :={(e2 (E2 ), ec (Ec )) | E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc )}.

Then we can express the probability space that represents PEB 1 as
B (1) := (U (S1 ) × U (Sc ), σ(GS1 ×Sc ), PS1 ×Sc ),
where for any E1 ∈ Φ(S1 ), Ec ∈ Φ(Sc ), we have

The following mapping, which will be denoted by Γ : Φ(S1 ⊗S2 ⊗
Sc ) → 2Φ(S1 )×Φ(S2 )×Φ(Sc ) and called the compatibility relation of
Φ(S1 ⊗ S2 ⊗ Sc ), is important in establishing connections among
total evidence, two partial evidential bodies, and combined evidence.
For each E ∈ Φ(S1 ⊗ S2 ⊗ Sc ), we define

PS1 ×Sc (e1 (E1 ), ec (Ec )) = PS1 ×S2 ×Sc (e1 (E1 ), U (S2 ), ec (Ec )),
and, similarly, we can express the probability space that represents
PEB 2 as
B (2) := (U (S2 ) × U (Sc ), σ(GS2 ×Sc ), PS2 ×Sc ),

Γ(E) := {(E1 , E2 , Ec ) | E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ),
E1 ∧ E2 ∧ Ec ⇔ E in US1 ⊗ S2 ⊗ Sc }.

where for any E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ), we have

Let e(E) denote the set of epistemic states in U(S1 ⊗ S2 ⊗ Sc )
whose most specific objective sentence known to be true is E (see
(1)). Also, let ˆe1 (E1 ), ˆe2 (E2 ), and ˆec (Ec ) denote the sets of epistemic
states in U (S1 ⊗ S2 ⊗ Sc ) whose most specific objective sentences
in Φ(S1 ), Φ(S2 ), and Φ(Sc ) that are known to be true are E1 , E2 ,
and Ec , respectively. Then, by extending the basic combination theorem established by Ruspini [11, 12], it is easy to show that for each
E ∈ Φ(S1 ⊗ S2 ⊗ Sc ),
�
ˆe1 (E1 ) ∩ ˆe2 (E2 ) ∩ ˆec (Ec ).
(3)
e(E) =

PS2 ×Sc (e2 (E2 ), ec (Ec )) = PS1 ×S2 ×Sc (U(S1 ), e2 (E2 ), ec (Ec )).
While B (1) and B (2) properly represent PEB 1 and PEB 2, respectively, we cannot use PS1 ×Sc and PS2 ×Sc in establishing the
knowledge PS1 ⊗S2 ⊗Sc of combined evidence if we want to ensure
that the resulting combined evidence does not contain any contradiction. In order to guarantee this contradiction-free property, we must
restrict B (1) and B (2) to the subset of U (S1 ) × U(S2 ) × U (Sc )
that does not contain any contradiction between the two partial evidential bodies. We will describe the subset as the contradiction-free
set. Define Γ1 to be the set of all E1 ∈ Φ(S1 ) such that there exist
E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ), and E ∈ Φ(S1 ⊗ S2 ⊗ Sc )\{ϕ} satisfying
E ⇔ E1 ∧E2 ∧Ec . Also define Γ2 and Γc analogously; Γ2 denotes the
set of all E2 ∈ Φ(S2 ) such that there exist E1 ∈ Φ(S1 ), Ec ∈ Φ(Sc ),
and E ∈ Φ(S1 ⊗ S2 ⊗ Sc )\{ϕ} satisfying E ⇔ E1 ∧ E2 ∧ Ec ,
and Γc denotes the set of all Ec ∈ Φ(Sc ) such that there exist
E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), and E ∈ Φ(S1 ⊗ S2 ⊗ Sc )\{ϕ} satisfying E ⇔ E1 ∧ E2 ∧ Ec . Then the contradiction-free set can be
expressed as
�
�
�
�
�
Ω :=
e1 (E1 ),
e2 (E2 ),
ec (Ec ) .

(E1 ,E2 ,Ec )∈Γ(E)

4.2

Representations of Evidential Bodies

As described in Section 3.5, each evidential body will be represented
by a probability space of the form (2). First we establish a probability
space for total evidence. Its sample space is U(S1 )×U (S2 )×U(Sc ).
The generating class of its σ-field is of the form
GS1 ×S2 ×Sc := {(e1 (E1 ), e2 (E2 ), ec (Ec )) |

E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc )} .

As mentioned in Section 3.5, we let σ(G) denote a σ-field whose
generating class is denoted by G. Thus total evidence is represented
by

E1 ∈Γ1

E2 ∈Γ2

Ec ∈Γc

Note that Ω is σ(GS1 ×S2 ×Sc )-measurable.
The portion of B (tot) that does not lead to any contradiction between the two partial evidential bodies can be obtained by restricting
B (tot) to Ω. Thus the portions of PEB 1 and PEB 2 that are actually
used to establish combined evidence can be derived from PS1 ×S2 ×Sc
conditioned on Ω. For all E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ), let

B (tot) :=
(U (S1 ) × U (S2 ) × U(Sc ), σ(GS1 ×S2 ×Sc ), PS1 ×S2 ×Sc ),
where PS1 ×S2 ×Sc is a measure representing knowledge about
σ(GS1 ×S2 ×Sc ).
Next we establish probability spaces that represent the two partial evidential bodies, PEB 1 and PEB 2. When agents 1 and 2

PΩ (e1 (E1 ), e2 (E2 ), ec (Ec ))
:= PS1 ×S2 ×Sc ((e1 (E1 ), e2 (E2 ), ec (Ec ))|Ω).

28

(4)

ECAI-2012 Workshop WL4AI

Then the portions of PEB 1 and PEB 2 that are actually used to create
combined evidence can be represented by
(1)

(1)

BΩ :=(U (S1 ) × U(Sc ), σ(GS1 ×Sc ), PΩ ),

(2)
BΩ

:=(U (S2 ) ×

(2)
U(Sc ), σ(GS2 ×Sc ), PΩ ),

1 and PEB 2, by assuming their conditional independence given
the common knowledge. We follow the terminology of Shafer [13]
and define probability assignments of evidential bodies. Let m :
Φ(S1 ⊗ S2 ⊗ Sc ) → [0, 1], m1 : Φ(S1 ) × Φ(Sc ) → [0, 1], and
m2 : Φ(S2 ) × Φ(Sc ) → [0, 1] denote the probability assignments
(1)
associated with combined evidence (Bcom ), PEB 1 (BΩ ), and PEB
(2)
2 ( BΩ ), respectively. In Ruspini’s epistemic framework [11,12], m
is defined by

(5)
(6)

where for each E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ),
(1)

PΩ (e1 (E1 ), ec (Ec )) :=PΩ (e1 (E1 ), U(S2 ), ec (Ec )),
(2)
PΩ (e1 (E2 ), ec (Ec ))

:=PΩ (U(S1 ), e2 (E2 ), ec (Ec )).

(7)

for each E ∈ Φ(S1 ⊗ S2 ⊗ Sc ). Similarly, m1 and m2 are defined
by

Finally we establish a probability space for combined evidence. Its
sample space is U (S1 ⊗ S2 ⊗ Sc ). The generating class of its σ-field
is of the form

(1)

m1 (E1 , Ec ) :=PΩ (e(E1 ), e(Ec )),

GS1 ⊗S2 ⊗Sc := {e(E) | E ∈ Φ(S1 ⊗ S2 ⊗ Sc )}.

m2 (E2 , Ec )

Notice that by Theorem 3, we have

(E1 , E2 , Ec ) ∈ Γ(E), E ∈ Φ(S1 ⊗ S2 ⊗ Sc )} .

The knowledge (i.e., the probability measure) of combined evidence must result from the portion of U(S1 )×U(S2 )×U(Sc ) where
the knowledge of agent 1 does not contradict that of agent 2. Thus
(tot)
it must be based on BΩ . Let PS1 ⊗S2 ⊗Sc denote the probability
measure of combined evidence. Then it is linked to PΩ by
= PΩ (e(E1 ), e(E2 ), e(Ec ))

(13)

Gc := {ec (Ec ) | Ec ∈ Φ(Sc )}.
As described in Section 4.2, we form combined evidence using not
(1)
(2)
PS1 ×Sc and PS2 ×Sc but PΩ and PΩ so that the resulting evidence
does not contain any contradictory knowledge. Hence the probability
measure that underlies mc must also be derived from PΩ defined at
(c)
(4). Thus, if we let PΩ denote the probability measure, then for each
Ec ∈ Φ(Sc ),

(9)

for each E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), Ec ∈ Φ(Sc ). Thus the combined
evidence is represented by

(c)

(14)

PΩ (Ec ) = PΩ (U(S1 ), U (S2 ), Ec ),

and the probability space for the common knowlege is expressed as

Bcom := (U (S1 ⊗ S2 ⊗ Sc ), σ(GS1 ⊗S2 ⊗Sc ), PS1 ⊗S2 ⊗Sc ). (10)

(c)

Before we use these probability spaces to describe our formulation of the process of combining partial evidential bodies based on
conditioning, we explain why we use the direct products (U(S1 ) ×
U (S2 ) × U (Sc ), U (S1 ) × U(Sc ), U (S2 ) × U(Sc ), and their traces
on Ω) in these representations. As described in Section 2, there is no
loss of generality in using a direct product as a sample space. The direct products described in this section allow us to clearly see several
important elements associated with evidence fusion based on conditioning. As described earlier, U (Sc ) is part of both PEB 1 and PEB
2. Thus, regarding U (Sc ), the two partial evidential bodies use the
same unary operator (Kc ) as well as the same frame of discernment
(Φ(Sc )). Hence the marginal probability distribution on U (Sc ) represents the common knowledge shared by the two partial evidential
bodies. This common knowledge introduces dependencies among the
partial evidential bodies. On the other hand, only PEB 1 provides
knowledge about U (S1 ), whereas only PEB 2 provides knowledge
about U (S2 ). By combining the two partial evidential bodies, we
gain knowledge about both U(S1 ) and U(S2 ) that do not contain
contradictions between the two partial evidential bodies. The direct
products are effective in clearly expressing these elements that are essential for characterizing the process of combining dependent partial
evidential bodies sharing common knowledge.

5

(12)

(2)
:=PΩ (e(E2 ), e(Ec )),

for each E1 ∈ Φ(S1 ), E2 ∈ Φ(S2 ), and Ec ∈ Φ(Sc ).
We also define a probability assignment mc : Φ(Sc ) → [0, 1] for
the shared common knowledge. First we define a probability space
for it. Its sample space is U(Sc ). The generating class of its σ-field
is of the form

GS1 ⊗S2 ⊗Sc = {ˆe1 (E1 ) ∩ ˆe2 (E2 ) ∩ ˆec (Ec ) |

PS1 ⊗S2 ⊗Sc (ˆe1 (E1 ) ∩ ˆe2 (E2 ) ∩ ˆec (Ec ))

(11)

m(E) := PS1 ⊗S2 ⊗Sc (e(E))

(8)

(c)

(15)

BΩ := (U (Sc ), σ(Gc ), PΩ ).
(c)

Note that PΩ can be derived from either PEB 1 or PEB 2 because
for each Ec ∈ Φ(Sc ),
(c)

(1)

(2)

PΩ (e(Ec )) = PΩ (U(S1 ), e(Ec )) = PΩ (U(S2 ), e(Ec )).

(16)

Thus, if we let mc : Φ(Sc ) → [0, 1] denote the probability assign(c)
ment associated with BΩ , then it is defined by
(c)

(17)

mc (Ec ) := PΩ (e(Ec ))

for each Ec ∈ Φ(Sc ).
In order to characterize the conditional independence of the two
partial evidential bodies, we consider three sub-σ-fields of σ(GΩ ) in
(tot)
BΩ . First we define the following three generating classes:
(1)

GΩ :={(e1 (E1 ), U (S2 ), U (Sc )) ∩ Ω | E1 ∈ Φ(S1 )},

(18)

(c)
GΩ

(20)

(2)
GΩ

:={(U(S1 ), e2 (E2 ), U (Sc )) ∩ Ω | E2 ∈ Φ(S2 )},
:={(U(S1 ), U (S2 ), ec (Ec )) ∩ Ω | Ec ∈ Φ(Sc )}.
(1)

(2)

(c)

(19)

Then the three σ-fields σ(GΩ ), σ(GΩ ), and σ(GΩ ) are sub-σ(1)
fields of σ(GΩ ). Note that knowledge about σ(GΩ ) (i.g., the proba(1)
(1)
bility measure on σ(GΩ )) can be obtained from BΩ since for each
E1 ∈ Φ(S1 ),

Combination Formula Based on Conditioning

Using the probability spaces defined in Section 4, we derive a formula for combining two dependent partial evidential bodies, PEB

(1)

PΩ (e1 (E1 ), U (S2 ), U (Sc )) = PΩ (e1 (E1 ), U (Sc )).

29

ECAI-2012 Workshop WL4AI

whence we have

(1)

However, the knowledge about σ(GΩ ) cannot be obtained from
(2)
(2)
BΩ . Similarly, knowledge about σ(GΩ ) can be obtained from
(2)
(1)
(c)
BΩ but not from BΩ . Knowledge about σ(GΩ ) can be obtained
(1)
(2)
from either BΩ or BΩ since for each Ec ∈ Φ(Sc ),

(1)

PΩ (A(E1 )|C(Ec )) =

(1)

PΩ (U (S1 ), U (S2 ), ec (Ec )) = PΩ (U(S1 ), ec (Ec ))
=

Similarly, we have

(2)
PΩ (U(S2 ), ec (Ec )).
(1)

(2)

PΩ (B(E2 )|C(Ec )) =

(2)

The conditional independence of σ(GΩ ) and σ(GΩ ) given
(c)
σ(GΩ ) is defined as follows (see, for instance, Pollard [8]).
(1)
Definition σ(GΩ ) and
(c)
pendent given σ(GΩ ) if

are said to be conditionally inde(c)
for each C ∈ σ(GΩ ) such that PΩ (C) �= 0,

(1)

(2)

(21)

(2)
σ(GΩ )

and
are conditionally inIf the two sub-σ-fields
(c)
dependent given σ(GΩ ), then we can obtain the probability assignment m defined at (11) from PEB 1 and PEB 2 using the following
theorem:

�

(E1 ,E2 ,Ec )∈Γ(E)

m1 (E1 , Ec ) m2 (E2 , Ec )
.
mc (Ec )

PΩ (e(E2 ), e(Ec ))PΩ (e(E2 ), e(Ec ))

(22)

PΩ (e(E1 ), e(E2 ), e(Ec )),

(c)

PΩ (e(Ec ))

(2)

(c)
PΩ (e(Ec ))

�

m(E) =

(E1 ,E2 ,Ec )∈Γ(E)

.

(28)

m1 (E1 , Ec ) m2 (E2 , Ec )
.
mc (Ec )

(29)

m1 (E1 , Ec ) m2 (E2 , Ec )
mc (Ec )

as desired.

✷

Notice that if mc is given by
�
1
mc (E) =
0

(E1 ,E2 ,Ec )∈Γ(E)

(23)

if E = U(Sc ),
otherwise,

(i.e., the two agents are ignorant about U(Sc )), then (22) becomes
the Dempster-Shafer combination formula.

(E1 ,E2 ,Ec )∈Γ(E)

where the first, second, and third equalities follow from (11), (3), and
(9), respectively. Let

6

A(E1 ) :=(e(E1 ), U(S2 ), U(Sc )),

Example

In this section, we provide a simple example that illuminates various
aspects of our combination formula. Define

B(E2 ) :=(U(S1 ), e(E2 ), U(Sc )),
C(Ec ) :=(U(S1 ), U(S2 ), e(Ec )).
(1)

(c)

PΩ (e(Ec ))

Therefore, it follows from (23) and (29) that

m(E) =PS1 ⊗S2 ⊗Sc (e(E))
�
=
PS1 ⊗S2 ⊗Sc (ˆe1 (E1 ) ∩ ˆe2 (E2 ) ∩ ˆec (Ec ))
=

=

(c)

PΩ (e(Ec ))

PΩ (e(E1 ), e(E2 ), e(Ec )) =

Proof For each E ∈ Φ(S1 ⊗ S2 ⊗ Sc )\{ϕ}, we have

�

(27)

Using (12)–(13) and (17), we reexpress the right-hand side of (28)
and obtain

Theorem 1 Suppose that
and
are conditionally in(c)
dependent given σ(GΩ ). Then for each E ∈ Φ(S1 ⊗ S2 ⊗ Sc )\{ϕ},
m(E) =

PΩ (e(E2 ), e(Ec )) PΩ (e(E2 ), e(Ec ))
(2)

(1)
σ(GΩ )

.

(2)

=

(2)

(2)
σ(GΩ )

(c)

PΩ (e(Ec ))

PΩ (e(E1 ), e(E2 ), e(Ec ))

for all A ∈ σ(GΩ ), B ∈ σ(GΩ ).
(1)
σ(GΩ )

PΩ (e(E2 ), e(Ec ))

Thus, it follows from (24)–(27) that

(2)
σ(GΩ )

PΩ (AB|C) = PΩ (A|C)PΩ (B|C)

P (e(E1 ), e(Ec ))
PΩ (A(E1 )C(Ec ))
.
= Ω (c)
PΩ (C(Ec ))
PΩ (e(Ec ))
(26)

ΩX := {x1 , x2 }, ΩY := {y1 , y2 }, ΩC := {c1 , c2 },

(2)

Note that A(E1 ) ∈ σ(GΩ ), B(E2 ) ∈ σ(GΩ ), and C(Ec ) ∈
(c)
(1)
(2)
σ(GΩ ). Suppose that σ(GΩ ) and σ(GΩ ) are conditionally inde(c)
pendent given σ(GΩ ). Then

Ω := ΩX × ΩY × ΩC ,

and consider a probability space B (tot) := (Ω, σ(Ω), P ), where
σ(Ω) denotes the power set of Ω. This probability space represents
the total evidence. Three sub-σ-fields of σ(Ω) are considered. Their
generating classes are

PΩ (e(E1 ), e(E2 ), e(Ec ))
= PΩ (A(E1 )B(E2 )C(Ec ))
= PΩ (A(E1 )B(E2 )|C(Ec ))PΩ (C(Ec ))
= PΩ (A(E1 )|C(Ec ))PΩ (B(E2 )|C(Ec ))PΩ (C(Ec )), (24)

GX := {({x}, ΩY , ΩC ) | x ∈ ΩX },

(30)

where the last equality follows from the conditional independence.
Here, from (14) (or from (16)), we have

GC := {(ΩX , ΩY , {c}) | c ∈ ΩC }.

(32)

(c)

PΩ (C(Ec )) = PΩ (U(S1 ), U(S2 ), e(Ec )) = PΩ (e(Ec )).

GY := {(ΩX , {y}, ΩC ) | y ∈ ΩY },

(31)

Let σ(GX ), σ(GY ), and σ(GC ) denote the sub-σ-fields of σ(Ω) generated by GX , GY , and GC , respectively.
Since the sample space in B (tot) is discrete, we characterize P
using its probability mass function, which we denote by fXY C . Thus
for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC ,

(25)

Also, from (7), we have
PΩ (A(E1 )C(Ec )) = PΩ (e(E1 ), U(S2 ), e(Ec ))
(1)

= PΩ (e(E1 ), e(Ec )),

fXY C (x, y, c) = PXY C ({x}, {y}, {c}).

30

ECAI-2012 Workshop WL4AI

where PXC and PY C denote the marginal probability measures on
ΩX × ΩC and ΩY × ΩC , respectively, resulting from P . Hence, for
all EX ⊆ ΩX , EY ⊆ ΩY , EC ⊆ ΩC ,

Let fC denote the marginal probability mass function on ΩC derived from P . We assume fC (c) �= 0 for each c ∈ ΩC . For all
x ∈ ΩX , y ∈ ΩY , c ∈ ΩC , let
fXY |C (x, y|c) :=
fX|C (x|c) :=
fY |C (y|c) :=

fXY C (x, y, c)
,
fC (c)
�
�
y � ∈ΩY fXY C (x, y , c)
�

fC (c)
�
x� ∈ΩX fXY C (x , y, c)

PXC (EX , EC ) = P (EX , ΩY , EC ),

(33)

PY C (EY , EC ) = P (ΩX , EY , EC ).
,

(34)

.

(35)

fC (c)

Thus B (1) contains no knowledge on ΩY whereas B (2) contains no
knowledge on ΩX , and we combine these partial evidential bodies to
establish knowledge on Ω := ΩX × ΩY × ΩC that faithfully reflects
B (tot) . Let fXC and fY C denote probability mass functions derived
from PXC and PY C , respectively. The probability assignments m1
and m2 associated with B (1) and B (2) , respectively, are defined by
�
PXC (θ1 ) if θ1 = {a1 } for some a1 ∈ ΩX × ΩC ,
m1 (θ1 ) =
0
otherwise,
�
PY C (θ2 ) if θ2 = {a2 } for some a2 ∈ ΩY × ΩC ,
m2 (θ2 ) =
0
otherwise.

We examine cases where (33)–(35) satisfy the following condition:
fXY |C (x, y|c) =fX|C (x|c)fY |C (y|c)

∀ x ∈ ΩX , y ∈ ΩY , c ∈ ΩC .

(36)

Tables 1–2 show the conditional probabilities fXY |C (x, y|c) for
x ∈ ΩX , y ∈ ΩY , c ∈ ΩC when we set fX|C (x1 |c1 ) = aX ,
fY |C (y1 |c1 ) = aY , fX|C (x1 |c2 ) = bX , fY |C (y1 |c2 ) = bY under
condition (36).
Table 1.

Note that knowledge on ΩC is shared by the two partial evidential
bodies, and the marginal probability mass function fC on ΩC can be
obtained from either B (1) or B (2) : For each c ∈ ΩC ,
�
�
fXC (x, c) =
fY C (y, c).
fC (c) =

Values of fXY |C (x, y|c1 ) when fX|C (x1 |c1 ) = aX ,
fY |C (y1 |c1 ) = aY .
y
x1
x2

x

Table 2.

y1
aX aY
(1 − aX )aY

x∈ΩX

y2
aX (1 − aY )
(1 − aX )(1 − aY )

The probability assignment mC associated with the marginal probability space (ΩC , σ(ΩC ), PC ) (PC is the marginal probability measure on ΩC derived from P) is defined by
�
PC (θ) if θ = {c} for some c ∈ ΩC ,
mC (θ) =
0
otherwise.

Values of fXY |C (x, y|c2 ) when fX|C (x1 |c2 ) = bX ,
fY |C (y1 |c2 ) = bY .

Let Bcom := (Ω, σ(Ω), Pcom ) denote the probability space that
represents the combined evidence resulting from B (1) and B (2) . The
probability assignment m associated with Bcom is defined by
�
Pcom (θ) if θ = {a} for some a ∈ Ω,
m(θ) =
0
otherwise.

y
x1
x2

x

y1
bX bY
(1 − bX )aY

y2
bX (1 − bY )
(1 − bX )(1 − bY )

From
these
conditional
probabilities,
we
can
compute fXY C (x, y, c) using (33). See Table 3. Thus these probTable 3.

y∈ΩY

Therefore, our goal is to achieve

Resulting values of fXY C (x, y, c)

m(θ) = P (θ) (= fXY C (x, y, c))
x
x1
x2
x1
x2
x1
x2
x1
x2

y
y1
y1
y2
y2
y1
y1
y2
y2

c
c1
c1
c1
c1
c2
c2
c2
c2

fXY C (x, y, c)
aX aY fC (c1 )
(1 − aX )aY fC (c1 )
aX (1 − aY )fC (c1 )
(1 − aX )(1 − aY )fC (c1 )
bX bY fC (c2 )
(1 − bX )bY fC (c2 )
bX (1 − bY )fC (c2 )
(1 − bX )(1 − bY )fC (c2 )

for each singleton subset θ = {(x, y, c)} of Ω (x ∈ ΩX , y ∈ ΩY ,
c ∈ ΩC ).
Since σ(GX ) and σ(GY ) are conditionally independent given
σ(GC ), we can use Theorem 1 to derive m from B (1) and B (2) :
For each x ∈ ΩX , y ∈ ΩY , c ∈ ΩC ,
m({(x, y, c)}) =

(38)

m1 ({(x, c)})m2 ({(y, c)})
mC ({c})
fXC (x, c)fY C (y, c)
=
fC (c)
= fX|C (x|c)fY |C (y|c)fC (c)

B (1) := (ΩX × ΩC , σ(ΩX × ΩC ), PXC ),
B

m1 ({(x, c)})m2 ({(y, c)})
.
mC ({c})

We have

abilities collectively represent total knowledge on Ω. Regarding the
three sub-σ-fields of σ(Ω) generated by the classes (30)–(32), notice
that σ(GX ) and σ(GY ) are conditionally independent given σ(GC )
in this case.
Two partial evidential bodies are represented by probability spaces
B (1) and B (2) defined by

(2)

(37)

= fXY |C (x, y|c)fC (c)

:= (ΩY × ΩC , σ(ΩY × ΩC ), PY C ),

= fXY C (x, y, c),

31

(39)
(40)

ECAI-2012 Workshop WL4AI

Regarding the combination formula described in Section 5, note
that we only need the two partial evidential bodies, nothing else, to
compute the right-hand side of (22); m1 and m2 are obtained from
PEB 1 and PEB 2, respectively [see (12) and (13)], and mc can be
obtained from either partial evidential bodiy [see (17)], as described
in Section 5. Also, to use the formula of Theorem 1, common knowl(c)
edge about conditioning events [BΩ in (15)] must be established;
it is clear from (21) in Definition 5 or from (22) in Theorem 1 that
the conditioning events and knowledge about them must be shared
by the two partial evidential bodies.

where the equality in (39) follows from (36). Thus it follows from
(38) and (40) that
m({(x, y, c)}) = fXY C (x, y, c)
for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC . Hence, as desired, (37) is satisfied.
For instance, we have
m1 ({(x1 , c1 )})m2 ({(y1 , c1 )})
mC ({c1 })
aX fC (c1 ) × aY fC (c1 )
=
= aX aY fC (c1 ),
fC ({c1 })

m({(x1 , y1 , c1 )}) =

REFERENCES

which equals the value of fXY C (x1 , y1 , c1 ) in Table 3. Using (38),
we can obtain all the values in the table.
If the combined evidence were formed by the classical DempsterShafer formula, then its probability assignment m� would be obtained by

[1] P. Billingsley, Probability and Measure, Wiley Interscience, New York,
3rd edn., 1995.
[2] R. Carnap, Logical Foundations of Probability, University of Chicago
Press, Chicago, Illinois, 1962.
[3] K. L. Chung, A Course in Probability Theory, Academic Press, London,
3rd edn., 2001.
[4] W. Feller, An Introduction to Probability Theory and Its Applications,
Volume 1, Wiley, New York, 3rd edn., 1968.
[5] W. Feller, An Introduction to Probability Theory and Its Applications,
Volume 2, Wiley, New York, 2nd edn., 1971.
[6] J. Hintikka, Knowledge and Belief, Cornell University Press, Ithaca,
New York, 3rd edn., 1962.
[7] R. Moore, Reasoning about Knowledge and Action, Technical Note
191, SRI International, Menlo Park, California, 1980.
[8] D. Pollard, A User’s Guide to Measure Theoretic Probability, Cambridge University Press, New York, 2002.
[9] S. J. Rosenschein and L. P. Kaelbling, ‘The synthesis of digital machines with provable epistemic properties’, in Proceedings of the Conference on Thoeretical Aspects of Reasoning about Knowledge, pp. 83–
98. Los Altos, California, (1986).
[10] S. M. Ross, Introduction to Probability Models, Academic Press, New
York, 9th edn., 2006.
[11] E. H. Ruspini, Logical Foundations of Evidential Reasoning, Technical
Note 408, SRI International, Menlo Park, California, 1986.
[12] Enrique H. Ruspini, ‘Epistemic logics, probability, and the calculus of
evidence’, in Classic Works of the Dempster-Shafer Theory of Belief
Functions, 435–448, Springer, (2008).
[13] G. Shafer, A Mathematical Theory of Evidence, Princeton University
Press, Princeton, New Jersey, 1976.
[14] R. S. Sutton and A. G. Barto, Reinforcement Learning, MIT Press,
Cambridge, Massachusetts, 1998.
[15] S. Thrun, W. Burgard, and D. Fox, Probabilistic Robotics, MIT Press,
Cambridge, Massachusetts, 2005.

m� ({(x, y, c)}) = m1 ({(x, c)})m2 ({(y, c)})
for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC . However, the resulting combined
evidence does not reflect the total evidence unless we have
fXC (x, c)fY C (y, c) = fXC (x, c)fY C (y, c)fC (c),

(41)

for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC . Since fC (c1 ) and fC (c2 ) are
both nonzero, it follows that (41) cannot be satisfied for all x ∈ ΩX ,
y ∈ ΩY , c ∈ ΩC . Therefore, the total evidence cannot be obtained
from the combined evidence that results from the classical DempsterShafer formula.
Another strategy to obtain combined evidence using the classical
combination formula might be as follows. First derive the marginal
probability mass function fX on ΩX from B (1) and the marginal
probability mass function fY on ΩY from B (2) (and fC from either
B (1) or B (2) ). Then obtain a probability assignment m�� by
m�� ({(x, y, c)}) = fX (x)fY (y)fC (c)
for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC . In order for this combined
evidence to precisely reflect the total evidence, the three sub-σ-fields
σ(GX ), σ(GY ), and σ(GC ) must be independent: We must have
fXY C (x, y, c) = fX (x)fY (y)fC (c)
for all x ∈ ΩX , y ∈ ΩY , c ∈ ΩC . This condition is rather restrictive.
For instance, to satisfy fXY C (x1 , y1 , c1 ) = fX (x1 )fY (y1 )fC (c1 ),
we must have
[aX fC (c1 ) + bX fC (c2 )][aY fC (c1 ) + bY fC (c2 )] = aX aY .

7

Conclusion

To our knowledge, our study is the first to rigorously formulate
the process of combining dependent partial evidential bodies that
share common knowledge by assuming their conditional independence given the common knowledge. As described in Section 1, our
assumptions regarding the dependent partial evidential bodies are
rather realistic, and conditional independence has been assumed and
used in solving a variety of real-world problems (see, for instance,
Feller [4,5], Sutton and Barto [14], Ross [10], Thrun et al. [15]). Ruspini’s formulation of evidential reasoning allows us to fully incorporate the probability-theoretic concept of conditioning in evidence
fusion.

32

ECAI-2012 Workshop WL4AI

Logics for belief functions on MV-algebras
Tommaso Flaminio and Llu´ıs Godo and Enrico Marchioni1
Abstract. In this paper we introduce a fuzzy modal logic to formalize reasoning with belief functions on many-valued events. We prove,
among other results, that several different notions of belief functions
can be characterized in a quite uniform way, just by slightly modifying the complete axiomatization of one of the modal logics involved
in the definition of our formalism.

1

S5 modal logic. The approach is based on exploiting the fact that a
belief function on classical logic formulas ϕ can be interpreted as
a probability on modal formulas ✷ϕ, and hence, in that setting, a
formula of the kind P ✷ϕ, where P is a fuzzy modality for probability, can be read as ϕ is believable and its semantics given by belief
functions.
The treatment we propose here can be considered as an extension and a generalization of [16]. In particular we will focus on representing belief functions defined over fuzzy sets of finite range,
that is, fuzzy sets on a finite set X and with membership values
on a finite subset Sk = {0, 1/k, . . . , (k − 1)/k, 1} of the real
unit interval [0, 1]. As we will recall later, every finite MV-algebra
can be easily represented as a subalgebra of fuzzy sets of the form
(Sk )X = {f | f : X → Sk }, for some natural k. Then, a probabilistic modality P will be introduced into a suitable modal logic Λk
over the (k + 1)-valued Łukasiewicz logic Łk , and we will define
the belief degree of a fuzzy event modeled by a Łk formula ψ as the
probability of ✷ψ, i.e. as the truth degree of P ✷ψ.
It is worth noticing that there is not a unique way to generalize belief functions on MV-algebras. In fact, we can distinguish at least the
cases in which the belief functions are such that their focal elements
are (1) crisp sets, (2) fuzzy sets, and (3) normalized fuzzy sets. Remarkably, all these cases can be uniformly treated in our multimodal
setting only by distinguishing among several axiomatic extensions of
the intermediate modal logic Λk . We will discuss these topics in the
subsections 6.1 and 6.2.
This paper is organized as follows. In Section 2 we will recall the
basic notions about classical belief functions, while Section 3 is devoted to preliminaries on finitely and infinitely-valued Łukasiewicz
logics, MV-algebras and states. Then in Section 4 we will introduce
belief functions on MV-algebras and we will prove some basic properties. In Section 5 we consider another equivalent approach to define belief functions on MV-algebras based on a generalization of
Dempster’s spaces. Section 6 will be devoted to the modal expansion
Λk of Łck , the (k + 1)-valued Łukasiewicz logic Łk with truth constants, proving results concerning local finiteness and completeness.
Moreover, in Subsections 6.1 and 6.2, we will introduce two relevant
axiomatic extensions of Λk that will be used to characterize distinguished classes of belief functions. In Section 7 we finally introduce
the probabilistic logic over Λk , F P (Λk , Łc ), a class of probabilisticbased models, and we prove completeness. Subsection 7.1 will focus
on completeness of the logic F P (Λk , Łc ) with respect to the semantics defined by belief function-based models, while in Subsection 7.2
we will introduce an extension of F P (Λk , Łc ) to deal with normalized belief functions. We end with Section 8, where we discuss our
future work.

Introduction and motivation

Dempster-Shafer theory of evidence [7, 30] is a generalization of
Bayesian probability theory in which degrees of uncertainty are evaluated by belief functions, rather than by probability measures. Belief
functions [30, 31] can be regarded as a special class of measures of
uncertainty on Boolean algebras of events representing an agent’s
degree of confidence in the occurrence of some event by taking into
account different bodies of evidence that support that belief [30].
In the literature several attempts to extend belief functions on
fuzzy events can be found. The first extension of Dempster-Shafer
theory to the general framework of fuzzy set theory was proposed
by Zadeh in the context of information granularity and possibility
theory [34] in the form of an expected conditional necessity. After Zadeh, several further generalizations were proposed depending on the way a measure of inclusion among fuzzy sets is used
to define the belief functions of fuzzy events based on fuzzy evidence. Indeed, given a mass assignment m for the bodies of evidence
{A1 , A2 , . . .}, and a measure I(A ⊆ B) of inclusion among fuzzy
sets, the belief of a fuzzy set B can be defined in general by the value:
Bel(B) = i I(Ai ⊆ B) · m(Ai ). We refer the reader to [20, 32]
for exhaustive surveys, and [1] for another approach through fuzzy
subsethood. Different definitions were also introduced by Dubois and
Prade [10] and by Denœux [8, 9] to deal with belief functions ranging
over intervals or fuzzy numbers.
Recently, in [23, 24] and in [14], the authors introduce a treatment
of belief functions on fuzzy sets within the algebraic framework of
MV-algebras. We will recall the main ideas of these approaches in
Section 4, but it is worth pointing out that the choice of MV-algebras
as a setting for that investigation will play a notable role in the development of the present work. In fact here we will focus our attention on the introduction of a multimodal logic for belief functions
on fuzzy sets, and, since MV-algebras are the equivalent algebraic
semantics for Łukasiewicz calculus, the latter can be used both as
ground logic to treat fuzzy events and as setting to axiomatize belief
functions over them as well.
The idea of formalising a logical system to reason with belief functions within the framework of Łukasiewicz logic is not new. In fact, a
logic to reason with classical belief functions over Łukasiewicz logic
was defined in [16] as a fuzzy probabilistic extension of the classical
1

IIIA - CSIC, Campus UAB s/n, 08193 Bellaterra, Spain. Email:
{tommaso,godo,enrico}@iiia.csic.es

33

ECAI-2012 Workshop WL4AI

2

Preliminaries on Belief functions on Boolean
algebras

(Ł1) ϕ → (ψ → ϕ),
(Ł2) (ϕ → ψ) → ((ψ → χ) → (ϕ → χ)),
(Ł3) (¬ϕ → ¬ψ) → (ψ → ϕ),
(Ł4) (ϕ ∨ ψ) → (ψ ∨ ϕ),
(MP) The rule of modus ponens: from ϕ and ϕ → ψ, deduce ψ.

Consider a finite set X whose elements can be regarded as mutually
exclusive (and exhaustive) propositions of interest, and whose powerset 2X represents all such propositions. The set X is usually called
the frame of discernment, and every element x ∈ X represents the
lowest level of discernible information we can deal with.
A map m : 2X → [0, 1] is said to be a basic belief assignment, or
a mass assignment whenever

For every k ∈ N, the (k + 1)-valued Łukasiewicz logic Łk is
the axiomatic extension of Ł defined by the following axioms (cf.
[17, 19]):
(Ł5) (k − 1)ϕ ↔ kϕ,
(Ł6) (lϕl−1 )k ↔ kϕl , for every l = 2, . . . , k − 2 that does not
divide k − 1.

m(A) = 1.

m(∅) = 0 and
A∈2X

Given such a mass assignment m on 2X , for every A ∈ 2X , the
belief of A is defined as
m(B).

bm (A) =

The notion of deduction and proof are the usual ones (see [19]). A
theory is any subset of F(V ), and for every theory Γ and for every
formula ϕ we will write Γ ϕ if ϕ can be proved from Γ in the logic
Łk .
The algebraic counterpart of (finitely-valued) Łukasiewicz calculus is the class of (finitely-valued) MV-algebras. An MV-algebra (cf.
[6, 19, 27]) is a system M = (M, ⊕, ¬, 0M ) of type (2, 1, 0) such
that the reduct (M, ⊕, 0M ) is a commutative monoid, and the following equations hold:

(1)

B⊆A

Every mass assignment m on 2X is in fact a probability distribution
X
on 2X that naturally induces a probability measure Pm on 22 . Consequently, the belief function bm defined from m can be equivalently
described as follows: for every A ∈ 2X ,
bm (A) = Pm ({B ∈ 2X : B ⊆ A}).
Therefore, identifying the set {B ∈ 2
X
teristic function on 22 defined by
βA : B ∈ 2X →

1
0

X

(2)

(MV1) x ⊕ ¬0M = ¬0M ,
(MV2) ¬¬x = x,
(MV3) ¬(¬x ⊕ y) ⊕ y = ¬(¬y ⊕ x) ⊕ x.

: B ⊆ A} with its characif B ⊆ A
otherwise,

For every k ∈ N, an MVk -algebra is any MV-algebra that also satisfies:

(3)

it is easy to see that, for every A ∈ 2X , and for every mass assignment m : 2X → [0, 1], we have bm (A) = Pm (βA ). This easy
characterization will be important when we discuss the extensions of
belief functions on MV-algebras. The following is a trivial observation about the map βA that can be useful to understand our generalization: for every A ∈ 2X , βA can be regarded as a map evaluating
the (strict) inclusion of B into A, for every subset B of X.
A subset A of X such that m(A) > 0 is said to be a focal element.
Every belief function is characterized by the value that m takes over
its focal elements, and therefore, the focal elements of a belief function bm contain the pieces of evidence that characterize bm itself.

3

(MV4) kx = (k − 1)x,
(MV5) (lxl−1 )k = kxl , for every l = 2, . . . , k − 2 that does not
divide k − 1,
where, in (MV4) and (MV5), 1M stands for ¬0M , and for every
n ∈ N, nx = x ⊕ . . . ⊕ x (n-times), and xn = x . . . x (ntimes). As in the case of the logical language, here other operations
can also be defined, among them x → y is ¬x ⊕ y and x y is
¬(¬x ⊕ ¬y).
In every MV-algebra M we can define an order relation by the
following stipulation: for every x, y ∈ M ,
x ≤ y iff ¬x ⊕ y = 1.

Preliminaries on Łukasiewicz logic, MV-algebras
and states

An MV-algebra is said to be linearly ordered, or an MV-chain, provided that the order ≤ is linear.
An evaluation e of formulas of F(V ) into an MV-algebra (MVk algebra) M is any map e : V → M that extends to compound formulas by truth functionality using the operations in M . We say that e is
a model of (or satisfies) a formula ϕ ∈ F(V ) when e(ϕ) = 1M . The
class of MV-algebras constitutes a variety (i.e. an equational class
[3]), and MV-algebras are the equivalent algebraic semantics for Łukasiewicz logic. Similarly, for every k, MVk -algebras form a variety
that is the equivalent algebraic semantics for Łk . Therefore Łukasiewicz logic is complete with respect to the class of MV-algebras, and
Łk is complete with respect to class of MVk -algebras.

The logical setting in which we frame our study is that of (infinitelyvalued) Łukasiewicz logic Ł, and its finitely-valued schematic extensions Łk . Formulas of (any finitely-valued) Łukasiewicz logic are
inductively defined from a countable set V = {p1 , p2 , . . .} of variables, along with the binary connective → and the unary connective
¬. We will denote by F(V ) the class of formulas defined from the set
of variables V .
Further connectives are definable from → and ¬ as follows:
ϕ⊕ψ is ¬ϕ → ψ ϕ ψ is ¬(¬ϕ⊕¬ψ) ϕ∨ψ is (ϕ → ψ) → ψ
ϕ ∧ ψ is ¬(¬ϕ ∨ ¬ψ) ϕ ↔ ψ is (ϕ → ψ) ∧ (ψ → ϕ)
The truth constant is ϕ → ϕ and the truth constant ⊥ is ¬ , and
we will henceforth use the following abbreviations: for every n ∈ N
and for every ϕ ∈ F(V ), nϕ will stand for ϕ ⊕ . . . ⊕ ϕ (n-times),
and ϕn will stand for ϕ . . . ϕ (n-times).
The propositional Łukasiewicz logic (Ł in symbols) is defined as
the following Hilbert style system of axioms and rules (cf. [19]):

Example 1 (Standard Algebras) (1) Equip the real unit interval
[0, 1] with the operations of
- truncated sum: for all x, y ∈ [0, 1], x ⊕ y = min(1, x + y),
- standard negation: for all x ∈ [0, 1], ¬x = 1 − x.

34

ECAI-2012 Workshop WL4AI

We will henceforth omit the superscript M whenever it will be superfluous.
The standard Łc -chain is the structure [0, 1]Łc
=
([0, 1]M V , {r}r∈Q ), i.e. the standard MV-chain together with
the rational truth constants r interpreted as themselves. For every
k ∈ N, Łck -algebras and the standard Łck -chain are defined in
analogous way.
The notion of evaluation of F(V )c -formulas into expanded MVstructures with truth constants is defined in the natural way. In particular, an Lc -evaluation on the standard Lc -chain is such that e(r) = r
for every r ∈ Q(L).
Analogous completenss results as those of Theorem 1 hold for the
logics Łc and Łck .

Then the algebra [0, 1]MV = ([0, 1], ⊕, ¬, 0) is an MV-algebra
called the standard MV-algebra. The variety of MV-algebras is generated, as a variety and as a quasi-variety, by [0, 1]MV (cf. [4, 6]). This
means that, in order to show that a given equality, or quasi-equality,
written in the algebraic language of MV-algebras, holds in every MValgebra, it is sufficient to check whether it holds in [0, 1]MV .
(2) For every k ∈ N let Sk = {0, 1/k, . . . , (k − 1)/k, 1}. Equip Sk
with the restrictions to Sk of the above defined truncated sum and
standard negation. We will henceforth denote by Sk the obtained
structure, that is usually called the standard MVk -algebra. The variety of MVk -algebras is generated by Sk (cf. [6]).
Clearly, the above examples (and the results cited therein) show a
stronger version of completeness for Ł and Łk that we are going to
make clear as follows.

3.2

Theorem 1 (1) Łukasiewicz logic Ł has the finite strong real completeness (FSRC for short), i.e.: for every finite theory Γ ⊆ F(V ),
and for every formula ϕ, Γ
ϕ in Ł iff every evaluation into the
MV-algebra [0, 1]MV that satisfies Γ, satisfies ϕ as well.

The notion of state on an MV-algebra generalizes that of a finitely
additive probability on a Boolean algebra. More specifically, by a
state on an MV-algebra M (cf. [26]) we mean a map from M into
the real unit interval [0, 1], s : M → [0, 1], satisfying:

(2) For every k ∈ N, Łk has the strong real completeness (SRC
for short), i.e.: for every theory Γ ⊆ F(V ), and for every formula
ϕ, Γ
ϕ in Łk iff every evaluation into the MVk -algebra Sk that
satisfies Γ, satisfies ϕ as well.

(S1) s(1M ) = 1,
(S2) s(x ⊕ y) = s(x) + s(y), whenever x

Remark 3 The notion of state easily extends to expanded MValgebras with truth constants, just by requiring the same two properties (S1) and (S2). Namely, if M c = (M, {r}r∈Q(L) ) is any Lc algebra, then (S1) and (S2) enforce every state s on M c to satisfy
s(r) = r for every rational r ∈ Q(L), and hence states on MValgebras with truth constants are homogeneous. Therefore, this enables us to concentrate on states on MV-algebras, regardless of the
fact that the languages are enriched by rational truth constants.

Remark 2 It is worth noticing that every finite MV-algebra M can
be represented as a finite direct product of finite MV-chains. In other
words, for every finite MV-algebra M , there exists a finite MV-chain
Sk , and a finite index set X such that M embeds into the direct
product Sk )X . This means that every finite MV-algebra can be seen
as a MV-subalgebra of functions from X into Sk , i.e. as a MV-algebra
of Sk -valued fuzzy sets of X. Therefore, without loss of generality, we
will henceforth concentrate on finite MV-algebras of fuzzy sets of this
form.

A state s on M is said to be faithful provided that s(x) = 0,
implies x = 0M . In other words, a state of M is faithful if the unique
element of M sent to 0 is the bottom element of M .
Example 2 Consider any MV-algebra M . Then, every homomorphism h : M → [0, 1]MV is a state. In addition, since the class
St(M ) of all the states of M is a convex subset of [0, 1]M (cf. [26]),
the homomorphisms of M into [0, 1]MV coincide with the extremal
points of St(M ).

Expanding Łukasiewicz logic with rational
truth constants

Let L denote either Ł or Łk , and let Q(L) denote the set of all the
rational numbers included into the standard algebra of L (recall Example 1). Therefore, if L stands for Ł then Q(Ł) stands for [0, 1]∩Q,
while if L stands for any (k + 1)-valued Łukasiewicz logic Łk , then
clearly Q(Łk ) = Sk .
The logic Lc is obtained by expanding the language of Łukasiewicz logic by means of symbols r for each r ∈ Q(L),2 and adding the
following bookkeeping axiom schemes:

Given a state s : M → [0, 1], we denote by Supp(s) its support,
i.e. Supp(s) = {x ∈ M : s(x) > 0}. The following theorem is an
immediate consequence of [22, Corollary 29].
Theorem 4 Let M = (Sk )X be a finite MV-algebra. Then for every state s : M → [0, 1] there exists a finitely additive probability
measure P on B(M ) = 2X such that for every f ∈ M ,

(Q1) (r1 → r2 ) ↔ min{1, 1 − r1 + r2 };
(Q2) ¬r ↔ 1 − r.

s(f ) =

The algebraic counterpart of Łc , are structures (M, {rM }r∈Q(Ł) )
where M is an MV-algebra, the rM ’s are nullary operations in M ,
and for every r, r1 , r2 ∈ Q(Ł) the following hold:
r1 M → r2 M
¬rM
2

=
=

min(1, 1 − r1 + r2 )
M
1−r

y = 0M , .

It can be easily shown that every state s on M satisfies s(¬x) =
1 − s(x), and hence in particular s(0M ) = 0.

Every MV-algebra M contains a largest Boolean algebra B(M )
called the Boolean skeleton of M , which is constituted by all the
idempotent elements of M . Indeed, the universe of B(M ) coincides
with the set {x ∈ M : x x = x}.

3.1

States on MV-algebras

4

x∈X

f (x) · P ({x}).

Belief functions on MV-algebras

In [23, 24], Kroupa provides a generalization of belief functions that
can be easily adapted to the framework of finite MV-algebras. Recalling Remark 2, we can assume that the finite MV-algebra we are
going to work with is M = (Sk )X for a suitable MV-chain Sk , and
a finite set X. Denote by 2X the powerset of X, and consider, for

M

We will henceforth denote by F(V )c the class of formulas obtained from
this expanded language.

35

ECAI-2012 Workshop WL4AI

Proposition 9 For every finite MV-algebra M , and for every b ∈
Bel(M ), b is totally monotone, i.e. b is monotone, and it satisfies:
for all a1 , . . . , an ∈ M ,

every a : X → Sk the map ρˆa : 2X → Sk defined as follows: for
every B ⊆ X,
ρˆa (B) = min{a(x) : x ∈ B}.

(4)
n

ˆ : (Sk )X → [0, 1] a Kroupa belief
Definition 5 We call a map b
X
function whenever there exists a state ˆs : (Sk )2 → [0, 1] such that
ˆ
for every a ∈ M , b(a)
= ˆs(ˆ
ρa ).

b
i=1

(−1)|I|+1 · b

≥

∅=I⊆{1,...,n}

ak

.

k∈I

On Boolean algebras, total monotonicity is a property that fully characterizes belief functions. It is an open problem whether the same
holds for belief functions on MV-algebras, even in our restricted setting.
For every belief function b : M → [0, 1] defined by a state s on
the finite MVk -algebra (Sk )M we know from Theorem 4 that there
exists a unique finitely additive probability measure P on 2M , the
Boolean skeleton of (Sk )M , such that, for every a ∈ (Sk )M

ˆ is called the state assignThe state ˆs needed in the definition of b
ˆ has been directly introduced as a combiment in [23]. Although b
nation of ρˆ with the state assignment ˆs, a notion of mass assignment
can also be introduced even for this generalized case. Indeed, since
X is finite, it turns out that one can equivalently define
ˆ
b(a)
=

ai

ρˆa (B) · ˆs(B).
B⊆X

ρa (b) = min{b(x) ⇒ a(x) : x ∈ X}

Let mb : (Sk )X → [0, 1] be the probability distribution associated to the probability measure P of (7), i.e. defined as mb (f ) =
P ({f }), for every f ∈ (Sk )X . In this case we get, for every f ∈ M ,
ρa (f ) · mb (f ).

b(a) = s(ρa ) =

(8)

f ∈(Sk )X

Then, for obvious reasons, we call mb the mass assignment associated to b.
Given a belief function b on M , in analogy with the classical
case, an element f ∈ M is said to be a focal element, provided that
mb (f ) > 0. Notice that the focal elements, are elements of the MValgebra M = (Sk )X , and hence they are not crisp sets in general.
This supports the interpretation that the belief functions defined as in
(6) differ from Kroupa’s definition by offering a more general setting
for evidence theory.
Let us denote by ⊥ the bottom element of M , i.e. the function
⊥ : X → Sk such that ⊥(x) = 0 for all x ∈ X. However, in
general, ρ⊥ does not coincide with the bottom element of (Sk )M . In
fact, if a ∈ M is a function such that for no x ∈ X, f (x) = 1, then it
immediately follows that ρ⊥ (f ) > 0. Therefore, b(⊥) = 0 does not
hold in general (and in particular, whenever s is a faithful state). We
call a belief function b on M normalized provided that all the focal
elements of b are normalized fuzzy sets, i.e. for every focal element
f ∈ M for b there exists a x ∈ X such that f (x) = 1.
For every r ∈ Sk , let r : X → Sk be the function constantly
equal to r. Then for every normalized fuzzy set f ∈ M , ρr (f ) =
inf{f (x) ⇒ r : x ∈ X} = r. Hence, if b is a normalized belief
function, b(r) = f ∈(Sk )X ρr (f ) · m(f ) = r. In other words the
following holds.

(5)

Remark 6 In a sense, for every a ∈ M , ρa can be identified as the
membership function of the fuzzy set of elements of M (and hence
the fuzzy subsets of X) that are included in a. In particular one has
ρa (b) = 1 whenever b ≤ a (for each point). Also notice that the
Boolean skeleton B(M ) of any finite MV-algebra M = (Sk )X coincides with 2X and hence, as also shown by the following result, for
every a ∈ M the map ρa extends ρˆa in the domain.
Proposition 7 For all a, a ∈ M , ρa∧a = min{ρa , ρa }, and
ρa∨a ≥ max{ρa , ρa }.
Now we introduce our definition of belief functions on MValgebras of fuzzy sets.
Definition 8 Let X be finite, and let M = (Sk )X be the finite MValgebra of fuzzy sets of X with values in Sk . A map b : M → [0, 1]
is called a belief function if there exists a state s : (Sk )M → [0, 1]
such that for every a ∈ M ,

Proposition 10 Let b ∈ Bel(M ) be a normalized belief function.
Then b is homogeneous, i.e. for every r ∈ Sk , b(r) = r.

(6)

We denote the class of all belief functions over M by Bel(M ).

5

Notice that if a ∈ M = (Sk )X then ρa ∈ (Sk )M and hence
s(ρa ) is defined for every a ∈ (Sk )X .
It is clear from the definition that Bel(M ) is a convex set, since
states are closed by convex combinations (recall Example 2).
3

(7)

f ∈(Sk )X

where ⇒ denotes the Łukasiewicz implication function (x ⇒ y =
min(1, 1 − x + y)). 3

b(a) = s(ρa ).

a(f ) · P ({f }).

s(a) =

ˆ
In particular, since 1 = b(X)
= B⊆X ˆs(B), the restriction of the
X
state ˆs to 2 (call it m)
ˆ is a classical mass assignment. Therefore, the
ˆ as those elements in 2X that the mass assignment
focal elements of b
ˆ is defined from crisp,
m
ˆ maps into a non-zero value. In this sense, b
and not fuzzy, pieces of evidence.
The definition that we introduce below generalizes Kroupa’s definition by introducing, for every a ∈ M , a map ρa assigning to every
fuzzy set b ∈ M its degree of inclusion into a (cf. [1]). To be more
precise, let M = (Sk )X , and consider, for every a ∈ M a map
ρa : M → [0, 1] defined as follows: for every b ∈ M ,

An alternative definition of belief functions based
on Dempster spaces

The definition of a belief function on a MV-algebra functions M =
(Sk )X we have proposed in Definition 8 cannot be done by only
working inside the MV-algebra M where the belief function is defined. In fact the definition also involves a state on the bigger algebra
(Sk )M .

Here the choice of ⇒ is due to the MV-algebraic setting, but other choices
could be made in other algebraic frameworks (see e.g. [1]).

36

ECAI-2012 Workshop WL4AI

Although there are no particular requirements for choosing S5, this
modal logic has the advantage of being locally finite. This requirement is crucial to prove completeness of the resulting probabilistic
logic with respect to a Kripke style semantics.
As mentioned in the introduction, in this paper we introduce a
similar approach for belief functions on fuzzy sets of (Sk )X and,
following the definition we introduced in Section 4, we will define
a probabilistic logic over a suitable fuzzy modal logic Λk . In fact,
in order to keep the defined logic sufficiently expressive and locally
finite, we will take Λk as the non-nested fragment of Λ(Fr, Łck ), the
minimal modal logic over the standard MVk -chain Sk defined and
studied in [2]. We will devote this section to describe these modal
logics and to show completeness of Λk .
The language of Λ(Fr, Łck ) is obtained by enlarging the language
of Łck by a unary modality ✷, and defining well formed formulas in
the usual inductive manner: (1) every formula of Łck is a formula; (2)
if ϕ and ψ are formulas, then ✷ϕ, ϕ ψ, and ϕ → ψ, are formulas.
A Łck -Kripke frame is a tuple (W, R) where W is a non-empty
set of possible worlds and R : W × W → Sk is an many-valued
accessibility relation. We denote by Fr the class of all Łck -Kripke
frames. A Łck -Kripke model is a triple (W, e, R) where (W, R) is a
Łck -Kripke frame, and for every possible world w, e(·, w) is a truth
evaluation of Łck -formulas into Sk .
Given a formula φ, and a Łck -Kripke model K = (W, e, R), for
every w ∈ W , we define the truth value of φ in w, φ w , as follows:

A possibility to overcome this, so to say, peculiar situation is to
resort to the original Dempster model of defining a belief function as
a lower probability induced by a multivalued mapping [7]. Indeed,
given a probability µ on the power set of a finite set E and a multivalued mapping Γ : E → 2X , one can consider an induced lower
probability on 2X defined as bel(A) = µ({v ∈ E | Γ(v) ⊆ A}),
for every A ⊆ X. This is in fact a belief function, and moreover,
every belief function on X comes defined in this way. The 4-tuple
D = (W, E, Γ, µ) is called a Dempster space.
In this section we show how to define belief functions on MValgebras of functions M = (Sk )X based on a natural generalization
of Dempster spaces and we will show, as in the classical case, that
both approaches turn out to be equivalent. The approach based on
generalized Dempster spaces will have some advantages regarding
the logical approach to belief functions developed in Section 7.
Definition 11 (Generalized Dempster space) A
Demptser space is a 4-tuple D = (W, E, Γ, µ) where

generalized

• W and E are non-empty sets
• µ : (Sk )E → [0, 1] is a state
• Γ : E → (Sk )W is a fuzzy set-valued mapping
For simplicity, generalized Dempster spaces will be simply called
Dempster spaces from now on. For each f ∈ (Sk )W define f :
E → Sk by f (v) = inf w∈W Γ(v)(w) ⇒ f (w).

- If φ is a formula of Łck , then φ K,w = e(φ, w),
- If φ = ✷ψ, then ✷ψ K,w = w ∈W (R(w, w ) ⇒ ψ K,w ),
- If φ is a compound formula, its truth value is computed truth functionally by means of Łck truth functions.

Definition 12 (Belief function given by a Dempster space) Given
a Dempster space D = (W, E, Γ, µ), the induced belief function
belD : (Sk )W → [0, 1] is defined as
belD (f ) = µ(

The truth value of a formula φ in K is then defined as φ K =
inf{ φ K,w | w ∈ W }. As usual, the notion of (local) logical
consequence in Fr is defined as follows: given a set of formulas
Γ ∪ {ϕ}, ϕ follows from Γ, written Γ |=Fr ϕ, iff for every Kripke
model K = (W, e, R) such that (W, R) ∈ Fr and every w ∈ W , if
ψ K,w = 1 for every ψ ∈ Γ, then ϕ K,w = 1 as well.
The axioms of Λ(Fr, Łck ) are the following:

f ).

In order to distinguish the two notions of belief functions that we
have introduced so far (namely those from Definition 8 that we will
denote by b, and the ones introduced above in Definition 12 that
we will denote by belD ), we will henceforth call Dempster belief
funcions those induced by a Dempster space as in Definition 12.

-

Lemma 13 For any Dempster space D = (W, E, Γ, µ), the Dempster belief function belD can be expresed as
belD (f ) =

g∈(Sk )W

ρf (g) · m(g).

where m(g) = µ({v ∈ E | Γ(v) = g}).

The rules of Λ(Fr, Łck ) are Modus Ponens (from ϕ and ϕ → ψ infer
ψ) and Monotonicity for ✷ (from ϕ → ψ infer ✷ϕ → ✷ψ).
The notion of proof in Λ(Fr, Łck ), denoted Λ(F r,Łck ) , is defined
as usual from the above axioms and rules. In [2] the authors show
that Λ(Fr, Łck ) is sound and complete with respect to the class Fr of
Łck -Kripke frames: for every set of formulas Γ ∪ {ϕ}, Γ |=Fr ϕ iff
Γ Λ(F r,Łck ) ϕ.

Finally, as it happens in the classical case, one can show that the
two notions of belief functions given in Definitions 8 and 12 are
equivalent.
Proposition 14 Let W be finite. A mapping b : (Sk )W → [0, 1] is
a belief function in the sense of Definition 8 iff there is a Dempster
space D = (W, E, Γ, µ) such that b = belD .

6

All the axioms for Łck
(✷1) ✷1
(✷2) (✷ϕ ∧ ✷ψ) → ✷(ϕ ∧ ψ)
(✷3) ✷(r → ϕ) ↔ (r → ✷ϕ), for each r ∈ Sk

Remark 15 In [5] it is shown that the classical modal logic K is
not locally finite. This means that the Lindenbaum-Tarski algebra of
K generated by any finite set of propositional variables is infinite
in general. In particular there is an infinite class of modal formulas
φ1 , φ2 , . . . such that for every i = j, φi ↔ φj is not valid in some
Kripke frame. Since every Kripke frame for K belongs to Fr as well,
this means that Λ(Fr, Łck ) is not locally finite either.

The minimal modal extension of Łck without
nested modalities

In [16] the authors introduce a probabilistic fuzzy modal logic defined over the classical modal logic S5 to axiomatize reasoning with
classical belief functions. Roughly speaking, the intuition behind that
approach is that the two modalities P for probably, and the classical
modality ✷ of S5, can be used to define a modality B by the combination P ✷, which behaves as a belief function over classical events.

Now we define Λk as the fragment of Λ(F r, Łck ) obtained by
restricting the language to formulas without nested modalities.
Namely, the set F(V )✷ of formulas of Λk is defined as follows:

37

ECAI-2012 Workshop WL4AI

(1) formulas of Łck are formulas of Λk , i.e. F(V )c ⊆ F(V )✷ ;
(2) for every formula ϕ ∈ F(V ), ✷ϕ ∈ F(V )✷ ;
(3) F(V )✷ is taken closed under the connectives of Łck .

As already mentioned before, we extend to fuzzy events the fuzzy
modal approach of [16] to define a logic to reason about uncertainty
on classical events modeled by belief functions. Namely, the approach is based on:

Notice that, in this restricted case, nested modalities are not allowed,
and hence, if for instance ϕ and ψ are non-modal formulas, then
(✷ϕ) ψ is a formula of F(V )✷ , but ✷(✷ϕ ψ) is not. In particular
notice that the above axioms (✷1)-(✷3) are formulas in F(V )✷ .
The axioms of the logic Λk are those of Λ(F r, Łck ), and its inference rules are Modus Ponens, and the Monotonicity rule for ✷, the
latter being restricted in the premises to formulas in F(V )c . We will
denote by Λk the provability relation in Λk .

• to consider fuzzy events modeled as propositions of (finitelyvalued) Łukasiewicz logic together with modality B, for belief,
in such a way that, informally speaking, the truth degree of Bϕ
corresponds to the belief degree (in the sense of belief functions)
of ϕ.
• to get a complete axiomatization of the modality B by relying
on the fact that any belief function on Łukasiewicz formulas4 ϕ
can be obtained as a probability (or state) on formulas ✷ϕ of the
minimal modal extension of Łukasiewicz logic Λk , and hence by
defining Bϕ as the combination of two other modalities P ✷ϕ,
where P is a probabilistic modality like in [13].

Lemma 16 The logic Λk is locally finite.
Theorem 17 The logic Λk is strongly complete with respect to the
class Fr of Łck -Kripke frames.

6.1

The case of Łck -frames with crisp accessibility
relations

In the same paper [2], the authors also study the subclass CFr of
Łck -Kripke frames (W, R) where the accessibility relation R is crisp
(two-valued). The corresponding logic, Λ(CFr, Łck ), is shown to be
axiomatizable by extending Λ(Fr, Łck ) with the well-known axiom
K:

The language of the logic F P (Λk , Łc ) is obtained by expanding
the language of Λk by a unary modality P . The class F(V )P of formulas is defined as follows:
(i) F(V )✷ ⊆ F(V )P ;
(ii) for every ψ ∈ F(V )✷ , P ψ is an atomic P -formula, for every
rational number r ∈ [0, 1], r is an atomic P -formula as well, and
they belong to F(V )P ; and
(iii) F(V )P is obtained by closing the class of atomic P -formulas under the connectives of Łukasiewicz logic Ł.

(K) ✷(ϕ → ψ) → (✷ϕ → ✷ψ).

Formulas of F(V )P which are not from F(V )✷ (i.e. propositional
combinations of formulas P ψ) will be called P -formulas. For every
ϕ ∈ F(V )c , we henceforth use the abbreviation B(ϕ) for P (✷ϕ).
These formulas will be formally introduced in the next section.
Notice that in F P (Λk , Łc ) we are allowing neither formulas that
contain nested occurrences of P nor compound formulas mixing formulas from F(V )✷ and F(V )P .
Axioms and rules of F P (Λk , Łc ) are as follows:

In a similar way to what we have shown in the above section, one can
consider the logic CΛk defined as the nested modality-free fragment
of Λ(CFr, Łck ). The same techniques used in the above section show
that CΛk is locally finite, and using [2, Lemma 4.20], one can also
prove strong completeness of CΛk with respect to the class CFr of
crisp Łck -Kripke frames.

6.2

• Axioms and rules of Λk for formulas of F(V )✷
• Axioms and rules of Łc for formulas in F(V )P
• The following probabilistic axioms for P -formulas (cf. [13]):

The case of Łck -frames with reflexive
accessibility relations

Consider the logics Λrk and CΛrk obtained by adding the axiom

(PAX0) P r ↔ r, for r ∈ Sk
(PAX1) P (¬ϕ) ↔ ¬P ϕ

(T ) ✷ϕ → ϕ

(PAX2) P (ϕ → ψ) → (P ϕ → P ψ)

to Λk and CΛk respectively. We will show that these logics are also
complete with respect to the corresponding subclasses of Łck -frames
(W, R) where R is reflexive fuzzy relation, i.e. that for all w ∈ W ,
R(w, w) = 1 holds. This case is not considered in [2] so, for the
sake of to be self contained, we provide a simple proof.

(PAX3) P (ϕ ⊕ ψ) ↔ [(P ϕ → P (ψ

We will henceforth denote by F P the provability relation of
F P (Λk , Łc ).
In the above definition, we could consider adding to Λk the axioms ✷(ϕ → ψ) → (✷ϕ → ✷ψ) and ✷ϕ → ϕ (one or both) as
we did in Sections 6.1 and 6.2. This would result in similar logics
F P (CΛk , Łc ), F P (Λrk , Łc ) and F P (CΛrk , Łc ).

Λrk

(resp. CΛrk ) is sound and strongly comsubclass of Łck -Kripke frames (W, R) from

Theorem 18 The logic
plete with respect to the
Fr (resp. CFr) where the relation R is reflexive.

7

ϕ)) → P ψ]

• The rule of necessitation for P : from ϕ derive P (ϕ), for ϕ ∈
F(V )✷

Logics for belief functions on fuzzy events

Remark 19 It is worth noticing that both F P (Λk , Łc ) and
F P (CΛk , Łc ) do not prove B(r) ↔ r for r ∈ Sk \ {0}. In fact,
although P (r) ↔ r holds (it is an instance of the axiom (PAX0)),
Λk ✷r ↔ r, indeed Λk only proves one direction, r → ✷r. Then,
it is clear that the extension Λrk , which contains the reflexivity axiom ✷ϕ → ϕ, does prove the equivalence r ↔ ✷r, and hence both
F P (Λrk , Łc ) and F P (CΛrk , Łc ) prove B(r) ↔ r.

In this section we are going to introduce a probabilistic modal
extension (cf. [13, 15, 18, 19]) of Λk (and its extensions CΛk ,
Λrk and CΛrk ) that we will denote F P (Λk , Łc ) (F P (CΛk , Łc ),
F P (Λkk , Łc ), F P (CΛrk , Łc ) respectively), to deal with the two definitions of belief functions on MV-algebras of fuzzy sets we discussed
in Section 4, namely Kroupa belief functions and the new equivalent
definitions we have introduced there and in Section 5, together with
their normalized versions.

4

38

According to the notions of belief functions introduced in Sections 4 and 5.

ECAI-2012 Workshop WL4AI

The following example shows that F P (Λk , Łc ) is sufficiently
strong to prove the property of total monotonicity for the modality
B.

• If Φ is a compound formula, its truth value is computed by truth
functionality.
Given a finite probabilistic Łck -Kripke model M = (W, e, R, s),
an equivalent probabilistic model can be introduced where the state
s is replaced by a probability distribution m on the set of possible
worlds:
M = (W, e, R, m)

Example 3 (Total Monotonicity) We first observe that the formula
✷ϕ ∨ ✷ψ → ✷(ϕ ∨ ψ) is a theorem of Λk . In fact,
Λk ✷ϕ → ✷(ϕ ∨ ψ), and
Λk ✷ψ → ✷(ϕ ∨ ψ), so that
Λk ✷ϕ ∨ ✷ψ → ✷(ϕ ∨ ψ).

that is, m : W → [0, 1] is defined as m(w) = s({w}), where
s : (Sk )W → [0, 1] is an extension of s : F✷
M → [0, 1]. Such an extension always exist by [21, Theorem 6] since F✷
M is MV-subalgebra
of (Sk )W . In such a model, according to (8) the evaluation of probabilistic formulas reduces to the following expression: Φ = P ψ, then

Now, applying the rule of necessitation for P , we get F P P (✷ϕ ∨
✷ψ → ✷(ϕ ∨ ψ)), and hence together with axiom (P AX2) instantiated as P (✷ϕ ∨ ✷ψ → ✷(ϕ ∨ ψ)) → (P (✷ϕ ∨ ✷ψ) → P (✷(ϕ ∨
ψ))), and a step of modus ponens, we get F P P (✷ϕ ∨ ✷ψ) →
P (✷(ϕ ∨ ψ)), i.e.
FP

P (✷ϕ ∨ ✷ψ) → B(ϕ ∨ ψ).

Pψ

(9)

γ1 → γ2

FP

Φ ↔ [P γ2 ↔ (P γ1 ⊕ (P γ2

P γ1 ))]

FP

Finally, by substituting in (9) P (✷ϕ ∨ ✷ψ) by the equivalent modal
formula P (✷ϕ) ⊕ (P (✷ψ)
P (✷ϕ ∧ ✷ψ)), we obtain F P
P (✷ϕ) ⊕ (P (✷ψ)
P (✷ϕ ∧ ✷ψ)) → B(ϕ ∨ ψ), and hence
P (✷(ϕ ∧ ψ))) → B(ϕ ∨ ψ), that is
F P P (✷ϕ) ⊕ (P (✷ψ)
B(ϕ) ⊕ (B(ψ)

w∈W

fψM (w) · m(w).

Now we can further consider the probabilistic logics F P (Λrk , Łc )
and F P (CΛrk , Łc ) built over the modal logics Λrk and CΛrk we have
introduced in Section 6.2. Adapting the proof of the above Theorem
21, it is fairly easy to see that these logics are sound and finitely
strongly complete with respect to the classes of probabilistic Łck Kripke models (W, e, R, s) in which R is a reflexive relation and
the class in which R is a crisp reflexive relation respectively. In the
next section we will show the importance of these logics to deal with
normalized belief functions.

(10)

But γ1 → γ2 F P P γ1 → P γ2 , and hence γ1 → γ2 F P
[P γ1 ⊕ (P γ2 P γ1 )] ↔ (P γ2 ↔ P γ2 ), and from (10) we have
that γ1 → γ2 F P Φ;
(ii) analogously, one can prove that γ2 → γ1 F P Φ.

FP

=

Theorem 21 (Probabilistic completeness) (1)
The
logic
F P (Λk , Łc ) is sound and finitely strong complete with respect
to the class of probabilistic Łck -Kripke models.
(2) The logic F P (CΛk , Łc ) is sound and finitely strong complete
with respect to the class of probabilistic classical Łck -Kripke models.

Now, one can check that for every γ1 and γ2 , F P P (γ1 ∨ γ2 ) ↔
P (γ1 ) ⊕ (P (γ2 ) P (γ1 ∧ γ2 )). Indeed, letting Φ denote this last
formula, by cases we have:
(i) since γ1 → γ2 F P (γ1 ∨ γ2 ) ↔ γ2 , and γ1 → γ2
(γ1 ∧ γ2 ) ↔ γ1 , we have

M,w

7.1

B(ϕ ∧ ψ)) → B(ϕ ∨ ψ).

Belief function semantics for belief formulas

Now, we introduce a class of models that are more closely related to
belief functions on MV-algebras as we discussed in Section 4. As we
have already observed in Proposition 7 (ii), Kroupa belief functions
are particular cases of those we introduced in Definition 8. We will
then focus on this latter generalization.
As for the formulas in F(V )P that well behave with respect to this
semantics, let us consider the following class.

This theorem is indeed the syntactical counterpart of the property of
total monotonicity for the case of two formulas. A similar argument
can be used, together with the associativity of ∨, to describe total
monotonicity for n formulas in the language of F P (Λk , Łc ).
The first kind of semantics we introduce for F P (Λk , Łc ) and
F P (CΛk , Łc ) is given by the classes of probabilistic Łck -Kripke
models, and probabilistic crisp Kripke models respectively.

Definition 22 The set of belief formulas (or B-formulas) is the subclass of F(V )P defined as follows: atomic belief formulas are those
of the form P (✷ψ) (where of course ψ is a formula in Łck ), that will
be henceforth denoted by B(ψ); compound belief formulas are defined from atomic ones using the connectives of Łc . The set of belief
formulas will be denoted by F(V )B .

Definition 20 A probabilistic Łck -Kripke model is a system
M = (W, e, R, s)
such that (W, e, R) is a Łck -Kripke model, and s : F✷
M → [0, 1]
M
is a state on the MV-algebra of functions F✷
=
{f
| ϕ ∈
ϕ
M
✷
M
M
F(V ) , fϕ : W → Sk , with fϕ (w) = ϕ M,w }.
If M is such that (W, R) is a classical Kripke frame, then M is
called a probabilistic classical Łck -Kripke model.

The class of models that we are about to introduce are based on
belief functions rather than states. The idea is to use an extension of
Dempster spaces that allows to evaluate formulas of F(V )c .
An evaluated Dempster space is a pair (D, e) where D is a Dempster space (Definition 11) and e is a Łck -evaluation.

Let M = (W, e, R, s) be a probabilistic (classical) Łck -Kripke
model. For every Φ ∈ F(V )P , and for every w ∈ W , we define
the truth value of Φ in M at w inductively as follows:

Definition 23 Given an evaluated Dempster space (D, e), the induced belief function on formulas of F(V )c is defined as

• If Φ ∈ F(V )✷ , then its truth value Φ M,w is evaluated in
(W, e, R) as defined in the previous section.
• If Φ = P ψ, then P ψ M,w = s(fψM ).

belD,e (ϕ) = belD (fϕ ) (= µ(

fϕ ))

where fϕ ∈ (Sk )W is the mapping defined by fϕ (w) = e(w, ϕ).

39

ECAI-2012 Workshop WL4AI

Lemma 30 T |=BF Φ iff for every probabilistic Łck -Kripke model
K = (W, R, e, µ), Ψ K = 1 for every Ψ ∈ T implies Φ K = 1.

Definition 24 (Belief function on formulas) A mapping bel :
F(V )c → [0, 1] is a belief function on formulas if there is an evaluated Dempster-space (D, e) such that bel = belD,e .

Finally we can formulate the following completeness result.
Consider a probabilistic Łck -Kripke model K = (W, R, e, s),
and define the evaluated Dempster space (DK , e), where DK =
(W, W, Γ, µ) where Γ : W → (Sk )W is defined as Γ(w) =
R(w, ·), and µ = s. Therefore, following Definition 23, we can say
that every probabilistic Kripke model induces (or defines) a belief
function as follows:

Theorem 31 (Completeness) Let T be a finite belief theory and let
Φ be belief formula. Then it holds that
T

As a direct corollary we have the following completeness result
for Kroupa belief functions.

belK (ϕ) = belDK ,e (ϕ).
Lemma 26 belK (ϕ) = µ(f✷ϕ ), where f✷ϕ : W → Sk is defined
as f✷ϕ (w) = e(w, ✷ϕ).

Corollary 32 For any finite belief theory R and belief formula Φ, it
holds that T F P (CΛk ,Łc ) Φ iff T |=BFKroupa Φ.

Therefore, the truth evaluation of belief formulas given by each
probabilistic Łck -Kripke model defines a belief function on nonmodal formulas. The next theorem provides the converse direction,
and hence both semantics are proved to be equivalent for belief formulas.

7.2

Dealing with normalized belief functions

In Section 4 we called normalized those belief functions b :
(Sk )X → [0, 1] whose focal elements are normalized fuzzy sets.
A belief model (Ω, m) hence is said to be normalized provided that
every focal element f ∈ (Sk )Ω (i.e. every f ∈ (Sk )Ω such that
m(f ) > 0) is a normalized fuzzy set.
Consider a probabilistic Łck -Kripke model K = (W, e, R, s) for
F P (Λrk , Łc ). In other words, let K = (W, e, R, s) be a probabilistic Łck -Kripke model, whose accessibility relation R is reflexive, and
define from K the evaluated Dempster space DK = (W, W, Γ, µ)
defined as in the previous section. Recall that Γ(w) = R(w, ·), and
hence the mass assignment associated to belK defined as in Lemma
13 induces focal elements g ∈ (Sk )W such that for some w ∈ W ,
g = Γ(w ) = R(w , ·). Therefore, if g = Γ(w ) is a focal element
of belK , g(w ) = Γ(w )(w ) = R(w , w ) = 1, and hence g is
normalized.

Theorem 27 Every belief function on formulas defined by an evaluated Dempster space (D, e) is given by a probabilistic Łck -Kripke
model Łck -Kripke model K = (W , R, e , s) where:
W = {(f, w) | f ∈ (Sk )W , w ∈ W }
for every (f, w), (g, w ) ∈ W , R((f, w), (g, w )) = f (w )
e ((f, w), ϕ) = e(w, ϕ), for each ϕ ∈ F(V )c
s is a state on (Sk )W such that for every f ∈ (Sk )W ,
w∈W

Φ iff T |=BF Φ,

i.e. Φ is derivable from T in the logic F P (Λk , Łc ) if, and only if,
every belief function on formulas that is a model of T also is a model
of Φ.

Definition 25 Given K = (W, R, e, µ), the induced belief function
on formulas of F(V )c is defined as

•
•
•
•

F P (Λk ,Łc )

s({(f, w)}) = m(f ).

Therefore, alternatively to the probabilistic Łck -Kripke model semantics for belief formulas, we can simply define a semantics based
on belief functions on formulas. This is formally done in the next two
definitions.

Proposition 33 For every probabilistic Łck -Kripke model K =
(W, e, R, s) with R reflexive, there exists a normalized belief function on formulas bel such that, for every belief formula Φ, Φ K =
Φ bel .

Definition 28 Let Φ a belief formula and let bel a belief function on
formulas of F(V )c . The truth evaluation of Φ by bel is defined by
induction as follows:

Conversely, let (D, e) = (W, E, Γ, µ, e) be an evaluated Dempster space inducing a normalized belief function on formulas bel =
belD,e , and let

• if Φ is an atomic belief formulas P ✷ϕ, then Φ bel = bel(ϕ);
• · bel is then extended to compound belief formulas using Łck
connectives.

• W = {(f, w) : f is normalized, and f (w) = 1},
• R and e (·) = · (f,w) are defined as in the proof of Theorem
27,
• s is a state on (Sk )W such that for every f ∈ (Sk )W ,

If Φ bel = 1 we say that bel is a model of Ψ. Moreover, we say
bel is a model of a set of belief formulas (belief theory) T if bel is a
model of each formula of T .

w∈W :f (w)=1

Definition 29 Let T be a belief theory and let Φ be belief formula.
T |=BF Φ iff for every belief function bel on formulas of F(V )c ,
Ψ bel = 1 for every Ψ ∈ T implies Φ bel = 1 as well.

s({(f, w)}) = m(f ),

where m is the mass associated to bel through Lemma 13.
Then M = (W , e , R, s) is a probabilistic Łck -Kripke model with
R reflexive. In fact for every (f, w) ∈ W , R((f, w), (f, w)) =
f (w) = maxw ∈W f (w ) = 1 because f is a focal element for m,
and bel is normalized. Moreover, since for every w0 ∈ W , the map
g : W → Sk such that g(w) = 1 if w = w0 , and g(w) = 0
otherwise is a normalized fuzzy subset of W , it follows that

Analogously, one can define logical consequence relations
|=BFKroupa , |=BFn and |=BFKroupa,n corresponding to the
classes of Kroupa belief functions, normalized belief functions and
normalized Kroupa belief functions, respectively.
Due to Theorem 27, T |=BF Φ can be equivalently given by probabilistic Łck -Kripke models.

W = {w ∈ W : (g, w) ∈ W }.

40

ECAI-2012 Workshop WL4AI

Therefore, taking this into account, if ψ is non-modal then, following
the lines of the proof of Theorem 27, we have ψ (f,w) = ρ ψ (f ).
If Φ is any belief formula, then Φ bel = Φ M , in other words the
following holds.

[6] R. Cignoli, I.M.L. D’Ottaviano, D. Mundici. Algebraic Foundations of
Many-valued Reasoning. Kluwer, Dordrecht, 2000.
[7] A. P. Dempster. Upper and lower probabilities induced by a multivalued
mapping. The Annals of Mathematical Statistics 38 (2): 325–339, 1967.
[8] T. Denœux. Reasoning with imprecise belief structures. Int. J. Approx.
Reasoning 20(1): 79–111, 1999.
[9] T. Denœux. Modeling vague beliefs using fuzzy-valued belief structures. Fuzzy Sets and Systems 116(2): 167–199, 2000.
[10] D. Dubois, H. Prade. Evidence Measures Based on Fuzzy Information.
Automatica 21(5), 547–562, 1985.
[11] D. Dubois, H. Prade. A Set-Theoretic View of Belief Functions: Logical
Operations and Approximations by Fuzzy Sets. In Classical works of
the Dempster-Shafer theory of belief functions. Studies in Fuzziness
and Soft Computing, 2008, Volume 219/2008, 375-410.
[12] F. Esteva, L. Godo, E. Marchioni. Fuzzy Logics with Enriched Language, in Handbook of Mathematical Fuzzy Logic - P. Cintula, P.
H´ajek, C. Noguera (eds), Studies in Logic, vol. 38, College Publications, Londres, 2011.
[13] T. Flaminio, L. Godo. A logic for reasoning about the probability of
fuzzy events. Fuzzy Sets and Systems 158(6): 625–638, 2007.
[14] T. Flaminio, L. Godo, E. Marchioni. Belief Functions on MV-Algebras
of Fuzzy Events Based on Fuzzy Evidence. In Proceedings of ECSQARU 2011, Lecture Notes in Artificial Intelligence 6717, Weiru Liu
(Ed.), pp. 628-639, 2011.
[15] T. Flaminio, L. Godo, E. Marchioni. Reasoning about uncertainty of
fuzzy events: an overview. in Understanding Vagueness - Logical,
Philosophical, and Linguistic Perspectives, P. Cintula et al. (Eds.), College Publications, to appear, 2011.
[16] L. Godo, P. H´ajek, F. Esteva. A Fuzzy Modal Logic for Belief Functions. Fundamenta Informaticae 57(2-4), 2003.
[17] R. Grigolia, Algebraic analysis of Łukasiewicz-Tarski n-valued logical
systems, in: R. W´ojcicki, G. Malinowski (Eds.), Selected Papers on
Łukasiewicz Sentencial Calculi, Wrocław, Polish Academy of Science,
Ossolineum, pp. 81–91, 1977.
[18] P. H´ajek, L. Godo, F. Esteva. Probability and Fuzzy Logic. In Proc. of
Uncertainty in Artificial Intelligence UAI’95, P. Besnard and S. Hanks
(Eds.), Morgan Kaufmann. San Francisco, 237–244 (1995).
[19] P. H´ajek. Metamathematics of fuzzy logics. Kluwer, Dordrecht, 1998.
[20] C. Hwang, M. Yang. Generalization of Belief and Plausibility Functions
to Fuzzy Sets Based on the Sugeno Integral. International Journal of
Intelligent Systems 22, pp. 1215–1228, 2007.
[21] T. Kroupa, Representation and extension of states on MV-algebras.
Archive for Mathematical Logic, 45 (4):381–392. 2006.
[22] T. Kroupa. Every state on semisimple MV-algebra is integral. Fuzzy
Sets and Systems 157(20): 2771–2782, 2006.
[23] T. Kroupa. From Probabilities to Belief Functions on MV-Algebras. In
Combining Soft Computing and Statistical Methods in Data Analysis,
C. Borgelt et al. (Eds.), AISC 77, Springer, pp 387–394, 2010.
[24] T. Kroupa. Extension of Belief Functions to Infinite-valued Events. Soft
Computing, to appear.
[25] R. McNaughton. A Theorem about Infinite-valued Sentential Logic. J.
Symb. Log. 16, 1–13, 1951.
[26] D. Mundici. Averaging truth values in Łukasiewicz logic. em Studia
Logica 55 (1) pp. 113–127, 1995.
[27] D. Mundici. Advanced Łukasiewicz calculus and MV-algebras, Trends
in Logic 35, Springer 2011.
[28] J. B. Paris. A note on the Dutch Book method, Revised version of a
paper of the same title which appeared in The Proceedings of the Second Internat. Symp. on Imprecise Probabilities and their Applications,
ISIPTA01, Ithaca, New York, 2001.
[29] S. Parsons. Some qualitative approaches to apply the Dempster-Shafer
theory. Information and Decision Technologies 19, 321–337, 1994.
[30] G. Shafer. A Mathematical Theory of Evidence. Princeton University
Press, Princeton 1976.
[31] P. Smets. Belief Functions. In Nonstandard Logics for Automated Reasoning, P. Smets et al. (eds.), Academic Press, London, pp. 253–277,
1988.
[32] J. Yen. Computing Generalized Belief Functions for Continuous Fuzzy
Sets. Int. J. Approx. Reasoning 6: 1–31, 1992.
[33] L. A. Zadeh. Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets
and Systems 1, 3-28, 1978.
[34] L. A. Zadeh. Fuzzy sets and information granularity. In Advances in
Fuzzy Sets Theory and Applications, (M. Gupta et al. eds), North Holland, 3–18, 1979.

Proposition 34 For each normalized belief function on formulas bel
there exists a probabilistic Łck -Kripke M = (W, e, R, s) with R reflexive, such that, for every belief formula Φ, Φ M = Φ bel .
From Proposition 33 and Proposition 34 we immediately get
Theorem 35 The logic F P (Λrk , Łc ) is sound and finitely strong
complete with respect to normalized belief functions on formulas.
The following result is a direct consequence of Theorem 35 and
Proposition 10. It clarifies what we discussed in Remark 19, i.e. that
F P (Λrk , Łc ) proves that the belief modality B is homogeneous.
Corollary 36 For every k ∈ N, and for every r ∈ Sk , F P (Λrk , Łc )
proves B(r) ↔ r.
Corollary 37 For any finite belief theory T and belief formula Φ, it
holds that T F P (CΛrk ,Łc ) Φ iff T |=BFKroupa,n Φ.

8

Conclusion

In this paper we presented a logical approach to belief functions on
MV-algebras. We have followed the idea developed in [16] where the
authors defined a logic for belief functions on Boolean algebras by
combining a probabilistic modality P with the classical S5 modality
✷. In [16], the choice of S5 as the modal logic for events is motivated by the need of a locally finite logical system (remember also
our proof of Theorem 21 where locally finiteness is a crucial requirement for the logic of events), and in fact S5 is the weaker classical
modal logic that fulfills that requirement (see [5]). In this paper we
started from a non-locally finite modal logic as logic for events, and
we recovered local finiteness by working on the syntactical level of
modal formulas, and specifically not allowing a nested use of ✷. In
fact, the same results the authors proved in [16] can be equivalently
obtained considering, as logic for events, a variant of the weaker classical modal logic K, without nested modalities. Indeed a nested use
of ✷ is useless when we define belief formulas as we did in Section
7.1, and as they are defined in [16, §4].
Acknowlegdments The authors acknowledge partial support from
the Spanish projects TASSAT (TIN2010- 20967-C04-01), Agreement
Technologies (CONSOLIDER CSD2007-0022, INGENIO 2010) and
ARINF (TIN2009-14704-C03-03), and by the Marie Curie IRSES
Project MaToMuVI (FP7-PEOPLE-2009). Flaminio acknowledges
partial support from the Juan de la Cierva Program of the Spanish
MICINN.

REFERENCES
[1] L. Biacino. Fuzzy subsethood and belief functions of fuzzy events.
Fuzzy Sets and Systems 158(1), 38–49, 2007.
[2] F. Bou, F. Esteva, L. Godo, R. Rodr´ıguez. On the Minimum ManyValued Modal Logic over a Finite Residuated Lattice. Journal of Logic
and Computation, vol. 21, issue 5, pp. 739–790, 2011.
[3] S. Burris and H.P. Sankappanavar, A course in Universal Algebra,
Graduate texts in Mathematics, Springer Veralg 1981.
[4] C. C. Chang. Algebraic Analysis of Many-valued Logics. Trans. Am.
Math. Soc. 88, 467–490, 1958.
[5] B. F. Chellas. Modal Logic: An Introduction. Cambridge University
Press, 1980.

41

ECAI-2012 Workshop WL4AI

42

ECAI-2012 Workshop WL4AI

NP-completeness of fuzzy answer set programming under
Łukasiewicz semantics
Marjon Blondeel 1 and Steven Schockaert 2 and Martine De Cock 3 and Dirk Vermeir 4
Abstract. Fuzzy answer set programming (FASP) is a generalization of answer set programming (ASP) in which propositions are allowed to be graded. Little is known about the computational complexity of FASP and almost no techniques are available to compute
the answer sets of a FASP program. In this paper, we first present
an overview of previous results on the computational complexity
of FASP under Łukasiewicz semantics, after which we show NPcompleteness for normal and disjunctive FASP programs. Moreover,
for this type of FASP programs we will show a reduction to bilevel
linear programming, thus opening the door to practical applications.

1

set of P . Note that “power” should be an element of each answer set
of P .
If the head of each rule consists of exactly one literal, the program
is called normal. If, in addition, a normal program does not contain
“not” nor “¬”, it is called simple.
Given a disjunctive ASP program P and a literal l, we are interested in the following three decision problems.
1. Existence: Does P have an answer set?
2. Set-membership: Does there exist an answer set I of P such that
l ∈ I?
3. Set-entailment: Does l ∈ I hold for each answer set I of P ?

INTRODUCTION

A summary of the complexity for these decision problems is given
in Table 1.

Answer set programming (ASP) [1] is a form of declarative programming that can be used to model combinatorial search problems.
Specifically, a search problem is translated into a disjunctive ASP
program, i.e. a set of rules of the form

Table 1.

r : a1 ∨ . . . ∨ an ← b1 ∧ . . . ∧ bm ∧ not c1 ∧ . . . ∧ not ck ,

simple
normal
disjunctive

with ai , bj , cl literals (atoms or negated atoms) or constants (“true”
or “false”) and “not” the negation-as-failure operator. Thus, in ASP
there are two types of negation: classical or strong negation “¬” and
negation-as-failure “not”. The intuitive difference is that ¬a is true
when ¬a can be derived, whereas not a is true if a cannot be derived.
Rule r indicates that whenever the body b1 ∧ . . . ∧ bm ∧ not c1 ∧
. . . ∧ not ck holds, that the head a1 ∨ . . . ∨ an should hold as well.
For example, consider the following ASP program P .
r1 :
r2 :

light
power

←
←

2
3

4

existence
in P
NP-complete
ΣP
2 -complete

set-membership
in P
NP-complete
ΣP
2 -complete

set-entailment
in P
coNP-complete
ΠP
2 -complete

P
P
Recall that ΠP
2 = coΣ2 , where Σ2 -membership means that the
problem can be solved in polynomial time on a non-deterministic
machine using an NP oracle.
Although ASP allows us to model combinatorial optimization
problems in a concise and declarative manner, it is not directly suitable for expressing problems with continuous domains. Fuzzy answer set programming (FASP) (e.g. [19, 32]) is a generalization of
ASP based on fuzzy logics [18] that is capable of modeling continuous systems by using an infinite number of truth values that correspond to intensities of properties. A (general) FASP program is a set
of rules of the form

power, not broken
1

Rule r1 informally means that we can conclude that the light is on
if there is no reason to think that the lamp is broken and if we can
establish that the power is on. A rule such as r2 is called a fact; the
head is unconditionally true; the power is on. Given such a program,
the idea is to find a minimal set of literals that can be derived from the
program. These “answer sets” then correspond to the solutions of the
original search problem. For example, {light, power} is an answer
1

Complexity of inference in ASP [1, 15]

r : g(a1 , . . . , an ) ← f (b1 , . . . , bm , not c1 , . . . , not ck ),
with ai , bj , cl literals (atoms or negated atoms) or constants c (with
c ∈ [0, 1] ∩ Q) and “not” the negation-as-failure operator, and where
f and g correspond to applications of fuzzy logical disjunctions and
conjunctions. Rule r now intuitively means that the truth value of the
head must be greater or equal than the truth value of the body. For
example, consider the following program P :

Vrije Universiteit Brussel, Department of Computer Science, Pleinlaan 2,
1050 Brussel, Belgium, email: mblondee@vub.ac.be, Funded by a joint Research Foundation-Flanders (FWO) project
Cardiff University, School of Computer Science and Informatics, 5 The
Parade, Cardiff, CF24 3AA, UK, email: s.schockaert@cs.cardiff.ac.uk
Ghent University, Department of Applied Mathematics and Computer Science, Krijgslaan 281, 9000 Gent, Belgium, email: martine.decock@ugent.be
Vrije Universiteit Brussel, Department of Computer Science, Pleinlaan 2,
1050 Brussel, Belgium, email: dvermeir@vub.ac.be

r1 :
r2 :

open
closed

←
←

not closed
not open

The properties “open” and “closed” can be given a value in [0, 1]
depending on the extent, e.g. the angle, to which a door is opened

43

ECAI-2012 Workshop WL4AI

programming problems (e.g. [4, 9, 27]). A popular way to solve such
a problem, e.g. in [4], is to translate the bilevel linear programming
problem into a nonlinear programming problem using Kuhn-Tucker
constraints. This new program is a standard mathematical program
and relatively easy to solve because all but one constraint is linear.
In a later study [5], an implicit approach to satisfying the nonlinear
complementary constraint was proposed, which proved to be more
efficient than the known strategies.
The paper is structured as follows. In Section 2 we provide the
necessary background on ASP, Łukasiewicz logic and FASP. In Section 3 we will discuss previous results about the computational complexity of FASP. In Sections 4 and 5 we will derive new complexity
results for disjunctive FASP programs, and in Section 6 we provide
an implementation using bilevel linear programming for this class of
programs. Finally, we present some conluding remarks in Section 7.

resp. closed. The rule r1 intuitively means that the door is open to
a degree greater or equal than the extent to which the door is not
closed. Rule r2 implies the opposite property.
In recent years, a variety of approaches to FASP have been proposed (e.g. [12, 20, 22, 25, 28, 29, 30]). The main differences are
the type of connectives that are allowed, the truth lattices that are
used, the definition of a model of a program and the way that partial
satisfaction of rules is handled. Note that FASP is not used to deal
with uncertainty, but with partial truth. See [14] for a discussion on
the difference between these two concepts. To deal with uncertainty,
ASP can be extended with possibility theory (e.g. [6]) or with probability theory (e.g. [2]). Still, FASP is sometimes useful as a vehicle to
simulate probabilistic or possibilistic extensions of ASP, as its ability to model continuity can be used to manipulate certainty degrees
[6, 13].
In particular, in this paper we are interested in disjunctive FASP
programs, i.e. FASP programs with rules of the form

2

BACKGROUND

2.1

a1 ⊕ . . . ⊕ an ← b1 ⊗ . . . ⊗ . . . bm ⊗ not c1 ⊗ . . . ⊗ not ck ,
where ⊕ and ⊗ are respectively the Łukasiewicz disjunction and
the Łukasiewicz conjunction and where ← is interpreted by the
Łukasiewicz implicator (see Section 2.2). Other types of programs
of interest are normal FASP programs, i.e. disjunctive FASP programs in which each rule has exactly one literal in the head, and
simple FASP programs, i.e. normal FASP programs that do not contain “not” nor “¬”.
Łukasiewicz logic is often used in applications because it preserves many desirable properties from classical logic. It is closely
related to mixed integer programming, as was first shown by McNaughton [23] in a non-constructive way. Later, H¨ahnle [17] gave a
concrete, semantics-preserving, translation from a set of formulas in
Łukasiewicz logic into a mixed integer program. Checking the satisfiability of a Łukasiewicz logic formula thus essentially corresponds
to checking the feasibility of a mixed integer program.
By construction, FASP relates to Łukasiewicz logic as ASP does
to classical logic. For Łukasiewicz logic, satisfiability is an NPcomplete problem [24]. Since satisfiability has the same complexity for classical logic, one would expect ASP and FASP to have the
same complexity as well. In the case of probabilistic ASP, the complexity of the existence problem has been shown to be ΣP
2 -complete
[21]. On the other hand, it does not necessarily need to hold that
the computational complexity remains the same, for instance in the
case of description logics. There are fuzzy description logics that,
unlike the classical case, do not have the finite model property under
Łukasiewicz logic or under product logic [8] and there are description logics that are undecidable under Łukasiewicz logic [10]. In a
previous paper [7] we showed ΣP
2 -completeness for general FASP
programs under Łukasiewicz semantics for the set-membership problem “Given a program P , a value λ ∈ [0, 1] ∩ Q and a literal l. Is
there an answer set I of P such that I(l) ≥ λ?”. However, for disjunctive FASP programs we were able to show NP-membership; a
lower complexity than for the corresponding class of ASP programs.
In this paper, we will extend the results from [7] by showing NPcompleteness for normal and disjunctive FASP programs. Moreover,
we will provide an implementation into bilevel linear programming.
This result can be used as a basis to built solvers for FASP.
Intuitively, in a bilevel linear programming problem there are two
agents: the leader and the follower. The leader goes first and attempts
to optimize his/her objective function. The follower observes this and
makes his/her decision. Since it caught the attention in the 1970s,
there have been many algorithms proposed for solving bilevel linear

Answer set programming (ASP)

A disjunctive ASP program is a finite set of rules of the form
r : a1 ∨ . . . ∨ an ← b1 ∧ . . . ∧ bm ∧ not c1 ∧ . . . ∧ not ck ,
with ai , bj , cl literals (atoms a or negated atoms ¬a) and/or the constants 1 (true) or 0 (false) with i ∈ {1, . . . , n}, j ∈ {1, . . . , m} and
l ∈ {1, . . . , k}. The operator “not” is the negation-as-failure operator. Intuitively, the expression not a is true if there is no proof that
supports a. On the other hand, ¬a is essentially seen as a new literal,
which has no connection to a, except for the fact that answer sets
containing both a and ¬a will be designated as inconsistent. If l is a
literal, then we define ¬l := ¬a if l = a with a an atom and ¬l := a
if l = ¬a with a an atom.
We refer to the rule by its label r. The expression a1 ∨ . . . ∨ an is
called the head rh of r and b1 ∧ . . . ∧ bm ∧ not c1 ∧ . . . ∧ not ck is the
body rb of r. In ASP, a rule of the form “0 ← a”, i.e. a constraint, is
usually written as “← a” and a rule of the form “a ← 1”, i.e. a fact,
as “a ←”.
Different classes of ASP programs are often considered, depending on the type of rules they contain. If P does not contain rules with
negation-as-failure, it is called a positive (disjunctive) ASP program.
If each rule in P has exactly one literal in the head, it is called a
normal ASP program. If P is a normal ASP program that is positive, it is called a definite ASP program. A definite ASP program not
containing strong negation is called a simple ASP program.
An interpretation I of P is any consistent set of literals I ⊆ LP
with
LP = {l | l literal in P } ∪ {¬l | l literal in P }
and where we say that I is consistent if for no literal l in LP we
have that l ∈ I and ¬l ∈ I. The set of interpretations I ⊆ LP will
be denoted by P(LP ). A literal l is true w.r.t. I, denoted as I |= l,
if l ∈ I. An interpretation I ∈ P(LP ) can be extended to rules as
follows:
•
•
•
•
•

I
I
I
I
I

|= 1, I � 0,
|= not l iff I � l,
|= (α ∧ β) iff I |= α and I |= β,
|= (α ∨ β) iff I |= α or I |= β,
|= (α ← β) iff I |= α or I � β.

with l a literal and α and β relevant expressions.
An interpretation I ∈ P(LP ) is called a model of a disjunctive
ASP program P if I |= r for each rule r ∈ P . A model I of P is

44

ECAI-2012 Workshop WL4AI

2.3

minimal if there exists no model J of P such that J ⊂ I, i.e. J ⊆ I
and J �= I. An interpretation I ∈ P(LP ) is called an answer set of
a positive disjunctive ASP program P if it is a minimal model of P .
Note that a simple ASP program P has exactly one answer set.
To define the semantics for disjunctive ASP programs P that are
not positive, one starts from a candidate answer set I ∈ P(LP ) and
computes the Gelfond-Lifschitz reduct P I [16] by removing all rules
in P that contain expressions of the form not l with l ∈ I and removing all expressions of the form not l in the remaining rules. An
interpretation I ∈ P(LP ) is called an answer set of P if it is an
answer set of the positive program P I .

We now recall a fuzzy version of ASP based on [19], combining ASP
(Section 2.1) and Łukasiewicz logic (Section 2.2).
A general FASP program (under Łukasiewicz semantics) is a finite
set of rules of the form
r : g(a1 , . . . , an ) ← f (b1 , . . . , bm , not c1 , . . . , not ck ),
with ai , bj , cl literals (atoms a or negated atoms ¬a) and/or the constants c (where c ∈ [0, 1] ∩ Q) with i ∈ {1, . . . , n}, j ∈ {1, . . . , m}
and l ∈ {1, . . . , k} and “not” the negation-as-failure operator. The
connectives f and g are compositions of the Łukasiewicz connectives
⊗ and ⊕. As for ASP, ¬a is essentially seen as a new literal, which
has no connection to a, except for the fact that answer sets containing
both a and ¬a “to a sufficiently high degree” will be designated as
inconsistent. If l is a literal, then we define ¬l := ¬a if l = a with a
an atom and ¬l := a if l = ¬a with a an atom.
We refer to the rule by its label r and g(a1 , . . . , an ) is called
the head rh of r and f (b1 , . . . , bm , not c1 , . . . , not ck ) is called the
body rb of r. Rules of the form c ← α with c a constant are called
constraints. As for ASP, we will consider several classes of FASP
programs. FASP programs without negation-as-failure are called
positive FASP programs. FASP programs only containing rules of
the form

Example 1. Consider the normal ASP program P
b
a

←
←

not a
not b

with a and b atoms. For an interpretation I1 = {a}, we have that
P I1 is equal to
a ←
Since I1 is a minimal model of P I1 , we conclude that I1 is an answer
set of P . Similar, I2 = {b} is also an answer set of P . One can easily
check that these are the only answer sets.
Remark 1. Note that an interpretation I ∈ P(LP ) can be seen as
a mapping I : LP → {0, 1} where I(l) = 1 if l ∈ I and I(l) = 0 if
l∈
/ I.

a1 ⊕ . . . ⊕ an ← b1 ⊗ . . . ⊗ bm ⊗ not c1 ⊗ . . . ⊗ not ck
are called disjunctive FASP programs. If a disjunctive FASP has exactly one literal in the head of each rule, it is called normal and if a
normal FASP program is positive and does not contain strong negation, it is called simple.
A consistent fuzzy interpretation I of a FASP program P is any
element of F(LP ) such that I(l) + I(¬l) ≤ 1 for each l ∈ LP with

Remark 2. A disjunctive ASP program P with strong negation can
be translated to a disjunctive ASP program P � without strong negation, by replacing each literal of the form ¬a with a new atom a� and
adding the constraint ← a ∧ a� . An interpretation I ∈ P(LP ) is an
answer set of P iff there exists an answer set I � ∈ P(LP � ) of P �
such that I(c) = I � (c) and I(¬c) = I � (c� ) for each atom c ∈ LP .

2.2

LP = {l | l literal in P } ∪ {¬l | l literal in P }.
A fuzzy interpretation I ∈ F (LP ) is extended to rules as follows:

Łukasiewicz logic

• [c]I = c
• [not l]I = 1 − I(l)
• [f (α, β)]I = f([α]I , [β]I ) where f is a prefix notation for ⊗ or ⊕
and f is the corresponding function defined on [0, 1] (see Section
2.2)
• [α ← β]I = min(1 − [α]I + [β]I , 1)

Fuzzy logics [18] form a class of logics whose semantics are based
on truth degrees taken from the unit interval [0, 1]. Łukasiewicz logic
is a particular type of fuzzy logic that is often used in applications
since it preserves many properties from classical logic.
In this paper, we will consider formulas built from a set of atoms
A, constants c for each element c ∈ [0, 1] ∩ Q and the connectives
conjunction ⊗, disjunction ⊕, negation ∼ and implication →. The
semantics of this logic are defined as follows. A fuzzy interpretation
is a mapping I : A → [0, 1] that can be extended to arbitrary formulas as follows;
•
•
•
•
•

Fuzzy answer set programming (FASP)

with c a constant, l a literal and α and β relevant expressions.
A fuzzy interpretation I ∈ F(LP ) is a fuzzy model of a FASP
program P if [r]I = 1 for each rule r ∈ P . For I1 , I2 ∈ F (LP ) we
write I1 ≤ I2 iff I1 (l) ≤ I2 (l) for each l ∈ LP . A fuzzy model I of
P is a minimal fuzzy model if there exists no model J of P such that
J < I, i.e. J ≤ I and J �= I. A fuzzy interpretation I ∈ F(LP )
is called an answer set of a positive FASP program P if it is a minimal fuzzy model of P . Remark that a positive FASP program can
have none, one or several answer sets [31]. However, similar as for
ASP, a simple FASP program has exactly one answer set which coincides with the least fixpoint of the immediate consequence operator
ΠP [12]. This operator maps fuzzy interpretations to fuzzy interpretations and is defined as

[c]I = c,
[α ⊗ β]I = max([α]I + [β]I − 1, 0),
[α ⊕ β]I = min([α]I + [β]I , 1),
[α → β]I = min(1 − [α]I + [β]I , 1) and
[∼ α]I = 1 − [α]I .

for a constant c and α and β formulas. The set of all fuzzy interpretations C → [0, 1] with C an arbitrary set will be written as F(C).
We say that I ∈ F (A) is a fuzzy model of a set of formulas B if
[α]I = 1 for each α ∈ B. For I1 , I2 ∈ F (A) we write I1 ≤ I2 if
I1 (a) ≤ I2 (a) for each a ∈ A. A fuzzy model I of a set of formulas B is called a minimal fuzzy model if there does not exist a fuzzy
model J of B such that J < I, i.e. J ≤ I and J �= I.

ΠP (I)(a) = sup{[rb ]I | (a ← rb ) ∈ P },
for an atom a ∈ LP and I ∈ F(LP ). For programs that are not
positive, a generalization of the Gelfond-Lifschitz reduct [19] is used.

45

ECAI-2012 Workshop WL4AI

show coNP-membership. However, for some subclasses of this type
of programs we could show P-membership. For example for programs having only disjunctions in the bodies of rules. We refer to [7]
for an extensive overview.
Some previous results for the complexity of the set-membership
problem for disjunctive FASP can be found in Table 2. In the next
section we will extend these results by showing NP-completeness
for normal and disjunctive FASP programs under several conditions
w.r.t. constraints and strong negation and in particular the case where
constraints and strong negation are not allowed. We will also present
results for other decision problems.

In particular, for a program P and a fuzzy interpretation I ∈ F(LP )
the reduct P I of P w.r.t. I is obtained by replacing in each rule r ∈ P
all expressions of the form not l by the interpretation [not l]I ; we
denote the resulting rule by r I . This new program P I = {rI | r ∈
P } is a positive FASP program and I is called an answer set of P if
I is an answer set of P I .
Example 2. Consider the normal FASP program P
b
a

←
←

not a
not b

with a and b atoms. We show that for each x ∈ [0, 1], Mx with
Mx (a) = x and Mx (b) = 1 − x is an answer set of P . We first
compute the reduct P Mx :
b
a

←
←

Table 2.

1−x
x

simple (even with strong negation)
normal (without constraints and with strong negation)
disjunctive (with constraints and strong negation)

The minimal model of P Mx is then exactly Mx . Note that there are
infinitely many answer sets.
Remark 3. Note that [0 ← a⊗a� ]I = 1 iff I(a)+I(a� ) ≤ 1. Hence,
a FASP program P with strong negation can be translated to a FASP
program P � without strong negation by replacing each literal of the
form ¬a by a new atom a� and adding the constraint 0 ← a ⊗ a� . An
interpretation I ∈ F(LP ) is an answer set of a FASP program P iff
there exists an answer set I � ∈ F (LP � ) of P � such that I(c) = I � (c)
and I(¬c) = I � (c� ) for each atom c ∈ LP .

4

set-membership
in P
in NP
in NP

NP-completeness of disjunctive FASP

In this section we will investigate the complexity of important decision problems for disjunctive FASP, i.e. the class of FASP programs
that are sets of rules of the form
a1 ⊕ . . . ⊕ an ← b1 ⊗ . . . ⊗ bm ⊗ not c1 ⊗ . . . ⊗ not ck
with ai , bj , cl literals (atoms a or negated atoms ¬a) and/or the constants c (where c ∈ [0, 1] ∩ Q) with i ∈ {1, . . . , n}, j ∈ {1, . . . , m}
and l ∈ {1, . . . , k}. Given a (disjunctive) FASP program P , a literal
l ∈ LP and a value λl ∈ [0, 1]∩Q, we are interested in the following
decision problems.

The following lemma is easily shown from the above definitions.
Lemma 1. Let P be a FASP program such that P = P1 ∪ C where
C is a set of constraints in P and I ∈ F(LP ). It holds that I is an
answer set of P iff I is an answer set of P1 and I is a fuzzy model of
C.

1. Existence: Does there exist an answer set I of P ?
2. Set-membership: Does there exist an answer set I of P such that
I(l) ≥ λl ?
3. Set-entailment: Is I(l) ≥ λl for each answer set I of P ?

Remark 4. In Lemma 1, an interpretation I : LP → [0, 1] is a
model of P1 ⊆ P if [r]I = 1 for each r ∈ P1 .

3

Complexity of the set-membership problem for disjunctive FASP
[7]

Complexity of FASP

Remark that these decision problems are generalizations of the
ones for ASP for which the complexity is given in Table 1. As we
have already pointed out in the introduction, one would expect ASP
and FASP to have the same computational complexity since FASP
relates to Łukasiewicz logic as ASP does to classical logic and the
complexity of all the main reasoning tasks in Łukasiewicz logic is
as in classical propositional logic. However, as will be proved in this
section, the computational complexity for disjunctive FASP turns out
to be lower than the one for disjunctive ASP.
We will first show that set-membership for disjunctive FASP is
NP-complete. We will do this by showing NP-membership in Proposition 1 and by showing in Proposition 2 that it is already NP-hard
for a subclass of disjunctive FASP. Next, in Propositions 3 and 4, we
derive resp. NP-completeness and coNP-completeness for resp. the
existence and the set-entailment problem for this particular subclass.
The proofs of these propositions can then be used to show resp. NPcompleteness and coNP-completeness for resp. the existence and the
set-entailment problem for disjunctive FASP.

In this section, we will recall some existing results about the computational complexity of FASP. In particular, we will consider the
following decision problem. Given a general FASP program P , a literal l ∈ LP and a value λl ∈ [0, 1] ∩ Q, is there an answer set I of
P such that I(l) ≥ λl ? We will refer to this decision problem as the
set-membership problem.
For the computational complexity of the set-membership problem
for general FASP programs, i.e. programs containing rules of the
form
r : g(a1 , . . . , an ) ← f (b1 , . . . , bm , not c1 , . . . , not ck ),
where f and g are arbitrary compositions of the Łukasiewicz connectives ⊗ and ⊕, one can show ΣP
2 -completeness. Indeed, from the
complexity of fuzzy equilibrium logic [26], it follows that the setmembership problem for general FASP programs under Łukasiewicz
P
semantics is in ΣP
2 . To show hardness, disjunctive ASP, which is Σ2 hard [15] can be reduced to general FASP by replacing the classical
connectives by the corresponding Łukasiewicz connectives and by
adding for each literal l in P the rule l ← l ⊕ l to ensure that the
truth value of l is either 0 or 1. In [7], for programs with exactly one
atom in the head of each rule and no “¬” or “not“ we could only

Proposition 1. Set-membership for disjunctive FASP is in NP.
Proof. From the analysis of the geometrical structure underlying
fuzzy equilibrium models [26], it follows that a FASP program P

46

ECAI-2012 Workshop WL4AI

has an answer set I such that I(l) ≥ λl iff there is such an answer
set that can be encoded using a polynomial number of bits.
Given a disjunctive program P and an answer set I; we check in
polynomial time that I is an answer set of P . Note that checking if
I(l) ≥ λl for a literal l can be done in constant time. By definition,
we need to check that I is a minimal fuzzy model of P I and that for
each l ∈ LP we have I(l) + I(¬l) ≤ 1. The latter is straightforward. To check whether I is a fuzzy model of P I , one can use linear
programming. Indeed for a rule r : a1 ⊕ . . . ⊕ an ← b1 ⊗ . . . ⊗ bm
in P I , seen as a Łukasiewicz formula, we have that

where x� is a fresh atom not used in α. We denote the resulting FASP
program by P .
1. First suppose that I is an answer set of P . By Lemma 1 we know
that I is an answer set of P1 and a fuzzy model of C where P1 is
the set of all rules in P of the form (2)-(5) and C is the set of all
constraints of the form (1) and (6).
Since I is a minimal fuzzy model of (P1 )I we know that for each
literal x it holds that I(x) = 1 − I(¬x) by rules (2) and (3) and
I(x� ) = max(I(x), I(¬x)) by rules (4) and (5). Since I must be a
fuzzy model of the constraints in C, it follows that 1 − I(x� ) = 0
by rule (6). If I(x� ) = I(x), then I(x) = 1 and I(¬x) = 0.
Otherwise, if I(x� ) = I(¬x), then I(¬x) = 1 and I(x) = 0.
Hence, I is a consistent Boolean interpretation.
Let us define the assignment G as follows. For each literal x in
α we have G(x) = “true” if I(x) = 1 and G(x) = “false” if
I(x) = 0. We check that this assignment evaluates α to “true”.
This follows easily by the following equations:

[b1 ⊗ . . . ⊗ bm → a1 ⊕ . . . ⊕ an ]I = 1
⇔ [(∼ b1 ) ⊕ . . . ⊕ (∼ bm ) ⊕ a1 ⊕ . . . ⊕ an ]I = 1
⇔ I(∼ b1 ) + . . . + I(∼ bm ) + I(a1 ) + . . . + I(an ) ≥ 1
⇔ 1 − I(b1 ) + . . . + 1 − I(bm ) + I(a1 ) + . . . + I(an ) ≥ 1
Hence, to check whether I is a fuzzy model of P I we use the
following
� linear program M . The function to be minimized is the
sum a∈P I a of all literals in P I and the constraints in M are the
following. For each literal a ∈ LP I we have 0 ≤ a ≤ 1 and a ≤
I(a) and for each rule
r : a1 ⊕ . . . ⊕ an ← b1 ⊗ . . . ⊗ bm

[¬ai1 ⊗ ¬ai2 ⊗ ¬ai3 → 0]I = 1
⇔ [0⊕ ∼ (¬ai1 ⊗ ¬ai2 ⊗ ¬ai3 )]I = 1
⇔ [0⊕ ∼ (¬ai1 )⊕ ∼ (¬ai2 )⊕ ∼ (¬ai3 )]I = 1
⇔ 0 + 1 − I(¬ai1 ) + 1 − I(¬ai2 ) + 1 − I(¬ai3 ) ≥ 1

1 ≤ 1 − b1 + . . . + 1 − bm + a1 + . . . + an

Since for I it holds that I(x) = 1 − I(¬x) for each literal x, we
obtain that

I

in P we have

or equivalently

[¬ai1 ⊗ ¬ai2 ⊗ ¬ai3 → 0]I = 1
⇔ I(ai1 ) + I(ai2 ) + I(ai3 ) ≥ 1

1 − m ≤ −b1 − . . . − bm + a1 + . . . + an .
If M has as solution I(a) for each literal a, then I is a minimal fuzzy
model.

Because I is a Boolean interpretation, it must hold that I(aij ) = 1
for at least one literal aij in each clause. Hence, G is an assignment that evaluates each clause ai1 ∨ ai2 ∨ ai3 , and thus the whole
expression α, to “true”.
2. Now suppose that P has no answer set. We need to show that there
is no assignment of the literals such that expression α evaluates to
“true”. We will show this by contraposition.
Consider an assignment G such that each clause ai1 ∨ ai2 ∨ ai3
evaluates to “true”. We define a fuzzy interpretation in F(LP )
by I(x) = 1 if G(x) = “true”, I(x) = 0 if G(x) = “false”,
I(¬x) = 1 − I(x) and I(x� ) = max(I(x), I(¬x)). We show
that I is an answer set of P , or by Lemma 1 that it is a minimal
fuzzy model of (P1 )I and a fuzzy model of C. It is clear that I is a
fuzzy model of (P1 )I . Now suppose there exists a fuzzy model J
of (P1 )I such that J < I. Since I is such that I(¬x) + I(x) = 1,
by the rules
¬x ← not x
x
← not(¬x)

Next, to obtain NP-completeness for the set-membership problem,
we prove that it is NP-hard by showing a reduction from 3SAT, which
is NP-complete [11], to disjunctive FASP. 3SAT is a decision problem whose instances are Boolean expressions written in conjunctive
normal form with 3 variables in each clause, i.e. expressions of the
form
(a11 ∨ a12 ∨ a13 ) ∧ (a21 ∨ a22 ∨ a23 ) ∧ . . . ∧ (an1 ∨ an2 ∨ an3 ),
where each aij is an atom or a negated atom, i.e. a literal. The problem consists of deciding whether there is a consistent assignment of
“true” and “false” to the literals such that the whole expression evaluates to “true”.
Proposition 2. Set-membership for normal FASP is NP-hard if constraints are allowed.
Proof. Consider an arbitrary instance

in P1 it follows that

(a11 ∨ a12 ∨ a13 ) ∧ (a21 ∨ a22 ∨ a23 ) ∧ . . . ∧ (an1 ∨ an2 ∨ an3 )
of 3SAT. We will refer to this expression by α. We translate each
clause ai1 ∨ ai2 ∨ ai3 to the rule
0 ← ¬ai1 ⊗ ¬ai2 ⊗ ¬ai3

J(¬x) ≥ [not x]I = 1 − I(x) = I(¬x) ≥ J(¬x)
and

(1)

and for each literal x in α we add the rules
(2)

¬x ← not x

x ← not(¬x)

x� ← x
�

x ← ¬x

J(x) ≥ [not(¬x)]I = 1 − I(¬x) = I(x) ≥ J(x).
Hence we have for each literal x that J(x) = I(x) and J(¬x) =
I(¬x). Since J < I, there must exist a literal x such that J(x� ) <
I(x� ) which implies by the rules

(3)
(4)
(5)

�

0 ← not(x )

x�
x�

(6)

47

←
←

x
¬x

ECAI-2012 Workshop WL4AI

5

in P1 that
�

�

�

�

I(x ) > J(x ) ≥ I(x) and I(x ) > J(x ) ≥ I(¬x).

This is impossible since either I(x) = 1 or I(¬x) = 1 and then
I(x� ) > 1.
It remains to be shown that I is a fuzzy model of C. Since
I(x� ) = max(I(x), I(¬x)) = 1 we have that I models the rule
0 ← not(x� ) for each literal x. As before, we obtain
⇔

COMPLEXITY OF DISJUNCTIVE FASP
PROGRAMS WITHOUT STRONG
NEGATION OR CONSTRAINTS

In this section we will investigate the complexity of the setmembership for disjunctive FASP if strong negation and constraints
are not allowed and show that it remains NP-complete. Moreover,
we will prove that for normal FASP, even if strong negation is not
allowed, it is also NP-complete.
First, we provide a lemma that enables us to simulate constraints
of a FASP program.

[0 ← ¬(ai1 ) ⊗ ¬(ai2 ) ⊗ ¬(ai3 )]I = 1
I(ai1 ) + I(ai2 ) + I(ai3 ) ≥ 1

Since each clause ai1 ∨ ai2 ∨ ai3 is satisfied by G, we know that
for least one aij it must hold that I(aij ) = 1. Hence I(ai1 ) +
I(ai2 ) + I(ai3 ) ≥ 1.

Lemma 2. Consider a FASP program P = P1 ∪ C where P1 is a
FASP program and C is a set of constraints of the form 0 ← α. Let
P � = P1 ∪ C � ∪ {z ← not y} where z and y are fresh atoms and
C � = {y ← α | (0 ← α) ∈ C}.
A fuzzy interpretation I ∈ F(LP ) is an answer set of P iff there
�
exists an answer set I � ∈ F(LP � ) such that I|L
= I and I � (z) ≥
P
1.

Corollary 1. Set-membership for normal FASP, if constraints are
allowed, is NP-complete.
Corollary 2. Set-membership for disjunctive FASP is NP-complete.

Proof. 1. Suppose that I ∈ F(LP ) is an answer set of P . Define
I � ∈ F(LP � ) as I � (a) = I(a) if a ∈ LP , I � (z) = 1 and I � (y) =
0. We show that I � is an answer set of P � .
�
First, we prove that I � is a fuzzy model of P � and thus of (P � )I .
�
Clearly, I is a fuzzy model of P1 and it models the rule z ←
not y. If y ← α is a rule in C � , then by assumption we have that
�
I = I|L
models the rule 0 ← α. Thus [0 ← α]I � = 1 and
P
[α]I � = 0 = I � (y). Hence I � models y ← α.
�
Next, we show that I � is a minimal fuzzy model of (P � )I . Sup�
pose there exists a fuzzy model J � ∈ F(LP � ) of (P � )I such
�
that J � ≤ I � . We show that J = J|L
is a fuzzy model of P I .
P
I
Clearly, J is a fuzzy model of (P1 ) . Since J � ≤ I � we have
that J � (y) ≤ I � (y) = 0, thus given a rule r : 0 ← α in C
we have that for the corresponding rule y ← α in C � it holds
that 0 = J � (y) ≥ [αI ]J , with αI the reduct of the expression α
w.r.t. I. Hence [rI ]J = 1. Because I is a minimal fuzzy model
of P I , it follows that I = J. As mentioned before, we have
J � (y) = I � (y) and since [z ← [not y]I � ]J � = 1, we also have
J � (z) ≥ 1 − I � (y) = I � (z) ≥ J � (z). Hence I � = J � , which
�
shows that I � is a minimal fuzzy model of (P � )I .
2. Suppose that I � ∈ F(LP � ) is an answer set of P � such that
�
I � (z) = 1. We show that I = I|L
is an answer set of P . By
P
Lemma 1 it is sufficient to show that I is an answer set of P1 and
a fuzzy model of C.
First, we show that I is a fuzzy model of C. Since I � is a minimal
�
fuzzy model of (P � )I , it must hold that I � (z) = 1 − I � (y) and
�
thus that I (y) = 0. Given a rule r : 0 ← α in C we have that
for the corresponding rule y ← α in C � it holds that 0 = I � (y) ≥
[α]I � , and thus [r]I = 1.
Next, note that I is a fuzzy model of (P1 )I since I � is a fuzzy
�
model of (P1 )I . Now suppose there exists a fuzzy model J ∈
F(LP1 ) of (P1 )I such that J ≤ I. Define J � ∈ F(LP � ) as follows: J � (a) = J(a) if a ∈ LP , J � (y) = 0 and J � (z) = 1. We
�
show that J � is a fuzzy model of (P � )I . By assumption, J � is
I�
a fuzzy model of (P1 ) . For the rule r : z ← not y in P � we
have J � (z) = 1 = I � (z) ≥ [not y]I � , hence J � models rI . Finally, given a rule r : y ← α in C � we have for the corresponding
�
rule 0 ← α in C that J � (y) = 0 ≥ [αI ]J � . Hence J � models
�
�
rI . Since J � ≤ I � and I � is a minimal fuzzy model of (P � )I it
follows that J � = I � and thus J = I.

Proof. Follows by the reduction in the proof of Proposition 2.
Proposition 3. Existence for normal FASP, if constraints are allowed, is NP-complete.
Proof. The same proof as for Proposition 1 can be used to show NPmembership and the proof for NP-hardness is entirely analogue to
the proof for Proposition 2.
Corollary 3. Existence for disjunctive FASP is NP-complete
Proof. Follows by the proof of Proposition 3.
In the proof of the following proposition we will use the notation
f|A to denote the function that is the restriction of f : B → C to the
domain A ⊆ B.

Proposition 4. Set-entailment for normal FASP, if constraints are
allowed, is coNP-complete.
Proof. Let us denote normal FASP for which constraits are allowed
by the term “extended normal FASP”.

1. One can show that the complementary decision problem, i.e.
“Given an extended normal FASP program P , a literal l ∈ LP
and a value λl ∈ [0, 1] ∩ Q; is there an answer set I of P such
that I(l) < λl ?” is in NP by adjusting the proof of Proposition 1;
it now has to be checked whether I(l) < λl instead of I(l) ≥ λl .
This shows coNP-membership.
2. To show coNP-hardness, we reduce the NP-hard problem “existence” to the complement of the set-entailment problem. Consider
an extended normal FASP program P . Define P � = P ∪ {a ← a}
with a a fresh atom. We show that P has an answer set iff it is not
the case that all answer sets I � of P � are such that I � (a) ≥ 0.5.
First suppose that P has an answer set I. Then there exists an
answer set I � of P � with I � (a) < 0.5. Indeed, define I � (a) = 0
and I � (x) = I(x) otherwise. Next, suppose that there exists an
�
answer set I � of P � such that I � (a) < 0.5. Then I = I|L
is an
P
answer set of P .

Corollary 4. Set-entailment for disjunctive FASP is coNP-complete.
Proof. Follows by the proof of Proposition 4.
A summary of these results can be found in Table 3.

48

ECAI-2012 Workshop WL4AI

Table 3. Complexity of inference in disjunctive FASP

disjunctive FASP
normal FASP, if constraints are allowed

existence
NP-complete
NP-complete

set-membership
NP-complete
NP-complete

set-entailment
coNP-complete
coNP-complete

In a bilevel linear program all objective functions and constraints
are linear. In particular, the type of bilevel linear programming problem in which we are interested is given by Bard [3]:

We use this lemma to show a variation of the reduction proposed
in the proof of Proposition 2.
Proposition 5. Set-membership for normal FASP is NP-hard.

arg minx c1 x + d1 y
s.t. A1 x + B1 y ≤ b1
arg miny c2 x + d2 y
s.t. A2 x + B2 y ≤ b2

Proof. Consider an arbitrary instance
(a11 ∨ a12 ∨ a13 ) ∧ (a21 ∨ a22 ∨ a23 ) ∧ . . . ∧ (an1 ∨ an2 ∨ an3 )
of 3SAT. We will refer to this expression by α. As shown in the proof
op Proposition 2, α is satisfied by an assigment G iff the propositional interpretation I, with I(x) = 1 if G(x) = “true” and
I(x) = 0 if G(x) = “false” is an answer set of P with P the
program obtained by translating each clause ai1 ∨ ai2 ∨ ai3 (see the
proof of Proposition 2).
By Remark 3 it follows that P can be rewritten to a disjunctive
FASP P � without strong negation and in which the head contains
exactly one atom or the constant 0 such that there is a one-on-one
correspondence between the answer sets. By Lemma 2, it follows that
we can define a normal FASP program P �� without constraints and
without strong negation such that the answer sets of P � correspond
to the answer sets of P �� for which a certain atom has at least truth
value 1.

where c1 , c2 ∈ Rn , d1 , d2 ∈ Rm , b1 ∈ Rp , b2 ∈ Rq , A1 ∈ Rp×n ,
B1 ∈ Rp×m , A2 ∈ Rq×n and B2 ∈ Rq×m .
Now consider a disjunctive FASP program P . We will translate P
to a bilevel linear program Q such that the solutions of Q correspond
to the answer sets of P . By definition I is an answer set of P iff
I is an answer set of P I . Informally, a guess I needs to be made
first and then it has to be checked whether this guess corresponds to
an answer set of P . If LP = {a1 , . . . , an }, then we will define the
vector a = (a1 , . . . , an ) and the vector a� = (a�1 , . . . , a�n ) where
each a�i intuitively corresponds to a guess for ai . For each such guess
I, I(ai ) = a�i , we want to check if it is a minimal fuzzy model of
P I . Note that P I is a positive FASP program in which each rule is
of the form

Corollary 5. Set-membership for normal FASP is NP-complete, even
is strong negation is not allowed.

with li , xj literals and/or constants. Similar to a previous calculation
in Proposition 2, if a fuzzy interpretation J ∈ F(LP ) is a model of
r, then it must hold that

r : l1 ⊕ . . . ⊕ ln ← x1 ⊗ . . . ⊗ xm ,

Proof. Follows by the reduction in the proof of Proposition 5.

J(l1 ) + . . . + J(ln ) ≥ J(x1 ) + . . . + J(xm ) − (m − 1).
Thus for each rule r ∈ P I we have a constraint x1 + . . . + xm −
m + 1 ≤ l1 + . . . + ln .
Hence, for each guess a� , i.e. an interpretation I, we check if there
is a minimal model J of P I such that J(ai ) ≤ I(ai ) = a�i by
minimizing all elements in the vector a subject to the constraints
arising from P I . This is the follower’s problem. Finally, the guess is
chosen such that the differences between J(ai ) and a�i are
� as small
�
as possible. This can be done by minimizing the function n
i=1 (ai −
ai ). If this sum is equal to 0, we have found a answer set. If this sum
is not equal to 0, there cannot be an answer set.
More structured, we have
�
�
arg mina� n
i=1 (ai − ai )
�
s.t. 0 ≤ ai ≤ 1
�
arg mina n
i=1 ai
s.t. �
ai + ¬ai ≤ 1, ai ≤ a�i ,�
0 ≤ ai ≤ 1 and
n
( m
x
)
−
m
+
1
≤
j
j=1
i=1 li for each rule (7)
with m, n ∈ N in the reduct w.r.t. a�

Corollary 6. Set-membership for disjunctive FASP programs is NPcomplete, even if constraints and strong negation are not allowed.
Proof. Follows by the reduction in the proof of Proposition 5.
A summary of these results can be found in Table 4.

6

(7)

Reduction to bilevel linear programming

In this section, we will show that we can translate disjunctive FASP
programs into bilevel linear programs such that all solutions of the
bilevel linear program are answer sets and if there are no solutions,
then there are no answer sets. Bilevel linear programming problems
are optimization problems in which the set of all variables is divided
into two sets X = {x1 , . . . , xn } and Y = {y1 , . . . , ym }. Each
possibility of assignments to the variables will be denoted by the
vector x = (x1 , . . . , xn ) for X and by the vector y = (y1 , . . . , yn )
for Y .
Intuitively, there are two agents, a leader who is responsible for
the variables in X and a follower responsible for the variables in Y .
Each vector y has to be chosen by the follower in function of the
choice by the leader x as an optimal solution of the so-called lower
level problem or the follower’s problem. Knowing this reaction, the
leader then wants to optimize his objective function in the so-called
upper level problem or the leader’s problem.

Example 3. Reconsider the normal FASP program P from Example
2. The corresponding bilevel linear program is
arg mina� ,b� (a� − a) + (b� − b)
s.t. 0 ≤ a� , b� ≤ 1
arg mina,b a + b
s.t. 0 ≤ a, b ≤ 1, a ≤ a� , b ≤ b�
1 − a� ≤ b, 1 − b� ≤ a

49

ECAI-2012 Workshop WL4AI

Table 4. Complexity of the set-membership problem for disjunctive FASP

normal FASP, even if strong negation is not allowed
disjunctive FASP, even if constraints and strong negation are not allowed
The only assignments to the variables such that the objective function of the leader is equal to 0 are the ones with a� = a, b� = b and
a� = 1 − b � .

[13] A. Dekhtyar and V.S. Subrahmanian, ‘Hybrid probabilistic programs’,
in Proceedings of the 14th International Conference on Logic Programming, pp. 391–405, (1997).
[14] D. Dubois and H. Prade, ‘Possibility theory, probability theory and
multiple-valued logics: a clarification’, Annals of Mathematics and Artificial Intelligence, 32(1-4), 35–66, (2001).
[15] T. Eiter and G. Gottlob, ‘Complexity Results for Disjunctive Logic
Programming and Application to Nonmonotonic Logics’, in Proceedings of the International Logic Programming Symposium, pp. 266–278,
(1993).
[16] M. Gelfond and V. Lifschitz, ‘The Stable Model Semantics for Logic
Programming’, in Proceedings of the Fifth International Conference
and Symposium on Logic Programming, pp. 1070–1080, (1988).
[17] R. H¨ahnle, ‘Proof theory of many-valued logic - linear optimization logic design: connections and interactions’, Soft Computing, 1, 107–
119, (1997).
[18] P. H´ajek, Metamathematics of Fuzzy Logic, Trends in Logic, 1998.
[19] J. Janssen, S. Schockaert, D. Vermeir, and M. De Cock, ‘General Fuzzy
Answer Set Programs’, in Proceedings of the International Workshop
on Fuzzy Logic and Applications, pp. 353–359, (2009).
[20] Y. Loyer and U. Straccia, ‘Epistemic foundation of stable model semantics’, Theory and Practice of Logic Programming, 6(4), 355–393,
(2006).
[21] T. Łukasiewicz, ‘Many-valued disjunctive logic programs with probabilistic semantics’, in LPNMR, pp. 277–289, (1999).
[22] T. Łukasiewicz and U. Straccia, ‘Tightly integrated fuzzy description
logic programs under the answer set semantics for the semantic web’,
in Proceedings of the 1st International Conference on Web Reasoning
and Rule Systems, pp. 289–298, (2007).
[23] R. McNaughton, ‘A theorem about infinite-valued sentential logic’, The
Journal of Symbolic Logic, 16(1), (1951).
[24] D. Mundici, ‘Satisfiability in many-valued sentential logic is NPcomplete’, Theoretical Computer Science, 52(5), 145–153, (1987).
[25] Madrid N. and M. Ojeda-Aciego, ‘Measuring Inconsistency in Fuzzy
Answer Set Semantics’, IEEE T. Fuzzy Systems, 19(4), 605–622,
(2011).
[26] S. Schockaert, J. Janssen, D. Vermeir, and M. De Cock, ‘Answer sets
in a fuzzy equilibrium logic’, in Proceedings of the 3rd International
Conference in Web Reasoning and Rule Systems, pp. 135–149, (2009).
[27] C. Shi, J. Lu, G. Zhang, and H. Zhou, ‘An extended branch and bound
algorithm for linear bilevel programming’, Applied Mathematics and
Computation, 180(2), 529–537, (2006).
[28] U. Straccia, ‘Query answering in normal logic programs under uncertainty’, in Symbolic and Quantitative Approaches to Reasoning with
Uncertainty, pp. 687–700, (2005).
[29] U. Straccia, ‘Annotated answer set programming’, in Proceedings of the
11th International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems, (2006).
[30] U. Straccia, ‘Query answering under the any-world assumption for normal logic programs’, in Proceedings of the 10th International Conference on Principles of Knowledge Representation and Reasoning, pp.
329–339, (2006).
[31] U. Straccia, M. Ojeda-Aciego, and C. V. Dam´asio, ‘On fixed-points
of multi-valued functions on complete lattices and their application to
generalized logic programs’, SIAM Journal on Computing, (5), 1881–
1911, (2009).
[32] D. Van Nieuwenborgh, M. De Cock, and D. Vermeir, ‘An introduction
to fuzzy answer set programming’, Annals of Mathematics and Artificial Intelligence, 50(3-4), 363–388, (2007).

Remark 5. A similar construction can be used if ASP is combined
with other fuzzy logics, e.g. product logic, but the resulting bilevel
program will not necessarily be linear.

7

set-membership
NP-complete
NP-complete

CONCLUSIONS

We have analyzed the computational complexity of FASP under
Łukasiewicz semantics. In particular, when restricting to disjunctions in the head of rules and conjunctions in the bodies of rules,
i.e. disjunctive FASP programs, NP-completeness was shown, which
stands in contrast with the fact that disjunctive ASP is ΣP
2 -complete.
This results even holds when restricting to disjunctive FASP without strong negation and with exactly one literal in the head of each
rule. Hence, allowing disjunctions in the head has no influence on the
computational complexity. Given that we have not been able to show
NP-membership for normal FASP programs in which both conjunction and disjunction are allowed in the bodies of rules, it is tempting
to speculate that, unlike in the classical case, allowing disjunction in
the body affects the computational complexity, whereas allowing it
in the head does not. Finally, we have proposed an implementation
of disjunctive FASP using bilevel linear programming which opens
the door to practical applications.

REFERENCES
[1] C. Baral, Knowledge Representation, Reasoning and Declarative Problem Solving, Cambridge University Press, 2003.
[2] C. Baral, M. Gelfond, and J.N. Rushton, ‘Probabilistic reasoning in
computer science’, in Logic Programming and Nonmonotonic Reasoning, 7th International Conference, pp. 21–33, (2004).
[3] J. Bard, Practical Bilevel Optimization: Algorithms and Applications,
Kluwer Academic Publishers: USA, 1998.
[4] J. Bard and J. Falk, ‘An explicit solution to the multi-level programming
problem’, Computers and Operations Research, 9, 77–100, (1982).
[5] J. Bard and J.T. Moore, ‘A branch and bound algorithm for the bilevel
programming problem’, SIAM Journal on Scientific and Statistical
Computation, 11, 281–292, (1990).
[6] K. Bauters, S. Schockaert, M. De Cock, and D. Vermeir, ‘Possibilistic
answer set programming revisited’, in Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence , (2010).
[7] M. Blondeel, S. Schockaert, M. De Cock, and D. Vermeir, ‘Complexity
of fuzzy answer set programming under Łukasiewicz semantics: first
results’, in Poster Proceedings of the 5th International Conference on
Scalable Uncertainty Management, pp. 7–12, (2011).
[8] F. Bobillo, F. Bou, and U. Straccia, ‘On the failure of the finite model
property in some fuzzy description logics’, Fuzzy Sets and Systems,
172(23), 1–12, (2011).
[9] W. Candler and R. Townsley, ‘A linear two-level programming problem’, Computers and Operations Research, 9, 59–76, (1982).
[10] M. Cerami and U. Straccia, ‘On the undecidability of fuzzy description
logics with GCIs with Łukasiewicz t-norm’, Technical report, (2011).
[11] S.A. Cook, ‘The complexity of theorem-proving procedures’, in Proceedings of the 3rd Annual ACM Symposium on the Theory of Computing, pp. 151–158, (1971).
[12] C.V. Dam´asio and L.M. Pereira, ‘Antitonic Logic Programs’, in Proceedings of the 6th International Conference on Logic Programming
and Nonmonotonic Reasoning, pp. 379–392, (2001).

50

ECAI-2012 Workshop WL4AI

Undecidability of Fuzzy Description Logics
with GCIs under Łukasiewicz Semantics
Marco Cerami1 and Umberto Straccia2
2

Abstract.
Recently there have been some unexpected results concerning
Fuzzy Description Logics (FDLs) with General Concept Inclusions
(GCIs). They show that, unlike the classical case, the DL ALC with
GCIs does not have the finite model property under Łukasiewicz
Logic or Product Logic, the previously proposed reasoning algorithms are neither correct nor complete and, specifically, knowledge
base satisfiability is an undecidable problem for Product Logic. We
complete here the analysis by showing that knowledge base satisfiability is also an undecidable problem for Łukasiewicz Logic.

1

In this section we are going to introduce the general definitions of
Ł-ALC based on Łukasiewicz t-norm.
Syntax. Let A be a set of concept names, R be a set of role names.
Concept names denote unary predicates, while role names denote binary predicates. The set of Ł-ALC concepts are built from concept
names A (also called atomic concepts) using connectives and quantification constructs over roles R 3 as described by the following syntactic rules:

Introduction

C

Description Logics (DLs) [1] play a key role in the design of Ontologies. Indeed, DLs are important as they are essentially the theoretical
counterpart of the Web Ontology Language OWL 2 [19], the standard
language to represent ontologies.
It is very natural to extend DLs to the fuzzy case and several fuzzy
extensions of DLs can be found in the literature. For a recent survey
on the advances in the field of fuzzy DLs, we refer the reader to [18].
Besides the generalization of DLs to the fuzzy framework, one of the
challenges of the research in this community is the fact that different
families of fuzzy operators (or fuzzy logics) lead to fuzzy DLs with
different computational properties.
Decidability of fuzzy DLs is often shown by adapting crisp DL
tableau-based algorithms to the fuzzy DL case [8, 21, 22, 23, 25, 26],
by a reduction to classical DLs [5, 6, 7, 9, 24], or by relying on some
Mathematical Fuzzy Logic [13] based procedures [11, 12, 14, 15].
However, recently there have been some unexpected results [2,
3, 4]. Indeed, unlike the classical case, for the DL ALC with GCIs
(i) [4] shows that it does not have the finite model property under
Łukasiewicz Logic or Product Logic, illustrates that some algorithms
are neither complete nor correct, and shows some interesting conditions under which decidability is still guaranteed; and (ii) [2, 3] show
that knowledge base satisfiability is an undecidable problem under
Product Logic. Also worth mentioning is [10], which illustrates the
undecidability of knowledge base satisfiability if one replaces the
truth set [0, 1] with complete De Morgan lattices equipped with a
t-norm operator.
In this paper, we complete the analysis by showing that knowledge
base satisfiability is an undecidable problem for the DL ALC with
GCIs under [0, 1]-valued Łukasiewicz Logic as well. We prove our
results following conceptually the methods devised in [2, 3, 10].

2

→

C 1 � C2

�
|

|

⊥

¬C

| A
|

| C1 � C2

∃R.C

|

|

∀R.C .

An assertion axiom is an expression of the form �a:C, n� (concept
assertion, a is an instance of concept C to degree at least n) 4 or of
the form �(a1 , a2 ):R, n� (role assertion, (a1 , a2 ) is an instance of
role R to degree at least n), where a, a1 , a2 are individual names, C
is a concept, R is a role name and n ∈ (0, 1] is a rational (a truth
value). An ABox A consists of a finite set of assertion axioms.
A General Concept Inclusion (GCI) axiom is of the form
�C1 � C2 , n� (C1 is a sub-concept of C2 to degree at least n), where
Ci is a concept and n ∈ (0, 1] is a rational. A concept hierarchy T ,
also called TBox, is a finite set of GCIs. In what follows we will use
the following shorthands:
• C1 → C2 for ¬C1 � C2 ;
• C1 ↔ C2 for (C1 → C2 ) � (C2 → C1 );
• min{C1 , C2 } for C1 � (C1 → C2 ), and min{C1 , . . . , Cn } for
min{. . . min{C1 , C2 }, . . .};
• max{C1 , C2 } for (C1 → C2 ) → C2 and max{C1 , . . . , Cn } for
max{. . . max{C1 , C2 }, . . .};
• n · C for the n-ary disjunction C � . . . � C;
• C1 � C2 for �C1 � C2 , 1� and a:C for �a:C, 1�;
• C1 ≡ C2 for the two axioms C1 � C2 and C2 � C1 (or, equivalently for axiom � � C1 ↔ C2 ).
Finally, a knowledge base K = �T , A� consists of a TBox T
and an ABox A. With sub(K) we denote the set of (sub)concept
expressions occurring in K.
3
4

1

The FDL Ł-ALC

IIIA-CSIC, Spain, email: cerami@iiia.csic.es
ISTI-CNR, Italy, email: umberto.straccia@isti.cnr.it

51

Each symbol may have super- and/or subscripts.
Often, in fuzzy DLs one may encounter concept assertions of the form
�a:C ≥ n� and �a:C ≤ n� instead. Note that the latter is equivalent to
�a:¬C, 1 − n�.

ECAI-2012 Workshop WL4AI

An important note is that in this paper, we mainly focus on witnessed models. This notion (see [14]) corresponds to the restriction
to the DL language of the notion of witnessed model introduced, in
the context of the first-order language, by H´ajek in [14, 16]. Specifically, a fuzzy interpretation I is said to be witnessed iff it holds that
for every complex concept C, every role R, and every x ∈ ∆I there
is some

Semantics. From a semantics point of view, an axiom �α, n� constrains the truth degree of the expression α to be at least n. In
the following, we use ⊗, ⊕, � and ⇒ to denote Łukasiewicz tnorm, t-conorm, negation function, and implication function, respectively [17]. They are defined as operations in [0, 1] by means of the
following functions:
a⊗b

:=

�a

:=

a⊕b

:=

a⇒b

:=

max{0, a + b − 1}

1. y ∈ ∆I such that (∃R.C)I (x) = RI (x, y) ⊗ C I (y).
2. y ∈ ∆I such that (∀R.C)I (x) = RI (x, y) ⇒ C I (y).

min{1, a + b}
1−a

If I satisfies conditions 1. and 2. then I is said to be witnessed. If
I satisfies only condition 1. then I is said to be weakly witnessed.
Note that for Łukasiewicz logic, condition 1. and 2. are equivalent,
so I is weakly witnessed iff I is witnessed. Throughout the paper we
will rely on the notion of witnessed interpretation only, but keep in
mind that the results apply, thus, to weakly witnessed interpretations
as well. Note also that it is obvious that in all finite fuzzy interpretations (this means that ∆I is a finite set) every supremum is a maximum (and the same holds for infima and minima) and, therefore,
finite fuzzy interpretations are indeed witnessed but the opposite is
not true.
Sometimes (see, e.g.,, [3]), the notion of witnessed interpretations
is strengthened to so-called strongly witnessed interpretations by imposing that additionally that for every complex concepts C, D, there
is some

min{1, 1 − a + b} ,

where a and b are arbitrary elements in [0, 1]. As in the classical
framework, the implication can be defined in terms of disjunction
(whose semantics is the t-conorm) and negation in the usual way:
a ⇒ b = �a ⊕ b. Note also that for any implication that, like
Łukasiewicz implication, is defined as the residuum of a continuous
t-norm ⊗, i.e.,
x ⇒ y = sup{z | x ⊗ z ≤ y} ,
we have that the following condition hold:
y ≥ x ⊗ z iff (x ⇒ y) ≥ z .

(1)

We will use a ⇔ b as shorthand for (a ⇒ b) ⊗ (b ⇒ a). Moreover,
the usual rules for dropping parenthesis will be used.
A fuzzy interpretation is a pair I = (∆I , ·I ) consisting of a
nonempty (crisp) set ∆I (the domain) and of a fuzzy interpretation
function ·I that assigns:

• y ∈ ∆I such that (C � D)I = C I (y) ⇒ DI (y)
has to hold.
Notice, however, that Łukasiewicz first order logic is complete
with respect to witnessed models, both under the general and the
standard semantics (see [14]). For this reason, from the undecidability of KB satisfiability with respect to witnessed interpretations that
we prove in this paper, can be easily obtained undecidability of KB
satisfiability with respect to interpretations that are not necessarily
witnessed.

1. to each atomic concept A a function AI : ∆I → [0, 1],
2. to each role R a function RI : ∆I × ∆I → [0, 1],
3. to each individual a an element aI ∈ ∆I such that aI �= bI
if a �= b (Unique Name Assumption, different individuals denote
different objects of the domain).
The fuzzy interpretation function is extended to complex concepts as specified in Table 1 (where x, y ∈ ∆I are elements of
the domain). Hence, for every complex concept C we get a function C I : ∆I → [0, 1]. The satisfiability of axioms is then defined
by the following conditions:

3

Undecidability of Ł-ALC with GCIs

1. I satisfies an axiom �a:C, n� if C I (aI ) ≥ n,
2. I satisfies an axiom �(a, b):R, n� if RI (aI , bI ) ≥ n,
3. I satisfies an axiom �C � D, n� if (C � D)I ≥ n where

Definition 1 (PCP). Let v1 , . . . , vp and w1 , . . . , wp be two finite
lists of words over an alphabet Σ = {1, . . . , s}. The Post Correspondence Problem (PCP) asks whether there is a non-empty sequence i1 , i2 , . . . , ik , with 1 ≤ ij ≤ p such that vi1 vi2 . . . vik =
wi1 wi2 . . . wik . Such a sequence, if it exists, is called a solution of
the problem instance.

Our proof consists of a reduction of the reverse of the Post Correspondence Problem (PCP) and follows conceptually the one in [2, 3,
10]. PCP is well-known to be undecidable [20], so is the reverse PCP,
as shown next.

(C � D)I = inf {C I (x) ⇒ DI (x)} .
x∈∆I

It is interesting to point out that the satisfaction of a GCI of the form
�C � D, 1� is exactly the requirement that ∀x ∈ ∆I , C I (x) ≤
DI (x) (i.e.,, Zadeh’s set inclusion); hence, in this particular case
for satisfaction only the partial order matters and not the exact value
of the implication ⇒.
As usual we will say that a fuzzy interpretation I satisfies (is a
model of) a KB K in case that it satisfies all axioms in K. And it is
said that a fuzzy KB K is satisfiable (has a model) iff there exists a
fuzzy interpretation I satisfying every axiom in K. A fuzzy KB K
entails an axiom �α, n� (denoted K |= �α, n�) iff any model of K
also satisfies �α, n�. Note that the problem of determining whether
K |= �(a, b):R, n� can easily be determined by checking if there is
�(a, b):R, m� ∈ A with m ≥ n.

For the sake of our purpose, we will rely on a variant of the PCP,
which we call Reverse PCP (RPCP). Essentially, words are concatenated from right to left rather than from left to right. In what follows,
as usual, we will denote by {1, . . . , p}∗ the set of words over alphabet {1, . . . , p} and by {1, . . . , p}+ the set of non-empty words over
alphabet {1, . . . , p}.

Definition 2 (RPCP). Let v1 , . . . , vp and w1 , . . . , wp be two finite lists of words over an alphabet Σ = {1, . . . , s}. The Reverse Post Correspondence Problem (RPCP) asks whether there is
a non-empty sequence i1 , i2 , . . . , ik , with 1 ≤ ij ≤ p such that
vik vik−1 . . . vi1 = wik wik−1 . . . wi1 . Such a sequence, if it exists,
is called a solution of the problem instance.

52

ECAI-2012 Workshop WL4AI

⊥I (x)
�I (x)
(C � D)I (x)
(C � D)I (x)
(¬C)I (x)
(∀R.C)I (x)
(∃R.C)I (x)

=
=
=
=
=
=
=

Table 1.

0
1
C I (x) ⊗ DI (x)
C I (x) ⊕ DI (x)
�C I (x)
inf y∈∆I {RI (x, y) ⇒ C I (y)}
supy∈∆I {RI (x, y) ⊗ C I (y)}
Semantics for Ł-ALC.

Undecidability of general KB satisfiability We show the undecidability by a reduction of RPCP to KB satisfiability problems.
Specifically, given an instance ϕ of RPCP, we will construct a
Knowledge Base Oϕ that is satisfiable iff ϕ has no solution.
In order to do this we will encode words v over the alphabet Σ as
rational numbers 0.v in [0, 1] in base s + 1; the empty word will be
encoded by the number 0.
So, let us define the following TBoxes:

For a word µ = i1 i2 . . . ik ∈ {1, . . . , p}∗ we will use vµ , wµ to
denote the words vik vik−1 . . . vi1 and wik wik−1 . . . wi1 . We denote
the empty string as � and define v� as �. The alphabet Σ consists of
the first s positive integers. We can thus view every word in Σ∗ as a
natural number represented in base s + 1 in which 0 never occurs.
Using this intuition, we will use the number 0 to encode the empty
word.
Now we show that the reduction from PCP to RPCP is a very simple matter and it can be done through the transformation of the instance lists to the lists of their palindromes defined as follows: let
Σ = {1, . . . , s} be an alphabet and v = t1 t2 . . . t|v| a word over Σ,
with ti ∈ Σ, for 1 ≤ i ≤ |v|, then the function pal : Σ∗ → Σ∗ is
defined as pal(v) = t|v| t|v|−1 . . . t1 . We will say that pal(v) is the
palindrome of v.

T

:= {

and for 1 ≤ i ≤ p
Tϕi

:= {

Lemma 3. Let v1 , . . . , vp and w1 , . . . , wp be two finite lists of words
over an alphabet Σ = {1, . . . , s}. For every non-empty sequence
i1 , i2 , . . . , ik , with 1 ≤ ij ≤ p it holds that
v i 1 v i 2 . . . vi k

=

V ≡ V1 � V2 , W ≡ W1 � W2 }

� � ∃Ri .�,
V � (s + 1)|vi | · ∀Ri .V1 ,
(s + 1)|vi | · ∃Ri .V1 � V,

W � (s + 1)|wi | · ∀Ri .W1 ,

wi 1 w i 2 . . . w ik

(s + 1)|wi | · ∃Ri .W1 � W

iff
pal(vik )pal(vik−1 ) . . . pal(vi1 ) =
pal(wik )pal(wik−1 ) . . . pal(wi1 ) .

�� � ∀Ri .V2 , 0.vi �,

(P roof ) First we prove by induction on k, that, for every sequence
v = vi1 vi2 . . . vik of words over Σ, it holds that pal(v) =
pal(vik )pal(vik−1 ) . . . pal(vi1 ).

�� � ∀Ri .¬V2 , 1 − 0.vi �,
�� � ∀Ri .W2 , 0.wi �,

�� � ∀Ri .¬W2 , 1 − 0.wi �,

• The case k = 1 is straightforward.

• Let v
=
vi1 vi2 . . . vik and suppose, by inductive
hypothesis,
that
pal(vi1 vi2 . . . vik−1 )
=
pal(vik−1 )pal(vik−2 ) . . . pal(vi1 ). It follows that pal(v) =
pal(vi1 vi2 . . . vik−1 , vik ) = pal(vik )pal(vik−1 ) . . . pal(vi1 ).

A � (s + 1)max{|vi |,|wi |} · ∀Ri .A

(s + 1)max{|vi |,|wi |} · ∃Ri .A � A } .
Now, let

Since the palindrome of a word is unique, we have that, if
vi1 vi2 . . . vik = wi1 wi2 . . . wik , then pal(vi1 vi2 . . . vik ) =
pal(wi1 wi2 . . . wik ) and, thus, pal(vik )pal(vik−1 ) . . . pal(vi1 )
= pal(wik ) pal(wik−1 ). . . pal(wi1 ).

Tϕ = T ∪

p
�

i=1

Tϕi .

Further we define the ABox A as follows:

Corollary 4. RPCP is undecidable.

A

(P roof ) The proof is based on the reduction of PCP to RPCP. For
every instance ϕ = (v1 , w1 ), . . . , (vp , wp ) of PCP, let f be the
function

:=

{a : ¬V, a : ¬W, �a : A, 0.01�,

�a : ¬A, 0.99�} .

Finally, we define
Oϕ := �Tϕ , A� .

f (ϕ) = (pal(v1 ), pal(w1 )), . . . , (pal(vp ), pal(wp )) .
Clearly f is a computable function. Moreover, ϕ ∈ P CP if
and only if there exists a non-empty sequence i1 , i2 , . . . , ik , with
1 ≤ ij ≤ p such that vi1 vi2 . . . vik = wi1 wi2 . . . wik , that is, by
Lemma 3,

Intuitively, Oϕ is built in such a way that, as we will see later on,
every interpretation I satisfying it has to contain a search tree for ϕ.
We now define the interpretation
Iϕ := (∆Iϕ , ·Iϕ )

pal(vik )pal(vik−1 ) . . . pal(vi1 ) =
pal(wik )pal(wik−1 ) . . . pal(wi1 )

as follows:

i.e., f (ϕ) ∈ RP CP . Therefore, ϕ ∈ P CP if and only if f (ϕ) ∈
RP CP .

• ∆Iϕ = {1, . . . , p}∗

53

ECAI-2012 Workshop WL4AI

Since I satisfies axioms �� � ∀Ri .V2 , 0.vi � and
�� � ∀Ri .¬V2 , 1 − 0.vi �, it follows that (∀Ri .V2 )I (g(µ)) ≥
0.vi and (∀Ri .¬V2 )I (g(µ)) ≥ 1 − 0.vi . Therefore,
for RiI (g(µ), g(µi)) = 1 we have V2I (g(µi)) =
I
0.vi = V2 ϕ (µi). Similarly, it can be shown that
Iϕ
W2 (µi) = 0.wi = W2I (g(µi)).
Now, since I satisfies axiom V ≡ V1 � V2 , then, V I (g(µi)) =
V1I (g(µi)) + V2I (g(µi)) = 0.vµ · (s + 1)−|vi | + 0.vi =
0.vi vµ = V Iϕ (µi).
Finally, by inductive hypothesis, assume that

• a Iϕ = �
• V Iϕ (�) = W Iϕ (�) = 0, AIϕ (�) = 0.01, and for 1 ≤ i ≤ 2,
I
I
Vi ϕ (�) = Wi ϕ (�) = 0
�
• for all µ, µ ∈ ∆Iϕ and 1 ≤ i ≤ p
�
1, if µ� = µi
Iϕ
�
Ri (µ, µ ) =
0, otherwise
• for every µ ∈ ∆Iϕ , where µ = i1 i2 . . . ik �= �
– V Iϕ (µ) = 0.vµ , W Iϕ (µ) = 0.wµ
−

– AIϕ (µ) = 0.01 · (s + 1)
–

I
V1 ϕ (µ)
−|wi |

�

j∈{i1 ,i2 ,...,ik }

max{|vj |,|wj |}

AI (g(µ)) = AIϕ (µ) =

I
W1 ϕ (µ)

= 0.vµ¯ · (s + 1)−|vik | ,
= 0.wµ¯ · (s +
k , where µ
1)
¯ = i1 i2 . . . ik−1 (last index ik is dropped
from µ, and we assume that 0.� is 0),
I

−

0.01 · (s + 1)

j∈{i1 ,i2 ,...,ik }

max{|vj |,|wj |}

,

where µ = i1 i2 . . . ik .
Since I satisfies axioms A � (s + 1)max{|vi |,|wi |} · ∀Ri .A, we
have that

I

– V2 ϕ (µ) = 0.vik , W2 ϕ (µ) = 0.wik .
It is easy to see that Iϕ is a witnessed model of Oϕ (note that
I
e.g., (∀Ri .V1 )Iϕ (µ) = V1 ϕ (µi)). 5
Moreover, as in [2] it is possible to prove that, for every witnessed
model I of Oϕ , there is a mapping g from Iϕ to I.

AI (g(µ)) ≤ (s + 1)max{|vi |,|wi |} · (∀Ri .A)I (g(µ))
≤ (s + 1)max{|vi |,|wi |} · AI (g(µi)) .

Likewise, since I satisfies axioms (s + 1)max{|vi |,|wi |} ·
∃Ri .A � A, we have that

Lemma 5. Let I be a witnessed model of Oϕ . Then there exists a
function g : ∆Iϕ → ∆I such that, for every µ ∈ ∆Iϕ , C Iϕ (µ) =
I
C I (g(µ)) holds for every concept name C and Ri ϕ (µ, µi) =
I
Ri (g(µ), g(µi)) holds for every i, with 1 ≤ i ≤ p.

AI (g(µ)) ≥ (s + 1)max{|vi |,|wi |} · (∃Ri .A)I (g(µ))
and, thus,

(P roof ) Let I be a witnessed model of Oϕ . We will build the function g inductively on the length of µ.

≥ (s + 1)max{|vi |,|wi |} · AI (g(µi))

AI (g(µ)) = (s + 1)max{|vi |,|wi |} · AI (g(µi)) .

I

(�) Since I is a model of Oϕ , then there is an element δ ∈ ∆
such that aI = δ. Since I is a model of Aϕ , setting g(�) = δ,
we have that V Iϕ (�) = 0 = V I (g(�)) and the same holds
for concept W . Moreover, since I is a model of Tϕ , we have
I
that V I (δ) = (V1 � V2 )I (δ) and, therefore V1 ϕ (�) = 0 =
I
V1 (g(�)) and the same holds for V2 , W1 and W2 . On the other
hand, we have that AIϕ (�) = 0.01 = AI (g(�)), as well. So,
g(�) = δ satisfies the condition of the lemma.

Therefore,
AI (g(µi))
=
=
=

(µi) Let now µ be such that g(µ) has already been defined. Now,
since I is a witnessed model and satisfies axiom � � ∃Ri .�,
then for all i, with 1 ≤ i ≤ p, there exists a γ ∈ ∆I
such that RiI (g(µ), γ) = 1. So, setting g(µi) = γ we get
I
1 = Ri ϕ (µ, µi) = RiI (g(µ), g(µi)). Furthermore, by induction hypothesis, we can assume that V I (g(µ)) = 0.vµ and
W I (g(µ)) = 0.wµ .
Since I satisfies axiom V � (s + 1)|vi | · ∀Ri .V1 , then
0.vµ = V I (g(µ)) ≤ (s + 1)|vi | · (∀Ri .V1 )I (g(µ)) =
(s + 1)|vi | · inf γ∈∆I {RiI (g(µ), γ) ⇒ V1I (γ)} ≤ (s + 1)|vi | ·
RiI (g(µ), µi) ⇒ V1I (µi) = (s + 1)|vi | · V1I (g(µi)).
Since I satisfies axiom (s + 1)|vi | · ∃Ri .V1 � V , then
0.vµ = V I (g(µ)) ≥ (s + 1)|vi | · (∃Ri .V1 )I (g(µ)) =
(s + 1)|vi | · supγ∈∆I {RiI (g(µ), γ) ⊗ V1I (γ)} ≥ (s + 1)|vi | ·
RiI (g(µ), µi) ⊗ V1I (µi) = (s + 1)|vi | · V1I (g(µi)). Therefore, (s + 1)|vi | · V1I (g(µi)) = 0.vµ and V1I (g(µi)) =
I
0.vµ · (s + 1)−|vi | = V1 ϕ (µi).
Similarly, it can be shown that W1I (g(µi)) = 0.wµ · (s +
I
1)−|wi | = W1 ϕ (µi).
5

�

=
=
=

(s + 1)− max{|vi |,|wi |} · AI (g(µ))
(s + 1)− max{|vi |,|wi |} · AIϕ (µ)

(s + 1)− max{|vi |,|wi |} · 0.01

·(s + 1)

−

�

j∈{i1 ,...,ik }

max{|vj |,|wj |}

0.01 · (s + 1)−(max{|vi |,|wi |}+
�

j∈{i1 ,...,ik }

max{|vj |,|wj |})

0.01 · (s + 1)

−

AIϕ (µi) ,

�

j∈{i1 ,...,ik ,i}

max{|vj |,|wj |}

which completes the proof.
From the last Lemma it follows that if the RPCP instance ϕ has
a solution µ, for some µ ∈ {1, . . . , p}+ , then vµ = wµ and, thus,
0.vµ = 0.wµ . Therefore, every witnessed model I of Oϕ contains an
element δ = g(µ) such that V I (δ) = V Iϕ (µ) = 0.vµ = 0.wµ =
W Iϕ (µ) = W I (δ). Conversely, from the definition of Iϕ , if ϕ has
no solution, then there is no µ such that 0.vµ = 0.wµ , i.e., there is
no µ such that V Iϕ (µ) = W Iϕ (µ).
However, as Oϕ is always satisfiable, it does not yet help us to
�
decide the RPCP. We next extend Oϕ to Oϕ
in such a way that an
�
instance ϕ of the RPCP has a solution iff the ontology Oϕ
is not witnessed satisfiable and, thus, establish that the KB satisfiability problem is undecidable. To this end, consider
�
:= �Tϕ� , A� ,
Oϕ

However, Iϕ is not a strongly witnessed model of Oϕ .

54

ECAI-2012 Workshop WL4AI

Undecidability of KB satisfiability w.r.t. finite models In this
section we address a subproblem of the previous one, that is, deciding
whether a KB has a finite model.
As in [3], given an instance ϕ of RPCP, we provide an ontology
˜ϕ and prove that it has a finite model iff ϕ has a solution. We now
O
define a TBox T˜ as follows:

where
Tϕ�

:= Tϕ ∪

�

1≤i≤p

{� � ∀Ri .(¬(V ↔ W ) � ¬A)} .

The intuition here is the following. If there is a solution for RPCP
then, by the observation before, there is a point δ in which the value
of V and W coincide under I. That is, the value of ¬(V ↔ W )
is 0 and, thus, the one of ¬(V ↔ W ) � ¬A is less than 1. So, I
�
cannot satisfy the new GCI in Tϕ� and, thus, Oϕ
is not satisfiable. On
the other hand, if there is no solution to the RPCP then in Iϕ there
is no point in which V and W coincide and, thus, ¬(V ↔ W ) > 0.
Moreover, we will show that the value of ¬(V ↔ W ) in all points is
strictly greater than A and, as A�¬A is 1, so also ¬(V ↔ W )�¬A
will be 1 in any point. Hence, Iφ is a model of the aditional axiom in
�
Tϕ� , i.e., Oϕ
is satisfiable.

T˜

:= {

V ≡ V1 � V2 , W ≡ W1 � W2 ,

¬(V ↔ W ) � max{C1 , . . . , Cp } } ,

and TBoxes T˜ϕi as follows:
T˜ϕi

:= {

Ci ≡ ∃Ri .�,

� � max{Ci , ¬Ci },

Proposition 6. The instance ϕ of the RPCP has a solution iff the
�
ontology Oϕ
is not witnessed satisfiable.

(Ci → V ) � (s + 1)|vi | · ∀Ri .V1 ,

(s + 1)|vi | · ∃Ri .V1 � (Ci → V ),

(P roof ) Assume first that ϕ has a solution µ = i1 . . . ik and let I
be a witnessed model of Oϕ . Let µ
¯ = i1 i2 . . . ik−1 (last index
ik is dropped from µ). Then by Lemma 5 it follows that there
are nodes δ, δ � ∈ ∆I such that δ = g(µ), δ � = g(¯
µ), with
V I (δ) = V Iϕ (µ) = W Iϕ (µ) = W I (δ) and RiIk (δ � , δ) = 1.
Then (V ↔ W )I (δ) = 1. Since (¬A)I (δ) < 1, then (¬(V ↔
W ) � ¬A)I (δ) < 1. Hence there is i, with 1 ≤ i ≤ p,
such that (∀Ri .(¬(V ↔ W ) � ¬A))I (δ � ) < 1. So, axiom
� � ∀Ri .(¬(V ↔ W ) � ¬A) is not satisfied and, therefore,
�
Oϕ
is not satisfiable.
For the converse, assume that ϕ has no solution. On the one hand
we know that Iϕ is a model of Oϕ . On the other hand, since ϕ
has no solution, then there is no µ = i1 . . . ik such that vµ = wµ
(i.e., 0.vµ = 0.wµ ) and, therefore, there is no µ ∈ ∆Iϕ such
that V Iϕ (µ) = W Iϕ (µ). Consider µ ∈ ∆Iϕ and i, with 1 ≤
i ≤ p and assume, without loss of generality, that V Iϕ (µi) <
W Iϕ (µi). Then

=
=
=
=
=
=
≤

≤
=

(V ↔ W )Iϕ (µi)

(V

Iϕ

(µi) ⇒ W

Iϕ

(Ci → W ) � (s + 1)|wi | · ∀Ri .W1 ,

(s + 1)|wi | · ∃Ri .W1 � (Ci → W ),
�� � ∀Ri .V2 , 0.vi �,

�� � ∀Ri .¬V2 , 1 − 0.vi �,
�� � ∀Ri .W2 , 0.wi �,

�� � ∀Ri .¬W2 , 1 − 0.wi � }
Now, let
T˜ϕ = T˜ ∪

A˜ϕ
(µi)) ⊗

1 ⊗ (W

(µi) ⇒ V

Iϕ

(µi))

Proposition 8. The instance ϕ of the RPCP has a solution iff the
˜ϕ has a finite model.
ontology O
(P roof ) (⇒) Let µ = i1 . . . ik be a solution of ϕ and let suf (µ)
be the set of all suffixes of µ 6 . We build the finite interpretation
I˜ϕ as follows:

1 − (W Iϕ (µi) − V Iϕ (µi))
1 − (0.wµi − 0.vµi )

1 − 0.01 · (s + 1)− max{|vµi |,|wµi |}
(¬A)Iϕ (µi) .

�

{a:¬V , a:¬W , a:max{C1 , . . . , Cp } } .
˜ϕ := �T˜ϕ , A˜ϕ � .
O

1 − W Iϕ (µi) + V Iϕ (µi)

−

:=

Finally,

W Iϕ (µi) ⇒ V Iϕ (µi)

1 − 0.01 · (s + 1)

j∈{i1 ,i2 ,...,ik ,i}

˜

• ∆Iϕ := suf (µ),

max{|vj |,|wj |}

• aIϕ = �,
˜

Iϕ

i=1

T˜ϕi .

Further we define the ABox A˜ϕ as follows:

(W Iϕ (µi) ⇒ V Iϕ (µi))
Iϕ

p
�

Iϕ

˜

Iϕ

• V Iϕ (�) = W Iϕ (�) = 0, and for 1 ≤ i ≤ 2, Vi

Iϕ

Therefore, (¬(V ↔ W )) (µi) ≥ A (µi). As A (µi) ⊕
(¬A)Iϕ (µi) = 1, it follows that for every µ ∈ ∆Iϕ and i, with
1 ≤ i ≤ p, it holds that (∀Ri .(¬(V ↔ W ) � ¬A))Iϕ (µ) = 1
�
and, therefore, Iϕ is a witnessed model of Oϕ
.

(�) =

I

Wi ϕ (�) = 0

˜

˜

˜

• for all ν ∈ ∆Iϕ , V Iϕ (ν) = 0.vν , W Iϕ (ν) = 0.wν

• for all ν, ν � ∈ ∆

˜ϕ
I

and 1 ≤ i ≤ p
�
˜ϕ
1, if ν � = iν
I
�
Ri (ν, ν ) =
0, otherwise

By Proposition 6, we have a reduction of a RPCP to a KB satisfiability problem. Note that all roles are crisp. Therefore,
Proposition 7. The knowledge base satisfiability problem is undecidable for Ł-ALC with GCIs. The result holds also if crisp roles are
assumed.

6

55

A suffix of a string t1 t2 . . . tn is a string tn−m+1 . . . tn (0 ≤ m ≤ n),
which is the empty string � for m = 0.

ECAI-2012 Workshop WL4AI

supδ� ∈∆I {RiI1 (δ, δ � ) ⊗ V1I (δ � )} ≥ RiI1 (δ, δi1 ) ⊗ V1I (δi1 ) =
1 ⊗ V1I (δi1 ) = V1I (δi1 ). Hence, V1I (δi1 ) = 0. In the same
way it can be proved that W1I (δi1 ) = 0.
Since I satisfies axiom �� � ∀Ri1 .V2 , 0.vi1 �, we have that
0.vi1 ≤ (RiI1 (δ, δi1 ) ⇒ V2I (δi1 )) = (1 ⇒ V2I (δi1 )) =
V2I (δi1 ).
Since I satisfies axiom �� � ∀Ri1 .¬V2 , 1 − 0.vi1 �, it follows that 1 − 0.vi1 ≤ (RiI1 (δ, δi1 ) ⇒ ¬V2I (δi1 )) = (1 ⇒
¬V2I (δi1 )) = ¬V2I (δi1 ) = 1 − V2I (δi1 ) and therefore,
V2I (δi1 ) ≤ 0.vi1 . So, V2I (δi1 ) = 0.vi1 . In the same way
it can be proved that W2I (δi1 ) = 0.wi1 .
Finally, since I satisfies axiom V ≡ V1 �V2 , then V I (δi1 ) =
V1I (δi1 ) ⊕ V2I (δi1 ) = 0 ⊕ 0.vi1 = 0.vi1 . In the same way
it can be proved that W I (δi1 ) = 0.wi1 . Moreover, since
V I (δ) = 0 �= 0.vi1 = V I (δi1 ), then δ �= δi1 and, thus,
|{δ, δi1 }| = 2, which completes the case.

˜

• for all ν ∈ ∆Iϕ and 1 ≤ i ≤ p,
�
˜ϕ
1, if iν ∈ suf (µ)
I
Ci (ν) =
0, otherwise
˜

• for all ν ∈ ∆Iϕ and 1 ≤ i ≤ p such that iν ∈ suf (µ)
˜
I

˜
I

– V1 ϕ (iν) = 0.vν · (s + 1)−|vi | , W1 ϕ (iν) = 0.wν · (s +
1)−|wi | ,
I

I

– V2 ϕ (iν) = 0.vi , W2 ϕ (iν) = 0.wi .
˜ϕ . Since V Iϕ (�) = 0.v� =
We show now that I˜ϕ is a model O
˜ϕ
I
0 and W (�) = 0.w� = 0, then the first two axioms in A˜ϕ
are satisfied. Since there is 1 ≤ i ≤ p such that i� = i ∈
˜
I
suf (µ), then Ci ϕ (�) = 1 and, therefore, the third axiom in
A˜ϕ is satisfied.
We now show that the axioms in T˜ and each T˜ϕi , with 1 ≤ i ≤
p are satisfied for every ν ∈ suf (µ). So, let ν ∈ suf (µ) \ {µ}.
Then there is 1 ≤ i ≤ p such that iν ∈ suf (µ) and, therefore,
˜
˜
I
I
by the definition of I˜ϕ , C ϕ (ν) = 1 and R ϕ (ν, iν) = 1.
˜

i

˜

Induction step n + 1. Let n > 1 and suppose, by inductive
hypothesis, that, for every j ≤ n, the above conditions hold.
Since ϕ has no solution, then vin . . . vi1 �= win . . . wi1
and, therefore, by inductive hypothesis, V I (δin ) =
0.vin . . . vi1 �= 0.win . . . wi1 = W I (δin ). Hence (V ↔
W )I (δin ) < 1 and, therefore, ¬(V ↔ W )I (δin ) > 0. So,
since I satisfies axiom ¬(V ↔ W ) � max{C1 , . . . , Cp },
(max{C1 , . . . , Cp })I (δin ) > 0 follows and, thus, there is
i such that CiI (δin ) > 0. Therefore, as I satisfies axiom
� � max{Ci , ¬Ci }, we have that CiI (δin ) = 1. Now, let
in+1 = i.
Since I satisfies axiom Cin+1 ≡ ∃Rin+1 .�, then there is
δ � ∈ ∆I such that RiIn+1 (δin , δ � ) = 1. So, let δin+1 = δ � .
Since I satisfies axiom (Cin+1 → V ) � (s +
|v
|
1) in+1 · ∀Rin+1 .V1 , then 0.vin . . . vi1 = (1 ⇒
0.vin . . . vi1 ) = (Cin ⇒ V )I (δin )) ≤ (s +
|v
|
1) in+1 · inf δ� ∈∆I {RiIn+1 (δin , δ � ) ⇒ V1I (δ � )} ≤
I
(Rin+1 (δin , δin+1 ) ⇒ V1I (δin+1 )) = V1I (δin+1 ). On

i

Therefore, (Ci → V )Iϕ (ν) = V Iϕ (ν) from which it follows
that every axiom in T˜ϕi is satisfied by I˜ϕ (the proof is the same
˜
as for Iϕ satisfying Tϕi ). E.g., note that V Iϕ (ν) = 0.vν =
˜
I

(s + 1)|vi | · V1 ϕ (iν) and, thus, both (Ci → V ) � (s + 1)|vi | ·
∀Ri .V1 and (s + 1)|vi | · ∃Ri .V1 � (Ci → V ) are satisfied.
Moreover, for every j �= i and ν � ∈ suf (µ), it holds that
˜
I

˜
I

Cj ϕ (ν) = 0 and Rj ϕ (ν, ν � ) = 0 and, therefore every axiom
˜
in T˜ϕj is satisfied as well (note that e.g., (∀Rj .V1 )Iϕ (ν) = 1).
This last argument holds for µ as well.
Finally, consider T˜ϕ . It is easy to check that the first two axioms
are satisfied in every ν ∈ suf (µ). For the third axiom, if ν ∈
˜
I

suf (µ) \ {µ}, then there is 1 ≤ i ≤ p such that Ci ϕ (ν) = 1
and, then, the axiom is trivially satisfied. Otherwise, if ν = µ,
˜
since µ is a solution for ϕ, then (¬(V ↔ W ))Iϕ (µ) = 0 and,
then, the axiom is trivially satisfied as well.

|v

the other hand, since I satisfies axiom (s + 1) in+1
∃Rin+1 .V1 � (Cin+1 → V ), then 0.vin . . . vi1
(1 ⇒ 0.vin . . . vi1 ) = (Cin ⇒ V )I (δin )
|v
|
(s + 1) in+1 · supδ� ∈∆I {RiIn+1 (δin , δ � ) ⊗ V1I (δ � )}

(⇐) For the converse, suppose that ϕ has no solution and let I
˜ϕ . By absurd, let us assume that I is finite and,
be a model of O
thus, witnessed.
Now, since I is a model of axioms a:¬V and a:¬W , then there
is a node aI = δ ∈ ∆I , such that V I (δ) = W I (δ) = 0.
Moreover, since I is a model of axioms V ≡ V1 �V2 and W ≡
W1 � W2 , then V1I (δ) = V2I (δ) = W1I (δ) = W2I (δ) = 0 as
well.
Next, we prove by induction that for every n ∈ N there is an
element δin ∈ ∆I such that:

|vin+1 |

(s + 1)

|vin+1 |

· (RiIn+1 (δin , δin+1 ) ⊗ V1I (δin+1 ))

|

·
=
≥
≥
=

(s + 1)
· V1I (δin+1 ). So, 0.vin . . . vi1 = (s +
|vin+1 |
· V1I (δin+1 ) and, thus, V1I (δin+1 ) = (s +
1)
−|vin+1 |
1)
· 0.vin . . . vi1 . In the same way it can be
−|w
|
proved that W1I (δin+1 ) = 0.win . . . wi1 · (s + 1) in+1 .
Since I satisfies axiom �� � ∀Rin+1 .V2 , 0.vin+1 �, we get
0.vin+1 ≤ RiIn+1 (δin , δin+1 ) ⇒ V2I (δin+1 ) = 1 ⇒
V2I (δin+1 ) = V2I (δin+1 ). Similarly, since I satisfies axiom �� � ∀Rin+1 .¬V2 , 1 − 0.vin+1 �, we get 1 − 0.vin+1 ≤
RiIn+1 (δin , δin+1 ) ⇒ ¬V2I (δin+1 ) = 1 ⇒ ¬V2I (δin+1 ) =
¬V2I (δin+1 ) = 1 − V2I (δin+1 ) and therefore, V2I (δin+1 ) ≤
0.vin+1 . So, V2I (δin+1 ) = 0.vin+1 . In the same way it can
be proved that W2I (δin+1 ) = 0.win+1 .
Finally, since I satisfies axiom V ≡ V1 � V2 , then
−|v
|
V I (δin+1 ) = V1I (δin+1 ) ⊕ V2I (δin+1 ) = ((s + 1) in+1 ·
0.vin . . . vi1 )⊕0.vin+1 = 0.vin+1 . . . 0.vi1 . In the same way
it can be proved that W I (δin+1 ) = 0.win+1 . . . 0.wi1 .
Moreover, since, by inductive hypothesis, for every j ≤
n, V I (δij ) = 0.vij . . . vi1 �= 0.vin+1 . . . vij . . . vi1 =

• V I (δin ) = 0.vin . . . vi1 ,
• W I (δin ) = 0.win . . . wi1 ,

and |{δ, δi1 , . . . , δin }| = n + 1 (all elements are distinct). As
a consequence, ∆I cannot be finite, contrary to the assumption
that I is finite.

Case n = 1. Since I is a witnessed model, it satisfies axiom
a:max{C1 , . . . , Cp }. So, there is i, such that CiI (δ) = 1.
Let i1 = i. Since I satisfies axiom Ci1 ≡ ∃Ri1 .�, then
there is δ � ∈ ∆I such that RiI1 (δ, δ � ) = 1. Let δi1 = δ � .
Since I satisfies axiom (s + 1)|vi1 | · ∃Ri1 .V1 � (Ci1 → V ),
then 0 = (1 ⇒ 0) = (Ci1 (δ) ⇒ V )I (δ) ≥ (s + 1)|vi1 | ·

56

ECAI-2012 Workshop WL4AI

[4] Fernando Bobillo, F´elix Bou, and Umberto Straccia, ‘On the failure of
the finite model property in some fuzzy description logics’, Fuzzy Sets
and Systems, 172(1), 1–12, (2011).
[5] Fernando Bobillo, Miguel Delgado, and Juan G´omez-Romero, ‘Crisp
representations and reasoning for fuzzy ontologies’, International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 17(4),
501–530, (2009).
[6] Fernando Bobillo, Miguel Delgado, Juan G´omez-Romero, and Umberto Straccia, ‘Fuzzy description logics under G¨odel semantics’, International Journal of Approximate Reasoning, 50(3), 494–514, (2009).
[7] Fernando Bobillo and Umberto Straccia, ‘On qualified cardinality restrictions in fuzzy description logics under Łukasiewicz semantics’,
in Proceedings of the 12th International Conference of Information
Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU 2008), eds., Luis Magdalena, Manuel Ojeda-Aciego, and
Jos´e Luis Verdegay, pp. 1008–1015, (June 2008).
[8] Fernando Bobillo and Umberto Straccia, ‘Fuzzy description logics
with general t-norms and datatypes’, Fuzzy Sets and Systems, 160(23),
3382—3402, (2009).
[9] Fernando Bobillo and Umberto Straccia, ‘Reasoning with the finitely
many-valued Łukasiewicz fuzzy description logic SROIQ’, Information Sciences, 181, 758–778, (2011).
[10] Stefan Borgwardt and Rafael Pe˜naloza, ‘Fuzzy ontologies over lattices
with t-norms’, in Proceedings of the 24th International Workshop on
Description Logics (DL-11). CEUR Electronic Workshop Proceedings,
(2011).
[11] Marco Cerami, Francesc Esteva, and F`elix Bou, ‘Decidability of a description logic over infinite-valued product logic’, in Proceedings of
the Twelfth International Conference on Principles of Knowledge Representation and Reasoning (KR-10). AAAI Press, (2010).
`
[12] Angel
Garc´ıa-Cerda˜na, Eva Armengol, and Francesc Esteva, ‘Fuzzy description logics and t-norm based fuzzy logics’, International Journal
of Approximate Reasoning, 51, 632–655, (July 2010).
[13] Petr H´ajek, Metamathematics of Fuzzy Logic, Kluwer, 1998.
[14] Petr H´ajek, ‘Making fuzzy description logics more general’, Fuzzy Sets
and Systems, 154(1), 1–15, (2005).
[15] Petr H´ajek, ‘What does mathematical fuzzy logic offer to description
logic?’, in Fuzzy Logic and the Semantic Web, ed., Elie Sanchez, Capturing Intelligence, chapter 5, 91–100, Elsevier, (2006).
[16] Petr H´ajek, ‘On witnessed models in fuzzy logic’, Mathematical Logic
Quarterly, 53(1), 66–77, (2007).
[17] Erich Peter Klement, Radko Mesiar, and Endre Pap, Triangular Norms,
Trends in Logic - Studia Logica Library, Kluwer Academic Publishers,
2000.
[18] Thomas Lukasiewicz and Umberto Straccia, ‘Managing uncertainty
and vagueness in description logics for the semantic web’, Journal of
Web Semantics, 6, 291–308, (2008).
[19] OWL 2 Web Ontology Language Document Overview,
http://
www.w3.org/TR/2009/REC-owl2-overview-20091027/,
W3C, 2009.
[20] Emil L. Post, ‘A variant of a recursively unsolvable problem’, Bulletin
of The American Mathematical Society, 52, 264–269, (1946).
[21] Giorgos Stoilos, Giorgos B. Stamou, Jeff Z. Pan, Vassilis Tzouvaras,
and Ian Horrocks, ‘Reasoning with very expressive fuzzy description logics’, Journal of Artificial Intelligence Research, 30, 273–320,
(2007).
[22] Giorgos Stoilos, Umberto Straccia, Giorgos Stamou, and Jeff Z. Pan,
‘General concept inclusions in fuzzy description logics’, in Proceedings
of the 17th Eureopean Conference on Artificial Intelligence (ECAI-06),
pp. 457–461. IOS Press, (2006).
[23] Umberto Straccia, ‘Reasoning within fuzzy description logics’, Journal
of Artificial Intelligence Research, 14, 137–166, (2001).
[24] Umberto Straccia, ‘Transforming fuzzy description logics into classical description logics’, in Proceedings of the 9th European Conference
on Logics in Artificial Intelligence (JELIA-04), number 3229 in Lecture Notes in Computer Science, pp. 385–399, Lisbon, Portugal, (2004).
Springer Verlag.
[25] Umberto Straccia, ‘Description logics with fuzzy concrete domains’,
in 21st Conference on Uncertainty in Artificial Intelligence (UAI-05),
eds., Fahiem Bachus and Tommi Jaakkola, pp. 559–567, Edinburgh,
Scotland, (2005). AUAI Press.
[26] Umberto Straccia and Fernando Bobillo, ‘Mixed integer programming,
general concept inclusions and fuzzy description logics’, Mathware &
Soft Computing, 14(3), 247–259, (2007).

V I (δin+1 ), then δij �= δin+1 . Furthermore, as V I (δ) =
0
�=
V I (δin+1 ), then δ
�=
δin+1 and, thus,
|{δ, δi1 , . . . , δin+1 }| = n + 2, which completes the case.

˜ϕ has no finite model.
So, O

By Proposition 8, we have a reduction of a RPCP to a finite satisfiability problem. Again, note that all roles are crisp. Therefore,
Proposition 9. The knowledge base finite satisfiability problem is
undecidable for Ł-ALC with GCIs. The result holds also if crisp roles
are assumed.
We conclude by pointing out that, as K |= �a:⊥, 1� iff K is not
satisfiable iff K |= �� � ⊥, 1�, both the entailment problem of determining whether K |= �a:C, n� and the problem of determining
whether K |= �C � D, n� are undecidable, and, thus, as well are undecidable the problems of determining bed(K, a:C) and bsd(K, C)
(w.r.t. arbitrary witnessed or finite models).
Corollary 10. For Ł-ALC with GCIs, with respect to arbitrary witnessed or finite models, (i) the best entailment degree problem for
concept assertions and GCIs is undecidable; and (ii) the best satisfiability degree problem is undecidable. These results hold also if crisp
roles are assumed.

4

Conclusions

In this paper we have proved that KB satisfiability problem with
GCIs is undecidable under infinite-valued Łukasiewicz semantics.
Despite the fact that we have mainly considered the notion of satisfiability with respect to witnessed interpretations, the completeness
of first order Łukasiewicz logic with respect to witnessed models,
proved also for the case of standard semantics in [13] and [14] allows
to apply the present result to the case of unrestricted interpretations
as well. Under the logical point of view this is an important result,
because helps to trace the limits of decidability for the fragments of
Łukasiewicz first order logic. As a related topic, it is known (see [4])
that KB satisfiability become a decidable problem when the KB is
acyclic or the TBox is empty.

ACKNOWLEDGEMENTS
The authors acknowledge support of the Spanish MICINN project
ARINF TIN2009-14704-C03-03, the grants 2009-SGR-1433/1434
from the Generalitat de Catalunya, and the grant JAEPredoc, n.074
of CSIC. The authors also want to thank Rafael Pe˜naloza and F`elix
Bou for their helpful comments and suggestions.

REFERENCES
[1] The Description Logic Handbook: Theory, Implementation, and Applications, eds., Franz Baader, Diego Calvanese, Deborah McGuinness, Daniele Nardi, and Peter F. Patel-Schneider, Cambridge University Press, 2003.
[2] Franz Baader and Rafael Pe˜naloza, ‘Are fuzzy description logics with
general concept inclusion axioms decidable?’, in Proceedings of 2011
IEEE International Conference on Fuzzy Systems (Fuzz-IEEE 2011).
IEEE Press, (2011).
[3] Franz Baader and Rafael Pe˜naloza, ‘GCIs make reasoning in fuzzy DLs
with the product t-norm undecidable’, in Proceedings of the 24th International Workshop on Description Logics (DL-11). CEUR Electronic
Workshop Proceedings, (2011).

57

ECAI-2012 Workshop WL4AI

58

ECAI-2012 Workshop WL4AI

Postulates for logic-based argumentation systems
Leila Amgoud 1
Abstract. This paper studies abstract logic-based argumentation
systems. It proposes three key rationality postulates that such systems should satisfy: consistency, closure under sub-arguments and
closure under the consequence operator of the underlying logic. It
then investigates the links between these postulates, and explores the
conditions under which they are guaranteed or violated.

1

As in [3], in this paper we consider argumentation systems that are
grounded on Tarski’s logics. We generalize the postulates that are
proposed in [11] to these logics, and introduce a new postulate.
This postulate says that if an extension contains an argument, then
all its sub-arguments should belong to the extension as well. We
show that the strong version of direct consistency that is proposed in
[3] follows naturally from the new postulate on sub-arguments and
the extended version of the initial definition of direct consistency.
Thus, strong consistency does not deserve to be a separate postulate.
To sum up, there are three basic postulates: 1) Closure under the
consequence operator of the logic; 2) Closure under sub-arguments;
3) Direct consistency, i.e., the version defined in [11]. Indirect
consistency and strong consistency follow from these postulates.
We show that the three postulates are independent and compatible,
i.e., they can be satisfied all together by an argumentation system. A
second contribution of this paper consists of studying under which
conditions the postulates are satisfied or violated. The satisfaction/violation of a postulate depends mainly on the attack relation.
We characterize some attack relations that lead to the satisfaction
of the three postulates, and some other relations that lead to the
violation of consistency.

Introduction

An argumentation system for reasoning with inconsistent information consists of a set of arguments, attacks among them, and a semantics for evaluating the arguments and computing thus, acceptable sets
of arguments, called extensions. Arguments are built from a knowledge base using an underlying logic. A logic contains two parts: a
language in which the formulas of the knowledge base are encoded,
and a consequence operator which is used for defining arguments
and attacks. In the ASPIC argumentation system [4], for instance,
the language of its logic is made of two types of rules: strict rules
which encode certain knowledge and defeasible rules which encode
uncertain ones. The consequence operator shows how these rules can
be chained. We will refer to such a logic as rule-based logic and to
systems grounded on it as rule-based systems.
The first work on rationality postulates in argumentation was done
by Caminada and Amgoud [11]. The authors focused only on rulebased systems, and proposed the following postulates that such systems should satisfy:
Closure: The idea is that if a system concludes x and there is a strict
rule x → y, then the system should also conclude y.
Direct consistency: the set of conclusions of arguments of each extension should be consistent.
Indirect consistency: the closure of the set of conclusions of arguments of each extension should be consistent.
As obvious as they may appear, these postulates are violated by
most rule-based systems (like [19]). Besides, they are tailored for
rule-based logics. Their counterparts for any other logic do not
exist. Later, Amgoud and Besnard made in [3] a first attempt on
generalizing the two postulates on consistency to a wider class of
logics. They considered the abstract monotonic logics of Tarski
[21]. They defined a new postulate for direct consistency which is
stronger than the original one. It imposes that the set of formulas
that are used in the supports of arguments of each extension should
be consistent. The authors justified this choice by the fact that an
extension represents a coherent position/point of view, thus it should
only involve a consistent set of formulas. They have then shown that
indirect consistency follows naturally from the new postulate, thus
indirect consistency does not deserve to be a postulate per se.
1

The paper is organized as follows: Section 2 defines the logic-based
argumentation systems we are interested in. Section 3 introduces the
three basic postulates, and studies the links between them. Section 4
investigates the conditions under which the postulate on consistency
is violated. The conditions under which the three postulates are satisfied are studied in Section 5. Section 6 discusses the importance of
our postulates in case of weighted argumentation systems.

2

Logic-based Argumentation Systems

It is well known that a structured argumentation system is built on
an underlying monotonic logic. In this paper, we do not focus on a
particular logic (like rule-based logic, propositional logic, . . .), but
we consider an abstract monotonic logic. Such abstraction makes
our study general and our results hold under any instantiation of the
abstract logic. We consider Tarski’s logics (L, CN) where L is a set
of well-formed formulas. Note that there is no particular requirement
on the kind of connectors that may be used. CN is a consequence
operator. It is a function from 2L to 2L which returns the set of
formulas that are logical consequences of another set of formulas
according to the logic in question. It should satisfy the following
basic properties:
1. X ⊆ CN(X)
2. CN(CN(X))
� = CN(X)
3. CN(X) = Y ⊆f X CN(Y )2

IRIT – CNRS, amgoud@irit.fr

2

59

Y ⊆f X means that Y is a finite subset of X.

(Expansion)
(Idempotence)
(Finiteness)

ECAI-2012 Workshop WL4AI

4. CN({x}) = L for some x ∈ L
5. CN(∅) �= L

Definition 5 (Output) Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. For x ∈ L, Σ |∼ x iff ∀E ∈ Ext(T ), ∃a ∈ E
s.t. Conc(a) = x. Output(T ) = {x ∈ L | Σ |∼ x}.

(Absurdity)
(Coherence)

Any logic whose CN satisfies the above properties is monotonic. The
associated notion of consistency is defined as follows:

It is easy to check that the set of outputs coincides with the set of
common conclusions of the extensions.

Definition 1 (Consistency) A set X ⊆ L is consistent wrt a logic
(L, CN) iff CN(X) �= L. It is inconsistent otherwise.

Property 1 Let T = (Arg(Σ),�R) be an AS over a knowledge base
Σ. It holds that Output(T ) = Concs(Ei ) with Ei ∈ Ext(T ).

Arguments are built from a finite knowledge base Σ ⊆ L as follows:

It is also obvious that the outputs of an AS are consequences of Σ
under CN.

Definition 2 (Argument) Let Σ be a knowledge base. An argument
is a pair (X, x) s.t. X ⊆ Σ, X is consistent, and x ∈ CN(X)3 . An
argument (X, x) is a sub-argument of another argument (X � , x� ) iff
X ⊆ X �.

Property 2 Let T = (Arg(Σ), R) be an AS over a knowledge base
Σ. It holds that Output(T ) ⊆ CN(Σ).

Notations: Supp and Conc denote respectively the support X
and the conclusion x of an argument (X, x). For all S ⊆ Σ,
Arg(S) denotes the set of all arguments that can be built from S
by means of Definition 2. Sub is a function that returns all the
sub-arguments of a given argument. For
� all E ⊆ Arg(Σ), Concs(E)
= {Conc(a) | a ∈ E} and Base(E) = a∈E Supp(a). Let CΣ denote
the set of all minimal conflicts4 of Σ.

It is worth mentioning that an argumentation system starts with a
monotonic logic (L, CN) and defines a non monotonic logic (L, |∼ ).
The non monotonicity of |∼ is obviously due to the status of arguments. An argument may be accepted under a given semantics and
becomes rejected when new arguments are received.

3

An argumentation system is defined as follows.

The first rationality postulate that an argumentation system should
satisfy concerns the closure of its output. The basic idea is that the
conclusions of a formalism should be “complete”. A user should not
perform on her own some extra reasoning to derive statements that
the formalism apparently “forgot” to entail. In [11], closure is defined
for rule-based argumentation systems. In what follows, we extend
this postulate to systems that are grounded on any Tarskian logic.
The idea is to define closure using the consequence operator CN.

Definition 3 (Argumentation system) An argumentation system
(AS) over a knowledge base Σ is a pair (Arg(Σ), R) where R ⊆
Arg(Σ) × Arg(Σ) is an attack relation. For a, b ∈ Arg(Σ), (a, b) ∈
R (or aRb) means that a attacks b.
The attack relation is left unspecified in order to keep the system
very general. It is also worth mentioning that the set Arg(Σ) may
be infinite even when the base Σ is finite. This would mean that the
argumentation system may be infinite5 .

Postulate 1 (Closure under CN) Let T = (Arg(Σ), R) be an AS
over a knowledge base Σ. T satisfies closure iff for all E ∈ Ext(T ),
Concs(E) = CN(Concs(E)).

Arguments are evaluated using any semantics which is based on
the notion of admissibility [13]. Note that any result that holds under
admissible semantics holds also under any semantics based on it. We
thus need to recall admissible semantics but also stable one since
some results are shown only under this particular semantics.

In [11], closure is imposed both on the extensions of an AS and on
its output set. The next result shows that the closure of the output set
does not deserve to be a separate postulate since it follows immediately from the closure of extensions.

Definition 4 (Semantics) Let (Arg(Σ), R) be an AS and E ⊆
Arg(Σ) and a ∈ Arg(Σ).

Proposition 1 Let T = (Arg(Σ), R) be an argumentation system
over a knowledge base Σ. If T satisfies closure, then Output(T ) =
CN(Output(T )).

• E is conflict-free iff � a, b ∈ E s.t. aRb.
• E defends a iff ∀b ∈ Arg(Σ) s.t. bRa, ∃c ∈ E s.t. cRb.
• E is an admissible extension iff E is conflict-free and E defends
any b s.t. b ∈ E.
• E is a stable extension iff E is conflict-free and for all b ∈ Arg(Σ)\
E, ∃c ∈ E s.t. cRb.

The second rationality postulate concerns sub-arguments. An argument may have one or several sub-arguments, reflecting the different
premises on which it is based. Thus, the acceptance of an argument
should imply also the acceptance of all its sub-parts. Let us illustrate
the importance of this postulate on the following example.

Let Ext(T ) denote the set of all extensions of T under a given
semantics that is based on admissibility, for instance grounded,
stable, preferred, etc (see [13] for definitions).

Example 1 Assume an AS T built on a propositional knowledge
base. Assume also that Ext(T ) = {E} such that E = {({p, p →
¬f }, ¬f )}, where p stands for penguin and f for fly. This means
that the two arguments ({p}, p) and ({p → ¬f }, p → ¬f ) are
rejected (since they do not belong to E). Thus, the unique accepted
argument is grounded on two formulas which are both rejected. It
seems counter-intuitive to accept such argument.

Let us now characterize the conclusions that may be drawn from
Σ by an argumentation system. The idea is to infer x from Σ iff it is
the conclusion of an argument in each extension.
3
4
5

Postulates for Argumentation Systems

Generally, the support X is minimal (for set ⊆). In this paper, we do not
need to make this assumption.
A set C ⊆ Σ is a minimal conflict of Σ iff i) C is inconsistent, and ii)
∀x ∈ C, C \ {x} is consistent.
An AS is finite iff each argument is attacked by a finite number of arguments. It is infinite otherwise.

Postulate 2 (Closure under sub-arguments) Let T = (Args(Σ),
R) be an AS over a knowledge base Σ. T is closed under subarguments iff for all E ∈ Ext(T ), if a ∈ E, then Sub(a) ⊆ E.

60

ECAI-2012 Workshop WL4AI

Until now, we revisited and extended the postulates proposed by
Caminada and Amgoud [11]. We showed that three of them (the closure of the output set, the consistency of the output set and indirect
consistency) might not be considered as postulates since they follow
naturally from more fundamental ones. The question now is: what
about the strong version of consistency that is proposed by Amgoud
and Besnard [3]? Should it be considered as a postulate or not? Recall that this postulate ensures that for each extension E of an AS,
Base(E) should be consistent.

It is easy to check that closure under sub-arguments is equivalent
to closure under super-arguments. The latter means that if an argument is excluded from an extension, then all arguments built on it (its
super-arguments) should also be excluded from that extension.
Property 3 Let T = (Args(Σ), R) be an AS over a knowledge base
Σ. T is closed under sub-arguments iff ∀E ∈ Ext(T ) if a ∈
/ E, then
∀b ∈ Args(Σ) s.t. a ∈ Sub(b), b �∈ E.
Another interesting property of this postulate is the following.

Strong Consistency: Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. T satisfies strong consistency iff for all E ∈
Ext(T ), Base(E) is consistent.

Property 4 Let T = (Args(Σ), R) be an AS over a knowledge base
Σ s.t. T is closed under sub-arguments. ∀E ∈ Ext(T ), it holds that:
• For all x ∈ Base(E), ({x}, x) ∈ E
• Base(E) ⊆ Concs(E)

This postulate is certainly stronger than Postulate 3.

The next result characterizes the extensions of argumentation systems that are closed under both CN and sub-arguments.

Proposition 4 If an AS satisfies strong consistency, then it also satisfies consistency.

Property 5 Let T = (Args(Σ), R) be an AS over a knowledge base
Σ. If T is closed under sub-arguments and under CN, then for all
E ∈ Ext(T ), Concs(E) = CN(Base(E)).

We show next that strong consistency does not deserve to be a postulate per se as it follows from the basic ones, namely consistency and
closure under sub-arguments. It is worth mentioning that this result
is very general as it holds under any semantics, any attack relation
and any Tarskian logic.

The third rationality postulate concerns the consistency of the results.
This is the minimum that can be required from a reasoning system.
The following postulate generalizes the ‘direct consistency postulate’
which was proposed for rule-based argumentation systems in [11].
Indeed, we define its counterpart under Tarskian logics.

Proposition 5 If an AS satisfies consistency and closure under subarguments, then it also satisfies strong consistency.

Postulate 3 (Consistency) Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. T satisfies consistency iff for all E ∈ Ext(T ),
Concs(E) is consistent.

An axiomatic approach should obey two important features: i) the
postulates should be independent, ii) the postulates should be compatible, i.e., they may be satisfied together. Hopefully, our three postulates are independent. Indeed, the consistency postulate is clearly
independent from the two others. The following example shows that
the two postulates on closure are independent as well.

As obvious as it may appear, this postulate is violated by some existing argumentation systems like the ASPIC+ system [18]. Let us
consider the following example:

Example 3 Assume that (L, CN) is propositional logic, T is an
AS with a unique extension E = {a, b}, Sub(a) = {a}, and
Sub(b) = {a, b}. Thus, T is closed under sub-arguments. Assume
that Concs(E) = {x, y}, then T violates closure under CN. Assume
another AS T � with a unique extension E = {a, a1 , a2 , ...} where
Conc(a) = x and ∀ai , Conc(ai ) = xi with xi ∈ CN({x}). Thus,
T � satisfies closure under CN. Assume that Sub(a) = {a, b}, then
T � violates closure under sub-arguments.

Example 2 Assume that R = {⇒ x, ⇒ ¬x ∨ y, ⇒ ¬y}, and that
all the other bases defined in [18] are empty. Only three arguments
can be built: A1 : ({⇒ x}, x), A2 : ({⇒ ¬x ∨ y}, ¬x ∨ y), A3 :
({⇒ ¬y}, ¬y). It can be checked that the three arguments are not
attacking each other using the attack relation defined in [18]. Thus,
the set {A1 , A2 , A3 } is an admissible extension. Consequently, the
inconsistent set {x, ¬x ∨ y, ¬y} is the output of the system!
As for closure, in [11] a postulate imposing the consistency of the
output is defined. We show next that such postulate is not necessary
since an AS that satisfies Postulate 3, has a consistent output.

The three postulates are also compatible as witnessed by the argumentation system studied in [12]. This system is grounded on propositional logic (an instance of Tarski’s logics) and uses the assumption
attack relation defined in [14]. It was shown that the system satisfies strong consistency under stable semantics. Thus, consistency is
also ensured. Besides, each stable extension is closed in terms of
arguments (E = Arg(Base(E))), so the system is closed under subarguments. Finally, it is easy to check that in this particular system,
closure under the consequence operator follows from consistency
and closure under sub-arguments.

Proposition 2 If T = (Arg(Σ), R) satisfies consistency, then the
set Output(T ) is consistent.
In [11], it was shown that some rule-based argumentation systems,
like [19], violate the postulate of indirect consistency. Recall that indirect consistency means that the closure (under strict rules) of the
conclusions of each extension is consistent. When this postulate is
violated, undesirable conclusions may be inferred. We show next that
in the case of Tarski’s logics, (direct) consistency coincides with indirect consistency. Thus, this latter does not deserve to be a postulate
per se.

4

On the Violation of Consistency Postulate

This section studies three properties of attack relations that may lead
to the violation of the consistency postulate. The first one concerns
the origin of the relation. We show that an attack relation should be
grounded on inconsistency.

Proposition 3 Let T = (Arg(Σ), R) be an AS over a knowledge base Σ. T satisfies consistency iff for all E ∈ Ext(T ),
CN(Concs(E)) is consistent.

61

ECAI-2012 Workshop WL4AI

Definition 6 (Conflict-dependent) An attack relation R is conflictdependent iff ∀a, b ∈ Arg(Σ), if aRb then Supp(a) ∪ Supp(b) is
inconsistent.

This result shows a broad class of attack relations that cannot be
used in argumentation: the symmetric ones. Thus, relations like
rebut or a combination of rebut and any other attack relation would
lead to the violation of consistency. Note that this result is conditioned by the existence of n-ary (n > 2) minimal conflicts in the
knowledge base. The idea is that, due to the binary character of the
attack relation, this latter is unable to capture n-ary minimal conflicts.

Note that all the attack relations that are used in existing structured
argumentation systems are conflict-dependent (see [16] for a summary of those relations). It is very natural that inconsistency would
be the origin of the attack relation.

Another mandatory property that an attack relation should fulfill is
that it captures all the minimal conflicts of the knowledge base, i.e.,
each minimal conflict should be captured by at least one attack in R.

Example 4 Let T = (Arg(Σ), R) be an AS built over the propositional knowledge base Σ = {b, p} where b stands for “Tweety
is a bird” and p for “Tweety is a penguin”. Assume that R =
{(x, y) | Supp(x) �= Supp(y)}. Note that R is not conflictdependent. It is easy to check that b, p ∈
/ Output(T ). This outcome
is certainly not intuitive.

Definition 7 (Conflict-exhaustive) An attack relation R is conflictexhaustive iff ∀C ∈ CΣ s.t. |C| > 1, ∃X ⊂ C s.t. ∃a, b ∈ Arg(Σ)
and Supp(a) = X, Supp(b) = C \ X and either aRb or bRa.
Note that an attack relation that is conflict-dependent is not necessarily conflict-exhaustive and vise versa. We show that argumentation systems whose attack relations are not conflict-exhaustive violate consistency. We show progressively this result.

In [3], it was shown that strong consistency is violated by argumentation systems that use a symmetric attack relation. One may think that
this result is true only when considering the strong version of consistency. Unfortunately, it is even true for the weaker version. Indeed,
we show that when the attack relation is symmetric, Postulate 3 is
violated. Before presenting the result, let us first show some intermediary results. The first one shows that when the knowledge base is a
minimal conflict with more than two formulas, then it is possible to
build a conflict-free set of arguments.

Lemma 3 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}. Let a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }. If R is
conflict-dependent and not conflict-exhaustive, then the set E =
{a1 , . . . , an } is conflict-free.
Note that symmetric relations are problematic only in presence of
ternary or more minimal conflicts, that is a conflict C s.t. |C| > 2.
However, non conflict-exhaustiveness is fatal even with only binary
conflicts. The previous conflict-free set of arguments defends its elements when the attack relation is not conflict-exhaustive.

Lemma 1 Let Σ = {x1 , . . . , xn } where n > 2 and CΣ = {Σ}.
Let a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }. If R is conflictdependent, then the set E = {a1 , . . . , an } is conflict-free.

Lemma 4 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}. Let a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }. If R is
conflict-dependent and not conflict-exhaustive, then the set E =
{a1 , . . . , an } defends its elements.

The previous conflict-free set of arguments defends even its elements
when the attack relation is symmetric.
Lemma 2 Let Σ = {x1 , . . . , xn } where n > 2 and CΣ = {Σ}. Let
a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }.
If R is conflict-dependent and symmetric, then the set E =
{a1 , . . . , an } defends its elements.

From the two lemmas, it follows that the set {a1 , . . . , an } is an admissible extension.
Proposition 9 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}. Let a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }. If R is
conflict-dependent and not conflict-exhaustive, then the set E =
{a1 , . . . , an } is an admissible extension.

From the two lemmas, it follows that the set {a1 , . . . , an } is an admissible extension.
Proposition 6 Let Σ = {x1 , . . . , xn } where n > 2 and CΣ = {Σ}.
Let a1 , . . . , an ∈ Arg(Σ) s.t. Supp(ai ) = {xi }. If R is conflictdependent and symmetric, then the set E = {a1 , . . . , an } is an admissible extension.

The next result shows that the argumentation framework built from
the knowledge base Σ = {x1 , . . . , xn } where n > 1 and CΣ = {Σ}
violates consistency.
Proposition 10 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}. Let T = (Arg(Σ), R) be an argumentation system over Σ
s.t. R is conflict-dependent and not conflict-exhaustive. T violates
consistency.

The next result shows that the argumentation framework built from
the knowledge base Σ = {x1 , . . . , xn } where n > 2 and CΣ = {Σ}
violates consistency.

Finally, this result is generalized to any knowledge base containing a
binary or more minimal conflict.

Proposition 7 Let Σ = {x1 , . . . , xn } where n > 2 and CΣ = {Σ}.
Let T = (Arg(Σ), R) be an argumentation system over Σ s.t. R is
conflict-dependent and symmetric. T violates consistency.

Proposition 11 Let CΣ s.t. ∃C ∈ CΣ and |C| > 1. If R is conflictdependent and not conflict-exhaustive, then the system (Arg(Σ), R)
violates consistency.

Finally, this result is generalized to any knowledge base containing a
ternary or n-ary (with n > 2) minimal conflict.

Let us summarize: in order to satisfy consistency, an argumentation
system built over a knowledge base under a Tarskian logic should use
an attack relation that is conflict-dependent, conflict-exhaustive but
not symmetric in case the base contains n-ary (with n > 2) minimal
conflicts.

Proposition 8 Let CΣ s.t. ∃C ∈ CΣ and |C| > 2. If R is conflictdependent and symmetric, then the system (Arg(Σ), R) violates consistency.

62

ECAI-2012 Workshop WL4AI

5

When are the Postulates Satisfied?

Proposition 14 Let T = (Args(Σ), R) be an AS. If R satisfies R2 ,
then T satisfies closure under sub-arguments under stable semantics.

In a previous section, we defined three rationality postulates that any
argumentation system should satisfy. An important question now is:
are there argumentation systems that may satisfy those postulates? If
yes, what are the characteristics of those systems? These questions
are very ambitious since an argumentation system has three main
parameters: the underlying monotonic logic (L, CN), the attack relation R and the semantics. In this paper, the three parameters are
left unspecified. Thus, getting a complete answer is a real challenge.
In this section, we identify one family of argumentation systems that
satisfy closure under the consequence operator, three broad families
of ASs that satisfy closure under sub-arguments, a broad family of
systems that satisfy consistency. The results are general in the sense
that they hold under any Tarskian logic, any acceptability semantics, and any attack relation that fulfills the mandatory properties discussed in the previous section.

5.1

The reverse is not necessarily true as shown next.

Example 5 Let Arg(Σ) = {a, b, c, d} be an argumentation system
such that Sub(b) = {a, b}, Sub(a) = {a}, Sub(c) = {c}, Sub(d) =
{d}. Assume also that cRa and dRb. It is clear that R2 is violated
since c does not attack b. However, the stable extension {c, d} is
closed wrt sub-arguments.
The second family of AS that satisfy closure under sub-arguments
uses attack relations that are based on and sensible for inconsistency.
Definition 9 (Conflict-sensitive) An attack relation R is conflictsensitive iff ∀a, b ∈ Arg(Σ), if Supp(a) ∪ Supp(b) is inconsistent,
then either aRb or bRa.
When the attack relation is conflict-dependent and sensitive, closure
under sub-arguments is satisfied.
Proposition 15 Let T = (Args(Σ), R) be an AS. If R is conflictdependent and conflict-sensitive, then T satisfies closure under subarguments under admissible semantics.

Satisfaction of the Closure Postulate

In this section, we identify a class of argumentation systems that satisfy closure under the consequence operator of the underlying logic
(L, CN). We show that an argumentation system that uses an attack
relation which captures all the minimal conflicts of the knowledge
base, and whose extensions contain all the arguments that may be
built from the set of formulas appearing in their arguments satisfies
closure under CN.

Notice that the attack relations in the first family of AS are not necessarily based on inconsistency. Finally, we show that argumentation
systems whose extensions are closed in terms of arguments enjoy
closure under sub-arguments.
Proposition 16 Let T = (Arg(Σ), R) be an AS over a knowledge
base Σ. If ∀E ∈ Ext(T ), E = Arg(Base(E)), then T is closed
under sub-arguments.

Proposition 12 Let T = (Arg(Σ), R) be an AS over a knowledge
base Σ such that R is conflict-exhaustive. If ∀E ∈ Ext(T ), E =
Arg(Base(E)), then T is closed under CN.

This result is true under any acceptability semantics. Indeed, no requirement is needed on the semantics.

It is worth mentioning that the above result holds under any acceptability semantics that is based on the notion of conflict-freeness.
Thus, it is true for semantics that are not based on admissibility like
the ones proposed in [7].

5.2

5.3

Satisfaction of the Consistency Postulate

In this section, we identify a class of argumentation systems that satisfy consistency. As for closure under sub-arguments, the result depends of the properties of the attack relations. Before that, we start
by a result showing a case where consistency coincides with strong
consistency.

Satisfaction of the Sub-Arguments Postulate

The satisfaction of Postulate 2 by an argumentation system depends
broadly on the properties of its attack relation. We show that when
this relation satisfies both rules R1 and R2 (see Definition 8), then
the system is closed under sub-arguments using admissible semantics
(and consequently, under any semantics based on admissibility).

Proposition 17 Let T = (Arg(Σ), R) be an argumentation system.
If ∀E ∈ Ext(T ), E = Arg(Base(E)), then T satisfies consistency
implies T satisfies strong consistency.
We now show that a system that uses an attack relation which captures all the minimal conflicts of the knowledge base and whose extensions contain all the arguments that may be built from the set of
formulas appearing in their arguments, satisfies consistency.

Definition 8 An attack relation R satisfies R1 (resp. R2 ) iff ∀a, b ∈
Arg(Σ) s.t. Supp(a) ⊆ Supp(b) and ∀c ∈ Arg(Σ), it holds aRc ⇒
bRc (resp. cRa ⇒ cRb).

Proposition 18 Let T = (Arg(Σ), R) be an AS over a knowledge base Σ s.t. R is conflict-exhaustive. If ∀E ∈ Ext(T ), E =
Arg(Base(E)), then T satisfies consistency.

The rule R1 says that if an argument a attacks another argument c,
then all the super-arguments of a should also attack c. The second
rule says that if an argument a is attacked by an argument c, then all
the super-arguments of a should also be attacked by c.

This result is true under any acceptability semantics provided that it
is based on the notion of conflict-freeness. Due to Proposition 17,
this class of argumentation systems satisfies also strong consistency.

Proposition 13 Let T = (Args(Σ), R) be an AS. If R satisfies R1
and R2 , then T satisfies closure under sub-arguments under admissible semantics.

Property 6 Let T = (Arg(Σ), R) be an AS over a knowledge base
Σ s.t. R is conflict-exhaustive. If ∀E ∈ Ext(T ), E = Arg(Base(E)),
then T satisfies strong consistency.
This result is very general since, as we already said, the requirement
on the attack relation is very natural and even satisfied by all the
existing attack relations (see [16] for a review of those relations).

The next result shows that closure under sub-arguments is less demanding under stable semantics. Indeed, in this case only property
R2 is required for the attack relation.

63

ECAI-2012 Workshop WL4AI

6

Postulates for Weighted Argumentation Systems

2) We defined three independent and compatible postulates under any
Tarskian logic: closure under consequence operator, closure under
sub-arguments, and consistency. Recall that two of these postulates
were only defined under rule-based logics.
3) We provided two families of AS that satisfy closure under subarguments, one family of AS that satisfy consistency, and finally two
broad families of AS that violate consistency. The results are very
general since they hold under any Tarskian logic, any semantics and
any attack relation which satisfies some mandatory properties.
4) We discussed the importance of the proposed postulates in
preference-based argumentation frameworks.
This work provides guidelines for instantiating Dung’s framework
as well as its extensions with preferences. It defines the properties
that should be ensured. It can also be used for evaluating existing
systems. For instance, instantiating Dung’s system with canonical
undercut [10] as attack relation is certainly a bad choice since the
resulting system will violate consistency. Similarly, the ASPIC+
system proposed in [18] violate both consistency and closure
under CN (see [2]). In [16] some examples of systems that satisfy
consistency are provided. Those systems are built on propositional
logic and use specified attack relations.

Since early nineties, before even the acceptability semantics of
Dung [13], arguments were assumed to have different strengths.
To the best of my knowledge, the first work on preference-based
argumentation systems is the one by Simari and Loui [20]. In that
paper, arguments are built from a propositional knowledge base, and
the ones that are based on specific information are assumed stronger
than those built from general rules. In [9], arguments are built from
a possibilistic knowledge base, and are compared following the
weakest link principle. The idea is that an argument is better than
another one if the weakest formula used in the former is more certain
than the weakest formula in the latter. Besides, there is a consensus
in the literature on the fact that the strengths of arguments should be
taken into account in the evaluation of arguments (e.g. [5, 8, 20]).
The first abstract preference-based argumentation framework was
proposed in [5]. It takes as input a set of arguments, an attack
relation, and a preference relation between arguments which is
abstract and can be instantiated in different ways. This proposal
was refined in [8] and generalized in [17] in order to reason even
about preferences. Thus, arguments may support preferences about
arguments. The basic idea behind these frameworks is to ignore
an attack if the attacked argument is stronger than its attacker.
Dung’s semantics are applied on the remaining attacks. In [6], it
was shown that these frameworks do not guarantee conflict-free
extensions. As a consequence, their instantiations may violate the
rationality postulate on consistency. Assume an argumentation
system with E = {a, b} as its admissible extension and such that
aRb. Since the attack relation should be conflict-dependent, thus
Supp(a) ∪ Supp(b) is certainly inconsistent. From Property 4,
if the argumentation system is closed under sub-arguments, then
Supp(a) ∪ Supp(b) ⊆ Concs(E) meaning that the set of conclusions
of E is inconsistent.

A lot of work still needs to be done. Our aim is to have a representation theorem that characterizes all the systems that satisfy the three
postulates. However, since a system has too many parameters (underlying logic, attack relation, semantics), this objective seems not
reachable. Consequently, we will investigate more classes of systems
that satisfy the postulates. Another future work consists of investigating more rationality postulates.

REFERENCES
[1] T. Alsinet, C. Ches˜nevar, and L. Godo, ‘A level-based approach to computing warranted arguments in possibilistic defeasible logic programming’, in International Conference on Computational Models of Argument (COMMA’08), pp. 1–12, (2008).
[2] L. Amgoud, ‘Five weaknesses of ASPIC+’, in IPMU’12, pp. 122–131,
(2012).
[3] L. Amgoud and Ph. Besnard, ‘Bridging the gap between abstract argumentation systems and logic’, in SUM’09, pp. 12–27, (2009).
[4] L. Amgoud, M. Caminada, C. Cayrol, , MC. Lagasquie, and
H. Prakken, ‘Towards a consensual formal model: inference part’, Deliverable D2.2 of ASPIC project, (2004).
[5] L. Amgoud and C. Cayrol, ‘A reasoning model based on the production
of acceptable arguments’, Annals of Mathematics and Artificial Intelligence, 34, 197–216, (2002).
[6] L. Amgoud and S. Vesic, ‘A new approach for preference-based argumentation frameworks’, Annals of Mathematics and Artificial Intelligence, 63(2), 149–183, (2011).
[7] P. Baroni, M. Giacomin, and G. Guida, ‘Scc-recursiveness: a general
schema for argumentation semantics’, Artificial Intelligence Journal,
168(1-2), 162–210, (2005).
[8] T. J. M. Bench-Capon, ‘Persuasion in practical argument using valuebased argumentation frameworks’, Journal of Logic and Computation,
13(3), 429–448, (2003).
[9] S. Benferhat, D. Dubois, and H. Prade, ‘Argumentative inference in
uncertain and inconsistent knowledge bases’, in UAI’93, pp. 411–419,
(1993).
[10] Ph. Besnard and A. Hunter, Elements of Argumentation, MIT Press,
2008.
[11] M. Caminada and L. Amgoud, ‘An axiomatic account of formal argumentation’, in AAAI’06, pp. 608–613, (2005).
[12] C. Cayrol, ‘On the relation between argumentation and non-monotonic
coherence-based entailment’, in IJCAI’95, pp. 1443–1448, (1995).
[13] P. M. Dung, ‘On the acceptability of arguments and its fundamental role
in nonmonotonic reasoning, logic programming and n-person games’,
Artificial Intelligence Journal, 77, 321–357, (1995).

A new approach for preference-based argumentation was proposed
in [6]. It takes into account preferences at the semantics level rather
than the attack level. The idea is to extend existing acceptability
semantics with preferences. In case preferences are not available or
do not conflict with the attacks, the extensions of the new semantics
coincide with those of the basic ones. This approach computes
extensions which are conflict-free. Instantiations of the abstract
framework proposed in [6] should satisfy the rationality postulates
discussed in the present paper.
In [1], a rule-based argumentation system that satisfies the postulate on consistency was proposed. It extends and repairs the Delp
system proposed in [15] and which violates the same postulate.

7

Conclusion

In this paper we tackled the important problem of defining rational
logic-based argumentation systems. We focused on defining postulates that such systems should verify. For that purpose, we revisited
and extended the two existing works on the topic [3, 11]. Our contributions are the following:
1) We discussed the existing postulates in the literature, and showed
that some of them do not deserve to be postulates per se since they
follow from more fundamental ones. This is particularly the case for:
strong consistency postulate proposed in [3], output consistency, output closure and indirect consistency that are proposed in [11].

64

ECAI-2012 Workshop WL4AI

[14] M. Elvang-Gøransson, J. Fox, and P. Krause, ‘Acceptability of arguments as ‘logical uncertainty’, in ECSQARU’93, pp. 85–90, (1993).
[15] A. Garc´ıa and G. Simari, ‘Defeasible logic programming: An argumentative approach’, Theory and Practice of Logic Programming, 4(1-2),
95–138, (2004).
[16] N. Gorogiannis and A. Hunter, ‘Instantiating abstract argumentation
with classical logic arguments: Postulates and properties’, Artificial Intelligence Journal, 175(9-10), 1479–1497, (2011).
[17] S. Modgil, ‘Reasoning about preferences in argumentation frameworks’, Artificial Intelligence Journal, 173:9–10, 901–934, (2009).
[18] H. Prakken, ‘An abstract framework for argumentation with structured
arguments’, Journal of Argument and Computation, 1, 93–124, (2010).
[19] H. Prakken and G. Sartor, ‘Argument-based extended logic programming with defeasible priorities’, Journal of Applied Non-Classical Logics, 7, 25–75, (1997).
[20] G.R. Simari and R.P. Loui, ‘A mathematical treatment of defeasible
reasoning and its implementation’, Artificial Intelligence Journal, 53,
125–157, (1992).
[21] A. Tarski, Logic, Semantics, Metamathematics (E. H. Woodger, editor)),
chapter On Some Fundamental Concepts of Metamathematics, Oxford
Uni. Press, 1956.

Conc(a) = x. It follows that x ∈ Concs(Ei ), ∀Ei ∈ Ext(T ) and
hence x ∈ ∩Concs(Ei ).
2) Assume that x ∈ ∩Concs(Ei ) with Ei ∈ Ext(T ). Thus, ∀Ei ,
∃ai ∈ Ei s.t. Conc(ai ) = x. Consequently, x ∈ Output(T ).
Proof of Property 2. Let T = (Arg(Σ), R) be an argumentation
system over a knowledge base Σ. Assume that x ∈ Output(T ).
Thus, from Definition 5, ∃a ∈ Arg(Σ) such that Conc(a) =
x. Since a ∈ Arg(Σ), then from Definition 2, Supp(a) ⊆ Σ
and x ∈ CN(Supp(a)). By monotonicity of CN, it follows that
CN(Supp(a)) ⊆ CN(Σ). Consequently, x ∈ CN(Σ).
Proof of Property 3. Let T = (Args(Σ), R) be an argumentation
system. Let E be one of its extensions under a given semantics. Assume that T is closed under sub-arguments and that b ∈ Args(Σ)
but b ∈
/ E. Assume c ∈ Args(Σ) s.t. b ∈ Sub(c) and c ∈ E. Since T
is closed under sub-arguments, then b would be in E. Contradiction.
Assume now that if a ∈
/ E, then ∀b ∈ Args(Σ) s.t. a ∈ Sub(b),
b �∈ E. Let a ∈ E and assume that b ∈ Sub(a) and b ∈
/ E. From the
previous property, a should not be in E.

Appendix
Lemma 5 Let C ∈ CΣ . For all X ⊂ C, if X �= ∅, then ∃x1 ∈
CN(X) and ∃x2 ∈ CN(C \ X) such that the set {x1 , x2 } is inconsistent.

Proof of Property 4. Let T = (Args(Σ), R) be an argumentation
system that is closed under sub-arguments. Let E be one of its extensions under a given semantics and x ∈ Base(E). Thus, ∃a ∈ E such
that x ∈ Supp(a). Since Supp(a) is consistent (by definition of an argument), then the set {x} is consistent (from Property 2 in [3]). Thus,
the pair ({x}, x) is an argument. Moreover, ({x}, x) ∈ Sub(a).
Since T is closed under sub-arguments, then ({x}, x) ∈ E.

Proof Let C be a minimal conflict. Consider X ⊂ C such that
X �= ∅. We prove the property by induction, after we first take care to
show that X is finite. By Tarski’s requirements, there exists x0 ∈ L
s.t. CN({x0 }) = L. Since C is a conflict, CN(C) =�CN({x0 }). As a
consequence, x0 ∈ CN(C). However, CN(C) = C � ⊆f C CN(C � )
by Tarski’s requirements. Thus, x0 ∈ CN(C) means that there exists C � ⊆f C s.t. x0 ∈ CN(C � ). This says that C � is a conflict.
Since C is a minimal conflict, C = C � and it follows that C is
finite. Of course, so is X: Let us write X = {x1 , . . . , xn }. Base
step: n = 1. Taking x to be x1 is enough. Induction step: Assume
the lemma is true up to rank n − 1. As CN is a closure operator,
CN({x1 , . . . , xn }) = CN(CN({x1 , . . . , xn−1 }) ∪ {xn }). The induction hypothesis entails ∃x ∈ L s.t. CN(CN({x1 , . . . , xn−1 }) ∪
{xn }) = CN(CN({x}) ∪ {xn }). Then, CN({x1 , . . . , xn }) =
CN({x, xn }). As CN({x, xn }) �= CN({xn }) and CN({x, xn }) �=
CN({x}) (otherwise C cannot be minimal), there exists y ∈ L
s.t. CN({x, xn }) = CN({y}) because (L, CN) is adjunctive. Since
CN({x1 , . . . , xn }) = CN({x, xn }) was just proved, it follows that
CN({y}) = CN({x1 , . . . , xn }).
Take X1 = X and X2 = C \ X1 . Since X is a non-empty proper
subset of C, so are both X1 and X2 . Then, the first bullet of this
property can be applied to X1 and X2 . As a result, ∃x1 ∈ L s.t.
CN({x1 }) = CN(X1 ) and ∃x2 ∈ L s.t. CN({x2 }) = CN(X2 ). The
expansion axiom gives {x1 } ⊆ CN({x1 }) and {x2 } ⊆ CN({x2 }).
Thus, x1 ∈ CN(X1 ) and x2 ∈ CN(X2 ). Using the expansion
axiom again, X1 ⊆ CN(X1 ) and X2 ⊆ CN(X2 ). Thus, X1 ∪
X2 ⊆ CN(X1 ) ∪ CN(X2 ) = CN({x1 }) ∪ CN({x2 }). It follows that C ⊆ CN({x1 }) ∪ CN({x2 }). Using Property 1 in [3],
CN({x1 }) ∪ CN({x2 }) ⊆ CN({x1 , x2 }), thus C ⊆ CN({x1 , x2 }).
Since C is inconsistent, Property 2 in [3] gives that CN({x1 , x2 }) is
inconsistent as well. By the definition of inconsistency, it follows
that CN(CN({x1 , x2 })) = L. Applying the idempotence axiom,
CN({x1 , x2 }) = L, thus the set {x1 , x2 } is inconsistent.

Proof of Property 5. Assume that T = (Args(Σ), R) is closed under sub-arguments and under CN. From Property 4, since T is closed
under sub-arguments, then it follows that Base(E) ⊆ Concs(E). By
monotonicity of CN, we get CN(Base(E)) ⊆ CN(Concs(E)). Since
T is closed under CN, then CN(Base(E)) ⊆ Concs(E).
⊆
� Besides, by definition of Concs(E), Concs(E)
CN(Supp(ai )) �
with ai ∈ E. From Property 1 in [3], it follows that
Concs(E) ⊆ CN( Supp(ai )), thus Concs(E) ⊆ CN(Base(E)).

Proof of Proposition 1 Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. Assume that T satisfies closure. From Expansion axiom, it follows that Output(T ) ⊆ CN(Output(T )). Assume now that x ∈ CN(Output(T )). Since CN satisfies finiteness, then there exists a finite number of formulas x1 , . . . , xn ∈ L
such that x1 , . . . , xn ∈ Output(T ) and x ∈ CN({x1 , . . . , xn }).
From Property 1, x1 , . . . , xn ∈ ∩Concs(Ei ) where Ei ∈ Ext(T ).
From monotonicity of CN, it holds that CN({x1 , . . . , xn }) ⊆
CN(∩Concs(Ei )). It holds also that x ∈ CN(Concs(E1 )) ∩ . . . ∩
CN(Concs(En )). Since T satisfies closure, then for each Ei it holds
that CN(Concs(Ei )) = Concs(Ei ). Thus, x ∈ Concs(E1 ) ∩ . . . ∩
Concs(En ). From Property 1, it holds that x ∈ Output(T ).
Proof of Proposition 2. Let T = (Arg(Σ), R) be an AS based on a
knowledge base Σ. Assume that T satisfies consistency. Thus, ∀Ei ∈
Ext(T ), Concs(Ei ) is consistent. Let E be a given extension in
the set Ext(T ). Since ∩Concs(Ei ) ⊆ Concs(E), then ∩Concs(Ei )
is consistent as well. Besides, from Property 1, Output(T ) =
∩Concs(Ei ). It follows that Output(T ) is consistent.

Proof of Proposition 3 Let T = (Arg(Σ), R) be an AS based on a
knowledge base Σ. Assume that T satisfies consistency. Thus, for all
E ∈ Ext(T ), Concs(E) is consistent. Thus, from Property 2 in [3],
CN(Concs(E)) is consistent.

Proof of Property 1. Let T = (Arg(Σ), R) be an argumentation
system over a knowledge base Σ.
1) Let x ∈ Output(T ). Thus, for all E ∈ Ext(T ), ∃a ∈ E s.t.

65

ECAI-2012 Workshop WL4AI

conflict-free. Thus, ∃ai , aj ∈ E such that ai Raj . Since R is conflictdependent, then Supp(ai ) ∪ Supp(aj ) is inconsistent. If n = 2, then
this is impossible since R is not conflict-exhaustive. If n > 2 this is
again impossible since |Supp(ai ) ∪ Supp(aj )| < n and thus, from
the definition of a minimal conflict, Supp(ai ) ∪ Supp(aj ) should be
consistent.

Assume now that for all E ∈ Ext(T ), CN(Concs(E)) is consistent. Since by Expansion axiom Concs(E) ⊆ CN(Concs(E)) then
Concs(E) is consistent.
Proof of Proposition 4. Let T = (Args(Σ), R) be an AS
that satisfies strong consistency. Thus, �for all E ∈ Ext(T ),
Base(E) is consistent.
Consequently,
ai ∈E Supp(ai ) is con�
sistent and CN( ai ∈E Supp(ai )) is consistent as well (since
if X is consistent, then CN(X) is consistent as well). Besides, for each ai ∈ E, Conc(ai ) ∈ CN(Supp(ai )). Thus,
Concs(E)
⊆ ∪CN(Supp(ai )). �
It follows that Concs(E) ⊆
�
CN( ai ∈E Supp(ai )). Since CN( ai ∈E Supp(ai )) is consistent,
then its subset Concs(E) is consistent.

Proof of Lemma 4 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}, and let (Arg(Σ), R) be an AS such that R is conflict-dependent
and not conflict-exhaustive. Let a1 , . . . , an ∈ Arg(Σ) be such that
Supp(ai ) = {xi }. Assume that the set E = {a1 , . . . , an } does not
defend its elements. Thus, ∃ai ∈ E such that ∃b ∈ Arg(Σ) and
bRai and E does not defend ai . Since R is conflict-dependent, then
Supp(ai ) ∪ Supp(b) is inconsistent. Thus, Supp(ai ) ∪ Supp(b) = Σ.
Consequently, Supp(b) = Σ \ Supp(ai ). This is impossible since R
is not conflict-exhaustive.

Proof of Proposition 5 Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. Assume that T satisfies consistency and closure
under sub-arguments. From closure under sub-arguments, it follows
that for all E ∈ Ext(T ), Base(E) ⊆ Concs(E) (Property 4). Since
T satisfies consistency, then the set Concs(E) is consistent. From
Property 2 in [3], it follows that Base(E) is consistent.

Proof of Proposition 9 Let Σ = {x1 , . . . , xn } where n > 1 and
CΣ = {Σ}, and let (Arg(Σ), R) be an AS such that R is conflictdependent and not conflict-exhaustive. Let a1 , . . . , an ∈ Arg(Σ)
be such that Supp(ai ) = {xi }. From Lemma 3, the set E =
{a1 , . . . , an } is conflict-free and from Lemma 4 it defends its elements. Thus, E = {a1 , . . . , an } is an admissible set.

Proof of Lemma 1 Let Σ = {x1 , . . . , xn } where n > 2 and
CΣ = {Σ}, and let (Arg(Σ), R) be an AS such that R is conflictdependent. Let a1 , . . . , an ∈ Arg(Σ) be such that Supp(ai ) =
{xi }. Assume that the set E = {a1 , . . . , an } is not conflict-free.
Thus, ∃ai , aj ∈ E such that ai Raj . Since R is conflict-dependent,
then Supp(ai ) ∪ Supp(aj ) is inconsistent. This is impossible since
|Supp(ai ) ∪ Supp(aj )| < n and thus, from the definition of a minimal conflict, Supp(ai ) ∪ Supp(aj ) should be consistent.

Proof of Proposition 10 Let Σ = {x1 , . . . , xn } where n > 1
and CΣ = {Σ}, and let T = (Arg(Σ), R) be an AS such that R
is conflict-dependent and not conflict-exhaustive. Let a1 , . . . , an ∈
Arg(Σ) be such that Supp(ai ) = {xi } and Conc(ai ) = xi . From
Proposition 9, the set E = {a1 , . . . , an } is an admissible set. Besides, Concs(E) = {x1 , . . . , xn }, thus T violates consistency.

Proof of Lemma 2 Let Σ = {x1 , . . . , xn } where n > 2 and
CΣ = {Σ}, and let (Arg(Σ), R) be an AS such that R is conflictdependent. Let a1 , . . . , an ∈ Arg(Σ) be such that Supp(ai ) = {xi }.
Assume that the set E = {a1 , . . . , an } does not defend its elements.
Thus, ∃ai ∈ E such that ∃b ∈ Arg(Σ) and bRai and E does not
defend ai . This is impossible since R is symmetric thus, ai Rb.

Proof of Proposition 11 Let T = (Arg(Σ), R) be an AS over a
base Σ s.t. R is conflict-dependent but not conflict-exhaustive. Thus,
there exists C = {x1 , . . . , xn } such that C is not captured by R.
It follows from Proposition 6 that the set E = {a1 , . . . , an }, with
Supp(ai ) = {xi } and Conc(ai ) = xi , is an admissible extension of
T . Moreover, from Proposition 10, E violates consistency. Thus, T
violates extension consistency.

Proof of Proposition 6 Let Σ = {x1 , . . . , xn } where n > 2 and
CΣ = {Σ}, and let (Arg(Σ), R) be an AS such that R is conflictdependent. Let a1 , . . . , an ∈ Arg(Σ) be such that Supp(ai ) = {xi }.
From Lemma 1, the set E = {a1 , . . . , an } is conflict-free and from
Lemma 2 it defends its elements. Thus, E = {a1 , . . . , an } is an
admissible set.

Proof of Proposition 12 Let T = (Arg(Σ), R) be an AS s.t. R is
conflict-exhaustive and ∀E ∈ Ext(T ), E = Arg(Base(E)).
Let E be an admissible extension and x ∈ CN(Concs(E)). Thus,
∃{x1 , . . . , xn } ⊆ Concs(E) s.t. x ∈ CN({x1 , . . . , xn }).
Besides, ∀xi , ∃ai ∈
� E s.t. xi ∈ CN(Supp(ai )). Thus,
{x1 , . . . , x�
⊆
Property 1
n}
i=1,n CN(Supp(ai )). From
�
in [3],
⊆ �CN( i=1,n Supp(ai )).
i=1,n CN(Supp(ai ))
Then, {x1 , . �
. . , xn }
⊆
CN( i=1,n Supp(ai )) and
x
∈
CN( i=1,n Supp(a
i )). From Property 6, Base(E)
�
is
⊆
Base(E), then
i=1,n Supp(ai )
� consistent. Since
(see
Property
2
in [3]). Coni=1,n Supp(ai ) is consistent
�
sequently, � the pair ( i=1,n Supp(ai ), x) is an argument.
Hence,
( i=1,n Supp(ai ), x)
∈
Arg(Base(E)) and thus,
�
( i=1,n Supp(ai ), x) ∈ E. It follows that x ∈ Concs(E).

Proof of Proposition 7 Let Σ = {x1 , . . . , xn } where n > 2
and CΣ = {Σ}, and let T = (Arg(Σ), R) be an AS such that
R is conflict-dependent. Let a1 , . . . , an ∈ Arg(Σ) be such that
Supp(ai ) = {xi } and Conc(ai ) = xi . From Proposition 6, the
set E = {a1 , . . . , an } is an admissible set. Besides, Concs(E) =
{x1 , . . . , xn }, thus T violates consistency.
Proof of Proposition 8 Let T = (Arg(Σ), R) be an AS over a base
Σ s.t. R is both conflict-dependent and symmetric. Consider C =
{x1 , . . . , xn } where n > 2 and assume that C ∈ CΣ . It follows
from Proposition 6 that the set E = {a1 , . . . , an }, with Supp(ai ) =
{xi } and Conc(ai ) = xi , is an admissible extension of T . Moreover,
Concs(E) is inconsistent. Thus, T violates consistency.

Proof of Proposition 13 Let T = (Args(Σ), R) be an AS such
that R satisfies R1 and R2 . Let E be an admissible extension of T .
Assume that E is not closed under sub-arguments. Thus, ∃a ∈ E
such that Sub(a) �⊆ E. This means that ∃a� ∈ Sub(a) and a� ∈
/ E.
Two possibilities hold:

Proof of Lemma 3 Let Σ = {x1 , . . . , xn } where n > 1 and CΣ =
{Σ}, and let (Arg(Σ), R) be an AS such that R is conflict-dependent
and not conflict-exhaustive. Let a1 , . . . , an ∈ Arg(Σ) be such that
Supp(ai ) = {xi }. Assume that the set E = {a1 , . . . , an } is not

1. E∪{a� } is conflicting. Thus, ∃b ∈ E such that either a� Rb or bRa�
hold. Assume that a� Rb. Since a� ∈ Sub(a) and R verifies R1 ,

66

ECAI-2012 Workshop WL4AI

then aRb. This contradicts the fact that E is admissible. Assume
now that bRa� . Since R satisfies R2 , then bRa, contradiction.
2. E does not defend a� . Thus, ∃b ∈
/ E such that bRa� and �c ∈ E
�
such that cRb. Since bRa and R satisfies R2 , then bRa. Since
a ∈ E and E is admissible, this means that ∃c ∈ E such that cRb.
Contradiction.

(ai ∈ E) and Supp(ai ) is consistent (by definition of an argument),
then |C| ≥ 2. Since R is conflict-exhaustive, then ∃X ⊂ C s.t.
∃a, b ∈ Arg(Σ) and Supp(a) = X, Supp(b) = C \ X and either aRb or bRa. Besides, Supp(a) ⊆ Base(E) (resp. Supp(b) ⊆
Base(E)), then a, b ∈ Arg(Base(E)). Since E = Arg(Base(E)),
then a, b ∈ E. This means that the extension E is conflicting. Contradiction.

Proof of Proposition 14 Let T = (Args(Σ), R) be an AS such that
R satisfies R2 . Let E be a stable extension of T which is not closed
under sub-arguments. Thus, ∃a ∈ E such that Sub(a) �⊆ E. This
means that ∃a� ∈ Sub(a) and a� ∈
/ E. Then, ∃b ∈ E such that bRa�
(according to the definition of a stable extension). Since R satisfies
R2 , then bRa. This contradicts the fact that E is conflict-free.
Proof of Proposition 15 Let E be an admissible extension of an AS
T = (Args(Σ), R). Assume that R is conflict-dependent and sensitive. Assume also that E is not closed under sub-arguments. That is,
∃a, a� ∈ Arg(Σ) s.t. a� ∈ Sub(a), a ∈ E and a� ∈
/ E. Two situations
are possible:
1. E ∪ {a� } is conflicting meaning that ∃b ∈ E s.t. either a� Rb or
bRa� . Since R is conflict-dependent, then Supp(a� ) ∪ Supp(b)
is inconsistent. Besides, a� ∈ Sub(a) thus Supp(a� ) ⊆ Sub(a).
From Property 2 in [3], Supp(a) ∪ Supp(b) is inconsistent as well.
Since R is conflict-sensitive, then either aRb or bRa. This contradicts the fact E is conflict-free.
2. E does not defend a� . Thus, ∃b ∈ Arg(Σ) s.t. bRa� . Since R
is conflict-dependent, then Supp(a� ) ∪ Supp(b) is inconsistent.
Besides, a� ∈ Sub(a) then Supp(a� ) ⊆ Sub(a). Thus, Supp(a) ∪
Supp(b) is inconsistent as well. Since R is conflict-sensitive, then
either aRb or bRa. Assume that aRb, thus a defends a� which
contradicts the fact that E does not defend a� . Assume now that
bRa. Since E is admissible and a ∈ E, then ∃c ∈ E s.t. cRb.
Thus, c defends even a� , this contradicts again the fact that E does
not defend a� .
Proof of Proposition 16 Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ. Assume that ∀E ∈ Ext(T ), E = Arg(Base(E)).
Let E ∈ Ext(T ) and a ∈ E. Since a ∈ E, then Supp(a) ⊆ Base(E).
Let b ∈ Sub(a), thus Supp(b) ⊆ Supp(a) and Supp(b) ⊆ Base(E).
It follows that b ∈ Arg(Base(E)). Consequently, b ∈ E. Then, T is
closed under sub-arguments.
Proof of Proposition 17 Let T = (Arg(Σ), R) be an AS such
that ∀E ∈ Ext(T ), E = Arg(Base(E)). Assume that T violates
strong consistency. Thus, there exists an extension E of T (under a
given semantics) such that Base(E) is inconsistent.
� Thus, ∃C ∈ CΣ
such that C ⊆ Base(E). Since Base(E) = ai ∈E Supp(ai ) and
Supp(ai ) is consistent, then |C| ≥ 2. Thus, ∃X ⊂ C such that X
and C \ X are consistent. From Proposition 1 (in [3]), there exist two
arguments a and b where Supp(a) = X and Supp(b) = C \X. From
Lemma 5, ∃x1 ∈ CN(X) and ∃x2 ∈ CN(C \ X) such that the set
{x1 , x2 } in inconsistent. Let Conc(a) = x1 and Conc(b) = x2 .
Since a, b ∈ Arg(Base(E)) and that E = Arg(Base(E)), then
a, b ∈ E. Thus, Concs(E) is inconsistent.
Proof of Proposition 18 Let T = (Arg(Σ), R) be an AS over a
knowledge base Σ s.t. R is conflict-exhaustive and for each E ∈
Ext(T ), E = Arg(Base(E)). Note that in this case, consistency coincides with strong consistency (from Proposition 17).
Let E be an admissible extension of T s.t. Base(E) is inconsistent.
�
Thus, ∃C ∈ CΣ s.t. C ⊆ Base(E). Since Base(E) = Supp(ai )

67

ECAI-2012 Workshop WL4AI

68

ECAI-2012 Workshop WL4AI

On Arguments and Conditionals
Revised version 26.9.2012

Emil Weydert
Abstract. We start the investigation of a new class of
semantic-oriented instantiations of abstract argumentation
frameworks with default conditionals based on the rankingconstruction paradigm for default reasoning. This allows us
to specify a new ranking extension semantics with nice properties.

1

2

Plausibilistic default reasoning

In the following, we assume a background language L closed
under the usual propositional connectives T, F, ¬, ∧, ∨, →, ↔,
interpreted by a classical satisfaction relation |=, which induces the associated monotonic entailment relation . Its
model sets are denoted by [[ϕ]] = {m | m |= ϕ}, resp. [[Σ]] =
∩ϕ∈Σ [[ϕ]] for Σ ⊆ L. Let BL be the corresponding propositional boolean algebra with domain BL = {[[ϕ]] | ϕ ∈ L}.
Default inference is an important instance of nonmonotonic
reasoning. It is concerned with drawing reasonable but potentially defeasible conclusions from usually finite knowledge
bases Σ ∪ ∆, where Σ is a set of assumptions or facts, e.g. describing a specific state of affairs in some domain language,
and ∆ is a collection of defaults encoding exception-tolerant
implicational information and guiding the defeasible inference
process. Here we assume that Σ ⊆ L is a finite belief base over
our background logic (L, ), whereas ∆ is a finite subset of
the flat conditional language

Introduction

The past years have seen a tremendous development of abstract argumentation theory, which started with the seminal
work of Dung [Dun 95]. Some authors have also begun to
investigate extensions of Dung’s original attack frameworks,
adding for instance support relations, preferences, joint attacks, or attacks on attacks. This multiplication of abstract
frameworks and corresponding semantics have raised the need
for a rational evaluation and comparison of these approaches.
A major question is whether an abstract account accurately
reflects concrete argumentative reasoning in the context of a
sufficiently expressive classical or – more realistically – defeasible logic. Consequently, the instantiation of abstract frameworks by actual argument configurations, relevant for justifying/criticising abstract extension semantics, has become
a major research topic. But most of this work is based on
traditional defeasible formalisms, like logic programming, or
Reiter’s default logic. While these are closer to the spirit of
Dung’s theory, they also fail to verify central desiderata for
default reasoning encoded in benchmark examples and rationality postulates. The goal of this paper is therefore to supplement existing efforts with an innovative semantic instantiation model which interprets arguments and attacks as default
conditional knowledge bases and exploits well-behaved ranking construction semantics for plausible reasoning [Wey 03] to
specify for attack frameworks a new evaluation/applicability
semantics with interesting properties.
The paper is organized as follows. First, we give an introduction to plausibilistic default reasoning and the ranking construction paradigm. After a short introduction into
generalized argumentation theory, we discuss syntactic and
semantic instantiations of argumentation frameworks in the
context of default reasoning. Here we focus on the shallow
semantics, which interprets abstract arguments and the attacks linking them by default conditionals. We then specify
a ranking-based extension semantics focusing on generic instantiations. To conclude we present several examples and list
important principles validated by this semantics.
1

1

L(

, ❀) = {ϕ

ψ | ϕ, ψ ∈ L} ∪ {ϕ ❀ ψ | ϕ, ψ ∈ L}

on top of L. The strict implication ϕ
ψ states that ϕ necessarily implies ψ, forcing us to accept ψ given ϕ. The default
implication ϕ ❀ ψ tells us that ϕ normally/plausibly/by default implies ψ. That is, if ϕ is believed and there is no conflicting information questioning ψ, it suggests/permits us to
accept ψ as well. The actual impact of a default δ of course
depends on its context Σ ∪ ∆ and the chosen nonmonotonic
inference notion |∼.
Examples are Reiter’s normal default rules ϕ : ψ/ψ, or plausible implications ϕ ❀ ψ based on a preferential/valuational
possible worlds semantics. Note that these represent two different types of default reasoning: on one side the autoepistemic, consistency- or context-based philosophy, on the other
side the plausibilistic, quasi-probabilistic perspective. The former one includes, e.g., Reiter’s default logic and logic programming. The second one is exemplified, e.g., by semanticbased preferential formalisms like system Z [Pea 90], or
maximum-entropy-based approaches [GMP 93]. For mainly
historical reasons, approches of the first kind have received
most attention. However, the second variant has a much better record w.r.t. handling benchmark examples and satisfying
common rationality postulates. This makes it a natural alternative search space for instantiating abstract argumentation.
We start with some general considerations. First, we have
to understand that the central concept in default reasoning is
not some monotonic conditional logic for L( , ❀), but a nonmonotonic meta-level inference relation |∼ specifying which

University of Luxembourg, Luxembourg – emil.weydert@uni.lu

69

ECAI-2012 Workshop WL4AI

conclusions ψ ∈ L can be plausibly inferred from a finite
knowledge base Σ ∪ ∆ with Σ ⊆ L and ∆ ⊆ L( , ❀). If we
set Σ |∼∆ ψ iff Σ ∪ ∆ |∼ ψ, we obtain a defeasible consequence
|∼
relation |∼∆ on L. Let C∆ (Σ) = {ψ | Σ |∼∆ ψ}.
The large number of competing proposals in nonmonotonic
reasoning has pushed the search for rationality postulates allowing their classification and evaluation [KLM 90, Mak 94].
But this work mostly considers consequence relations over
L, like |∼∆ , i.e. it ignores the inferential impact of specific
defaults. So, much less is known about the properties and
desiderata for ∆ → |∼∆ (see [Wey 03]). This scarcity of general inferential guidelines can however be met by focusing on
the semantic base of plausible reasoning, which may actually
be more promising to begin with.
A central concept here is that of a linear plausibility valuation P l : BL → V . These are maps from propositions to
plausibility values in a linearly ordered structure with endpoints V = (V, , ⊥, ≤) which are required to be monotonic
w.r.t. ⊆ and ≤ [FH 01]. If we intend ⊥ to mark impossibility,
we also must have that P l(A) = ⊥ implies P l(B∪A) = P l(B).
Each such valuation concept specifies a plausibility semantics
for strict/default conditionals based on the following truth
conditions (writing sloppily P l(ϕ) = P l([[ϕ]]).

sufficient to consider rational-valued ranking measures (e.g.,
integers are not enough to fully implement minimal information inference methods). The most general ranking value
space is the (saturated) ordered additive structure of positive nonstandard reals (with infinitesimals, infinite numbers)
extended by ∞.
Definition 3.1 (Ranking measures)
A map R : BL → ([0, ∞], 0, ∞, +, ≥) is called a ranking
measure iff for all A, B ∈ BL R(T ) = 0, R(F ) = ∞, and
R(A ∪ B) = min≤ {R(A), R(B)}. R(.|.) is the associated conditional ranking measure on BL × BL defined by
R(B|A) = R(A ∩ B) − R(A) if R(A) = ∞, else R(B|A) = ∞.
Note that lower values indicate less surprise and more plausibility. R0 is the uniform ranking measure, i.e. R0 (A) = 0 for
A = ∅. The classical order-of-magnitude interpretation reads
R(A) = r > 0 as P (A) ∼ εr , where P is a nonstandard probability measure over BL and ε an infinitesimal. This useful
correspondence allows the exploration of probabilistic inference techniques at the ranking level.
In the ranking context, we use |=rk , [[.]]rk , rk to denote
|=pl , [[.]]pl , pl . rk then validates the rules of rational conditional logic [KLM 90]. For the purpose of minimization, it
is useful to consider threshold-based truth conditions for defaults, stipulating specific default strengths. For r ∈]0, ∞], we
set

• P l |=pl ϕ ❀ ψ iff P l(ϕ ∧ ¬ψ) < P l(ϕ ∧ ψ) or P l(ϕ) = ⊥.
• P l |=pl ϕ
ψ iff P l(ϕ ∧ ¬ψ) = ⊥.
The resulting model set concept [[.]]pl for ∆ ⊆ L( , ❀) is
defined by [[∆]]pl = {P l : BL → V | P l |=pl ∆}. Let pl be the
associated monotonic consequence relation on L( , ❀) given
by ∆ pl δ iff [[∆]]pl ⊆ [[δ]]pl . If we adopt this semantics, we
may drop
because ϕ
ψ is then semantically equivalent
to ϕ ∧ ¬ψ ❀ F .
The most general semantic framework for plausibilistic default reasoning, as we understand it, is based on plausibility
choice operators I mapping each pair (Σ, ∆), with Σ, ∆ as
above, to a set I(Σ, ∆) ⊆ [[∅]]pl of plausibility valuations. We
may interpret the elements of I(Σ, ∆) as modeling the preferred belief states induced by Σ and ∆. A default inference
notion |∼I can then be specified by

R |=rrk ϕ ❀ ψ iff R(ϕ ∧ ψ) + r ≤ R(ϕ ∧ ¬ψ).
Because every pair of r, r ∈]0, ∞[ can be exchanged by an
automorphism of the additive value structure (x → r /r × x),
all the r ∈]0, ∞[ are structurally equivalent w.r.t. + and ≤.
Hence, w.l.o.g., we may focus on r = 1.
Our next task is to specify the nonmonotonic semantics
for default conditionals. This amounts to find an appropriate ranking choice function I. Our starting point is the construction paradigm for default reasoning introduced in [Wey
95,96], which inspired several well-behaved default inference
notions [Wey 98, 03]. The initial idea here was that a default
does not only specify a constraint over plausibility measures,
but may also indicate specific valuation transformations of
R0 to realize this constraint. For instance, we may consider
only those ranking models of a default base ∆ which are constructible from R0 through particular revision steps determined by the defaults in ∆. Here we can exploit Spohn’s
parametrized revision concept [Spo 88], which implements
Jeffrey-conditionalization for ranking measures and is backed
by the minimal information philosophy. For instance, a default
ϕ ❀ ψ is meant to allow revision/expansion with the material
implication ϕ → ψ, which in our variant of Spohn’s approach
corresponds to uniformly shifting upwards the (worlds in the)
proposition [[ϕ ∧ ¬ψ]] until ϕ → ψ is believed.

Σ |∼I∆ ψ iff I(Σ, ∆) |=pl ∧Σ ❀ ψ.
In the following, we will focus on context-independent I,
i.e. verifying I(Σ, ∆) = I(∅, ∆) (= I(∆)). For instance, if
we set V = (N ∪ {∞}, 0, ∞, >) and compare valuations pointwisely, then I(∆) = {M in≤ [[∆]]pl } essentially specifies system
Z [Pea 90].

3

Preferred ranking constructions

We will consider a semantics for default conditionals based on
the simplest plausibility valuation concept which reasonably
handles independence and conditionalization, namely ranking measures [Wey 95]. These are semi-qualitative, quasiprobabilistic valuations expressing the degree of surprise
of propositions. The notion goes back to, and generalizes,
Spohn’s integer-valued natural conditional functions, known
as κ-functions, which he introduced to model the iterated revision of graded plain belief [Spo 88, 90]. They have become
popular in epistemic modeling and knowledge representation
because they bridge preference-based and probabilistic reasoning. For default reasoning in finite contexts, it is usually

Definition 3.2 (Expansion constructibility)
Let ∆ = {ϕi ❀ ψi | i ≤ n} ⊆ L(❀). A ranking measure R is
said to be (expansion-)constructible from R over ∆, written
R ∈ Constr(∆, R), iff there are ranking values r0 , . . . , rn ∈
[0, ∞] s.t., if (R + r[ρ])(χ) = min{R(χ ∧ ρ) + r, R(χ ∧ ¬ρ)},
R = R + Σi≤n ri [ϕi ∧ ¬ψi ].

70

ECAI-2012 Workshop WL4AI

is a typically finite collection of abstract entities representing
arguments, and ✄ is a binary attack relation modeling possibly asymmetric conflicts between arguments. To grasp the
sophistication of real-world argumentation, a number of authors have extended this basic framework concept to include,
e.g., support relations, preferences, valuations, joint attacks,
or attacks on attacks. Most of these generalizations can be
formalized by first-order hyperframeworks [Wey 11].

The power of ranking-construction-based default entailment
is illustrated by the fact that we can obtain a robust, wellbehaved default inference relation, called system J [Wey 96],
just by setting
IJ (∆) = Constr(∆, R0 ) ∩ [[∆]]rk .
Note that for system J, on the inferential level, it doesn’t
make a difference whether we use the standard or a finite
threshold semantics for the defaults. However, the stronger
and more differentiated threshold interpretation simplifies the
specification of canonical preferred ranking models.
A desirable feature inspired by the minimal shifting philosophy is what we have called justifiable constructibility
[Wey 96]. It seeks minimal shifting in the sense that the targeted ranking constraints interpreting defaults should not be
over-satisfied. Note that the definition below requires truthconditions with thresholds, or well-ordered ranking values.

Definition 4.1 (Hyperframeworks) A first-order hyperframework (HF) is a structure A = (A, (Pi )i∈I , (Rj )j∈J ),
where A = ∅ is a set of possible arguments, and the Pi , Rj
are ni , mj -ary relations over A. The Rj are called the basic
conflictual relations of A. B ⊆ A is said to be conflict-free
w.r.t. A iff no conflictual Ri is satisfiable over B.
A HF is meant to express on an abstract level specific inferential or epistemic relationships between logical entities whose
internal structure is ignored. The conflictual relations determine when a set of arguments is to be considered inconsistent
or inacceptable. Dung’s attack frameworks are instances of
HFs with |I| = 0, |J| = 1, and m0 = 2. The attack relation
✄ is conflictual. Preference and support are examples of nonconflictual binary relations. Set attacks can be modeled by
introducing an attack relation for each cardinality.
The basic inferential task in abstract argumentation consists in evaluating A so as to determine at the macro-level
the acceptable attitudes of an agent w.r.t. the arguments. In
the simplest scenario, argumentative positions correspond to
particular conflict-free collections of arguments E ⊆ A called
extensions. But we may also consider more fine-grained assessments of arguments, like labelings or prioritizations. More
generally, the role of an evaluational argumentation semantics
is to associate with any HF A of a suitable type a possibly
empty set of distinguished evaluation structures over its domain A which interpret at least a unary predicate In characterizing the accepted arguments.

Definition 3.3 (Justifiable constructibility)
Let ∆ = {ϕi ❀ ψi | i ≤ n}. Then a ranking construction
model R∗ = R + Σi≤n ai [ϕi ∧ ¬ψi ] |=rk ∆ is called justifiably
constructible w.r.t. ∆, written R∗ ∈ Ijj (∆), iff proper shifting
of [[ϕj ∧ ¬ψj ]], i.e. aj > 0, implies the existence of an i ≤ n
with [[ϕi ∧ ¬ψi ]] = [[ϕj ∧ ¬ψj ]] such that the corresponding
constraint becomes an equality constraint R∗ (ϕi ∧ ψi ) + 1 =
R∗ (ϕi ∧ ¬ψi ).
This definition takes into account the possibility that there
could be several defaults with identical exceptional parts
[[ϕ ∧ ¬ψ]], but not all of them being realized as equality constraints. If ∆ rk F , we have Ijj (∆) = ∅. For minimal core
default sets [GMP 93], the corresponding well-behaved default
inference notion |∼jj then offers the same results as maximumentropy-based approaches2 . In fact, the direct translation of
entropy maximization (ME) to the ranking level [Wey 95b,
03] always produces a unique justifiably constructible model
me
me
}.
, i.e. Ime (∆) = {R∆
R∆
In general, Ijj (∆) may fail to be a singleton, but it can
be strengthened into a more sophisticated intuitive ranking
construction in the tradition of system Z which generates for
every consistent default base ∆ a canonical justifiably constructible model, like the JZ-model [Wey 98, 03]. It does so
through a hierarchical construction process aimed at avoiding
longer shifts. |∼jz is then not only backed by its natural, welljustified ranking construction procedure, but it also satisfies
most of the major desiderata formulated in the literature. Because it is not affected by the ambiguities and the arbitrariness
of the passage between ranking and probability constraints,
|∼jz may actually constitute a conceptually more appealing
implementation of the minimal information philosophy for
ranking measures than |∼me . However, for the restricted applications in our present paper, justifiable constructibility is
actually enough to characterize a unique ranking model so
that we do not have to worry about these distinctions. But
they become relevant in more expressive contexts.

4

Definition 4.2 (Hyperframework semantics) A semantics for HFs is an evaluation map E which associates with
each HF A ∈ dom(E) a set E(A) of evaluation structures
B = (A, InB , ...) over its domain A, called the hyperextensions of A, such that isomorphic A induce isomorphic E(A),
and that the set of accepted arguments InB is conflict-free
w.r.t. A.
For instance, Dung’s preferred semantics can be modeled by
a map Epr associating with each framework (A, ✄) the set of
structures {(A, E) | E is a maximal admissible extension of
(A, ✄)}. Note that the above requirements are of course not
the only ones one might wish to impose upon E.

5

To evaluate and actually apply these semantics, the abstract
frameworks have to be instantiated in the sense of being linked
to concrete logical entities and their inferential/epistemic relations and properties. In particular, we may want to identify
for each argument a ∈ A a sentence ψa expressing the explicit
claim of a. For instance, in ASPIC and its derivates [Pra 10]
the arguments are mapped to suitable rule-trees built from
strict and defeasible rules, topped by ψa , and attacks like

Abstract argumentation

An abstract argumentation framework in the sense of Dung
[Dung 95] is a structure of the form A = (A, ✄), where A
2

Arguments and instantiations

For different constructibility-flavoured or ME-based accounts, see
e.g. [GMP 93, BSS 00, KI 01, BP 03].

71

ECAI-2012 Workshop WL4AI

minimal ∆ ⊆ ∆a validating Σa ∪ ∆ |∼ ψa are overridden by
some ∆ ⊂ ∆ ⊂ ∆a with Σa ∪ ∆ |∼ ψa . Because, as we
will see, natural instantiations may well produce inferentially
inconsistent arguments, it seems sensible to be cautious and
just ask for inferential correctness.
In what follows, we are going to explore instantiation from
a semantic perspective and interpret and evaluate abstract
argumentation through ranking-based default formalisms, ignoring syntactic and computational issues.

rebuttal or undercut are interpreted by specific syntactic relationships between tree components.
Loosely in line with [CW 11], the general strategy in argumentation may be as follows. First, we construct from a
given knowledge base over some reference logic a meta-logical
system which is composed of subbases, or proof-trees (to be
abstractly modeled by the a ∈ A), and which encodes all the
relevant connections (to be abstractly modeled by the Pi , Rj )
between these. Secondly, we pass to the resulting abstract hyperframework and compute its hyperextensions. Thirdly, we
instantiate the hyperextensions. Last but not least, we extract
conclusions from their instantiations. An interesting question
is then whether and to what extent the inferential expectations for the input knowledge base, e.g. specified by a nonmonotonic reference logic, are met by the inferences actually
generated with the help of abstraction, evaluation, instantiation, and consequence extraction.
On one hand, an instantiation constitutes a reality check for
the coarse-grained abstract approaches, clarifying their potential as well as their limitations. Those not validated by an
instantiation may still indicate ways for improvement, be it by
pointing to better semantics, or by suggesting richer abstract
frameworks. Of course, passing from a concrete to an abstract
level is necessarily accompanied by a loss of information. Thus
we cannot expect more than approximating a complex nonmonotonic or paraconsistent inferential reality, while possibly
gaining additional computational or conceptual accessibility.
On the other hand, the abstract perspective offers a tool
for analyzing, criticizing, and revising complex fine-grained
nonmonotonic formalisms by illuminating specific inferential
relationships (e.g. the structure of asymmetric conflicts). In
fact, different levels may suggest different intuitions, principles, and properties. Instantiations can therefore provide insights and benefits for both sides, especially in the realm of
richer hyperframeworks.
In real life, arguments are commonly based on defeasible
inference steps exploiting defaults. More formally, a concrete
argument a picks up a finite base Σa of domain assertions
from a collection of initial assumptions or accepted facts Σ ⊆
L, exploits a finite subset ∆a of strict/plausible implications
from a collection of conditionals ∆ ⊆ L( , ❀), and uses this
to justify a conclusion ψa ∈ L. To specify what justification
means, we need a suitable defeasible inference relation |∼ on
top of L and L( , ❀). An argument a may then be called
inferentially correct w.r.t. |∼ iff ψa can be inferred from Σa
and ∆a .

6

Semantic instantiations

As we noticed before, it is important to investigate the relationship between abstract argumentation frameworks and
their concrete instantiations, e.g. with the help of default formalisms. For instance, Caminada and his co-workers were able
to show that some common acceptability semantics at the abstract level fail to verify desirable properties formulated at
the instantiation level [CA 07, CW 11]. However, we have to
put this type of results into the right perpective. First, we
may observe that most existing instantiations mostly exploit
consistency-based default formalisms close to Reiter’s default
logic or logic programming, which are known to provide an
incomplete picture of default reasoning. However, if we use
as indicators the main benchmark examples from the literature, popular postulates for nonmonotonic inference, and the
possibility to link qualitative to quantitative uncertainty, this
approach looks less appealing. While it may be reasonable to
start with instantiation contexts which did inspire Dung’s theory in the first place, in the next step one should also pay attention to nonmonotonic target formalisms more in line with
central desiderata for default reasoning. In the present paper,
we will honour this observation by taking a look at possible
contributions from ranking-based default entailment, e.g. system JJ or system JZ.
For reasons of space, we have to restrict ourselves to
interpret standard argumentation structures of the form
A = (A, ✄) where ✄ is understood as an attack relation
between abstract arguments. Let L = (L( , ❀), rk , |∼) be
our reference default formalism.

Instantiating arguments.
We distinguish two main instantiation levels: the syntactic
and the semantic one. At the syntactic level, we instantiate each abstract argument a ∈ A by a system of formulas Isyn (a) over L. For instance, Isyn (a) could be a specific
inferential construction, e.g. a proof tree. Because here we
are primarily interested in the semantic analysis, we adopt
a coarse-grained approach where Isyn (a) only indicates the
sets of L-formulas involved as premises, inferential guides
(e.g. rules/conditionals), or conclusions. More precisely, we
consider Isyn which map each argument a ∈ A to its inferential profile (Σa , ∆a , ψa ), where Σa ∪ {ψa } ⊆ L and
∆a ⊆ L( , ❀) are assumed to be finite. The first two components identify the premise base Σa ∪ ∆a , the third one the
conclusion or claim ψa . We call Isyn correct w.r.t. the nonmonotonic logic L iff Isyn (a) is inferentially correct, i.e. if
Σa ∪ ∆a |∼ ψa for all a ∈ A. Because the instantiation of
atomic loops a ✄ a may produce inconsistent bases, we do not
impose premise consistency a priori. Of course, this doesn’t

• Inferential correctness: Σa ∪ ∆a |∼ ψa .
We call the triple (Σa , ∆a , ψa ) the inferential profile of a. We
do not a priori assume that the profile characterizes a. In
classical logic-based argumentation [BH 08], arguments are
represented by pairs of the form (Φ, ψ), consisting of a support set Φ ⊆ L and a claim ψ ∈ L, which have to satisfy three
requirements: (1) Φ
F (consistency), (2) Φ ψ (correctness), and (3) for each Φ ⊂ Φ, Φ
ϕ (minimality). While
these principles may seem decent and reasonable, we must
keep in mind that they have been formulated in the context
of monotonic reasoning. The counterpart to (1) is inferential
consistency: Σa ∪ ∆a |∼ F , whereas (2) corresponds to inferential correctness. But in the nonmonotonic realm there can
be situations where minimality fails in the sense that all the

72

ECAI-2012 Workshop WL4AI

mean that all the syntactic instantiations are born equal.
At the semantic level, we introduce semantic instantiation
functions Isem which determine the actual semantic content
of an argument a by providing an interpretation Isem (a) of
Isyn (a). More specifically, we interpret each correct inferential
profile Isyn (a) = (Σa , ∆a , ψa ) by a semantic structure of the
form

we adopt a semantic perspective, we are only interested in semantically invariant attack specifications. That is, whether at
the syntactic level Isyn (a) attacks Isyn (b) should only depend
on the corresponding shallow/deep semantic interpretations
(0)
(0)
Isem (a), Isem (b). Consequently, we will specify concrete attack relations at the semantic level.
So, how should we reflect an attack a ✄ b at the semantic
level? The idea is to interpret attack configurations as ranking
constraints. That is, in the context of an instantiation function I, we instantiate ✄ by a suitable set of ranking measures
R = R✄ ⊆ [[∆I ]]rk . For instance, let a, b be two arguments
whose shallow instantiations are characterized by (ϕa , ψa ) and
(ϕb , ψb ). If an attack is meant to indicate an actual conflict between the nonmonotonic conclusions, then it seems necessary
to impose at least R(ψa ∧ ψb ) = ∞ for R ∈ R✄ . Incompatible
monotonic contents can be modeled by R(ϕa ∧ ϕb ) = ∞.
If R(ϕa ∧ ϕb ) = ∞ and R(ψa ∧ ψb ) = ∞, we get R(ψa ∧
¬ψb |ϕa ∧ ϕb ) = R(ψa |ϕa ∧ ϕb ) and R(¬ψa ∧ ψb |ϕa ∧ ϕb ) =
R(ψb |ϕa ∧ ϕb ). These two conditional ranking values state the
degree of surprise, relative to the common context ϕa ∧ ϕb , of
exclusively concluding ψa , resp. ψb . If ψa is here less surprising
than ψb , we may interpret this as a attacking b, and similarly
for the converse. On the other hand, if these ranks turn out
to be equal, we are in the presence of an equilibrated mutual
0
attack. From a shallow instantiation I = Isem
and a reference
class of ranking measures R, we can define a specific attack
relation ✄R
I on AI = {([[ϕa ]], [[ψa ]]) | a ∈ A}. Let us abbreviate
([[ϕ]], [[ψ]]) by (ϕ, ψ).

|∼

Isem (a) = ([[Σa ]], [[∆a ]]ind
rk , I|∼ (∆a ), [[C∆a (Σa )]]).
|∼

[[Σa ]] and [[C∆a (Σa )]] ⊆ [[ψa ]] are classical model sets of (L, |=).
[[∆a ]]ind
= {[[δ]]rk | δ ∈ ∆a } specifies the ranking semanrk
tic content of the individual conditionals in ∆a . This refined
structural semantic perspective is necessary to determine the
constructible ranking-models, and more generally, to grasp
implicit independence assumptions within default knowledge.
Last but not least, I|∼ (∆a ) is the ranking-model set resulting from applying the preferred ranking choice function I of
the chosen default entailment concept |∼ to ∆. If Isyn (a) is
|∼
correct, i.e. [[C∆a (Σa )]] ⊆ [[ψa ]], Isem characterizes what we
may call the deep semantics of arguments by providing a finegrained account of the relevant default knowledge.
If we are primarily interested in the semantic modeling of
the classical premises and conclusions, putting the defaults
into a black box, we may also consider simpler semantic units.
But to achieve this, we first have to extract additional information from ∆a . In fact, the hard classical monotonic content
of Σa ∪ ∆a is determined not just by Σa , but also by the the
necessities which ∆a monotonically entails.
✷|∼ (∆a ) = {ϕ | ∆a

rk

¬ϕ ❀ F }.

Definition 6.1 (Shallow semantic instantiations)
Let A = (A, ✄) be an AF and I be a shallow semantic instantiation function for A. For (ϕa , ψa ), (ϕb , ψb ) ∈ AI , we say
that (ϕa , ψa ) semantically attacks (ϕb , ψb ) w.r.t. a collection
of ranking models R ⊆ [[∆I ]], written (ϕa , ψa ) ✄R
I (ϕb , ψb ),
iff for all R ∈ R, R(ψa ∧ ψb ) = ∞ and R(ψa |ϕa ∧ ϕb ) ≤
R
R(ψb |ϕa ∧ ϕb ). Let AR
I = (AI , ✄I ). We call (I, R) a shallow
semantic instantiation of A = (A, ✄) iff I : A → AR
I is an
isomorphism.

As before, the nonmonotonic propositional content is fixed
|∼
by [[C∆a (Σa )]]. The semantic content of a expressible in L
is then characterized by the pair of propositions ([[Σa ]] ∩
|∼
0
[[✷|∼ (∆a )]], [[C∆a (Σa )]]). We then call Isem
(a) = ([[Σa ]] ∩
|∼

[[✷|∼ (∆a )]], [[C∆a (Σa )]]) the shallow semantic instantiation of
the argument a. For reasons of space, we will have to restrict
our discussion to the shallow semantics.
In a finitary context, the shallow semantic units are
pairs of L-propositions ([[ϕa ]], [[ψa ]]) with [[ψa ]] ⊆ [[ϕa ]],
sloppily denoted by (ϕa , ψa ), where ϕa , ψa represent the
monotonic, resp. nonmonotonic content of an argument
a. Because [[ϕ ❀ ψ]]rk = [[ϕ ❀ ϕ ∧ ψ]]rk , this comes
close to interpreting arguments by conditionals. Each unit
(ϕa , ψa ) interprets a minimal inferential profile of the form
Isyn (a) = ({ϕa }, {ϕa ❀ ψa }, ψa ). Setting I = Isyn , let
ΣI = {ϕa | a ∈ A} and ∆I = {ϕa ❀ ψa | a ∈ A}. ΣI ∪ ∆I
constitutes the global knowledge base associated with the
framework A by I. We emphasize that ΣI ∪ ∆I doesn’t have
to be consistent w.r.t. |∼. That is, ΣI ∪ ∆I |∼ F is possible,
and so is {ϕa } ∪ {ϕa ❀ ψa } |∼ F .

That is, the attacks on the semantic level specified by ✄R
I then
exactly represent those on the abstract level expressed by ✄.
We observe that each A = (A, ✄) has many shallow semantic instantiations (I, R), obtained by varying the proposition
pairs associated with the individual abstract arguments, or
the collection of ranking models representing ✄. For a single loop a ✄ a and R ∈ R, we have R(ψa ∧ ψa ) = ∞ =
R(ϕa ∧ ψa ) + 1 ≤ R(ϕa ∧ ¬ψa ), hence R(ϕa ) = ∞.
Let us also take a short look at the classical types of attack
in deductive argumentation, namely rebuttal, undermining,
and undercut. In our shallow semantic context, incompatibility between propositions is modeled by ranking constraints
expressing necessities w.r.t. ϕa , ψa , ϕb , ψb . Rebuttal is characterized by incompatible consequents, whereas undermining
states a conflict between a consequent and an antecedent.
Undercut is meant to break the inferential link between antecedent and consequent, e.g. by rebutting relevant subarguments. It may be understood as an intermediate condition
between undermining and rebuttal.

Instantiating attacks.
The next step is to interpret the attack links a ✄ b in A by
suitable relations over the corresponding instantiated arguments. In the context of traditional proof-theoretic instantiations, the existence of an attack is read off directly from
the syntactic/logical structure of arguments, be they modeled as trees or knowledge bases. In our approach, we access
concrete arguments through their inferential profiles. Because

• Rebuttal: R(ψa ∧ ψb ) = ∞, e.g. if ψa ¬ψb .
• Undermining: R(ψa ∧ ϕb ) = ∞, e.g. if ψa ¬ϕb .

73

ECAI-2012 Workshop WL4AI

First we observe that in our semantic reading, rebuttal is the
weakest condition because ψb ϕb . There are four qualitative
attack configurations involving two arguments, namely ϕa ∧ϕb
being compatible with neither, one, or both of ψa , ψb . If a
asymmetrically undermines b, we get the constraints R(ψa ∧
ϕb ) = ∞ and R(ψb ∧ ϕa ), R(ϕa ∧ ϕb ) = ∞. Then R(ψb |ϕa ∧
R
ϕb ) < R(ψa |ϕa ∧ ϕb ) = ∞, i.e. b ✄R
I a and a ✄I b under the
shallow attack semantics. It follows that naive undermining
is hard to justify for nonmonotonic arguments whose claim is
stronger than their premise set.

7

A possible cause of concern are the multiple distinct instantiations I available for any given A. Consider for instance
A = ({p, q, r}, {(p, q), (q, r)}), i.e. p ✄ q ✄ r.
A together with a shallow semantic instantiation I then induces ranking constraints, resulting from I and the representation of ✄, which are described by the conditionals in
∆A,I = {ψp ∧ ψq ❀ F , ψq ∧ ψr ❀ F , ϕp ∧ ϕq ❀ ψp ,
ϕq ∧ ϕr ❀ ψq , ϕp ❀ ψp , ϕq ❀ ψq , ϕr ❀ ψr }.
The canonical justifiably constructible ranking model, i.e. the
JZ-model, of ∆A,I then usually takes the form

Ranking extensions

Semantic instantiations offer new possibilities to identify reasonable argumentative positions and to determine the beliefs
they induce. More specifically, we may seek evaluation semantics more in line with interpreting argumentation frameworks by default knowledge bases. These may then be compared with traditional acceptability semantics specified and
justified at the abstract level. Suppose we have a framework A = (A, ✄) with a shallow instantiation (I, R), where
I is characterized by {(ϕa , ψa ) | a ∈ A} (ψa
ϕa ), and
R ⊆ [[∆I ]]rk is a collection of ranking measures representing
✄.
An obvious requirement for any acceptable argumentative
position S ⊆ A w.r.t. (I, R) is that its joint antecedents ϕS =
∧a∈S ϕa are not considered epistemically impossible by every
R ∈ R, i.e. there has to be some R ∈ R with R(ϕS ) = ∞. In
particular, the premises of the instantiated arguments must
be consistent w.r.t. . We call such an S coherent w.r.t. (I, R).
Within S, coherence precludes self-attacks a ✄ a, but not a ✄ b
for a = b.

A,I
Rjz
= R0 + ∞[ψp ∧ ψq ] + ∞[ψq ∧ ψr ] + 1[ϕp ∧ ϕq ∧ ¬ψp ] +
1[ϕq ∧ ϕr ∧ ¬ψq ] + 1[ϕp ∧ ¬ψp ] + 1[ϕq ∧ ¬ψq ] + 1[ϕr ∧ ¬ψr ].
A,I
A natural and powerful choice is therefore to set R = {Rjz
}.
But, if we freely choose I, only subjected to the validation of
A,I
∆A,I by Rjz
, nothing can prevent us from picking up ϕx , ψx
so that ψp ∧ ψr ∧ ϕq F . The resulting ≤I,R -maxima then
A,I
become {p}, {q}, because S = A and Rjz
maps ψA,{p} and
ψA,{q} to rank 3, which is minimal in ϕA . Unfortunately, this
violates a hallmark of conflict-based argumentative reasoning, namely the necessary activation of unattacked arguments,
which would impose the extension {p, r}. In fact, no defendable choice of R would bring us here the intended result. Thus,
we have to restrict or prioritize the choice of argument instantiations to obtain a reasonable ranking-based evaluation
semantics EI,R .

8

Definition 7.1 (Coherence)
S ⊆ A is coherent w.r.t. (I, R) iff R(ϕS ) = ∞.

Generic instantiations

Our observations above suggest to evaluate the A only
w.r.t. generic semantic instantiations, which are meant to explore the information available in A but try to stay as uncommitted or unbiased as possible, e.g. by minimizing logical
dependencies.
If abstract arguments are understood as black boxes, only
known through their external connections, we may stipulate
by default the logical independence of their syntactic instantiations. That is, for different a, b ∈ A, the non-logical vocabularies of Isyn (a) = (Σa , ∆a , ψa ) and Isyn (b) = (Σb , ∆b , ψb ) are
taken to be disjoint. Genericity furthermore invites to apply
Ockham’s razor and to give priority to the simplest instances
of Σa , ∆a , ψa . This matches the perspective of shallow semantic instantiation. All this amounts to introduce independent
propositional atoms Xa , Ya for each a ∈ A and to set

Each E ⊆ S now specifies a proposition given by
ψS,E := ϕS ∧ ∧a∈E ψa ∧ ∧a∈A−E ¬ψa .
It describes those worlds within the joint monotonic content
of the a ∈ S which validate exactly the (consequents of the)
arguments in E. Because I(a)✄R I(b) implies R(ψa ∧ψb ) = ∞,
the presence of conflicts a ✄ b in E makes ψS,E impossible.
Note however that the absence of binary conflicts alone may
be insufficient to prevent R(ψS,E ) = ∞, which could result
from n-ary conflicts, or a biased choice of logically dependent
ϕa , ψa .
Given a shallow instantiation (I, R), what are the most
reasonable coherent environments S ⊆ A and extension candidates E ⊆ S? First, we may focus on maximal coherent S ⊆ A
because premises should not be rejected a priori without good
reasons. Then it seems natural to choose those extensions E
which induce the most plausible ψS,E according to R.

Σa = {Xa }, ∆a = {Xa ❀ Ya }, and ψa = Ya .

• E ≤I,R E iff for each maximal coherent S ⊆ A with
E, E ⊆ S and for all R ∈ R, R(ψS,E ) ≤ R(ψS,E ).

This gives us a minimally informative non-trivial instantiation of a ∈ A. The corresponding generic shallow semantic instantiation is then defined by I A (a) = ([[ϕa ]], [[ψa ]]) =
([[Xa ]], [[Xa ∧ Ya ]]). I A is, up to renaming, completely specified by the cardinality of A. Hence, the specification of the
evaluation semantics will only depend on the choice of R. I A
determines a canonical default base ∆A encoding the ranking
constraints imposed by A. We have

E is said to be an (I, R)-ranking-extension of A, or E ∈
EI,R (A), iff E is a ≤I,R -maximum.

∆A = {ϕa ❀ ψa | a ∈ A} ∪ {ψa ∧ ψb ❀ F | a ✄ b or
b ✄ a} ∪ {ϕa ∧ ϕb ❀ ψa | a ✄ b, b ✄ a}.

Definition 7.2 (Ranking extensions) Let (I, R) be a
shallow instantiation of A = (A, ✄) and ≤I,R be a relation
over finite subsets of A such that

74

ECAI-2012 Workshop WL4AI

If, in the indices, we use ✄ to express one-sided, and ✁/✄ to
express any-sided attacks, because of genericity, the unique
justifiably constructible ranking model of ∆A is

The admissibility dogm, which ignores implicit global constraints, rejects the extensions {a}, {b}, {c}. On the other
hand, R = Rjz is characterized by the shifting coefficients
sa , sb , sc = 1, ra,b , rb,c , rc,a = 1, and supports R(ψa ) =
R(ψb ) = R(ψc ) = 4. Because all the other alternatives
are set to ∞, we actually get the maximal conflict-free sets
{a}, {b}, {c} as our extensions, i.e., Ejz violates admissibility.

A
Rjz
= R0 + Σa∈A 1[ϕa ∧ ¬ψa ] + Σa✄b 1[ϕa ∧ ϕb ∧ ¬ψa ] +
Σa✁/✄b ∞[ψa ∧ ψb ].
A
We then set R = RA
jz = {Rjz }. Because the sets {ϕa , ψa }
are logically independent, and the defaults expressing the
attacks a ✄ b just concern ϕa ∧ ϕb , only those propositions ϕa with a ✄ a are made impossible. In fact,
{ϕa ❀ ψa , ψa ∧ ψa ❀ F } rk ϕa ❀ F . Thus, in line with
intuition, (I A , RA
jz ) trivializes exactly the self-defeating arguA
ments. The maximal coherent subset of A w.r.t. RA
is
jz and I
A
therefore {a ∈ A | a ✄ a}. We observe that, by itself, Rjz does
not characterize A. For instance, A = ({a, b}, {(b, a), (a, a)})
and A = ({a, b}, {(b, a), (a, b), (a, a)}) produce the same
A
A
= R0 + ∞[ϕa ] + 1[ϕb ∧ ¬ψb ]. Actually, we
Rjz
= Rjz
can always drop or add links between a self-reflective and
another argument because the details are absorbed by the
impossibility of the joint area. That is, frameworks with
the same set of 1-loops and sharing the same attack strucA
ture for the non-reflective arguments determine the same Rjz
.

Attack on 2-loop: {a, b, c} with a ✄ b ✄ c ✄ b.
Because sa , sb , sc = 1 and ra,b = 1, we get R(ψa ) =
2, R(ψb ) = R(ψc ) = 3, R(ψa,b ) = R(ψb,c ) = ∞, but
R(ψa,c ) = 1. Hence Ejz (A) = {{a, c}}, which includes the
canonical stable extension.
Attack from 2-loop: {a, b, c} with b ✄ a ✄ b ✄ c.
Because sa , sb , sc = 1 and rb,c = 1, we get R(ψa ) = 3, R(ψb ) =
2, R(ψc ) = 3, R(ψa,b ) = R(ψb,c ) = ∞, and R(ψa,c ) = 2.
Hence Ejz (A) = {{b}, {a, c}} consists of the stable extensions.
3,1-loop: {a, b, c} with a ✄ b ✄ c ✄ a ✄ a.
Here S = {b, c} is the maximal coherent set and we get
R(ψb ) = 1, R(ψb,c ) = 3 and R(ψc ) = 2. It follows that Ejz (A)
= {{b}}. This extension is not admissible. Note that the stage
extension {c} is also not included.

JZ-evaluation semantics: Ejz = EI A ,RA .
jz

Alternatively, we may seek a more robust evaluation semantics based on system J. It puts all the constructible models of
∆A into the set RA
j .
RA
j

3,2-loop: {a, b, c} with b ✄ a ✄ b ✄ c ✄ a.
We obtain R(ψa ) = 4, R(ψb ) = 3, and R(ψc ) = 3, giving us
Ejz (A) = {{b}, {c}}. We observe that the stable extension {b}
is here the only admissible one.

= {R0 + Σa∈A sa [ϕa ∧ ¬ψa ] + Σa✄b ra,b [ϕa ∧ ϕb ∧ ¬ψa ] +
Σa✁/✄b ∞[ψa ∧ ψb ] | 0 < sa , ra,b }.

It follows that the ranking-based evaluation semantics Ejz diverges from the other main proposals found in the literature.

Here, similar remarks apply concerning reflective arguments.

9

As documented by the previous examples, the well-justified
Ejz exhibits a slightly unorthodox behaviour. It is therefore
particularly interesting to see how it handles some common
postulates for extension semantics (see e.g. [BCG 11]). To
reflect our broader logical perspective, we will adapt the notation somewhat.

Properties and principles

We are now ready to investigate how ranking extension semantics handles some standard examples. For each instance,
we will specify A and the full attack relation ✄. Assuming
genericity, A− = {a ∈ A | a ✄ a} is the only maximally coherent subset and so it is enough to compare RA (ψA− ,E ) for
E ⊆ A− . Let us use ψx1 ...xn to refer to ψA− ,{x1 ...xn } .

Isomorphy.
For each isomorphism f : A ∼
= A , E(A ) = f E(A).

Simple reinstatement: {a, b, c} with a ✄ b ✄ c.

Conflict-freedom.
If E ∈ E(A) and a, b ∈ E, then a ✄ b.

The grounded extension {a, c} is the canonical result put forward by any standard evaluation semantics. First, let us consider the robust semantics based on Rj , which includes all the
ranking constructible R |= ∆A . Suppose sa = sb = sc = 1,
ra,b = 1, and rb,c = 1. The resulting R is clearly a model of
∆A which satisfies R(ψa ) = 3, R(ψa,c ) = 2, R(ψc ) = 4 and
R(ψb ) = 3. The other alternatives within ϕS = ϕA get rank
∞. Because R(ψa,c ) is minimal, this would therefore support
the usual extension E = {a, c}. But now let’s set rb,c = 3.
Again we get R |=rk ∆A , but also R(ψa ) = 5, R(ψa,c ) =
4, R(ψc ) = 6 and R(ψb ) = 3, which now backs the unwanted
extension E = {b}. It follows that Rj does not validate
reinstatement. But the JZ-semantics Rjz does. In fact, the
first ranking construction R above represents the unique JJ,
i.e. the JZ-model. Because of the role of simple reinstatement
in argumentative inference, we will therefore focus on Ejz .

Full reinstatement.
If E ∈ E(A), a ∈ A, and for each b ✄ a there is an a ∈ E with
a ✄ b, then a ∈ E.
Non-reflective reinstatement.
If E ∈ E(A), a ∈ A, for each b ✄ a there is an a ∈ E with
a ✄ b, and there is no a ∈ E with a ✄ a , then a ∈ E.
I-maximality.
If E, E ∈ E(A) and E ⊆ E , then E = E , i.e. the extensions
are inclusion-maximal.
Directionality.
Let A1 = (A1 , ✄1 ), A2 = (A2 , ✄2 ) be such that A1 ∩ A2 = ∅,
✄0 ⊆ A1 × A2 , and A = (A1 ∪ A2 , ✄1 ∪ ✄0 ∪ ✄2 ). Then
E(A1 ) = {E ∩ A1 | E ∈ E(A)}.

3-loop: {a, b, c} with a ✄ b ✄ c ✄ a.

75

ECAI-2012 Workshop WL4AI

We note that the ranking-based mechanisms for conditional prioritization deployed in system JZ/JJ are much more
sophisticated than standard specificity-based strategies for
rule prioritization. This is well-known from default reasoning. But even in the limited application context above, a
preference-based argument evaluation which defines attack
using specificity-derived preferences and conflict, often produces results incompatible with what the ranking extension
semantics suggests, e.g. for variants of loops.

Among the traditional extension semantics, only the
grounded, the preferred, and the ideal semantics satisfy all
these requirements [BG 07]. What about our ranking extension semantics based on system JJ/JZ?3
Theorem 9.1 (Basic properties)
Ejz = Ejj verifies isomorphy, conflict-freedom, non-reflective
reinstatement, and I-maximality. It falsifies full reinstatement
and directionality.
The violation of reinstatement directly follows from how the
semantics handles 3-loops. The failure of directionality may
reflect the slight contrapositive effects characteristic of quasiprobabilistic default reasoning. On the other hand, directionality also fails for other prominent approaches, like the semistable semantics, and, as usual, can be enforced by using Ejz
as the base function for a SCC-recursive semantics [BGG 05].
To conclude, we take a look at two further properties inspired by the cumulativity principle for nonmonotonic inference. They state that if we drop an argument rejected by
every extension, then this shouldn’t add, resp. erase, skeptical conclusions. A|B here means A restricted to B.

10

Conclusions

Thus, although argumentative inference relies on semantic
methods which specify default inference notions verifying cumulativity at the factual level, it fails itself to validate cumulativity.

In the present paper we have given some first hints on how the
powerful ranking construction paradigm for default reasoning
can be exploited to interpret abstract argumentation frameworks and to specify corresponding applicability semantics.
To illustrate this, we have focused on the simplest class of semantic instantiations, where arguments are essentially interpreted as conditionals or pairs of monotonic and nonmonotonic content. While our ranking-based extension semantics
is orthogonal to existing approaches, its behaviour is quite
promising. Our results thus show that there are interesting
alternatives to the traditional instantiation concepts.
This work is of course still rather preliminary, the exploration of the semantic perspective has just begun. In
addition to a more thorough theoretical investigation of the
basic account, we plan to analyze also more sophisticated
default-based instantiation models, which may bring us closer
to real-world argumentation. Another interesting research
thread will be to consider richer hyperframeworks, which
may profit from powerful semantic foundations.

Theorem 9.2 (Non-cumulativity)
Ejz violates Arg-CUT and Arg-CM.

Bibliography

Argumentative cut (Arg-CUT)
If a ∈ ∪E(A), then ∩E(A|A − {a}) ⊆ ∩E(A).
Argumentative cautious montony (Arg-CM)
If a ∈ ∪E(A), then ∩E(A) ⊆ ∩E(A|A − {a}).

The counterexample for Arg-CUT is provided by a ✄ b ✄ c ✄
a ✄ c, because {a} ⊆ {a} ∩ {b}. The one for Arg-CM is obtained by adding furthermore b ✄ a. Here {b} ⊆ {a} ∩ {b}.
While the preferred semantics also violates Arg-CM, it verifies Arg-CUT. In fact, for context-based nonmonotonic reasoning, CUT without CM is a common scenario. The lesson
we may draw from this, in addition to recognizing the intrinsically contextual character of argumentative reasoning, is that
the extensions by themselves only partly reflect the inferential reality, so that dropping seemingly irrelevant parts, like
necessarily rejected arguments, may still have a considerable
effect. Also observe that we interpret arguments by default
conditionals. But in default reasoning, if we add to the default base individual defeasible conclusions as necessities, we
may arrive at drastically different conclusions. Furthermore,
cumulativity typically fails at the default level. The above result may therefore just confirm that attack frameworks are
conceptually closer to default sets than to factual evidence.
Another attempt to merge ideas from plausibilistic default
reasoning and argumentation theory has been presented in
[KIS 11]. It combines defeasible logic programming [GS 04]
with a prioritization criterion based on system Z. Although
the goals and the formal details of their account are quite
different from what we have done, this research direction looks
promising also from our perspective.
3

BCG 11 P. Baronia1, M. Caminada, M. Giacomin. An introduction to argumentation semantics. The Knowledge Engineering Review 26(04):365-410, 2011.
BG 07 P. Baronia1, M. Giacomin. On principle-based evaluation of extensionbased argumentation semantics. AIJ 171:675-700, 2007.
BGG 05 P. Baroni, M. Giacomin, G. Guida. SCC-recursiveness: a general schema
for argumentation semantics. AIJ 168:163-210, 2005.
BH 08 P. Besnard, A. Hunter. Elements of Argumentation. The MIT Press, 2008.
BP 03 R.A. Bourne, S. Parsons: Extending the maximum entropy approach to
variable strength defaults. Annals of Mathematics and Artificial Intelligence
39(1-2): 123-146, 2003.
BSS 00 S. Benferhat, A. Saffiotti, P. Smets. Belief functions and default reasoning. Artificial Intelligence 122(1-2): 1-69, 2000.
CA 07 M.W.A. Caminada, L. Amgoud. On the evaluation of argumentation formalisms. Artificial Intelligence 171(5-6):286-310, 2007.
CW 11 M.W.A. Caminada, Y. Wu. On the Limitations of Abstract Argumentation. Proceedings of BNAIC 2011, Gent, 2011.
Dun 95 P. Dung. On the acceptability of arguments and its fundamental role in
nonmonotonic reasoning, logic programming and n-person games. AIJ 77:321357, 1995.
FH 01 N. Friedman, J. Halpern. Plausibility measures and default reasoning.
Journal of the ACM, 48(4):648-685, 2001.
GMP 93 M. Goldszmidt, P. Morris, J. Pearl. A maximum entropy approach to
nonmonotonic reasoning. IEEE Transactions of Pattern Analysis and Machine
Intelligence, 15:220-232, 1993.
GS 04 A.J. Garcia, G.R. Simari. Defeasible logic programming: An argumentative
approach. Theory and Practice of Logic Programming, 4(1):95138, 2004.
KI 01 G. Kern-Isberner. Conditionals in nonmonotonoic reasoning and belief revision, LNAI 2087. Springer, 2001.
KIS 11 G. Kern-Isberner G.R. Simari. A Default Logical Semantics for Defeasible
Argumentation. Proc. of FLAIRS 2011, AAAI Press, 2011.
LM 92 D. Lehmann, M. Magidor. What does a conditional knowledge base entail?
Artificial Intelligence, 55:1-60, 1992.
Pea 90 J. Pearl. System Z: a natural ordering of defaults with tractable applications to nonmonotonic reasoning. TARK 3: 121-135. Morgan Kaufmann, 1990.
Pra 10 H. Prakken. An abstract framework for argumentation with structured
arguments. Argument and Computation, 1(2):93124, 2010.
Spo 88 W. Spohn. Ordinal conditional functions: a dynamic theory of epistemic
states. Causation in Decision, Belief Change, and Statistics (eds. W.L. Harper,
B. Skyrms): 105-134. Kluwer, 1988.
Spo 90 W. Spohn. A general non-probabilistic theory of inductive reasoning. Uncertainty in Artificial Intelligence 4 (eds. R.D. Shachter et al.): 149-158. NorthHolland, Amsterdam, 1990.
Spo 09 W. Spohn. A survey of ranking theory. Degrees of Belief. An Anthology
(eds. F. Huber, C. Schmidt-Petri): 185-228. Oxford University Press, 2008.
Wey 95 E. Weydert. Default entailment: A preferential construction semantics
for defeasible inference. KI 1995: 173-184. Springer, 1995.
Wey 95b E. Weydert. Defaults and infinitesimals. Defeasible inference by nonarchimdean entropy maximization. UAI 95: 540-547. Morgan Kaufmann, 1995.
Wey 96 E. Weydert. System J - revision entailment. FAPR 96: 637-649. Springer,
1996.
Wey 98 E. Weydert. System JZ - How to build a canonical ranking model of a
default knowledge base. KR 98: 190-201. Morgan Kaufmann, 1998.
Wey 03 E. Weydert. System JLZ - Rational default reasoning by minimal ranking
constructions. Journal of Applied Logic 1(3-4): 273-308. Elsevier, 2003.
Wey 11 E. Weydert. Semi-stable extensions for infinite frameworks. In Proc.
BNAIC 2012: 336343.

An initial proof of directionality and reinstatement was erroneous.

76

ECAI-2012 Workshop WL4AI

A logic for approximate reasoning
with a comparative connective
Thomas Vetterlein1
of relational implication would significantly complicate the interpretation of automatically generated arguments. In the present work, we
are interested to avoid this complication as well. This is why we deal
only with statements of the form “fact A suggests fact B (to a possibly restricted extent)”.
The completeness proof does not become easier by the restriction
of the language. The typical technical difficulties arise also in the
present framework. Recall that completeness theorems exist for LAE
[8, 5]. For the “pure” version of LAE, however, based on a countable
number of propositions and an arbitrary similarity space, an axiomatisation has not yet been found. By now, certain additional conditions have been used, most remarkably finiteness of the language and
of the model. This restriction cannot easily be removed. A conjunction of all variables, each of which can be negated, has been called
a m.e.c.; in the presence of an infinite number of variables, axioms
containing m.e.c.’s are not usable.
To find an axiomatisation for LAE requires in fact a solution
for two problems. When, in the completeness proof, we construct
a model of a theory of LAE we must (1) ensure the symmetry of
the similarity relation, and (2) achieve that the degree of provability
of one proposition from another one leads to a Hausdorff similarity.
Both problems can be overcome by means of m.e.c.’s.
The present contribution is meant as a step towards an axiomatisation of LAE in a more general framework. That is, the two axiom
schemes of the proof system in [8] that contain m.e.c.’s is no longer
used. However, we offer a progress only in case of one of these axiom schemes. The second one is avoided by a simple generalisation
of the model and a more elegant solution would requires surely not
less of an effort than in the present case.
We tackle problem (2). The key idea of the present approach is
to use a new connective, in addition to conjunction, disjunction, and
negation. The connective has a comparative character and is denoted
by ; a proposition α
β holds in all worlds that are similar to α
at least to the degree to which they are similar to β. Problem (1), in
contrast, remains unsolved. To overcome it, we simply give up the
requirement of the symmetry of the similarity relation; we work with
a quasisimilarity relation.
A connective of a similar type like
can be found in other areas
of logic as well. A comparative connective is present, for instance, in
logics of preference; see, e.g., von Wright’s monograph [12].
Furthermore, the connective
might be found to have some resemblance with the implication connective → in fuzzy logic. However, this resemblance mainly exists on the formal level; otherwise
the two concepts are not comparable, simply because the settings are
different. Our setting uses a notion of proximity and α
β holds
whenever α is closer than β. In fuzzy logic, α → β is the weakest
proposition implying β when combined with α. We note that, in par-

Abstract. The Logic of Approximate Entailment (LAE), introduced
in R. Rodr´ıguez’s Ph.D. Thesis, uses a graded version of the classical
consequence relation. In LAE, reasoning about facts is possible even
if relationships between them hold only approximately.
Here, we consider a modification of LAE. Namely, we introduce
an additional binary connective
expressing the relative proximity
of a proposition when compared to another one. We propose a proof
system for the new logic and show finite strong completeness. Certain common problems with the axiomatisation of logics for approximate reasoning are shown to be avoidable in the extended language.

1 Introduction
Approximate reasoning, proposed originally by E. Ruspini in his
seminal paper [9], aims at a formalisation of implicative relationships between facts for the case that these relationships do not necessarily hold strictly. The framework that he proposed is as simple
as convincing. To model the statement that a proposition α implies
another one β to a possibly non-one degree d, a set of worlds W is
endowed with a similarity relation s; α and β being interpreted by
d
A ⊆ W and B ⊆ W , respectively, the statement α ⇒ β is satisfied
if A ⊆ Ud (B). Here, Ud (B) contains all worlds similar to B to the
degree at least d.
Logics for metric spaces have been studied in the past in various
contexts. Among the more recent examples, we may mention the papers [11, 10]. Here, we follow the lines of research on logics that
are associated with approximate reasoning. For an overview over the
field to which we intend to contribute, we refer to [6]. Among the
proposed formalisms we find, for instance, logics that use a graded
modal operator to express similarity [4, 3]. An alternative possibility is to use a graded entailment relation; this idea appears in [2, 3]
and was systematically developped in R. Rodr´ıguez Thesis [8]. The
Logic of Approximate Entailment, or LAE for short, is in the centre
of our own interest.
The expressive power of LAE is lower than in case of the modal
logics. Here, we even go one step further and restrict the expressiveness of the language once more. Our motivation is the following.
Our ultimate aim is to develop logics for the automatic generation
of arguments as done by expert systems; the medical expert system
CADIAG-2 [1] is an example. System like CADIAG-2 are not based
on probability theory; they are rather designed to produce a chain
of arguments which could originate from a human expert. Here, the
inference relation appears exclusively at the outermost level; implications do not occur as proper subformulas. In fact, to allow the nesting
1

Johannes Kepler University Linz, Austria, email: Thomas.Vetterlein@jku.at

77

ECAI-2012 Workshop WL4AI

ticular, that the problem of interpreting the implication in fuzzy logic
in an intuitively satisfactory manner is not inherited.

Let (W, s) be a quasisimilarity space. An evaluation for LAEC is
a structure-preserving mapping v from F to (W, s). A conditional
d

formula α ⇒ β is satisfied by an evaluation v if

2 The logic LAEC

v(α) ⊆ Ud (v(β)).

Our setting for approximate reasoning follows the lines of the papers
[2, 4, 8, 6]. The basic framework consists, first of all, of a non-empty
set W , called the set of possible worlds. Second, W is endowed with
a quasisimilarity relation, which reflects the assumption that a given
world may more or less resemble to another one.
In contrast to earlier papers on the topic, we allow the similarity
to be non-symmetric. In spite of the afore mentioned proof-technical
background, we can say that this choice is in line with applications
where similarity models an agent’s subjective estimations. In this
case, indeed, it is reasonable to have a degree telling how close a
property w is when seen from v, and a second one for the converse
viewpoint.

A theory of LAEC is a set of conditional formulas. We say that a
d
theory T semantically entails a conditional formula α ⇒ β if all
d
evaluations satisfying all elements of T also satisfy α ⇒ β.
We present now a calculus for LAEC. Whereas the content of the
rules (at least those that do not involve ) reflects the content of
the axioms used in earlier papers on LAE, the chosen style of the
syntax is inspired by the Gentzen-style proof systems that have been
developped in fuzzy logic during the last years [7].
In what follows, a CPL tautology is meant to be a formula that
arises from a tautology of classical propositional logic by uniform
replacement of its atoms by propositional formulas of LAEC.
We note furthermore that, for c ∈ [0, 1], c c is abbreviated as c2 .

Definition 2.1. Let W be any non-empty set; let [0, 1] be the real unit
interval; and let be the Łukasiewicz t-norm. A function s : W ×
W → [0, 1] is called a quasisimilarity relation on s w.r.t. if, for
any u, v, w ∈ W ,

Definition 2.4. The rules and axioms of LAEC are, for any α, γ, β ∈
F, for any finite set Γ ⊆ F, and for any c, d ∈ [0, 1], the following:
d

d

Γ, α, β ⇒ γ
(S1) s(u, u) = 1 (reflexivity),

d

d

Γ, α ⇒ β

d

Γ, α ⇒ γ

s(v, w) ≤ s(u, w) ( -transitivity).

d

Γ, β ⇒ γ

Γ⇒α

d

d

Γ, α ∨ β ⇒ γ

In this case, we call (W, s) a quasisimilarity space. The similarity of
a world w ∈ W with a set A ⊆ W of worlds is then defined by

c

Γ⇒β

Γ⇒ α∨β

d

1

α⇒β

Γ⇒α

α
c2

1

d

⇒β

Γ ⇒ β

k(w, A) = sup s(w, a).

1

α⇒α

a∈A

Finally, for A ⊆ W and d ∈ [0, 1] we put

Γ, α

β

α
d

β⇒γ

α

1

γ⇒α

β, β

γ

d

Γ, (¬α ∧ β)

α⇒γ

d

Γ⇒γ

Ud (A) = {w ∈ W : k(w, A) ≥ d}.
c

Γ⇒α

In what follows, we will use the following well-known notion.
Given a quasisimilarity s : W × W → [0, 1], there is a natural way
to measure the similarity between two subsets of W . The Hausdorff
quasisimilarity induced by s is given by

d

α⇒γ

c d

Γ ⇒ γ
c

Γ⇒α
d

d

Γ⇒⊥

, where d ≤ c

1

Γ⇒⊥

Γ⇒α

h(A, B) = inf k(a, B)

, where d > 0

1

α⇒β

0

a∈A

α⇒β

1

α ∧ ¬β ⇒ ⊥

= inf sup s(a, b)
a∈A b∈B

1

α ⇒ β, where ¬α ∨ β is a CPL tautology

for A, B ⊆ W . Note that this measure of the difference between two
sets was also used by Ruspini in his influential paper [9].

d

The notion of proof of a conditional formula α ⇒ β from a theory
d
T is defined as usual; we write T α ⇒ β if it exists.
1
A theory T is called consistent if T does not prove ⇒ ⊥.

Definition 2.2. Let (W, s) be a quasisimilarity space. For any pair
A, B ⊆ W , we define
A

d

Γ, α ∧ β ⇒ γ

(S2) s(u, v) = 1 implies u = v (separability),
(S3) s(u, v)

Γ⇒β

To illustrate how statements in LAEC read, we consider the following example:

B = {w ∈ W : k(w, A) ≥ k(w, B)}.

We define the Logic of Approximate Entailment with Comparison,
or LAEC for short, model-theoretically as follows.

Lemma 1. The following rule is derivable in LAEC:
d

Γ ⇒α∨β

Definition 2.3. The propositional formulas of LAEC are built up
from a countable set of variables ϕ0 , ϕ1 , . . . and the constants ⊥,
by means of the binary operators ∧, ∨, and , and the unary operator
¬. The set of propositional formulas is denoted by F. A conditional
formula of LAEC is a triple consisting of two propositional formulas
α and β as well as a value d ∈ [0, 1], denoted

Γ, α
Proof. We just note that both α
provable in LAEC.

d

β⇒α
1

β, α ⇒ α and α

1

β, β ⇒ α are

In words, we can express Lemma 1 as follows: If some world w
has a similarity ≥ d to α or β and w has a greater similarity to α
than to β, then w has the similarity ≥ d to α.

d

α ⇒ β.

78

ECAI-2012 Workshop WL4AI

3 Completeness for LAEC

(1) ϑji ≤ 14 density(pT j−1 );

The proof of the completeness theorem requires some preparations.

;
(2) ϑji ≤ 14 ϑj−1
i

Lemma 2. The following rules are derivable in LAEC:

for any γ, δ ∈ F,
(3) |pT j (γ, δ) − pT j−1 (γ, δ)| ≤ ϑj−1
i

i

i

1

1

α

1

γ⇒β

γ

1

α⇒γ

γ

d

Γ⇒β

β

α

d2

Γ, α ⇒ β
Γ, β

d

α⇒γ

Γ, α

i

where 1 ≤ j ≤ ki .
Let T1 = T10 = T and ϑ1 = ϑ01 = ϑ. Assume that, for i ≥ 1,
Ti = Ti0 and ϑi = ϑ0i are already defined. Let Vi = {vi0 , . . . , viki }
be the range of pTi , where vi1 < . . . < viki = 1. Let Tiki +1 = Ti
and ϑki i +1 = ϑi . For j = 1, . . . , ki , let

β⇒α

α⇒β

ε ∧ (αi ∨ βi ) ⇒ ⊥ and

pTi (ε, αi ) = pTi (ε, βi ) = vij }

d

Γ⇒γ
and

d

Γ ⇒α∨β
Γ, α

1

Gij = {ε ∈ F : T

d

β⇒γ

d

β⇒α

ϑji =

In what follows, r , where r ∈ R+ , denotes the smallest natural
number greater than or equal to r.

1
4

1
j
1−vi

∧ density(pT j−1 )).
(ϑj−1
i
i

j

j

v +ϑ

Tij = Tij−1 ∪ {ε i⇒ i αi : ε ∈ Gij }.

Definition 3.1. Let T be a theory of LAEC, and let α, β be propositional formulas. We define the provability degree of the pair α, β
w.r.t. T by

Properties (1) and (2) are obviously fulfilled. Let furthermore γ, δ ∈
c
F and consider a proof of γ ⇒ δ from Tij , where c = pT j (γ, δ).
i

c

pT (α, β) = sup {t ∈ [0, 1] : T

Then there is a proof of γ ⇒ δ from Tij+1 , where c = (c−nϑji )∨0,
1
where 0 ≤ n ≤
j . Then c is the largest element ≤ c in the

t

α ⇒ β}.

1−vi

range of pT j−1 , hence c = pT j−1 (γ, δ), and (3) follows.

Furthermore, by the density of pT , denoted by density(pT ), we
mean the infimum of all differences between distinct elements of the
range of pT .

i

i

Ti . Let γ, δ ∈ F; then for any i, j, we have

|pT j (γ, δ) − pT (γ, δ)| ≤ 31 density(pT j+1 ).

If the theory T is understood, we will write p instead of pT .
We note that, in the following proofs, we consider [0, 1] as a lattice
and write ∧, ∨ for the minimum and maximum operations, respectively.

i

i

1
ϑ|.
3

Claim (E1) and (E3)
In particular, |pT (γ, δ) − pT (γ, δ) ≤
follow as well as the consistency of T .
To show (E2), let ε0 , ε1 , . . . and α, β ∈ F be as indicated. Note
that, since all Ti are finite, pTi (εl , α), l = 0, 1, . . ., is eventually
constant. There are two possibilities:
Case 1. For some i and j and some m ≥ 1, |pTi (εl , α) −
pTi (εl , β)| = d > 0 for all l ≥ m. Then |pT (εl , α)−pT (εl , β)| ≥
1
d for all l ≥ m, and claim (E2) follows.
3
Case 2. For all i, pTi (εl , α) = pTi (εl , β) eventually. This is then
in particular the case for the i that indexes the pair (α, β). Let m
and j be such that pTi (εl , α) = pTi (εl , β) = vij for all l ≥ m.
Then εm ∈ Gij for all m ≥ l. It follows pT j (εm , β) = vji and

Lemma 3. Let T be a consistent finite theory of LAEC such that
e
T does not prove the conditional formula ζ ⇒ η. Then there is a
consistent theory T ⊇ T such that the following holds:
e

(E1) T does not prove ζ ⇒ η.
1

(E2) For any sequence (εi )i∈N in F such that T proves ε1 ⇒ ε0 ,
1
ε2 ⇒ ε1 , . . ., and for any pair α, β ∈ F such that T proves
1
1
α ∧ β ⇒ ⊥ and ε ∧ (α ∨ β) ⇒ ⊥, i p(εi , α) = i p(εi , β).

i

pT j (εm , α) = vij − ϑji . But this implies that the difference remains

(E3) There is an l ∈ [0, 1) such that, for any pair α, β ∈ F, either
p(α, β) = 1 or p(α, β) ≤ l.

i

strictly positive for all extensions of Tij ; a contradiction. Thus Case
2 never occurs.

Proof. Note first that e > 0. Let e¯ ∈ [0, 1] the largest value < e
e
¯
0
ζ ⇒ η
such that T
ζ ⇒ η. Such a value exists because T
and because T , and consequently the range of pT , is finite. Put ϑ =
(¯
e − e) ∧ density(pT ).
Let (αi , βi ), i < ω, be all pairs of formulas α and β such that T
1
proves α ∧ β ⇒ ⊥. We will define a sequence of consistent finite
theories

Theorem 3.1. Let T be a consistent finite theory of LAEC. Then T
e
proves a conditional formula ζ ⇒ η if and only if T semantically
e
entails ζ ⇒ η.
Proof. It is not difficult to check the soundness. To prove the come
pleteness, assume that T does not prove ζ ⇒ η. By Lemma 3, we
can assume that T fulfills the following conditions instead of the
e
indicated ones: T is consistent, does not prove ζ ⇒ η, and has properties (E2) and (E3).
1
For α, β ∈ F, let α β if T
α ⇒ β, and let α ≈ β if α β
and β
α. Then ≈ is an equivalence relation, and it is not difficult
to see that ≈ is compatible with ∧, ∨, and ¬. By Lemma 2, ≈ is
also compatible with . Endowed with the induced operations and
the classes of ⊥ and , the quotient ( F ; ∧, ∨, ¬, , ⊥ ,
), is

T = T1 = T10 ⊆ . . . ⊆ T1k1 =
= T2 = T20 ⊆ . . . ⊆ T2k2 =
=

i

Let T =

...

and along with each theory Tij , we will define values ϑji with the
following properties:

79

ECAI-2012 Workshop WL4AI

The last step to show that p is induced by s is the proof of

a Boolean algebra endowed with the additional operation . Note
that F and thus also F is countable.
As our first step, we establish some facts about the provability
d
degree p. Clearly, for any α, β ∈ F and d ∈ [0, 1], T
α ⇒ β

p(α, β) = inf k(w, β).
w α

In case that α ≈ ⊥, there is no w ∈ W such that w
α, and
the claim is verified noting that p(⊥, β) = 1. Assume that α ≈ ⊥.
Obviously, p(α, β) ≤ maxw ε p(ε, β) = k(w, β) for all w
α.
Similarly as above, we choose a sequence α = α0 α1 . . . that
is a basis of a filter w
α such that p(α, β) = p(αi , β) for all i.
Then p(α, β) = k(w, β).
Consider now again the Boolean homomorphism ι. We have to
show that

d

implies d ≤ pT (α, β), and d < pT (α, β) implies T α ⇒ β.
It is furthermore easily seen that, for any α1 , α2 , β ∈ F,
p(α1 ∨ α2 , β) = p(α1 , β) ∧ p(α2 , β).
Furthermore, for any α, β1 , β2 , there are α1 , α2 such that α ≈ α1 ∨
α2 and
p(α, β1 ∨ β2 ) = p(α1 , β1 ) ∧ p(α2 , β2 ).
Indeed, we may choose α ∧ (β1
β2 ) for α1 and α ∧ (β2
β1 )
for α2 .
Let W be the set of prime filters of F . Due to the consistency of
T , W is non-empty. For w ∈ W and α ∈ F, we write w
α for
α ∈ w. Then ι : F → PW, α → {w ∈ W : w
α} is an
injective homomorphism of Boolean algebras.
For w ∈ W and α ∈ F, we put

ι(α

β) = {w ∈ W : k(w, α) ≥ k(w, β)}.

Indeed, w α β implies k(w, α) ≥ k(w, β). Furthermore, from
k(w, α) > k(w, β) it follows w
α
β. In case that k(w, α) =
k(w, β) = 1, we have seen above that w
α and w
β and thus
w α
β. Finally, k(w, α) = k(w, β) < 1 contradicts condition
(E2) of Lemma 3 above.
The proof is complete that (W, s) provides a model for LAEC.
Furthermore, it is easily verified that all elements of T are satisfied
e
and that ζ ⇒ η is not satisfied.

k(w, α) = sup p(ε, α),
w ε

and for v, w ∈ W , put

4 Conclusion

s(v, w) = inf k(v, δ).
w δ

We have presented a logic for approximate reasoning – LAEC, the
Logic of Approximate Entailment with Comparison. LAEC differs
from LAE, the Logic of Approximate Entailment, in that it contains
a connective that is non-standard in approximate reasoning: the comparative connective . A further difference between LAEC and LAE
is that our models are quasisimilarity spaces rather than similarity
spaces. We have presented a Gentzen-type proof system for LAEC
and have proven its completeness for finite theories.
The rules are transparent and allow a straightforward interpretation, the new ones for
included. Formulas of special syntactical
form are not required.
There is a lot of room for further research. Most desirably, it
should be examined if the possibly non-symmetric similarity spaces,
allowed in the present approach, can be excluded.
In fact, we do not know if the symmetry of the similarity relation
would actually matter. That is, we are not sure if the calculus presented here is not already complete also for the symmetric case. We
are not able to provide an example to show the difference.
Another topic concerns proof-theory. This is an aspect that, according to our impression, has been largely neglected for logics of
the type discussed here. However, if such logics are to be used for
expert systems, the question of an automatic proof search, decidability and the like should be examined as well.

It is not difficult to check that s : W ×W → [0, 1] is reflexive and transitive. To see that also separability holds for s, that is, to see that
s is actually a quasisimilarity, assume s(v, w) = 1, but v = w, for
some v, w ∈ W . Then k(v, δ) = 1 for some w δ such that v δ.
Consequently, for any ϑ < 1, there is an ε such that δ ∧ ε ≈ ⊥ and
p(ε, δ) > ϑ. But p(ε, δ) < 1 then, and a contradiction to property
(E3) arises.
Note that p can be viewed as a function on F instead of F, and
consequently also as a function on ι( F ), a Boolean subalgebra of
PW . Adopting the latter view, we claim that p coincides with the
Hausdorff quasisimilarity induced by s. To see this, we first show
k(w, α ∨ β) = k(w, α) ∨ k(w, β)
for any w ∈ W and α, β ∈ F. Clearly, k(w, α ∨ β) ≥ k(w, α) ∨
k(w, β). Furthermore, by definition k(w, α ∨ β) = supw ε p(ε, α ∨
β), hence for any ϑ > 0 there is a particular ε such that w ε and
k(w, α ∨ β) − ϑ ≤ p(ε , α ∨ β). Then p(ε , α ∨ β) = p(ε1 , α) ∧
ε1 ,
p(ε2 , β), where ε1 ∨ ε2 ≈ ε . We assume, w.l.o.g., that w
and we conclude k(w, α ∨ β) − ϑ ≤ p(ε1 , α) ≤ supw ε p(ε, α) =
k(w, α) ≤ k(p, α) ∨ k(w, β), that is, k(w, α ∨ β) ≤ k(p, α) ∧
k(w, β).
We next show
k(v, α) = sup s(v, w)
w α

ACKNOWLEDGEMENTS

for v ∈ W and α ∈ F. Assume first that α ≈ ⊥. Then k(v, α) =
k(v, ⊥) = supw ε p(ε, ⊥) = 0 because ε ∈ w for some w ∈ W

The author was partially supported by the Vienna Science and Technology Fund (WWTF) Grant MA07-016.

d

implies ε ≈ ⊥, hence T ε ⇒ ⊥ for any d > 0. Furthermore, there
is no prime filter w ∈ W containing α = ⊥ ; hence the claim
follows.
Assume that α ≈ ⊥. Then we obviously have k(v, α) ≥
inf w δ k(v, δ) = s(v, w) for all w α. Now, note that for any χ ∈
F, k(p, α) = k(p, (α∧χ)∨(α∧¬χ)) = k(p, α∧χ)∨k(p, α∧¬χ);
it follows that there is a sequence α = α0 α1 . . . that is a basis
of a filter w α such that k(v, αi ) = k(v, α) for all i, in particular
k(v, α) = s(v, w).

REFERENCES
[1] K.-P. Adlassnig and G. Kolarz, ‘Cadiag-2: Computer-assisted medical
diagnosis using fuzzy subsets’, in Approximate Reasoning in Decision
Analysis, eds., M. M. Gupta and E. Sanchez, 219–247, North-Holland
Publ. Comp., Amsterdam, (1982).
[2] Didier Dubois, Francesc Esteva, Pere Garcia, Llu´ıs Godo, and Henri
Prade, ‘A logical approach to interpolation based on similarity relations’, Int. J. Approx. Reasoning, 17(1), 1–36, (1997).

80

ECAI-2012 Workshop WL4AI

[3] Francesc Esteva, Pere Garcia, and Llu´ıs Godo, ‘Similarity-based reasoning’, in Discovering the World with Fuzzy Logic: Perspectives and
Approaches to Formalization of Human-Consistent Logical Systems,
eds., Vil´em Nov´ak and Irina Perfilieva, 367–393, Springer (PhysicaVerlag), Heidelberg, (2000).
[4] Francesc Esteva, Pere Garcia, Llu´ıs Godo, and Ricardo Rodr´ıguez, ‘A
modal account of similarity-based reasoning’, Int. J. Approx. Reasoning, 16(3-4), 235–260, (1997).
[5] Francesc Esteva, Llu´ıs Godo, Ricardo O. Rodr´ıguez, and Thomas Vetterlein, ‘On the logics of similarity-based approximate and strong entailment’, in Proceedings of ESTYLF 2010, (2010).
[6] Llu´ıs Godo and Ricardo O. Rodr´ıguez. Logical approaches to fuzzy
similarity-based reasoning: an overview. Della Riccia, Giacomo (ed.)
et al., Preferences and similarities. Lectures from the 8th international
workshop of the international school for the synthesis of expert knowledge (ISSEK), Udine, Italy, October 5–7, 2006; Wien: Springer. CISM
Courses and Lectures 504, 75-128 (2008), 2008.
[7] George Metcalfe, Nicola Olivetti, and Dov Gabbay, Proof theory for
fuzzy logics, Applied Logic Series 36. Dordrecht: Springer, 2009.
[8] Ricardo O. Rodr´ıguez, Aspectos formales en el Razonamiento basado
en Relaciones de Similitud Borrosas, Ph.D. dissertation, Technical University of Catalonia (UPC), 2002.
[9] Enrique H. Ruspini, ‘On the semantics of fuzzy logic’, Int. J. Approx.
Reasoning, 5(1), 45–88, (1991).
[10] M. Sheremet, D. Tishkovsky, F. Wolter, and M. Zakharyaschev, ‘A logic
for concepts and similarity.’, J. Log. Comput., 17(3), 415–452, (2007).
[11] Frank Wolter and Michael Zakharyaschev, ‘A logic for metric and
topology.’, J. Symb. Log., 70(3), 795–828, (2005).
[12] Georg Henrik von Wright, The Logic of Preference, Edinburgh University Press, Edinburgh, 1963.

81

ECAI-2012 Workshop WL4AI

82

ECAI-2012 Workshop WL4AI

Borderline vs. Unknown: a Comparison Between
Three-Valued Valuations, Partial Models, and
Possibility Distributions 1
Davide Ciucci

2

and Didier Dubois

2
3

3

Introduction
2

Three-valued logics have been used for different purposes,
depending on the meaning of the third truth-value. Among
them, Kleene logic [9] is typically assumed to deal with incomplete knowledge, with the third truth-value interpreted as
unknown. However, possibility is to interpret the additional
truth-value as borderline, as a means of representing indeterminism in vague predicates. It is then tempting to use Kleene
logic as a simple logic of non-Boolean predicates as recently
done by Lawry and Gonzalez-Rodriguez [11]. They introduced
a new formalism to handle three-valued vague predicates in
Kleene logic by means of pairs of Boolean valuations, one being weaker than the other. Basic connectives of conjunction,
disjunction and negation can be expressed by composing valuation pairs. Moreover they showed that deleting the constraint
between the two Boolean valuations, such connectives recover
Belnap 4-valued logic of conflict. They use another equivalent
representation consisting of pairs of subsets of atomic variables, that are disjoint when they represent Kleene valuations.
More recently Lawry and Dubois [10] proposed operations for
merging valuation pairs and study their expression in terms of
pairs of subsets of atoms. However, in restricted cases Kleene
logic three-valued valuation pairs coincide with Boolean partial models expressing a form of incomplete information. Orthopairs of variable sets then represent the sets of variables
that are known to be true and of those that are known to
be false. The natural generalisation of partial models consist
1

and Jonathan Lawry

of epistemic states, understood as subsets of interpretations
of a Boolean language, which can be viewed as all-or-nothing
possibility distributions. However, possibility theory, even in
its all-or-nothing form, is much more expressive than Kleene
logic for handing incomplete information [8].
In this paper we explore connections between these representation tools and the combination rules that can be expressed in each setting. The aim of the paper is to lay bare
the differences between Kleene logic as a logic of vagueness
with the same formalism viewed as a logic of incomplete information, cast in the setting of possibility theory.

Abstract.
In this paper we explore connections between several representations of vagueness and incomplete information. These
include valuation pairs of Lawry and Gonzalez-Rodriguez,
orthopairs of variable sets, Boolean possibility and necessity measures modelling incomplete Boolean information. We
highlight the difference between these formalisms and study
to what extent operations for merging valuation pairs can be
expressed by means of operations on orthopairs and on underlying possibility distributions.

1

2

Boolean epistemic states as disjunctions
of orthopairs of positive literals

Let A be a finite set of propositional variables. Let us consider
a Boolean valuation w : A → {0, 1} and also call Ω the set of
all such valuations.
An epistemic state E ⊆ Ω is a subset of valuations. It is a
state of information according to which all that is known is
that the real world is properly described by one of the valuations in E. The set of models of a formula φ based on propositional variables A is denoted by E = [φ]. We can represent
equivalently an epistemic state E by a possibility distribution,
i.e., a mapping of the form
(
1 if w ∈ E (it means possible)
πE (w) =
0 otherwise (impossible)
Another equivalent way to represent a valuation w is to
consider the partition of the set of propositional variables A =
A+ ∪ A− it induces, in the sense that
^
^
a∧
¬a.
w=
a∈A+

a∈A−

It is often the case that a valuation w is simply represented
by the subset Aw = {a ∈ A : w(a) = 1} = A+ of positive
literals it satisfies as per the above expression. It lays bare
one-to-one correspondence between Ω and 2A .
Now, let us suppose that an agent expresses knowledge
by means of positive literals, P ⊆ A. We can have two attitudes with respect to the other variables in A\P . First,
the open world assumption (OWA). In this case nothing is
assumed
V about A\P . The corresponding epistemic state is
EP = [ a∈P a]. It is a Cartesian product in Ω with positive

First author supported by FP7-Marie Curie Action (IEF)
n.276158
IRIT, Universit´
e Paul Sabatier, 118 route de Narbonne, 31062
Toulouse cedex 4 (France)
Department of Engineering Mathematics, University Of Bristol, Queen’s Building, University Walk, Bristol BS8 1TR, United
Kingdom

83

ECAI-2012 Workshop WL4AI

projections on variables in P . The corresponding possibility
distribution is of the form π(w) = mina∈P πa (aw ), where πa
is a possibility distribution on {a, ¬a} and aw = a if w is a
model of a (w(a) = 1) and ¬a otherwise. In the paper we
write πa (aw ) as πa (w) for short. Note that π¬a = 1 − πa
On the contrary, under the closed world assumption
(CWA), it is supposed that what is not said to be true is
false, thus N = A\P are the negative facts. This corresponds
to pick-up justVa single V
valuation among all the possible ones
in EP : wP = a∈P a ∧ a∈P c ¬a. In terms of possibility distributions, it is such that

E(P,N) = ∪{E : (PE , NE ) = (P, N )}. RC(E) can be called
the rectangular closure (RC) of E.
From the above discussion, it is clear that the collection
of all orthopairs can be mapped only to a subset of all the
possibility distributions. This implies that not all the possibility distributions are representable as orthopairs. Take for
instance the empty set on Ω (it represents contradiction): it
does not correspond to any orthopair. More generally, any
epistemic state E ⊆ Ω can be represented by a collection of
orthopairs, which encodes a disjunction of partial models. To
see it, consider a Boolean formula φ whose set of models is
exactly E. Then, put φ in the disjunctive normal form (as a
disjunction of conjunctions of literals). Each such conjunction
can be represented by an orthopair. So any epistemic state can
be represented by a disjunction of orthopairs.
We may even wish to represent E by a set of mutually exclusive orthopairs. This is because it is always possible to put
a disjunction of conjunctions into a disjunction of mutually
exclusive conjuncts.
To do so, we need a notion of consistency between orthopairs. Two orthopairs (P1 , N1 ), and (P2 , N2 ) are consistent
if and only if P1 ∩ N2 = ∅ and P2 ∩ N1 = ∅. It is clear that
E(P1 ,N1 ) ∩ E(P2 ,N2 ) = ∅ if and only if (P1 , N1 ), and (P2 , N2 )
are consistent. The problem of representing a Boolean formula as a disjunction of mutually exclusive conjuncts is a
matter of computing normal forms (like binary decision diagrams). An open problem is to turn a disjunction of orthopairs into an equivalent disjunction of inconsistent ones. For
the case of two orthopairs (P1 , N1 ), and (P2 , N2 ), we should
find (Pi , Ni ), i = 1, . . . , n, such that (Pi , Ni ) and (Pj , Nj ) are
inconsistent, ∀i = j = 1 . . . , n, and

π(w) = min(min πa (w), minc 1 − πa (w))
a∈P

a∈P

that takes value 1 only for w = wP .
More generally, we can assume that an agent is able to express both positive and negative knowledge, i.e., two sets of
variables (P, N ) such that P ∩N = ∅. Clearly, A\(P ∪N ) represents variables for which the agent has no knowledge. (P, N )
is called an orthopair,
and V
it corresponds to a conjunction of
V
literals in A, i.e., a∈P a ∧ a∈N ¬a. This is sometimes called
a partial interpretation or partial model [3].
We can define its set of models as the collection of all valuations which satisfy it. The satisfaction of an orthopair (P, N )
by an interpretation w must be defined as follows: w |= (P, N )
if Aw ∩ N = ∅ and Acw ∩ P = ∅, or equivalently P ⊆ Aw and
N ⊆ Acw . It corresponds to a special kind of epistemic state
E(P,N) of the form
^
^
E(P,N) = [
a∧
¬a.] = {ω : P ⊆ Aw , N ⊆ Acw }.
a∈P

a∈N

where P, N ⊆ A and P ∩ N = ∅. Then, from E(P,N) we can
obtain the possibility distribution π(P,N) as

E(P1 ,N1 ) ∪ E(P2 ,N2 ) = ∪i=1,...,n E(Pi ,Ni ) .
Based on an epistemic state described by a possibility distribution π representing an epistemic state E, we can define possibility and necessity degrees N (φ) and Π(φ) [8] by Π(φ) = 1
if and only if ∃w ∈ Ω, w |= φ and 0 otherwise; N (φ) = 1 if
and only if ∀w ∈ Ω, w |= φ and 0 otherwise. We can compute
the pair (N, Π) of functions SL → {0, 1} from an orthopair
(P, N ) as follows :
V
V
• N (θ) = 1 if V
a∈P a ∧
a∈N
V ¬a |= θ and 0 otherwise.
• Π(θ) = 1 if a∈P a ∧ a∈N ¬a ∧ θ is consistent, and 0
otherwise.

π(P,N) (w) = min(min πa (w), min 1 − πa (w))
a∈P

a∈N

The corresponding epistemic state takes the form of a Cartesian product, what can be called an hyper-rectangle, by analogy with the Cartesian product of intervals in the real line
Rn . Then, given any other such possibility distribution, their
intersection is still a rectangle, hence representable by an orthopair, whereas their union is not.
In the case of possibility distributions over Ω, each dimension is a propositional variable on {0, 1}, thus we have hyperrectangles in the space {0, 1}n . We can project a possibility distribution on each dimension P roja (π(P,N) ) and obtain
the set of possible values left by π(P,N) for the variable i. Of
course, we can have only three cases:
8
>
a∈N
<{0}
P roja (π(P,N) ) = {1}
a∈P
>
:
{0, 1} otherwise

N is called a necessity measure and Π a possibility measure.
N (θ) = 1 means that θ is certainly true, and Π(θ) = 1 that θ
is possibly true, if the epistemic state is described by (P, N ).
In particular, if N (θ) = 0 and Π(θ) = 1 it means that the
truth of θ is unknown in epistemic state (P, N ).

3

Paraconsistent valuations

One may wish to relax the condition P ∩ N = ∅ defining orthopairs. The epistemic view of this license is that if a ∈ P ∩N ,
it means that there are reasons to believe the truth of a and
reasons to believe a to be false as well. For instance, there may
be agents claiming the truth of a and other agents claiming its
falsity. This approach corresponds to the semantics of some
paraconsistent logics such as Belnap’s [1] or the quasi-classical
logic of Besnard and Hunter [2]. We call such pairs of atoms

The use of projections will enable us to express operations
combining orthopairs, such as the intersection, in a simple
and effective manner on Ω.
Conversely, for any subset of Boolean valuations E ⊂ Ω
we can assign a single orthopair RC(E) = (PE , NE ) by
letting a ∈ PE iff w(a) = 1, ∀w ∈ E, and a ∈ NE iff
w(a) = 0, ∀w ∈ E. The map E → (PE , NE ) defines an
equivalence relation on possibility distributions over Ω and

84

ECAI-2012 Workshop WL4AI

special case of possibility theory where incomplete information is restricted to Cartesian products of marginal pieces
of information about atoms.
• In the three-valued valuation case, atoms are not Boolean,
and each valuation is a complete model whereby some
atoms are neither true nor false but borderline, in the scope
of modeling vagueness. This is the view used by Shapiro [12]
and Lawry & Gonzalez-Rodriguez [11], based on Kleene
three-valued logic.

(F, G) ∈ 2A × 2A with F ∩ G = ∅ paraconsistent. For such
pairs, it is clear that E(F,G) = ∅. Another semantic is necessary for them.
A pair (F, G) in the paraconsistent case is closely related
to Belnap [1] 4-valued logic, namely
•
•
•
•

If
If
If
If

a ∈ F \ G then a has Belnap truth-value TRUE
a ∈ G \ F then a has Belnap truth-value FALSE
a ∈ F ∩ G then a has Belnap truth-value BOTH
a ∈ F ∪ G then a has Belnap truth-value NONE

In the three-valued valuation case, truth-functionality is
thus assumed namely 1 > u > 0 and

While an orthopair (P, N ) can be associated a possibility
distribution on interpretations, it is no longer possible for a
paraconsistent orthopair (F, G), as E(F,G) = ∅. One may then
represent such a paraconsistent orthopair by means of two
standard orthopairs of the form (F, G \ F ) and (F \ G, G) laying bare the positive and the negative sides of the pieces of
information. They are pairs of orthopairs (P1 , N1 ), (P2 , N2 )
with P2 ⊆ P1 , N1 ⊆ N2 , N1 ∩ P2 = ∅, P1 ∪ N1 = P2 ∪ N2
letting P1 = F, N2 = G. The corresponding paraconsistent orthopair is of the form (P1 , N2 ) but corresponds to
two possibility distributions (two disjoint epistemic states
Ei = E(Pi ,Ni ) , i = 1, 2). See Dubois, Konieczny and Prade [6],
for the use of paraconsistent orthopairs in the setting of possibilistic logic. More generally we could reconstruct a paraconsistent orthopair from any two orthopairs (P1 , N1 ), (P2 , N2 )
as (F, G) = (P1 ∪ P2 , N1 ∪ N2 ) as follows
• If a ∈ P1 \ N2 ∪ P2 \ N1 then a has Belnap
TRUE
• If a ∈ N1 \ P2 ∪ N2 \ P1 then a has Belnap
FALSE
• If a ∈ (P1 ∩ N2 ) ∪ (P2 ∩ N1 ) then a has Belnap
BOTH
• If a ∈ P1 ∪ N2 ∪ P2 ∪ N1 then a has Belnap
NONE

• τ (¬0) = 1, τ (¬1) = 0, τ (¬u) = u, which reads τ (¬p) =
1 − τ (p).
• τ (p ∧ q) = min(τ (p), τ (q))
• τ (p ∨ q) = max(τ (p), τ (q))
Lawry & Gonzalez-Rodriguez[11] propose to represent ternary
valuations τ by pairs (v, v) of Boolean valuations on {0, 1},
defined as follows: for atoms a, b . . . , and formulas φ built from
atoms and Kleene connectives ¬, ∨, ∧:
•
•
•
•
•
•

truth-value

In the above v is a lower Boolean valuation, and v is an upper
Boolean valuation. It can be checked that if τ (φ) is computed
by means of Kleene truth tables and the pair (v, v) is computed by the above identities,

truth-value
truth-value

• if τ (φ) = 1 then v(φ) = v(φ) = 1;
• if τ (φ) = 0 then v(φ) = v(φ) = 0;
• if τ (φ) = u then v(φ) = 0, v(φ) = 1;

truth-value

Letting (P1 , N1 ) = (F, G \ F ) and (P2 , N2 ) = (F \ G, G), we
do recover (P1 ∪ P2 , N1 ∪ N2 ) = (F, G).
In the following, the notation (P, N ) corresponds to genuine
orthopairs, while we use (F, G) in the general case.

4

if τ (a) = 1 then v(a) = v(a) = 1;
if τ (a) = 0 then v(a) = v(a) = 0;
if τ (a) = u then v(a) = 0, v(a) = 1;
v(¬φ) = 1 − v(φ);
v(φ ∧ ψ) = min(v(φ), v(ψ)); v(φ ∧ ψ) = min(vφ), v(ψ));
v(φ ∨ ψ) = max(v(φ), v(ψ)); v(φ ∨ ψ) = max(v(φ), v(ψ));

Clearly the property v ≤ v holds. So, there is also a oneto-one correspondence between Boolean valuation pairs such
that v ≤ v and orthopairs (P, N ) defining P = {a ∈ A :
v(a) = v(a) = 1}, N = {a ∈ A : v(a) = v(a) = 0}, and
v(a) = 0, v(a) = 1 if a ∈ P ∪ N .
It can be shown by induction that the three-valued valuation τ can be simply expressed in terms of v, v as

Ternary valuations vs. partial
interpretations

It is possible to establish a bijection between orthopairs and
three-valued valuations. Let us consider a three-valued valuation on the set of variables τ : A → 3 with 3 = {0, u, 1}.
Then, we can induce an orthopair as: a ∈ P if τ (a) = 1,
a ∈ N if τ (a) = 0. Vice versa, given an orthopair we have the
following three-valued function:
8
>
<0 a ∈ N
τ (a) = 1 a ∈ P
>
:
u otherwise

τ (φ) =

v(φ) + v(φ)
,
2

encoding the third truth-value u as 1/2. So, in the case where
v ≤ v we can represent the relation between three-valued functions, orthopairs and pairs of Boolean functions as in Fig.1.
The above approach to vagueness based on Kleene logic
and orthopairs of propositional variables may be puzzling for
scholars that are following the original intuitions in [9] on the
interpretation of the third truth-value b as unknown instead
of borderline. Indeed, here we are interested in classifying precisely described objects with respect to vague categories represented by propositional atoms a ∈ A that share the states
of the world in three parts.
There is a striking similarity between Kleene valuation pairs
(v, v) and necessity-possibility pairs (N, Π), namely:

This bijection indicates that there are as many partial models as 3-valuations. However, the intended meanings are quite
different
• In the partial model scenario, atoms are Boolean and a partial model represents incomplete information, so this is a

85

ECAI-2012 Workshop WL4AI

case the diagram of Figure 1 should be updated as follows

τ ∈ O 3A o



/ (v, v)
v:
v
v
vv
vv
v
zv

τ ∈O 4A o

(P, N )



/ (v, v)
:
v
v
vv
v
vv
zvv

(F, G)
Figure 1.

However, the semantics of such inconsistent valuations is
unclear as it introduces a second kind of borderline truthvalue, which plays the same role as the first one with respect
to true and false.
The authors also try to define the semantics of Kleene logic
formulas in terms of sets of pairs of atomic formulas (F, G) ∈
2A × 2A . Let Λ(φ) = {(v, v), v(φ) = 1} which corresponds to a
set of pairs (F, G) including paraconsistent orthopairs. They
propose the following inductive definitions

Bijection among three-valued functions τ , orthopairs
(P, N ) and pairs of Boolean functions v ≤ v.

• N (¬θ) = 1 − Π(θ) and Π(¬θ) = 1 − N (θ)
• N (θ ∧ ϕ) = min(N (θ), N (ϕ))
• Π(θ ∨ ϕ) = max(Π(θ), Π(ϕ))
However there is a difference between them : while v(θ ∧ ϕ) =
min(v(θ), v(ϕ)) and v(θ ∨ ϕ) = max(v(θ), v(ϕ)), in general
Π(θ∧ϕ) ≤ min(Π(θ), Π(ϕ)) and N (θ∨ϕ) ≥ max(N (θ), N (ϕ))
only. In particular, Π(θ ∧¬θ) = 0 (non-contradiction law) and
N (θ ∨ ¬θ) = 1 (excluded middle law). In fact, (N, Π) is a
pair of KD modalities in epistemic logic, which explains why
they are not compositional. A Kleene valuation pair (v, v)
would be trivial in a Boolean context, while in the threevalued propositional setting accommodating borderline cases,
such deviant modalities (where the lower necessity-like valuation distributes over disjunctions) are not trivial. More general
Kleene algebras are studied in [4].
It is easy to lay bare propositions φ for which valuation
pairs (v, v) and possibility-necessity pairs (Π, N ) differ. For
instance, a ∨ b and a ∨ (¬a ∧ b) are not equivalent propositions
under Kleene valuation pairs. Indeed, consider the orthopair
(P, N ) = ({b}, ∅). Since v(b) = v(b) = 1, it is obvious that
v(a ∨ b) = v(a ∨ b) = 1 too. However,
•
•
•
•
•
•

•
•
•
•

They prove a number of elementary equivalences from Kleene
logic on this basis and study the dual set of valuation pairs
Ξ(φ) = (Λ(¬φ))c . Basically they show that if (v, v) corresponds to the pair (F, G) of subsets of atoms, then, for any
Kleene logic formula Φ, v(φ) = 1 if and only if (F, G) ∈ Λ(φ)
and v(φ) = 1 if and only if (F, G) ∈ Ξ(φ).
It is interesting to notice that this construction is instrumental in adding uncertainty to the Kleene-based threevalued logic of vagueness, by assigning probability masses to
pairs (F, G) of subsets of atoms, enforcing zero probabilities
when F ∩ G = ∅.
However, this framework for uncertainty in three-valued
logic relies on the use of paraconsistent orthopairs. Indeed the
very definitions of Λ(φ) use paraconsistent orthopairs even
if one restricts Λ(a) to orthopairs. Indeed if (P, N ) is an
orthopair, then (N c , P c ) is generally a paraconsistent one,
so that the definition of Λ(¬φ) requires the use of paraconsistent orthopairs, even if for atoms, restricting Λ(a) to
{(P, N ), a ∈ P } yields Λ(¬a) = {(P, N ), a ∈ N }, namely a
set of orthopairs.
Interestingly, if (F, G) ∈ Λ(a), it means that v (F,G) (a) = 1,
i.e., a ∈ F which means that a is TRUE or BOTH in Belnap
terminology. If a is TRUE, it means that a ∈ G, but then
a ∈ F c ∪G, in other words, the pair (Gc , F c ) makes a TRUE as
well. If a is BOTH, it means that a ∈ G, but then a ∈ F c ∪Gc ,
in other words, the pair (Gc , F c ) makes a NONE (1/2). So it
is clear that v (F,G) (a) = 1 is equivalent to v (Gc ,F c ) (a) = 1. In
other words, the set {(Gc , F c ) : (F, G) ∈ Λ(a)} = {(F, G), a ∈
G} contains all pairs that make a TRUE or NONE, that is
Ξ(a), and it means that v (Gc ,F c ) (a) = 1: if φ is TRUE or
BOTH for (F, G), it is TRUE or NONE for (Gc , F c ).
Likewise it is easy to see that if φ is FALSE or BOTH for
(F, G), it is FALSE or NONE for (Gc , F c ). Indeed if (F, G) ∈
Λ(¬a), it means that v (F,G) (a) = 0, i.e., a ∈ G which means
that a is FALSE or BOTH in Belnap terminology. If a is
FALSE, it means that a ∈ F , but then a ∈ F ∪ Gc , in other
words, the pair (Gc , F c ) makes a FALSE as well. If a is BOTH,
it means that a ∈ G∩F , and the pair (Gc , F c ) makes a NONE
(1/2) again. So it is clear that v (F,G) (a) = 0 is equivalent to
v (Gc ,F c ) (a) = 0.

v(a) = 1 and v(a) = 0 since a ∈ P ∪ N ;
v(¬a) = 1 and v(¬a) = 0 likewise;
v(¬a ∧ b) = min(v(¬a), v(b)) = 1;
v(¬a ∧ b) = min(v(¬a), v(b)) = 0;
So v(a ∨ (¬a ∧ b)) = max(v(a), v(¬a ∧ b)) = 1;
So v(a ∨ (¬a ∧ b)) = max(v(a), v(¬a ∧ b)) = 0;

However, in the Boolean setting the two formulas a ∨ b and
a ∨ (¬a ∧ b) have the same set of models, so N (a ∨ b) =
N (a ∨ (¬a ∧ b)), and N (a ∨ b) = N (a ∨ (¬a ∧ b)).
More generally as it is known that Kleene logic has no tautology: given a tautological boolean formula φ, there exists a
Kleene valuation pair (v, v) such that v(φ) = 1, v(φ) = 0. In
contrast, for any possibility necessity pair, N (φ) = Π(φ) = 1.

5

Λ(a) = {(F, G), a ∈ F }
Λ(φ ∧ ψ) = Λ(φ) ∩ Λ(ψ)
Λ(φ ∨ ψ) = Λ(φ) ∪ Λ(ψ)
Λ(¬φ) = {(Gc , F c ) : (F, G) ∈ Λ(φ)}c

Generalized valuation pairs

Lawry and Gonzalez-Rodriguez [11] extend Kleene valuation
pairs to cases where v ≤ v. Such valuations pairs exactly
correspond to paraconsistent orthopairs (F, G) such that F ∩
G = ∅. In that case, it corresponds to four-valued valuations
in the sense of Belnap. The authors indeed show that truthtables corresponding to the inductive definitions of Kleene
valuation pairs over the language become Belnap 4-valued
truth-tables when these inductive definitions are applied to
all valuation pairs (v, v) without the restriction v ≥ v. In this

86

ECAI-2012 Workshop WL4AI

We can prove this for all formulas:

6

Proposition 5.1. Two implications hold:

In [5] and [10] some order relations and operations on orthopairs are considered. We give here a complete picture of
these methods to combine orthopairs, and their correspondence with valuation pairs and three-valued functions. In the
case of valuation pairs we consider only valuations of propositional variables. Indeed, not all the following results apply
when considering more complex formulas. The problem seems
to lie in the formulas containing negations. However, this issue
will need a further in-depth study.
First of all, let us consider the standard order on 3: 0 <
1
< 1. Given two three-valued valuations, τ1 , τ2 , we can let
2
τ1 1 τ2 mean τ1 (a) ≤ τ2 (a), ∀a ∈ A. It expresses the idea of
being “not more true than”. On orthopairs it reads

• ∀φ ∈ L, if v (F,G) (φ) = 1 then v (Gc ,F c ) (φ) = 1.
• ∀φ ∈ L, if v (F,G) (φ) = 0 then v (Gc ,F c ) (φ) = 0.
Proof: If φ is an atom, see the above paragraph. Assume
the result is true for φ and ψ.
• Let v (F,G) (φ ∨ ψ) = max(v(F,G) (φ), v (F,G) (ψ)) = 1: If
v (F,G) (φ) = 1 then by assumption v (Gc ,F c ) (φ) = 1 and
thus v (Gc ,F c ) (φ ∨ ψ) = 1.
• Let v (F,G) (φ ∧ ψ) = min(v (F,G) (φ), v (F,G) (ψ)) = 1:
Hence v (F,G) (φ) = v (F,G) (φ) = 1. Since by assumption
v (Gc ,F c ) (φ) = v (Gc ,F c ) (ψ) = 1 it is clear that v (Gc ,F c ) (φ ∧
ψ) = 1.
• Similar reasoning for conjunction and disjunction and
v (F,G) (φ) = 0
• Let v(F,G) (¬φ) = 1. Hence v(F,G) (φ) = 1 − v (F,G) (¬φ) =
0. By assumption, it follows that v (Gc ,F c ) (φ) = 0. Hence
v (Gc ,F c ) (¬φ) = 1. Likewise for v (F,G) (¬φ) = 0.
c

Order relations and aggregation
operations in Kleene three-valued logic

(P1 , N1 )

1

(P2 , N2 )

iff

P1 ⊆ P2 , N2 ⊆ N1

(1)

and on pairs of valuations
v1

1

v2

∀a

iff

v 1 (a) ≤ v 2 (a)

v 1 (a) ≤ v 2 (a)

c

This result explains the formula Λ(¬φ) = {(G , F ) : (F, G) ∈
Λ(φ)}c : the set {(Gc , F c ) : (F, G) ∈ Λ(φ)} contains pairs of
sets of atoms that make φ TRUE or NONE; its complement
contains the pairs that make φ FALSE or BOTH.
One natural question is the following: if we restrict Λ(φ) to
genuine orthopairs O(φ) = Λ(φ) ∩ {(P, N ) ∈ 2A × 2A , P ∩ N =
∅}, then can we apply Lawry’s recursive definitions of Λ(φ)
to O(φ)? For conjunction and disjunction it seems to work
but not for negation. Indeed, given a formula φ we cannot
apply the recursive definition for negation considering only
orthopairs in O(φ), i.e.,

This ordering is known as the truth ordering [1]: “v1 is less
true than v2 ”. It is the canonical extension of the order 0 < 1
to subsets of {0, 1}. It leads to the chain structure 0 < 1/2 < 1
on 3 and to the following join and meet on orthopairs:
(P1 , N1 )

1

(P2 , N2 ) := (P1 ∩ P2 , N1 ∪ N2 )

(2)

(P1 , N1 )

1

(P2 , N2 ) := (P1 ∪ P2 , N1 ∩ N2 )

(3)

They are the usual join and meet relations considered on orthopairs (see for instance [5]). Once considered on pairs of
valuations, we see that they correspond to the conjunction
and disjunction of the lower and upper valuations:

{(N c , P c ) : (P, N ) ∈ O(φ)}c = O(¬φ).

v1 ∧1 v2 = (v1 ∧ v 2 , v 1 ∧ v 2 )

Example 5.1. Let A = {a, b} and φ = a ∧ ¬b. Then, we have
Λ(φ) = {({a}, {b}), ({a, b}, {a, b}) and O(φ) = {({a}, {b})}.
If we desire to compute O(¬φ) we have to compute at first
Λ(¬φ) and the consider only the orthopairs. Indeed, on the
contrary, we have {(N c , P c ) : (P, N ) ∈ O(φ)} = O(φ) and
so {(N c , P c ) : (P, N ) ∈ O(φ)}c contains pairs which are not
disjoint such as ({a, b}, {a, b}) and even pairs which should
not be in Λ(¬φ) such as (∅, ∅).

v1 ∨1 v2 = (v1 ∨ v 2 , v 1 ∨ v 2 )
Another natural order relation
(P1 , N1 )

2

(P2 , N2 )

iff

2

on orthopairs is:

P1 ⊆ P2 , N1 ⊆ N2

(4)

This relation is known as the knowledge ordering [13] or the
semantic precision [10], which on valuations reads as

Moreover, in general, O(¬φ) = {(N, P ) : (P, N ) ∈ O(φ)}
hold for atoms but not for all formulas. We only have {(N, P ) :
(P, N ) ∈ O(φ)} ⊆ O(¬φ).

v1

2

v2

∀a

iff

v 1 (a) ≤ v 2 (a)

v 2 (a) ≤ v 1 (a).

It means v2 is at least as informative as v1 . Once interpreted
on three values, it can be seen that it does not generate a
lattice structure but only the meet-semilattice of figure 2.
The meet with respect to this order is defined (on orthopairs) as

Example 5.2. Let φ = pi ∧ ¬pj . Then O(φ) = {(P, N ) :
pi ∈ P, pj ∈ N }. On the other hand, O(¬φ) = O(¬pi ∨ pj ) =
{(P, N ) : pi ∈ N } ∪ {(P, N ) : pj ∈ P }, which is different from
{(N, P ) : (P, N ) ∈ O(pi ∧ ¬pj )} since, for instance, (∅, {pi })
belongs to O(¬φ) but not to {(N, P ) : (P, N ) ∈ O(pi ∧ ¬pj )}.

(P1 , N1 )

It seems that a recursion formula using only orthopairs for
computing O(¬θ) for a negation of a formula does not exist.
The reason seems to be that the negation of the formula corresponding to a partial model associated to an orthopair is
not a formula corresponding to an orthopair at all.
So, at present, the only chance is to recover Kleene orthopairs semantics from Belnap pair semantics, which in our
opinion is not fully satisfactory.

2

(P2 , N2 ) := (P1 ∩ P2 , N1 ∩ N2 )

(5)

It is pessimistic as it only keeps what both orthopairs retain
as true or false. This is operation ⊗ on valuation pairs [10]:
v1 ⊗ v2 = v(P1 ∩P2 ,N1 ∩N2 ) = (v 1 ∧ v 2 , v 1 ∨ v 2 )
Clearly, the join can be naturally defined as
(P1 , N1 )

87

2

(P2 , N2 ) := (P1 ∪ P2 , N1 ∪ N2 )

(6)

ECAI-2012 Workshop WL4AI

they are uninorms on {0, 1/2, 1} used in the three-valued logic
of conditional events [7].
If we consider the consensus operation in [10], defined as

1
•

0
•?
?

??
??
??

•







(P1 , N1 )

1
2

Figure 2.

we can see that it is a mix of 3 and 4 . Thus we can think to
interpret 3 and 4 as partial consensus where in 3 both the
agents restrict their view on the positive part and in 4 on
the negative part. The corresponding operation on valuation
pairs are:

The semilattice structure of order 3.

It does not always exist on orthopairs as the result may become paraconsistent. It is the optimistic combination operator
⊕ on valuation pairs [10]:

The cases where it exists then correspond to the situation
where the two orthopairs are consistent, that is: P1 ∩ N2 =
P2 ∩ N1 = ∅. Generalizing both orderings to paraconsistent
orthopairs yields a bilattice structure laid bare by Belnap [1].
Now, by relaxing the requirements of order 2 , we can obtain two other orderings, which generate two lattice operations. In one case we keep the condition on the first component and in the other the condition on the second one. That
is, the new order relations on orthopairs are:
(P1 , N1 )

3

(P2 , N2 )

iff

Bnd2 ⊆ Bnd1 , N1 ⊆ N2

(7)

(P1 , N1 )

4

(P2 , N2 )

iff

P1 ⊆ P2 , Bnd2 ⊆ Bnd1 ,

(8)

v1 <4 v2

iff

and
and

v 2 (a) ≤ v 1 (a)
¬v 2 (a) ∧ v2 (a) ≤ ¬v 1 (a) ∧ v1 (a)
v 1 (a) ≤ v 2 (a).

On three values, the orders (7) and (8) correspond to a
different order with respect to the standard one on numbers,
according to the following equations:
iff

∀x τ1 (x) ≤ τ2 (x)

where

τ1 ≤ 4 τ2

iff

∀x τ1 (x) ≤ τ2 (x)

where

1
2
1
2

v3 ∨4 v2 = (v 1 ∨ v 2 , (v 1 ∨ v 2 ) ∧ (v 2 ∨ v 1 ))

(12)

3

:

((P1 ∩ P2 ) ∪ [(P1 ∩ N2 ) ∪ (P2 ∩ N1 )], N1 ∩ N2 ) (13)

4

:

(P1 ∩ P2 , (N1 ∩ N2 ) ∪ [(N1 ∩ P2 ) ∪ (N2 ∩ P1 )]) (14)

from which we better understand that we “add” something to
the intersection of positive (resp., negative) parts. The corresponding operations on valuation pairs are:

¬v 2 (a) ∧ v2 (a) ≤ ¬v 1 (a) ∧ v1 (a)

τ1 ≤ 3 τ2

(11)

If we consider the two meet operations 3 , 4 applied to two
orthopairs which are in order relation ( 3 or 4 ) then they
both reduce to 2 (that is, ⊗). On the contrary, in the general situation, with 3 we reduce the positive region of agent
1 considering only the situations where agent 2 has a certain
opinion, either positive or negative, and dually agent 1 with
respect to agent 2. Similarly for 4 the negative part is reduced considering only the certainty zone of the other agent.
Let us note that we can express the two operations in the
following way:

with Bnd = N c \P (Bnd stands for boundary following
rough-set terminology) and thus the condition Bnd2 ⊆ Bnd1
can be equivalently expressed as P1 ∪ N1 ⊆ P2 ∪ N2 . It can be
easily seen that order 2 implies orders 3 and 4 but not vice
versa. On pairs of valuations the two orders are translated as:
iff

v3 ∨3 v2 = ((v 1 ∧ v 2 ) ∨ (v 2 ∧ v 1 ), v 1 ∧ v 2 )

On 3 the consensus operator is
8
>
1 if τ1 (x) = 1, τ2 (x) = 0
>
>
>
>
>
or τ2 (x) = 1, τ1 (x) = 0
<
(τ1 τ2 )(x) = 0 if τ1 (x) = 0, τ2 (x) = 1
>
>
>
or τ2 (x) = 0, τ1 (x) = 1
>
>
>
:
u otherwise

v1 ⊕ v2 = v(P1 ∪P2 ,N1 ∪N2 ) = (v 1 ∨ v 2 , v 1 ∧ v 2 ).

v1 <3 v2

(P2 , N2 ) = (P1 \N2 ∪ P2 \N1 , N1 \P2 ∪ N2 \P1 )

∧3 : ((v1 ∧ v 2 ) ∨ (v 1 ∧ ¬v 2 ) ∨ (v 2 ∧ ¬v 1 )), v 1 ∨ v 2 )

(15)

∧4 : (v1 ∧ v 2 , (v 1 ∨ v 2 ) ∧ (v1 ∨ ¬v 2 ) ∧ (v 2 ∨ ¬v 1 ))

(16)

Finally, Figure 4 represents these three orderings on orthopairs (U = N c ).

≤ 1 ≤ 0 (9)
$"

≤ 0 ≤ 1 (10)

$# $"
!#

These two orderings give rise to the following meet and join
operations on orthopairs

!"

(a)

(P1 , N1 )

3

(P2 , N2 )

:=

(P1 \N2 ∪ P2 \N1 , N1 ∪ N2 )

(P1 , N1 )

3

(P2 , N2 )

:=

(P1 \Bnd2 ∪ P2 \Bnd1 , N1 ∩ N2 )

(P1 , N1 )

4 (P2 , N2 )

:=

(P1 ∪ P2 , N1 \P2 ∪ N2 \P1 )

(P1 , N1 )

4

(P2 , N2 )

:=

(P1 ∩ P2 , N1 \Bnd2 ∪ N2 \Bnd1 )

$#

Figure 3.

!"

!"

!# $#

$"

!#

(b)

Representations of orders

(c)

3,

4

and

2.

Thus, orderings 3 and 4 are less demanding from the
“knowledge” point of view than ordering 2, but they have

We note that in the probabilistic literature the operations
and 3 are named quasi-conjunction and quasi-disjunction;

3

88

ECAI-2012 Workshop WL4AI

The order relation 2 is just the subsethood relation of subsets of Ω, i.e., E(P1 ,N1 ) 2 E(P2 ,N2 ) iff E(P2 ,N2 ) ⊆ E(P1 ,N1 ) .
The counterpart of orders 1 , 3 , 4 is drawn in Figure 4(b),
that is we only have a partial overlap of the two subsets.

the advantage to generate a lattice structure, with the possibility to define intersection and union. Lawry and Dubois [10]
also consider the difference:
v2 := (v1 ∧ v 2 , v 1 ∨ v 2 )

v1

(P2 , N2 ) := (P1 \N2 , N1 \P2 )
8
>
<1 τ1 = 1, τ2 = 0
(τ1 τ2 )(x) := 0 τ1 = 0, τ2 = 1
>
:
u otherwise

(P1 , N1 )

!"
!"

Now, let us considering negations. The standard involutive
negation ¬ defined as ¬0 = 1, ¬u = u, ¬1 = 0, corresponds
on orthopairs to the following operation: ¬(P, N ) := (N, P )
and so on valuation pairs to: ¬(v, v) := (¬v, ¬v). We can
also consider paraconsistent − and intuitionistic ∼ negation,
defined on three-values as: −0 =∼ 0 = 1, −1 =∼ 1 = 0,
−u = 1 and ∼ u = 0. On orthopairs they are translated
respectively as
−(P, N ) := (P c , P )

(a)

Figure 4.
1, 3,

∼ (P, N ) := (N, N c )

∼ (v, v) := (v, v)

The first three columns of Table 1 summarize the above results.
3
0
u
1
undef.
0<u<1
u < 1; u < 0
u<1<0
u<0<1
min
max
min2
max2

Orthopairs
(∅, X)
(∅, ∅)
(X, ∅)
undef.

+
¬
E(¬(·))

+
¬
E(¬(·))

Table 1.

7

1
2
3
4
1
1
2
2

Valuation pairs
(0, 0)
(0, 1)
(1, 1)
undef.
≤
≤2
≤3
≤4
∧
∨
⊗
⊕

¬

(b)

Representations of orders 2 (on the left) and
(on the right) on possibility distributions.

4

Example 7.1. Let us consider (P1 , N1 ) 3 (P2 , N2 ). Then,
the valuation w such that w (p) = 1 for all p ∈ P2 and
w (p) = 0 elsewhere belongs to E2 but not to E1 since
w (p) = 0, p ∈ P1 \P2 . On the contrary, w (p) = 0, p ∈ N1
and w (p) = 1 elsewhere is such that w ∈ E1 and w ∈ E2 .
Both w , w are compatible with the fact Bnd2 ⊆ Bnd1 and
N1 ⊆ N2 . A similar example can be given in the case of
1, 4.

so, on valuation pairs they read as
−(v, v) := (¬v, ¬v)

!#

!#

Ω
ω0
Ω
ω1
∅
overlap1
⊇
overlap2
overlap3

Now, let us consider the operations. First of all 2 , that is
⊗, and 2 . Clearly they are the meet and join (when it exists)
on orthopairs. On the other hand the join and meet with
respect to the subsethood relation are the intersection and
union of sets (possibility distributions). However, 2 does not
correspond to the union between possibility distributions, i.e.,
E(P1 ,N1 ) 2 (P2 ,N2 ) = E(P1 ,N1 ) ∪ E(P2 ,N2 ) . We can just prove:
Proposition 7.1.

Proj
∩

E(P1 ,N1 ) ∪ E(P2 ,N2 ) ⊆ E((P1 ,N1 )

2 (P2 ,N2 ))

.

The other direction does not hold, indeed, consider the
following valuation w∗ : w∗ (p) = 1 if p ∈ P1 ∩ P2 and
w∗ (p) = 0 if p ∈ (P1 ∩ P2 )c , then w∗ ∈ E(P1 ,N1 ) 2 (P2 ,N2 )
but w∗ ∈ E(P1 ,N1 ) ∪ E(P2 ,N2 ) .
This behaviour is due to the non-representability of non
rectangular regions by orthopairs. Indeed, we can only represent the smallest hyper-rectangle which contains E(P1 ,N1 )
and E(P2 ,N2 ) (the rectangular closure of their union), which
corresponds indeed to E((P1 ,N1 ) 2 (P2 ,N2 )) .

∪
Proj
·c

We recall that ⊕ is not always definable.

Proposition 7.2. E((P1 ,N1 ) 2 (P2 ,N2 )) = ×i (P roji E(P1 ,N1 ) ∪
P roji E(P2 ,N2 ) ) = RC(E(P1 ,N1 ) ∪ E(P2 ,N2 ) ).

From orthopairs to possibility
distributions

On the other hand, the union of two possibility distributions
is generally not representable on orthopairs, but on the powerset of orthopairs, since it corresponds to the collection (not
aggregation) of two orthopairs. We can denote this situation
as (P1 , N1 ) + (P2 , N2 ) with the meaning that it represents the
set {(P1 , N1 ), (P2 , N2 )}. From an interpretation standpoint
we can think that we desire to collect all the situations where
at least one of two agents is right, without specifying which
one. It can be easily seen that

We now translate all the above orders and operations in terms
of Boolean possibility distributions, i.e., subsets of Ω.
First of all, let us consider constant elements. We have that
(∅, A) and (A, ∅) corresponds to a possibility distribution with
just one element, respectively: ∀a ∈ A, w0 (a) = 0 and ∀a ∈
A, w1 (a) = 1. On the other hand, (∅, ∅) generate the whole
set of valuations Ω. The contradiction (emptyset on Ω) is not
representable by an orthopair, or we can interpret it as being
generated by all paraconsistent (ortho-)pairs (F, G).

E((P1 ,N1 )+(P2 ,N2 )) = E(P1 ,N1 ) ∪ E(P2 ,N2 ) .

89

ECAI-2012 Workshop WL4AI

Further, by propositions 7.1 and 7.5 we can derive

Of course, we cannot express this operation in terms of set
operations on A. The same applies to three-valued functions,
since this operation just corresponds to the set of the two
functions representing the two orthopairs τ(P1 ,N1 ) +τ(P2 ,N2 ) =
{τ(P1 ,N1 ) , τ(P2 ,N2 ) }.
If we consider the case of two consistent orthopairs, then
also the operation 2 is defined and we have:
Proposition 7.3. E(P1 ,N1 ) ∩ E(P2 ,N2 ) = E(P1 ,N1 )
E(P1 ,N1 ) (P2 ,N2 ) .

2 (P2 ,N2 )

E(P1 ,N1 ) ∪ E(P2 ,N2 ) ∪ E((P1 ,N1 )

=

E((P1 ,N1 )

which is clearly different from the possibility distribution we
obtain from the (involutive) negation of (P, N ):
E(¬(P,N)) = E(N,P )
.
The + operation enables also to deal with the negation
of a possibility distribution in terms of orthopairs. Let us
define the unary operations E (P, N ) = (+pi ∈P ({pi }, ∅)) +
(+ni ∈N (∅, {ni })), that is, E = {({pi }, ∅), (∅, {ni }) : pi ∈
P, ni ∈ N }. Then:

Vice-versa by considering the projections of E(P,N)
and complementing them we obtain the corresponding of
E(¬(P,N)) with the caution not to use the set complement
but the three-valued involutive complement: {0} = {1},
{1} = {0} and {0, 1} = {0, 1}.
Proposition 7.4. ×i (P roji EP,N ) = E(¬(P,N))
Finally, the consensus E(P1 ,N1 ) (P2 ,N2 ) contains the intersection of the two possibility distribution and is contained in
E(P1 ,N1 ) 2 (P2 ,N2 ) .
Proposition 7.5.
.

However, it is incomparable with the union, that is there
exists w ∈ E(P1 ,N1 ) (P2 ,N2 ) such that w ∈ E(P1 ,N1 ) ∪ E(P2 ,N2 )
and vice versa.
Example 7.2. Let us consider the following w1 ,
(
1
p ∈ (P1 \N2 ∪ P2 \N1 )
w1 (p) =
0
otherwise
it belongs to E(P1 ,N1 ) (P2 ,N2 ) and not to E(P1 ,N1 ) ∪ E(P2 ,N2 ) .
Vice versa, the following valuation
8
1
p ∈ P1
>
>
>
<0
p ∈ N1
w2 (p) =
>
0
p ∈ P2 \P1
>
>
:
1
otherwise
belongs to E(P1 ,N1 ) ∪ E(P2 ,N2 ) and not to E(P1 ,N1 )

(P2 ,N2 ))

= E(P1 \N2 ,N1 \P2 ) ∩ E(P2 \N1 ,N2 \P1 ) .

[1] N. D. Belnap, ‘A useful four-valued logic’, in Modern Uses
of Multiple-Valued Logic, eds., J. M. Dunn and G. Epstein,
8–37, D. Reidel Publishing Company, (1977).
[2] P. Besnard and A. Hunter, ‘Quasi-classical logic: Nontrivializable classical reasoning from incosistent information’,
in ECSQARU, eds., Christine Froidevaux and J¨
urg Kohlas,
volume 946 of Lecture Notes in Computer Science, pp. 44–51.
Springer, (1995).
[3] S. Blamey, ‘Partial logic’, in Handbook of Philosophical Logic,
eds., D. M. Gabbay and F. Guenthner, volume 3, 1–70, D.
Reidel Publishing Company, (1985).
[4] G. Cattaneo, D. Ciucci, and D. Dubois, ‘Algebraic models
of deviant modal operators based on de morgan and kleene
lattices’, Inf. Sci., 181(19), 4075–4100, (2011).
[5] D. Ciucci, ‘Orthopairs: A simple and widely usedway to model
uncertainty’, Fundam. Inform., 108(3-4), 287–304, (2011).
[6] D. Dubois, S. Konieczny, and H. Prade, ‘Quasi-possibilistic
logic and its measures of information and conflict’, Fundam.
Inform., 57(2-4), 101–125, (2003).
[7] D. Dubois and H. Prade, ‘Conditional objects as nonmonotonic consequence relationships’, IEEE Transaction of
Sysyems, Man, and Cybernetics, 24(12), 1724–1740, (1994).
[8] D. Dubois and H. Prade, ‘Possibility theory, probability theory and multiple-valued logics: A clarification’, Annals of
Mathematics and Artificial Intelligence, 32, 35–66, (2001).
[9] S. C. Kleene, Introduction to metamathematics, North–
Holland Pub. Co., Amsterdam, 1952.
[10] J. Lawry and D. Dubois, ‘A bipolar framework for combining
beliefs about vague propositions’, in Proceedings KR 2012,
Roma, pp. 530–540, (2012).
[11] J. Lawry and I. Gonz´
alez Rodr´ıguez, ‘A bipolar model of assertability and belief’, Int. J. Approx. Reasoning, 52(1), 76–
91, (2011).
[12] S. Shapiro, Vagueness in Context, Oxford University Press,
2006.
[13] Y. Yao, ‘Interval sets and interval-set algebras’, in Proceedings of the 8th IEEE International Conference on Cognitive
Informatics, pp. 307–314, (2009).

The operation E on three-valued functions, corresponds to
collect all the following functions:
(
(
0
x = ni
1
x = pi
τ (x) =
τ (x) =
1/2 otherwise
1/2 otherwise

2 (P2 ,N2 )

.

REFERENCES

(E(P,N) )c = EE(¬(P,N))

⊆ E(P1 ,N1 )

2 (P2 ,N2 )

Table 1 summarizes these translations from one language to
another. The term “Proj” means that the corresponding operation can be characterized in terms of projections. The impossibility to express 1 and 1 in terms of general subsets
of valuation comes from the fact that they do not consider
positive and negative literals on a pair. Other impossible direct translations come from the fact that the set-union of
hyper-rectangles of interpretations is generally not an hyperrectangle, or stated otherwise, that the disjunction of partial
models is not a partial model.

(E(P,N) )c = {ω : ∃p ∈ P w(p) = 0 or ∃p ∈ N w(p) = 1}

(P2 ,N2 )

⊆ E(P1 ,N1 )

But not the opposite direction, as can be seen by considering
the valuation w∗ above.
If we write (P1 , N1 ) (P2 , N2 ) in terms of unions among orthopairs, we see that (P1 , N1 ) (P2 , N2 ) = (P1 \N2 , N1 \P2 ) ∪
(P2 \N1 , N2 \P1 ) and thus by proposition 7.3, we get

Let us consider now the case of negation. The negation of
a possibility distribution E is its set complement

E(P1 ,N1 ) ∩ E(P2 ,N2 ) ⊆ E(P1 ,N1 )

(P2 ,N2 ))

(P2 ,N2 ) .

90

ECAI-2012 Workshop WL4AI

Handling partially ordered preferences
in possibilistic logic
- A survey discussion Didier Dubois and Henri Prade and Fayçal Touazi1
Abstract. This paper advocates possibilistic logic with partially ordered priority weights as a powerful representation format for handling preferences. An important benefit of such a logical setting is
the ability to check the consistency of the specified preferences. We
recall how Qualitative Choice Logic statements (and related ones),
as well as CP-nets preferences can be represented in this framework.
We investigate how a generalization of CP-nets, namely CP-theories,
can also be handled in a partially ordered possibilistic logic setting.
Finally we suggest how this framework may be used for handling
preference queries.

1

N (p) = minω�∈M (p) (1 − π(ω)) = 1 − Π(¬p), where Π is the
possibility measure associated to N and M (p) is the set of models
induced by the underlying propositional language for which p is true.
The base B N is associated to the possibility distribution
N
πB (ω) = minj=1,...,m π(pj ,αj ) (ω) on the set of interpretations,
where π(pj ,αj ) (ω) = 1 if ω ∈ M (pj ), and π(pj ,αj ) (ω) = 1 − αj
if ω �∈ M (pj ). An interpretation ω is all the more possible as it does
not violate any formula pj having a higher priority level αj . Hence,
this possibility distribution is expressed as a min-max combination:
N
πB
(ω) =

INTRODUCTION

∆
πB
(ω) = max π[qi ,βi ] (ω)
i=1,...,n

with π[qi ,βi ] (ω) = βi if ω ∈ M (qi ) and π[qi ,βi ] (ω)
S = 0 oth∆
erwise. If ω ∈ M (qi ), πB
(ω) ≥ βi , and if ω ∈ i∈I M (qi ),
∆
(ω) ≥ maxi∈I βi . So this base is a description “from below"
πB
∆
of πB
, which is the most specific possibility distribution in agreement with the knowledge base B ∆ . A dual possibilistic base B ∆ can
always be transformed in a base in which the formulas qj are con∆
junctions of literals (cubes) without altering πB
.
∆
A possibilistic logic base B expressed in terms of guaranteed
possibility measure can always be rewritten equivalently in terms of
standard possibilistic logic B N based on necessity measures [10, 8]
N
∆
and conversely with the equality πB
= πB
. This transformation is
N
similar to a description from below of πB .
In case of mutually exclusive propositions, p1 ,... pi , ..., pn , if
N (p1 ) ≥ α1 > 0, then N (p2 ) = ... = N (pn ) = 0 for the sake

POSSIBILISTIC LOGIC

We consider a propositional language where formulas are denoted
by p1 , ..., pn , and Ω is its set of interpretations. Let B N =
{(pj , αj ) | j = 1, . . . , m} be a possibilistic logic base where pj
is a propositional logic formula and αj ∈ L ⊆ [0, 1] is a priority level [23]. The logical conjunctions and disjunctions are denoted
∧ and ∨. Each formula (pj , αj ) means that N (pj ) ≥ αj , where
N is a necessity measure, i.e., a set function satisfying the property
N (p ∧ q) = min(N (p), N (q)). A necessity measure is associated
to a possibility distribution π as follows:
1

max(1 − αj , IM (pj ) (ω))

where IM (pj ) is the characteristic function of M (pj ). So, if ω �∈
T
N
N
(ω) ≤ 1 − αj , and if ω ∈ j∈J M (¬pj ), πB
(ω) ≤
M (pj ), πB
N
minj∈J (1 − αj ). It is a description “from above" of πB , which is
the least specific possibility distribution in agreement with the knowledge base B N . A possibilistic base B N can be transformed in a base
where the formulas pi are clauses (without altering the distribution
N
πB
). We can still see B N as a conjunction of weighted clauses, i.e.,
as an extension of the conjunctive normal form.
A dual representation of the possibilistic logic is based on guaranteed possibility measures. A guaranteed possibility measure is
associated to a possibility distribution π as follows: ∆(p) =
minω∈M (p) π(ω). Hence a logical formula is a pair [q, β], interpreted
as the constraint ∆(q) ≥ β, where ∆ is a guaranteed possibility
(anti-)measure characterized by ∆(p ∨ q) = min(∆(p), ∆(q)) and
∆(∅) = 1. In such a context, a base B ∆ = {[qi , βi ] | i = 1, . . . , n}
is associated to the distribution

Possibilistic propositional logic is a logic where classical propositions are associated with priority levels; see [23] for an introduction.
In this setting, inconsistency amounts to having a classically inconsistent set of propositions that are all associated with strictly positive
priority levels. In particular, one cannot give priority both to p and to
¬p. Possibilistic logic may be used for handling uncertainty, or preferences. In this discussion paper, we survey the use of possibilistic
logic for representing preferences, and compare it with popular representation settings for preferences such as CP-nets [14], CP-theories
[36], or Qualitative Choice Logic [15]; see [17] for an introductory
survey on the handling of preferences in artificial intelligence, operations research, or data bases literature.
After a brief refresher on possibilistic logic, the paper provides
an account of the handling of ordered conjunctions and disjunctions
for preference modeling in possibilistic logic. We then advocate the
use of partially ordered symbolic weights for coping with the need
of leaving room for incomparability, as observed in CP-nets or in
CP-theories settings.

2

min

j=1,...,m

IRIT, University of Toulouse, France, email: {dubois, prade, Faycal.Touazi}@irit.fr

91

ECAI-2012 Workshop WL4AI

i.e., one prefers to have the three conditions satisfied rather
than the two first ones only, which is itself better than having
just the first condition satisfied (which in turn is better than not
having even the first condition satisfied). This is indeed simply
described in possibilistic logic as the conjunction of prioritized goals
C = {(p1 , γ1 ), (p2 , γ2 ), (p3 , γ3 )} with 1 = γ1 > γ2 > γ3 > 0. It
can be checked that this possibilistic logic base is associated with
the possibility distribution

of consistency. But, the set of requirements ∆(p1 ) ≥ β1 > 0, ...,
∆(pi ) ≥ βi > 0, ..., ∆(pn ) ≥ βn > 0 is consistent, and if β1 =
1 > · · · > βi > · · · > βn > 0, it can be equivalently represented
by N (p1 ) ≥ α1 , N (p1 ∨ p2 ) ≥ α2 , ..., N (p1 ∨ p2 ∨ · · · ∨ pi ) ≥ αi ,
..., N (p1 ∨ p2 ∨ · · · ∨ pn ) ≥ αn , with αi = 1 − βi+1 and βn+1 = 0.
What makes the possibilistic logic setting particularly appealing
for the representation of preferences is not only the fact that the language incorporates priority levels explicitly, but the existence of different representation formats [9, 21], whose representation power is
equivalent [4, 5], but which are more or less natural or suitable for
expressing preferences. Thus, preferences can be represented

πC (ω) = 1 if ω ∈ M (p1 ∧ p2 ∧ p3 )
1 − γ3 if ω ∈ M (p1 ∧ p2 ∧ ¬p3 )
1 − γ2 if ω ∈ M (p1 ∧ ¬p2 )
0 if ω ∈ M (¬p1 ).

• as prioritized goals, i.e. possibilistic formulas of the form (pi , αi )
meaning that N (pi ) ≥ αi , and stating that making pi true has
priority level αi ;
• in terms of guaranteed satisfaction levels by means of formulas of
the form [qj , βj ] understood as ∆(qj ) ≥ βj , and stating that as
soon as one satisfies qj then one reaches at least satisfaction levels
βj [6];
• by means of a possibility distribution, where an ordering is explicitly stated between the interpretations of the language; the ordering is complete as soon as the values of the possibility degrees are
known;
• in terms of conditionals of the form Π(p ∧ q) > Π(p ∧ ¬q) (including the case where is p is a tautology, i.e., N (q) > N (¬q) =
0 ⇔ Π(q) = 1 > Π(¬q)) expressing that in the context where
p is true, there is at least one interpretation where q is true which
is preferred to all interpretations where q is false. As pointed out
in [18, 20] and analyzed in details in [33], there are other comparative statements of interest, namely ∆(p ∧ q) > Π(p ∧ ¬q),
Π(p ∧ q) > ∆(p ∧ ¬q), and ∆(p ∧ q) > ∆(p ∧ ¬q). For instance,
the first one of the three is clearly more drastic than the initial one
we considered since it requires that in context p, any interpretation
where q is true is preferred to all interpretations where q is false;
• as Bayesian-like networks, since a possibilistic logic base can be
encoded either as a qualitative or as a quantitative possibilistic
networks and vice-versa. Qualitative and quantitative possibilistic networks are respectively associated with a minimum- and a
product-based definition of conditioning [3].

Disjunctions. We may also consider disjunctive queries with priorities, i.e., queries of the form “p1 is required with priority, or failing
this p2 , or still failing this p3 ”, as discussed in [13]. It has the following intended meaning in terms of interpretations:

3

M (p1 ) � M (¬p1 ∧p2 ) � M (¬p1 ∧¬p2 ∧p3 ) � M (¬p1 ∧¬p2 ∧¬p3 ).

which fully agrees with the above ordering.
Moreover in a logical encoding, a query such as “find the x’s such
that condition Q is true", i.e., ∃x Q(x)? is usually processed by
refutation. Using a small old trick due to Green [27], it amounts to
adding the formula(s) corresponding to ¬Q(x) ∨ answer(x), expressing that if item x satisfies condition Q it belongs to the answer,
to the logical base describing the content of the database. It enables
theorem-proving by resolution to be applied to question-answering.
This idea extends to preference queries expressed in a possibilistic
logic setting [13]. The expression of the query Q corresponding to
the above set of prioritized goals is then of the form
Q = {(¬p1 (x) ∨ ¬p2 (x) ∨ ¬p3 (x) ∨ answer(x), 1),
(¬p1 (x) ∨ ¬p2 (x) ∨ answer(x), 1 − γ3 ),
(¬p1 (x) ∨ answer(x), 1 − γ2 )}.
where 1 > 1 − γ3 > 1 − γ2 . Then, the levels associated with
the possibilistic logic formulas expressing the preference query
are directly associated with the possibility levels of the possibility
distribution πC providing its semantics.

ORDERED CONJUNCTIONS AND
DISJUNCTIONS

As can be checked, it corresponds to the following possibilistic logic
base representing a conjunction of prioritized goals:

In the following, propositional variables refer to properties of items,
to be rank-ordred in terms of preferences, and formulas represent
requests to be satisfied.
Conjunctions. Putting priorities on goals is easy to understand as
a way for specifying preferences, and amounts to express a weighted
conjunction of goals, which may be stated by means of ‘and if possible’ in statements such as “p1 and if possible p2 and if possible p3 ”
(p1 is more important than p2 , which is itself more important than
p3 ). Such statements have been first considered in [34] in another
setting.
The pi ’s may be logically independent or not. For the sake of simplicity, we use here three conditions only, but what follows would
straightforwardly extend to n conditions. We denote by M (pi ),
M (pi ∧ pj ), the set of items (if any) satisfying condition pi , the
set of items (if any) satisfying pi and pj , and so on. So the query “p1
is required and if possible p2 also and if possible p3 too”, has the
following intended meaning (� reads “is preferred to”)

DN = {(p1 ∨ p2 ∨ p3 , 1), (p1 ∨ p2 , γ2 ), (p1 , γ3 )}.
(with 1 > γ2 > γ3 ) whose associated possibility distribution is
πDN (ω) = 1 if ω ∈ M (p1 )
1 − γ3 if ω ∈ M (¬p1 ∧ p2 )
1 − γ2 if ω ∈ M (¬p1 ∧ ¬p2 ∧ p3 )
0 if ω ∈ M (¬p1 ∧ ¬p2 ∧ ¬p3 ),
which is clearly in agreement with the above ordering. It can be also
equivalently expressed in a question-answering perspective by the
possibilistic logic base:
Q� = {(¬p1 (x) ∨ answer(x), 1),
(¬p2 (x) ∨ answer(x), 1 − γ3 ),
(¬p3 (x) ∨ answer(x), 1 − γ2 )}.

M (p1 ∧p2 ∧p3 ) � M (p1 ∧p2 ∧¬p3 ) � M (p1 ∧¬p2 ) � M (¬p1 )

92

ECAI-2012 Workshop WL4AI

which states that if an item x satisfies p1 , then it belongs to the answer to degree 1, and if it satisfies p2 (resp. p3 ), then it belongs to
the answer to a degree at least equal to 1 − γ3 (resp 1 − γ2 ).
As noticed in [13, 24], there is a perfect duality between conjunctive and disjunctive queries. Indeed the disjunctive query “p3 is required, or better p2 , or still better p1 ” can be also equivalently expressed under the conjunctive form “p1 or p2 or p3 is required and
if possible p1 or p2 , and if possible p1 ”. Conversely, the conjunctive
query “p1 is required and if possible p2 and if possible p3 ” can be
equivalently stated as the disjunctive query “p1 is required, or better
p1 and p2 , or still better p1 and p2 and p3 ”. This can be checked on
their respective possibilistic logic representations.
Let us point out the close relation between the possibilistic representation and qualitative choice logic (QCL) [15]. Indeed QCL introduces a new connective denoted ×, where p1 × p2 means “if possible
p1 , but if p1 is impossible then (at least) p2 ”. This corresponds to a
disjunctive preference of the above type. Then, the query “p1 , or at
least p2 , or at least p3 ”, which, as already explained, corresponds to
stating that p1 is fully satisfactory, p2 instead is less satisfactory, and
p3 instead is still less satisfactory, can be directly represented in the
possibilistic logic based on guaranteed possibility measures [2]. Using the notation of Section 2, the corresponding weighted base simply writes D∆ = {[p1 , 1], [p2 , 1 − γ3 ], [p3 , 1 − γ2 ]}, which clearly
echoes Q� . It encodes the same possibility distribution on models as
the necessity-based possibilistic logic base DN .
Note that in Q� , as in Q, the weights of the possibilistic logic formulas express a priority among the answers x that may be obtained.
They may be also viewed as representing the levels of satisfaction of
the answers obtained.
The linguistic expression of conjunctive queries may suggest that
p1 , p2 , p3 are logically independent conditions that one would like
to cumulate, as in the query “I am looking for a reasonably priced
hotel, if possible downtown, and if possible not far from the station”,
while in disjunctive queries one may think of p3 as a relaxation of
p2 , itself a relaxation of p1 . In fact there is no implicit limitation on
the type of conditions involved in conjunctive or disjunctive queries.
For instance, a conjunctive query such as “I am looking for a hotel
less than 2 km from the beach, if possible less than 1 km from the
beach, and if possible on the beach”, corresponds to the idea of
approximating a fuzzy requirement, such as “close to the beach” by
three of its level cuts, which are then relaxation or strengthening of
one another.

M (¬p1 ∧p2 ∧p3 ) � M (¬p1 ∧p2 ∧¬p3 ) � M (¬p1 ∧¬p2 ∧p3 ) �
M (¬p1 ∧ ¬p2 ∧ ¬p3 )
It can be checked that it can be encoded in possibilistic logic under
the form (we only give the question-answering form here):
Q” = {(¬p1 (x) ∨ ¬p2 (x) ∨ ¬p3 (x) ∨ answer(x), 1),
(¬p1 (x) ∨ ¬p2 (x) ∨ answer(x), α), (¬p1 (x) ∨ ¬p3 (x) ∨
answer(x), α� ),
(¬p1 (x) ∨ answer(x), α�� ), (¬p2 (x) ∨ ¬p3 (x) ∨ answer(x), β),
(¬p2 (x) ∨ answer(x), β � ), (¬p3 (x) ∨ answer(x), γ)}
with 1 > α > α� > α�� > β > β � > γ.
Constraints and wishes. A request of the form “A and if possible
B”, where both A and B are prioritized sets of specifications may be
understood in fact in different ways. Either we consider that A and
B are of the same nature, and the request may be reorganized into a
unique set of prioritized goals, or alternatively one may consider that
what is expressed in B is not at all compulsory, but are just “wishes”
that should be used for further discrimination between situations
that would be ranked in the same way according to A [22, 24]. We
are going to examine the difference between the two points of view,
in the simple case where both A and B are made of two conditions,
namely
A = {(a2 , 1), (a1 , 1 − α)} with 1 > 1 − α > 0, and
B = {(b2 , 1), (b1 , 1 − α� )} with 1 > 1 − α� > 0.
We further assume in this example that i) the conditions in A are
nested, as well as the ones in B, and ii) the conditions in B are refinements of those in A, which is necessary for allowing for a “wish”
understanding of B [22] in the second view. This means that we assume M (a2 ) ⊇ M (aT
1 ) ⊇ M (b1 ), M (a2 ) ⊇ M (b2 ) ⊇ M (b1 ) and
α� < α, with M (b2 ) M (a2 ) �= ∅.
When both A and B are viewed as constraints, i.e. as sets of
prioritized goals, namely and respectively, the request “A and if
possible B” translates into a unique set G of prioritized goals, where
the goals in B are discounted by 1 − λ, where α < λ so that the
weakest constraint in A has priority over the strongest constraint in
B:
G=
{(a2 , 1), (a1 , 1−α), (b2 , min(1, 1−λ)), (b1 , min(1−α� , 1−λ))}.

Hybrid queries. A mutual refinement of the two above types of
queries leads to “full discrimination-based queries” [13]. It amounts
to computing a lexicographic ordering of the different worlds (here
23 = 8 with 3 conditions), under the tacit, default assumption that it
is always better to have a condition fulfilled rather than not, even if
a more important condition is not satisfied. However, it is clear that
sometimes satisfying an auxiliary condition while failing to satisfy
the main condition may be of no interest, as in the example “I would
like a coffee if possible with sugar”, where having sugar or not, if no
coffee is available, makes no difference. There are even situations,
in case of a conditional preference, where it may be worse to have
p2 satisfied than not when p1 cannot be satisfied, as in the example
“I would like a Ford car if possible black” (if one prefers any other
color for non Ford cars). Full discrimination-based queries are thus
associated with the following preference ordering:

This possibilistic logic base is associated with the possibility
distribution
πG (ω) = 1 if ω ∈ M (a1 ∧ b1 )
λ if ω ∈ M (a1 ∧ ¬b1 )
α if ω ∈ M (a2 ∧ ¬a1 ∧ b2 )
0 if ω ∈ M (¬a2 ).
Let us now consider the second view where only A is regarded
as a set of prioritized constraints, while B is a set of prioritized
wishes. Now we keep A and B separate. Each interpretation ω is the
associated with a pair of values: the first (resp. the second) value is
equal to 1 − γ ∗ (resp. 1 − δ ∗ ) where γ ∗ (resp. δ ∗ ) is the priority of
the formula violated by ω having the highest priority in A (resp. B).
We obtain, the following vector-valued possibility distribution:

M (p1 ∧ p2 ∧ p3 ) � M (p1 ∧ p2 ∧ ¬p3 ) � M (p1 ∧ ¬p2 ∧ p3 ) �
M (p1 ∧ ¬p2 ∧ ¬p3 ) �

93

ECAI-2012 Workshop WL4AI

Namely if c is true, one should have a or b (the choice is only
between a and b), and in context c, it is somewhat imperative to
have a true. This encodes a constraint of the form N (¬c ∨ a) ≥ α,
itself equivalent here to a constraint on a conditional necessity
measure N (a|c) ≥ α (see, e.g., [23]). This is still equivalent
to Π(¬a|c) ≤ 1 − α, where Π is the dual possibility measure
associated with N . It expresses that the possibility of not having
a is upper bounded by α, i. e. ¬a is all the more impossible
as α is small. Such a modeling has been proposed in [30] for
representing preferences, and approximating CP-nets. It can be
proved that {(¬c ∨ a ∨ b, 1), (¬c ∨ a, α)} is equivalent to requesting
N (a|c) ≥ α > 0 = N (b|c). Note that when b ≡ ¬a, the first
clause becomes a tautology, and thus does not need to be written.
Strictly speaking, the possibilistic clause (¬c ∨ a, α) expresses a
preference for a (over ¬a) in context c. The clause (¬c ∨ a ∨ b, 1) is
only needed if a ∨ b does not cover all the possible choices. Assume
a ∨ b ≡ ¬d (where ¬d is not a tautology), then it makes sense to
understand the preference for a over b in context c, as the fact that
in context c, b is a default choice if a is not available. If one wants
to open the door to remaining choices, it is always possible to use
(¬c ∨ a ∨ b, α� ) with α� > α, instead of (¬c ∨ a ∨ b, 1). Thus,
the approach easily extends to non binary choices. For instance,
“I prefer Renault (r) to Chrysler (c) and Chrysler to Ford (f )" is
encoded as {(r ∨ c ∨ f, 1), (r ∨ c, α), (r, α� )}, with α > α� .

π(A,B) (ω) = (1, 1) if ω ∈ M (a1 ∧ b1 )
(1, α� ) if ω ∈ M (a1 ∧ ¬b1 ∧ b2 )
(1, 0) if f ω ∈ M (a1 ∧ ¬b2 )
(α, α� ) if ω ∈ M (a2 ∧ ¬a1 ∧ b2 )
(α, 0) if ω ∈ M (a2 ∧ ¬a1 ∧ ¬b2 )
(0, 0) if ω ∈ M (¬a2 ).
Note the lexicographic ordering of the evaluation vectors. We now
have 6 layers of interpretations (instead of 4 in the previous view),
which makes it clear that this second view is more refined. However,
in the rest of the paper, all the preferences are viewed as constraints.

4

CP-NETS IN POSSIBILISTIC LOGIC

This section presents a possibilistic logic approach with symbolic
weights that generalizes the representation of preferences reviewed
in Section 3. The proposed method enables the handling of conditional preferences, as well as the representation of prioritized conjunctions. The approach is both more faithful to user’s preferences
than the CP-net approach as we shall see. Formally, a CP-net [28] N
over the set of Boolean variables V = {X1 , · · · , Xn } is a directed
graph over the nodes X1 , · · · , Xn , and there is a directed edge from
Xi to Xj if the preference over the value Xj is conditioned on the
value of Xi . Each node Xi ∈ V is associated with a conditional
preference table CP T (Xi ) that associates a strict (possibly empty)
partial order >CP (ui ) with each possible instantiation ui of the parents of Xi . A complete preference ordering satisfies a CP-net N iff it
satisfies each conditional preference expressed in N . In this case, the
preference ordering is said to be consistent with N . Since CP-nets
encode partial orders, while possibilistic logic encodes a complete
preorder (when priorities are given), these two formalisms cannot be
equivalent. The best we can do is to approximate CP-nets in possibilistic logic. A faithful approximation of a CP-net in possibilistic
logic consists in preserving all strict preferences induced by the CPnet [18, 20]. However, by enforcing appropriate ordering constraints
between symbolic weights, we can obtain an exact representation of
a CP-net in possibilistic logic with symbolic weights [29, 32], as explained now.
Using an example, we first present the idea of representing conditional preferences by means of possibilistic logic formulas with
symbolic weights. We then introduce a natural preorder between formulas, which may be then completed by further constraints between
symbolic weights. Lastly, a general evaluation procedure is outlined.

4.1

It is worth noticing that the encoding of preferences in this framework also applies to Lacroix and Lavincy’s approach [34], namely,
when one wants to express that “p1 ∧ p2 is preferred to p1 ∧ ¬p2 "
and p1 is mandatory. It is encoded by ((p1 ∧ p2 ) ∨ (p1 ∧ ¬p2 ), 1),
equivalent to (p1 , 1), and by (p1 ∧p2 , 1−α) equivalent to (p1 , 1−α)
and (p2 , 1 − α), (p1 , 1 − α) being subsumed by (p1 , 1). Thus, one
retrieves the encoding (p1 , 1) and (p2 , 1 − α), already proposed in
Section 3.

4.2

Preorder induced by formulas with symbolic
priority levels.

When one does not know precisely how imperative the preferences
are, the weights can be handled in a symbolic manner, and then
partially ordered. This means that the weights are replaced by
variables that are assumed to belong to a linearly ordered scale
(the strict order will be denoted by � on this scale), with a top
element (denoted 1) and a bottom element (denoted 0). Thus, 1 − (.)
should be regarded here just as denoting an order-reversing map
on this scale (without having a numerical flavor necessarily), with
1 − (0) = 1, and 1 − (1) = 0. On this scale, one has 1 � 1 − α, as
soon as α �= 0. The weights are different from 1 but are all greater
than 0. We assume that the order-reversing map relates to two scales:
the one graded in terms of necessity degrees, or if we prefer here in
terms of imperativeness, and the one graded in terms of possibility
degrees, i.e. here, in terms of satisfaction levels. Thus, the level of
priority α for satisfying a preference is changed by the involutive
mapping 1 − (·) into a satisfaction level when this preference is
violated.

Possibilistic representation of conditional
preferences – An example.

Example 1 taken from [36], is about planning holidays, where one
has the following preferences: one can either go next week (n) or
later in the year (¯
n). One can decide to go either to Oxford (o) or
to Manchester (¯
o), and one can either take a plane (p) or drive and
take a car (¯
p). So, there are three variables X1 , X2 and X3 where
X1 ={n, n
¯ }, X2 ={o, o¯} and X3 ={p, p¯}, where X stands for a set of
possible assignments of X. Suppose the person prefers to go next
week than later in the year and prefers to fly than to drive unless he
goes later in the year to Manchester.
Such preferences can be encoded as prioritized goals in possibilistic logic, as explained now. The possibilistic encoding of the conditional preference “in context c, a is preferred to b” is a pair of possibilistic formulas: {(¬c ∨ a ∨ b, 1), (¬c ∨ a, α)} with 1 > α > 0.

Example 1: Let N be a CP-net over variables X1 , X2 and X3 ,
let Γ be a set of constraints, ϕi ∈ Γ, where ϕ1 = � : n > n
¯,
ϕ2 = � : o > o¯, ϕ3 = n : p > p¯, ϕ4 = o : p > p¯ and
ϕ5 = no
¯ : p¯ > p. These constraints do not encode a complete
CP-Net. But it can be completed by making it explicit with the
additional constraints : ϕ6 = no : p > p¯, ϕ7 = n¯
o : p > p¯

94

ECAI-2012 Workshop WL4AI

and ϕ7 = n
¯ o : p > p¯. Note that in possibilistic logic, we are not
obliged to explicit all these constraints, indeed it is encoded by the
possibilistic constraints K1 = {c1 = (n, α), c2 = (o, β), c3 =
(¯
n∨p, γ), c4 = (¯
o ∨ p, δ), c5 = (n ∨ o ∨ p¯, ε)}. Since the values
of the weights α, β, γ, δ, ε are unknown, no particular ordering is
assumed between them. Table 1 gives the satisfaction levels for
the possibilistic clauses encoding the five elementary preferences,
and the eight possible choices. The last column gives the global
satisfaction level by minimum combination.

Table 1.
nop
no¯
p
n¯
op
n¯
op¯
n
¯ op
n
¯ o¯
p
n
¯ o¯p
n
¯ o¯p¯

c1
1
1
1
1
1- α
1- α
1- α
1- α

Possible alternative choices in Example1.
c2
1
1
1- β
1- β
1
1
1- β
1- β

c3
1
1-γ
1
1-γ
1
1
1
1

c4
1
1-δ
1
1
1
1-δ
1
1

c5
1
1
1
1
1
1
1-ε
1

min
1
1-γ,1-δ
1- β
1- β,1-γ
1- α
1- α,1-δ
1- α, 1- β,1-ε
1- α ,1- β

Figure 1.

4.3
Even if the values of the weights are unknown, as it is the case in
the above example, a partial order between the interpretations (they
are 8 in our example) is naturally induced by a Pareto ordering (denoted �P ar ) between the corresponding vectors evaluating the satisfaction levels with respect to the constraints.
Generally speaking, let K = {(ai , αi )} be a set of formulas associated with symbolic weights. Let t, t� be two interpretations of the
set of formulas {ai |i = 1, n)} associated with the vectors of their
evaluations with respect to each formula in K. Then, we have

CP-net and partial order induced by it

Introducing preferences between symbolic
weights

The authors of [32] have proposed an encoding of CP-nets by imposing a partial order between the symbolic weights of formulas. The
partial order on symbolic weights is defined as follows. For each pair
of formulas (¬ui ∨ x, αi ) and (¬uj ∨ y, αj ) such that X is a father of Y where uj is (¬ui ∨ ¬x) or (¬ui ∨ x), we put αi > αj
[32, 28]. These constraints between symbolic weights can be obtained by Algorithm 1, which computes the partial order between
symbolic weights from a set of ceteris paribus statements.
Once we have got this partial order over symbolic weights, we
use the leximin order defined below, for refining the �P ar ordering
used before:

t �P ar t� iff Σt ⊂ Σt� ,
where Σt (resp. Σt� ) is the set of formulas in K violated by t (resp.
t� ).
In our example, we have for instance the following P areto orderings between the 5-component vectors

Leximin with partially ordered weights: Let Ψ = {1 −
α1 , · · · 1−αn , 1} be a set of symbolic possibility degrees , and ω, ω �
two interpretations ∈ Ω. Let Ψ(ω) = (πi (ω) · · · πn (ω)), Ψ(ω � ) =
(πi (ω � ) · · · πn (ω � )) be their vectors of evaluation in terms of sym(1−α, 1, 1, 1, 1) �P ar (1−α, 1−β, 1, 1, 1) �P ar (1−α, 1−β, 1, 1, 1−ε) bolic weights (with respect to the violated formulas). Then the leximin ordering denoted �lex between vectors of values belonging to a
whatever the values of α, β, ε. Thus, we get the following partial
totally ordered set consists in applying the discrimin procedure after
order between interpretations:
reordering their components in increasing order. The leximin ordernop �P ar {no¯
p, n¯
op, n
¯ op, n¯
op¯, n
¯ o¯
p, n
¯ o¯p¯, n
¯ o¯p}
ing can be extended as follows:
n
¯ op �P ar n
¯ o¯p �P ar n
¯ o¯p¯
n¯
op �P ar n¯
op¯ ; n
¯ op �P ar n
¯ o¯
p
• delete all pairs (πi (ω), πj (ω � )) where πi (ω) = πj (ω � ) so we get
�
Thus, this partial order amounts to rank-ordering a vector v after
Ψ∗ (ω) and Ψ∗ (ω � ) where Ψ∗ (ω) ∩ Ψ∗ (ω � ) = ∅
a vector v, each time the set of preferences violated in v is strictly in• ω �lex ω � iff min(Ψ∗ (ω) ∪ Ψ∗ (ω � )) ⊆ Ψ∗ (ω)
cluded in the set of preferences violated in v � , since nothing is known
• ω and ω are incomparable iff min(Ψ∗ (ω) ∪ Ψ∗ (ω � )) �⊆ Ψ∗ (ω)
on the relative values of the symbolic levels (except they are strictly
and min(Ψ∗ (ω) ∪ Ψ∗ (ω � )) �⊆ Ψ∗ (ω � ).
smaller than 1, when different from 1). Then a vector v is greater
Note that this leximin ordering is the same as discrimin and
than another v � , only when the components of v are equal to 1 for
P areto orderings, if weights are incomparable. When some weights
those components that are different in v and v � .
are comparable, discrimin and P areto orderings still coincide due
We could also use the discrimin order denoted by �discrimin
to the particular nature of the vectors that are compared (i.e., vectors
defined in the following way: identical vector components are dis(u1 , · · · , ui , · · · , un ) such as ui ∈ {1, 1 − αi }), but the extended
carded, and the minima of the remaining components for each vector
leximin refines the Pareto ordering.
are compared. Note that t and t� are comparable only if one of the two
minima returns 1 (which is the only evaluation known to be greater
In Example 1, in the order induced by the Pareto ordering, the
than any symbolic weight (�= 1)). In fact here, the orderings �P ar
interpretations n¯
op¯, n
¯ o¯
p, n
¯ o¯p¯ are incomparable. Applying algorithm
and �discrimin coincide.

95

ECAI-2012 Workshop WL4AI

1, we give priority to father nodes, i.e., here, we introduce the following constraints between the symbolic weights α > max(γ, δ, ε)
and β > max(γ, δ, ε). Then, the application of leximin ordering
allows us to distinguish between {n¯
op¯, n
¯ o¯
p} and n
¯ o¯p¯. So, the
order induced by the CP-net, or equivalently the one induced by the
possibilistic approach giving priority to father nodes (see Figure 1) is:

minω|=tux π(ω) > maxω� |=tux� π(ω � ) [33] which has the
same semantics as the “irrespectively" constraint (given u x is preferred to x� irrespective of the assignments to W ). The possibilistic
encoding of CP-theory expression uses exactly the same possibilistic
formulas (with symbolic weights) as for the corresponding CP-net
expression (when W is ignored). All the additional constraints
between the weights of the father nodes with respect of child node
are also maintained. Further, constraints between weights are added
according to the procedure that we describe now.

nop �lex {no¯
p, n¯
op, n
¯ op},
{no¯
p, n
¯ op} �lex n
¯ o¯
p, {n¯
op, n
¯ op} �lex n¯
op¯
{n¯
op¯, n
¯ o¯
p} �lex n
¯ o¯p¯ �lex n
¯ o¯p

Consider a CP-theory expression u : x > x� [W ]. It is encoded
by a possibilistic preference statement (¬u ∨ x, αi ). Then we shall
add the constraint αi > αj for any αj , such that (¬u ∨ w, αj )
is a possibilistic preference statement, with the same context u,
over one variable (or more) w ∈ W . These constraints over
weights can be obtained by Algorithm 2: from a set of CP-theory
statements of the forme u : x > x� [W ], we elicit a partial order
over symbolic weights used for inducing the same order between
interpretations as the CP-theory. This procedure indeed guarantees
that the constraints of the form ∆(tux) > Π(tux� ) which is same
as ∀w, w� ∈ W , π(tuxw) > π(tux� w� ) will be satisfied. Let us
give a sketch of the reason why:

Algorithm 1 calculates the relative importance between CP-net preferences statements
Require: C a set of constraints of the form (Pi , αi )
Γ a set of preference statement of the form u : x > x�
IDC=∅
for ϕi = ui : xi > x�i in Γ do
for cj in C do
if cj is of the form (ui , αj ) then
for ck in C do
if ck is of the form (¬ui ∨ xi , αk ) then
IDC ← IDC + (αj > αk )
end if
end for
end if
end for
end for
return IDC

5

Consider X = {x, x� } and W = {w, w� }, the possibilistic encoding
of the constraint will be ci = (¬u ∨ x, αi ), and consider that we
got a possibilistic constraint cj = (¬u ∨ w, αj ). Let the possibility
distribution of the constraint ∆(tux) > Π(tux� ) ∀t ∈ T :
•
•
•
•

CP-THEORIES IN POSSIBILISTIC LOGIC

Wilson [35, 36] has proposed a new formalism named CP-theories
that extends CP-nets and TCP-nets in order to express stronger
conditional preferences as well as the usual CP-net ceteris paribus
statements. For a set of variables V , the language LV (abbreviated
to L) consists of all statements of the form u : x > x� [W ], where
u is an assignment to a set of variables U ⊆ V (i.e., u ∈ U ),
x, x� ∈ X are different assignments to some variable X �∈ U (and
so x and x� correspond to different values of X) and W is some
subset of V − U − {X}. If ϕ is the statement u : x > x� [W ],
we may write uϕ = u, Uϕ = U, xϕ = x, x�ϕ = x� , Wϕ = W
and Tϕ = V − ({X} ∪ U ∪ W ). Subsets of L are called
conditional preference theories or CP-Theories (on V ). For
ϕ = u : x > x� [W ], let ϕ∗ be the set of pairs of interpretations
{(tuxw, tux� w� ) : t ∈ Tϕ , w, w� ∈ W }. Such pairs (ω, ω � ) ∈ ϕ∗
are intended to represent a preference for ω over ω � , and ϕ is
intended as a compact representation of the preference information
ϕ*. Informally, ϕ represents the statement that, given u and any
t, x is preferred to x� , irrespective of the assignments to W , it
means that we prefer any outcome with x to any outcome with x� ,
in the context
u. For conditional preference theory Γ ⊆ L, define
S
Γ∗ = ϕ∈Γ ϕ∗ , so Γ∗ represents a set of preferences. We assume
here that preferences are transitive, so it is then natural to define
order >Γ , induced on V by Γ, to be the transitive closure of Γ∗ . With
this type of statements (CP-theory statements), we can represent a
CP-net by a statement u : x > x� [W ] with W = ∅ and a TCP-net
with W containing at most one variable [36].

π(tuxw) > π(tux� w)
π(tuxw� ) > π(tux� w)
π(tuxw) > π(tux� w� )
π(tuxw� ) > π(tux� w� )

Proof: we proceed using reductio ad absurdum, so, we suppose
that αj ≥ αi . Consider the two interpretations ω1 = tuxw� and
ω2 = tux� w, ω1 satisfies the first constraint (ci ) and falsifies the
second one (cj ), however, ω2 falsifies the first constraint and satisfies
the second one, let v1 = (1, 1 − αj ) and v2 = (1 − αi , 1) be
the vectors of satisfactions associated to ω1 and ω2 respectively,
ω1 � ω2 imply 1−αj > 1−αi , that means αj < αi (contradiction)
QED.
Example 2 [36] : Let Γ be a CP-Theory over three variables
X1 , X2 and X3 , composed of set of preferences statements ϕ1−5
given by: ϕ1 = � : x1 > x¯1 [X2 , X3 ], ϕ2 = x1 : x3 > x¯3 [X2 ], ϕ3
= x1 : x2 > x¯2 , ϕ4 = x¯1 : x2 > x¯2 [X3 ], ϕ5 = x¯1 : x3 > x¯3 , this
statements are coded in possibilistic logic by:
K2 = {c1 = (x1 , α), c2 = (x¯1 ∨ x3 , β), c3 = (x¯1 ∨ x2 , γ), c4 =
(x1 ∨ x2 , δ), c5 = (x1 ∨ x¯3 , ε)}.
Table 2 gives the satisfaction levels for the possibilistic clauses
encoding the five elementary preferences, and the eight possible
choices. The last column gives the global satisfaction level by
minimum combination.
After applying the P areto ordering (or equivalently here,
discrimin ordering), what we get is an ordering which is less refined than the ordering induced by the CP-theory or by the CP-net
(see Figure 2). But we can capture the CP-theory ordering by taking
into account an ordering between weights that reflects the relative
importance of the constraints, and which can be elicited from the
CP-theory. In the example, we should enforce α > max(β, γ, δ, ε)
due CP-net “father" constraints (X1 is the father of X2 and of X3 );

In possibilistic logic, a CP-theory statement ϕ = u : x > x� [W ]
is represented by : ∆(tux)
>
Π(tux� ) standing for

96

ECAI-2012 Workshop WL4AI

Table 2.
x1 x2 x3
x1 x2 x¯3
x1 x¯2 x3
x1 x¯2 x¯3
x¯1 x2 x3
x¯1 x2 x¯3
x¯1 x¯2 x3
x¯1 x¯2 x¯3

Possible alternative choices in Example2.
c1
1
1
1
1
1-α
1-α
1-α
1-α

c2
1
1-β
1
1-β
1
1
1
1

c3
1
1
1-γ
1-γ
1
1
1
1

c4
1
1
1
1
1
1
1-δ
1-δ

c5
1
1
1
1
1-ε
1
1-ε
1

min
1
1-β
1-γ
1-β,1-γ
1-α,1-ε
1-α
1-α,1-δ,1-ε
1-α,1-ε

besides, we have β > γ due to the “irrespectively" constraint [w. r. t.
X2 ] in ϕ2 and we have δ > ε due to the “irrespectively" constraint
[w. r. t. X3 ] in ϕ4 (by applying the procedure explained above, or
Algorithm 2). Then, the order induced by the CP-theory and the one
captured by the possibilistic approach (taking account the above inequalities between symbolic weights) coincide. It is given by:
x1 x2 x3 �lex x1 x¯2 x3 �lex x1 x2 x¯3 �lex x1 x¯2 x¯3 �lex x¯1 x2 x¯3 �lex
x¯1 x2 x3 �lex x¯1 x¯2 x3 �lex x¯1 x2 x¯3
Algorithm 2 calculates the relative importance between CP-theory
preferences statements
Require: C a set of constraints of the form (Pi , αi )
Γ a set of preference statement of the form u : x > x� [W ]
IDC=∅
for ϕi = ui : xi > x�i [Wi ] in Γ do
if Wi =∅ then
IDC ← IDC + Algorithm 1 (C ,{ϕi })
else
for cj in C do
if cj is of the form (¬ui ∨ xi , αj ) then
for ck in C do
if ck is of the form (¬ui ∨ ¬xi ∨ v, αk ) or
(¬ui ∨ z, αk )/z ∈ Wi , v ∈ {V − U } then
IDC ← IDC + (αj > αk )
end if
end for
end if
end for
end if
end for
return IDC

Figure 2.

of weights substantially increases its representation capabilities, especially with respect to inconsistency handling. We have shown how
the use of symbolic weights in the possibilistic logic setting enables
us to deal with partial orders (encoding CP-nets and CP-theories in
this way). This constitutes an alternative to the introduction of a preference relation inside the representation language, as in, e.g., [12].
Moreover, it has been recalled how the use of symbolic weights
[11] enables us to represent CP-nets faithfully in the possibilistic
logic setting, by imposing greater priority weights to father nodes.
Moreover, possibilistic logic with symbolic weights has a representation power much richer than the one of CP-nets, since, e.g., one
may give priority to a constraint associated with a child node (which
is impossible in CP-nets or in TCP-nets). Then, after restating the
CP-theory representation framework, and results illustrating its expressive power which generalizes CP-nets and TCP-nets [36], we
have shown that a CP-theory can be faithfully represented in possibilistic logic by introducing further inequalities between symbolic
weights in order to take into account the CP-theory idea that some
preferences hold irrespective of the values of some variables. An interesting question for further research would be to examine the possible relations that may exist between the non symmetrical notion of
independence in possibilistic networks [1] and some limitations of
graphical representation settings such as CP-nets.
We have also indicated that our handling of preferences statements
in the style of Qualitative Choice Logic remains close to mainstream
database approaches to preference queries pioneered by Lacroix and
Lavency [34]. It has also already pointed out that Chomicki’s approach [16] based on winnow operator can be also expressed in our
setting [28].
Lastly, let us also mention other possibilistic logic-based works in
preference modeling where one may handle both general statements
about importance levels and (couter)-examples [19, 26]. This kind
of approach may also incorporate a Choquet’s integral-like handling
of importance levels [31]. Moreover, a possibilistic logic representation of Sugeno integral has been recently proposed [25], and last

As a summary, the Pareto ordering (here equivalent to the discrimin ordering) is obtained without introducing any inequality constraint between importance weights (all symbolic weights, distinct
from 1, remain incomparable). Then the CP-net is obtained by enforcing priorities in favor of constraints associated with “father"
nodes, but ignoring the “irrespectively" constraints of the CP-theory.
Note that Pareto ordering is compatible with the CP-net and CPtheory orderings, but less refined, and the CP-net ordering is less
refined than the CP-theory one (due to the ignorance of “irrespectively" constraints).

6

Lexmin, Cp-net and CP-Theory orders in Example 2

CONCLUDING REMARKS

In this paper, the possibilistic logic framework has been recalled and
its interest for preference representation strongly advocated. Clearly,
possibilistic logic is still close to classical logic, but the introduction

97

ECAI-2012 Workshop WL4AI

but not least possibility theory setting enables to represent bipolar
preferences, where both negative preferences (rejections) and positive preferences (what is really desired) can be expressed [7].

7

[18] D. Dubois, S. Kaci, and H. Prade, ‘CP-nets and possibilistic logic: Two
approaches to preference modeling. Steps towards a comparison’, in
Proc. of Multidisciplinary IJCAI’05 Workshop on Advances in Preference Handling, Edinburg, July 31-Aug. 1, 2005, (2005).
[19] D. Dubois, S. Kaci, and H. Prade, ‘Expressing preferences from generic
rules and examples - A possibilistic approach without aggregation function’, in Europ. Conf. on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’05), Barcelone, July 6-8, 2005,
ed., L. Godo, pp. 293–304. Springer, (2005).
[20] D. Dubois, S. Kaci, and H. Prade, ‘Approximation of conditional preferences betworks “CP-nets" in possibilistic logic’, in IEEE Inter. Conf.
on Fuzzy Systems (FUZZ-IEEE), Vancouver, July 16-21, (2006).
[21] D. Dubois, S. Kaci, and H. Prade, ‘Representing preferences in the possibilistic setting’, in Preferences: Specification, Inference, Applications,
eds., G. Bosi, R. I. Brafman, J. Chomicki, and W. Kie¨sling, number
04271 in Dagstuhl Seminar Proceedings, (2006).
[22] D. Dubois and H. Prade, ‘Bipolarity in flexible querying’, in Proc. 5th
Inter. Conf. on Flexible Query Answering Systems (FQAS’02, Copenhagen, Oct. 27-29, eds., T. Andreasen, A. Motro, H. Christiansen, and
H. L. Larsen, volume 2522 of LNCS, pp. 174–182. Springer, (2002).
[23] D. Dubois and H. Prade, ‘Possibilistic logic: a retrospective and
prospective view’, Fuzzy Sets and Systems, 144, 3–23, (2004).
[24] D. Dubois and H. Prade, ‘Modeling “and if possible" and “or at least":
Different forms of bipolarity in flexible querying’, in Volume dedicated
to Patrick Bosc, eds., O. Pivert and S. Zadrozny, Studies in Computational intelligence, Springer, (2012, to appear).
[25] D. Dubois, H. Prade, and A. Rico, ‘A possibilistic logic view of Sugeno
integrals’, in Eurofuse Workshop on Fuzzy Methods for KnowledgeBased Systems (EUROFUSE’11), Régua, Portugal, Sept. 21-23, eds.,
P. Melo-Pinto, P. Couto, C. Serôdio, and B. De Baets, number 107
in Advances in Intelligent and Soft Computing, pp. 19–30. Springer,
(2011).
[26] R. Gérard, S. Kaci, and H. Prade, ‘Ranking alternatives on the basis of
generic constraints and examples - A possibilistic approach’, in Inter.
Joint Conf. on Artificial Intelligence (IJCAI), Hyderabad, Jan. 6-12,
2007, pp. 393–398, (2007).
[27] C. Green, ‘Theorem-proving by resolution as a basis for questionanwering systems’, in Machine Intelligence, Vol. 4, eds., D. Michie and
B. Meltzer, 183–205, Edinburgh University Press, (1969).
[28] A. HadjAli, S. Kaci, and H. Prade, ‘Database preference queries - A
possibilistic logic approach with symbolic priorities’, Ann. Math. Artif.
Intell., 63(3-4), 357–383, (2011).
[29] S. Kaci and H. Prade, ‘Relaxing ceteris paribus preferences with partially ordered priorities’, in Europ. Conf. on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’07), Hammamet, Oct. 30-Nov.2, 2007, ed., K. Mellouli, number 4724 in LNAI,
pp. 660–671. Springer, (2007).
[30] S. Kaci and H. Prade, ‘Relaxing ceteris paribus preferences with partially ordered priorities’, in 9th European Conference on Symbolic
and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’07), pp. 660–671, (2007).
[31] S. Kaci and H. Prade, ‘Constraints associated with Choquet integrals
and other aggregation-free ranking devices’, in Inter. Conf. on Information Processing and Management of Uncertainty in Knowledgebased Systems (IPMU’08), Malaga, June 22-27,, eds., L. Magdelena,
M. Ojeda-Aciego, and J. L. Verdegay, pp. 1344–1351, (2008).
[32] S. Kaci and H. Prade, ‘Mastering the processing of preferences by using
symbolic priorities’, in 18th European Conference on Artificial Intelligence (ECAI’08), pp. 376–380, (2008).
[33] S. Kaci and L. van der Torre, ‘Reasoning with various kinds of preferences: Logic, non-monotonicity and algorithms’, Annals of Operations
Research, 163(1), 89–114, (2008).
[34] M. Lacroix and P. Lavency, ‘Preferences: Putting more knowledge into
queries’, in Proc. of the 13th Inter. Conference on Very Large Databases
(VLDB’87), pp. 217–225, (1987).
[35] N. Wilson, ‘Extending CP-nets with stronger conditional preference
statements’, in Proc. 19th National Conference on Artificial Intelligence (AAAI’04), pp. 735–741, (2004).
[36] N. Wilson, ‘Computational techniques for a simple theory of conditional preferences’, Artif. Intell., 175(7-8), 1053–1091, (2011).

Acknowledgements

The authors thank Lluis Godo and Jérôme Mengin for their helpful
discussions and remarks.

REFERENCES
[1] N. Ben Amor, K. Mellouli, S. Benferhat, D. Dubois, and H. Prade, ‘A
theoretical framework for possibilistic independence in a weakly ordered setting’, Inter. J. of Uncertainty, Fuzziness and Knowledge-Based
Systems, 10(2), 117–155, (2002).
[2] S. Benferhat, G. Brewka, and D. Le Berre, ‘On the relation between
qualitative choice logic and possibilistic logic’, in Proc. 10th International Conference IPMU, pp. 951–957, (2004).
[3] S. Benferhat, D. Dubois, L. Garcia, and H. Prade, ‘On the transformation between possibilistic logic bases and possibilistic causal networks’,
Inter. J. of Approximate Reasoning, 29, 135–173, (2002).
[4] S. Benferhat, D. Dubois, S. Kaci, and H. Prade, ‘Bridging logical,
comparative and graphical possibilistic representation frameworks ’, in
6th. Europ. Conf. (ECSQARU’01), Toulouse, Sept. 19-21, pp. 422–431.
Springer, (2001).
[5] S. Benferhat, D. Dubois, S. Kaci, and H. Prade, ‘Graphical readings of
possibilisitc logic bases ’, in 17th Conf. Uncertainty in Artificial Intelligence (UAI’01), Seattle, Aug. 2-5, pp. 24–31. Morgan Kaufmann Publ.,
(2001).
[6] S. Benferhat, D. Dubois, S. Kaci, and H. Prade, ‘Possibilistic logic
representation of preferences: relating prioritized goals and satisfaction levels expressions’, in Proc. 15th. Europ. Conf.on Artificial Intelligence, ECAI 2002, Lyon, July 21-26, 2002, pp. 685–689. IOS Press,
(2002).
[7] S. Benferhat, D. Dubois, S. Kaci, and H. Prade, ‘Bipolar possibility
theory in preference modeling: Representation, fusion and optimal solutions’, Information Fusion, 7, 135–150, (2006).
[8] S. Benferhat, D. Dubois, S. Kaci, and H. Prade, ‘Modeling positive and
negative information in possibility theory’, Int. J. of Intellig. Syst., 23,
1094–1118, (2008).
[9] S. Benferhat, D. Dubois, and H. Prade, ‘Towards a possibilistic logic
handling of preferences’, Applied Intelligence, 14, 303–317, (2001).
[10] S. Benferhat and S. Kaci, ‘Logical representation and fusion of prioritized information based on guaranteed possibility measures: Application to the distance-based merging of classical bases’, Artificial Intelligence, 148, 291–333, (2003).
[11] S. Benferhat and H. Prade, ‘Encoding formulas with partially constrained weights in a possibilistic-like many-sorted propositional logic’,
in IJCAI-05, Proc. 19th Inter. Joint Conf. on Artificial Intelligence, Edinburgh, July 30-Aug. 5, eds., L. Pack Kaelbling and A. Saffiotti, pp.
1281–1286, (2005).
[12] M. Bienvenu, J. Lang, and N. Wilson, ‘From preference logics to preference languages, and back’, in Proc. 12th Inter. Conf. on Principles of
Knowledge Representation and Reasoning (KR’10), Toronto, Canada,
May 9-13, eds., F. Z. Lin, U. Sattler, and M. Truszczynski, pp. 414–424.
AAAI Press, (2010).
[13] P. Bosc, O. Pivert, and H. Prade, ‘A possibilistic logic view of preference queries to an uncertain database’, in Proc. IEEE Inter. Conf. on
Fuzzy Systems (FUZZ-IEEE’10), Barcelona, Spain, July 18-23, pp. 1–
6, (2010).
[14] C. Boutilier, R. I. Brafman, C. Domshlak, H. Hoos, and D. Poole,
‘CP-nets: A tool for representing and reasoning with conditional ceteris paribus preference statements’, J. Artificial Intelligence Research
(JAIR), 21, 135–191, (2004).
[15] G. Brewka, S. Benferhat, and D. Le Berre, ‘Qualitative choice logic’,
Artificial Intelligence, 157, 203–237, (2004).
[16] J. Chomicki, ‘Preference formulas in relational queries’, ACM Transactions on Database Systems, 28, 1–40, (2003).
[17] C. Domshlak, E. Hüllermeier, S. Kaci, and H. Prade, ‘Preferences in ai:
An overview’, Artif. Intell., 175(7-8), 1037–1052, (2011).

98

ECAI-2012 Workshop WL4AI

Strong possibility and weak necessity as a basis
for a logic of desires
Emiliano Lorini1 and Henri Prade2
Abstract. Strong possibility and weak necessity measures are two
decreasing set functions that have been introduced in the setting of
possibility theory. They are respectively min-decomposable with respect to union and max-decomposable with respect to intersection.
This research note advocates that the characteristic properties of the
strong possibility and weak necessity set functions are meaningful
when modeling the notion of desire and a dual notion of admissibleness. This setting thus offers a semantic basis for developing a logic
of graded desires.

In this research note we provide a preliminary investigation of the
potentials of possibility theory for modeling desires. We first present
a background on possibility theory. We then investigate the modeling of desires in terms of strong possibility, as well the dual notion of
admissibleness in terms of weak necessity, before pointing out some
lines for further research on the relationship between possibility theory and the logic of emotions.

1

Let π be a mapping from a set of worlds W to [0, 1] that rank-orders
them. Note that this encompasses the particular case where π reduces
to the characteristic function of a subset E ⊆ W . The possibility distribution π may represent a plausibility ordering (and E the available
evidence) when modeling epistemic uncertainty, or a satisfactoriness
ordering (E is then the subset of satisfactory worlds) when modeling
preferences. Let us recall the complete system of the 4 set functions
underlying possibility theory [6] and their characteristic properties:

2

Introduction

Possibility theory has been originally proposed as an alternative approach to probability for modeling epistemic uncertainty, independently by two authors. In economics, Shackle [17] advocated a new
view of the idea of expectation in terms of degree of surprise (a
disguise for a degree of impossibility). Later in computer sciences,
Zadeh [19] has introduced a setting for modeling the information
originated from linguistic statements in terms of fuzzy sets (understood as possibility distributions). Zadeh’s proposal for a possibility
theory relies on the idea of possibility measure, a max-decomposable
set function with respect to union taking its values in the unit interval.
However, in these works, the duality between possibility and necessity (captured by a min-decomposable set function with respect to
intersection) was not exploited at all.
Later, it has been recognized that two other set functions, which
contrast with the two previous ones by their decreasingness, make
also sense in the possibility theory [6]. These two latter set functions,
which are dual of each other, model an idea of strong (guaranteed)
possibility and of weak necessity respectively, while the original possibility measure is a measure of consistency between the considered
event and the available information, corresponding to an idea of weak
possibility.
The framework of possibility theory with its four basic set functions exhibits a rich structure of oppositions, which can be also
closely related to other structures of oppositions that exist in modal
logics and other settings such that formal concept analysis for instance [7]. Moreover, possibility theory is graded since the four set
functions can take values in the unit interval. This very general setting can not only be interpreted in terms of uncertainty. It makes also
sense for preference modeling in particular. But it is also of interest
in the modeling of situations that require modal logic languages, and
where grading modalities is meaningful. For instance, when modeling uncertainty, necessity measures are useful for representing beliefs
and their epistemic entrenchments [5].
1
2

Background on possibility theory

• i) The (weak) possibility measure (or potential possibility)
Π(A) = max π(w)
w∈A

evaluates to what extent there is a world in A that is possible.
When π reduces to E, Π(A) = 1 if A ∩ E �= ∅, which expresses
the consistency of the event A with E, and Π(A) = 0 otherwise.
Possibility measures are characterized by the following decomposability property:
Π(A ∪ B) = max(Π(A), Π(B))
• ii) The dual (strong) necessity measure (or actual necessity)
N (A) = min 1 − π(w) = 1 − Π(A)
w�∈A

evaluates to what extent it is certain (necessarily true) that all possible worlds are in A. When π reduces to E, N (A) = 1 if E ⊆ A,
which expresses that E entails event A (when E represents evidence), and N (A) = 0 otherwise. The duality of N w. r. t. Π
expresses that A is all the more certain as the opposite event A is
impossible. Necessity measures are characterized by the following
decomposability property:
N (A ∩ B) = min(N (A), N (B))
• iii) The (strong) possibility measure (or actual, or “guaranteed”
possibility)
∆(A) = min π(w)

IRIT-CNRS, University of Toulouse, France, email: lorini@irit.fr
IRIT-CNRS, University of Toulouse, France, email: prade@irit.fr

w∈A

99

ECAI-2012 Workshop WL4AI

evaluates to what extent any value in A is possible. When π reduces to E, ∆(A) = 1 if A ⊆ E, and ∆(A) = 0 otherwise.
Strong possibility measures are characterized by the following
property:
∆(A ∪ B) = min(∆(A), ∆(B))

Intuitively speaking, with the term admissibleness we refer to a
weaker form of motivational attitude. We assume that an agent considers a given state of affairs ϕ admissible if ϕ does not conflict with
the agent’s current desires. In this sense, ϕ is admissible if it is compatible with the agent’s current desires.
Following the initial ideas presented in [14], let us explain why the
operator ∆ is a good candidate for modeling the concept of desire
and why the the operator ∇ is a good candidate for modeling the
concept of desire compatibility.
To this aim, we introduce a simple propositional language defined
by the following grammar:

.
• iv) The dual (weak) necessity measure (or potential necessity)
∇(A) = max 1 − π(w) = 1 − ∆(A)
w�∈A

evaluates to what extent there is a value outside A that is impossible. When π reduces to E, ∇(A) = 1 if A ∪ E �= U , and
∇(A) = 0 otherwise. Weak necessity measures are characterized
by the following property:

ϕ

• W is a set of worlds or states,
• des : W −→ [0, 1] is a total function mapping every world w in
W to its desirability (or pleasantness) value in [0, 1],
• V : Atm −→ 2W is a valuation function which maps every
atomic proposition to the set of worlds in which the atomic proposition is true.

∆ and ∇ are set decreasing functions. This contrasts with (weak)
possibility and (strong) necessity measures which are both set increasing functions.
A modal logic counterpart of these 4 modalities has been proposed
in the binary-valued case (things are possible or impossible) [3].
The close linkage between Spohn functions and (weak) possibility
and (strong) necessity measures can be found in [5].

For any model M = �W, des, V � and atomic proposition p ∈ Atm,
||p|| = {w ∈ W : w ∈ V (p)} denotes the extension of p. The
extension of propositional formulas is defined in the standard way as
follows:
||¬ϕ|| = W \ ||ϕ||
||ϕ ∧ ψ|| = ||ϕ|| ∩ ||ψ||
We here assume for any model M there exists a world in this
model with a minimal degree of desirability 0. This type of normality constraint is traditionally assumed in the context of possibility theory. Formally speaking we assume that for every model
M = �W, des, V �:

∆ and ∇ as operators of desire

The possibility operator Π and the necessity operator N have a clear
epistemic interpretation both in the framework of possibility theory
and in the framework of Spohn’s theory of uncertainty [18] generally
referred to as ‘κ calculus’ (Goldszmidt & Pearl [11] refer to it as
‘rank-based system’ and ‘qualitative probabilities’).
Differently from the operators Π and N , the operators ∆ and ∇
do not have an intuitive interpretation in terms of epistemic attitudes.
More generally, although ∆ and ∇ make sense from the point of
view of possibility theory and also from a logical point view, it is not
completely clear which kind of mental attitudes these two operators
aim at modeling.
Here we defend the idea that ∆ and ∇ can be viewed as operators
modeling motivational mental attitudes such as goals or desires.3 In
particular, we claim that the operator ∆ can be used to model the
notion of desire, whereas the operator ∇ can be used to model the
notion of admissibleness (or desire compatibility).4
According to the philosophical theory of motivation based on
Hume [12], a desire can be conceived as an agent’s motivational attitude which consists in an anticipatory mental representation of a
pleasant (or desirable) state of affairs (representational dimension of
desires) that motivates the agent to achieve it (motivational dimension of desires). In this perspective, the motivational dimension of an
agent’s desire is realized through its representational dimension. For
example when an agent desires to be at the Japanese restaurant eating sushi, he imagines himself eating sushi at the Japanese restaurant
and this representation gives him plesaure. This pleasant representation motivates him to go to the Japanese restaurant in order to eat
sushi.
3

4

p | ¬ϕ | ϕ ∧ ϕ

where p ranges over a given set of atomic propositions Atm =
{p, q, . . .}. The other Boolean constructions �, ⊥, ∨, → and ↔ are
defined from p, ¬ and ∧ in the standard way. Furthermore, we define
a model as a tuple M = �W, des, V � where:

∇(A ∩ B) = max(∇(A), ∇(B))

3

::=

(NormDes ) there is w ∈ W such that des(w) = 0.

3.1

Modeling desire using ∆

We here assume that in order to determine how much ϕ is desirable
an agent takes into consideration the worst situation in which ϕ is
true. Therefore, for any model M = �W, des, V � and propositional
formula ϕ, we can interpret
∆(||ϕ||) = min des(u)
u∈||ϕ||

as the extent to which the agent desires ϕ to be true.
Let us justify the following two properties for desires:
∆(||ϕ ∨ ψ||) = min(∆(||ϕ||), ∆(||ψ||))
and
∆(||ϕ ∧ ψ||) ≥ max(∆(||ϕ||), ∆(||ψ||))

According to the first property, an agent desires ϕ to be true with
a given strength α and desires ψ to be true with a given strength β
if and only if the agent desires ϕ or ψ to be true with strength equal
to min(α, β). Notice that in the case of epistemic states, this property would not make any sense because the plausibility of ϕ ∨ ψ
should be clearly at least equal to the maximum of the plausibilities of ϕ and ψ. For the notion of desires, it seems intuitively satisfactory to have the opposite, namely the level of desire of ϕ ∨ ψ

We use the term ‘motivational’ mental attitude (e.g., a desire, a goal or an
intention) in order to distinguish it from an ‘epistemic’ mental attitude such
as knowledge or belief.
Another possible term is desire admissibility that we take it to be synonymous of desire compatibility.

100

ECAI-2012 Workshop WL4AI

should be at most equal to the minimum of the desire levels of ϕ
and ψ. Indeed, we only deal with here with “positive”5 desires (i.e.,
desires to reach something with a given strength). Under this proviso, the level of desire of ϕ ∧ ψ cannot be less than the maximum
of the levels of desire of ϕ and ψ. According to the second property,
the joint occurrence of two desired events ϕ and ψ is more desirable than the occurrence of one of the two events. This is the reason
why in the right side of the equality we have the max. The latter
property does not make any sense in the case of epistemic attitudes
like beliefs, as the joint occurrence of two events ϕ and ψ is epistemically less plausible than the occurrence of a single event. On
the contrary it makes perfect sense for motivational attitudes likes
desires. By way of example, suppose Peter wishes to go to the cinema in the evening with strength α (i.e., ∆(||goToCinema||) = α)
and, at the same time, he wishes to spend the evening with his
girlfriend with strength β (i.e., ∆(||stayWithGirlfriend ||) = β).
Then, according to the preceding property, Peter wishes to to go
the cinema with his girlfriend with strength at least max{h, k} (i.e.,
∆(||goToCinema ∧stayWithGirlfriend ||) ≥ max{α, β}). This is
a reasonable conclusion because the situation in which Peter achieves
his two desires is (for Peter) at least as pleasant as the situation in
which he achieves only one desire. A similar intuition can be found
in [1] about the min-decomposability of disjunctive desires, where
however it is emphasized that it corresponds to a pessimistic view of
desires.

3.2

following valid inference rule which follows straightforwardly from
the previous one and from the definition of ∇(||ϕ||) as 1−∆(||¬ϕ||):
∆(||ϕ||) > 0
——————————
∇(||ϕ||) = 1
Let us now consider the case in which the agent does not desire ϕ
(i.e., ∆(||ϕ||) = 0). In this case two different situations are possible:
either ∆(||¬ϕ||) = 0 and ϕ is fully compatible with the agent’s desires (i.e., ∇(||ϕ||) = 1), or ∆(||¬ϕ||) > 0 and then ϕ is not fully
compatible with the agent’s desires (i.e., ∇(||ϕ||) < 1).

4

The following is a valid inference rule for ∆-based logic, see [3, 8]
for the proof:
∆(||ϕ ∧ ψ||) ≥ α
∆(||¬ϕ ∧ χ||) ≥ β
——————————
∆(||ψ ∧ χ||) ≥ min(α, β)
Therefore, if we interpret ∆ as a desire operator, we have that if
an agent desires ϕ ∧ ψ with strength at least α and desires ¬ϕ ∧ χ
with strength at least β, then he desires ψ ∧ χ with strength at least
min(α, β). This seems a reasonable property of desires. By way of
example, suppose Peter desires to be in a situation in which he drinks
red wine and eats a pizza with strength at least α and, at the same
time, he desires to be in a situation in which he does not drink red
wine and eats tiramis´u as a dessert with strength at least β. Then, it is
reasonable to conclude that Peter desires to be in a situation in which
he eats both a pizza and tiramis´u with strength at least min(α, β).
Another rule, never published, mixes ∆ (alias desire) and ∇
(alias admissibleness). Namely

Modeling admissibleness using ∇

From the normality constraint (NormDes ), we can deduce the
following inference rule:
∆(||ϕ||) > 0
——————————
∆(||¬ϕ||) = 0
This means that if an agent desires ϕ to be true — in the sense that
he desires ϕ to be true with some strength α > 0 — then he does
not desire ϕ to be false. In other words, an agent’s desires must be
consistent.
As pointed out above, we claim that the operator ∇ allows to capture a concept of admissibleness (or desire compatibility): ∇(||ϕ||)
represents the extent to which an agent considers ϕ an admissible
state of affairs or, alternatively, the extent to which the state of affairs
ϕ is compatible with the agent’s desires. An interesting situation is
when the state of affairs ϕ is maximally admissible for the agent (i.e.,
∇(||ϕ||) = 1). This is the same thing as saying that the agent does
not desire ϕ to be false (i.e., ∆(||¬ϕ||) = 0). Intuitively, this means
that ϕ is totally admissible inasmuch as the level of desire for ¬ϕ is
0. In particular, when the subset E ⊆ W of satisfactory or desirable
worlds is not graded, ∇(||ϕ||) = 1 if and only if E ∩||¬ϕ|| �= ∅, i.e.,
¬ϕ is consistent with what is undesirable, represented by the complement E of E in W . Another interesting situation is when the state
of affairs ϕ is maximally desirable for the agent (i.e., ∆(||ϕ||) = 1).
This is the same thing as saying that ¬ϕ is not at all admissible for
the agent (i.e., ∇(||¬ϕ||) = 0).
It is worth noting that if an agent desires ϕ to be true, then ϕ
should be maximally admissible. This property is expressed by the
5

Further inference rules

∆(||ϕ ∧ ψ||) ≥ α
∇(||¬ϕ ∧ χ||) ≥ β
——————————
∇(||ψ ∧ χ||) ≥ α ∗ β
where α ∗ β = α if α > 1 − β and α ∗ β = 0 if 1 − β ≥ α.
Proof. First, we have by duality ∆(||ϕ ∧ ψ||) ≥ α ⇔ ∇(||¬ϕ ∨
¬ψ||) ≤ 1 − α.
Then observe ¬ϕ ∧ χ ≡ (¬ϕ ∨ ¬ψ) ∧ (¬ϕ ∨ ψ) ∧ χ
Thus ∇(||¬ϕ ∧ χ||) = max(∇(||¬ϕ ∨ ¬ψ||), ∇(||(¬ϕ ∨ ψ) ∧
χ||)) ≥ β
which leads to max(1 − α, ∇(||ψ ∧ χ||)) ≥ β from which the
result follows.
The last inequality is obtained by noticing that ∇(||(¬ϕ ∨ ψ) ∧
χ||) ≤ ∇(||ψ ∧ χ||) due to the decreasingness of ∇.
It can be shown that α ∗ β is the tightest lower bound that can be
established for the above pattern. QED
Thus, in particular, if ϕ is fully admissible (∇(||ϕ||) = 1), and
¬ϕ ∧ ψ is fully desirable (∆(||¬ϕ ∧ ψ||) = 1), then ψ is fully
admissible (∇(||ψ||) = 1).

The distinction between positive and negative desires is a classical one in
psychology. Negative desires correspond to state of affairs the agent wants
to avoid with a given strength, and then desires the opposite to be true.
However, we do not develop this bipolar view here.

The two above inference rules are the counterparts of the pattern

101

ECAI-2012 Workshop WL4AI

We only show how the basic operators of possibility theory discussed
above can be exploited in order to model intensity of hope and fear.
The operator of strong necessity N has been used in the past
to model a notion of graded belief both in possibility theory and
in the context of Spohn’s κ calculus (where it amounts to state
the complete impossibility of worlds). That is, N (||ϕ||) can be
interpreted as the extent to which the agent believes that ϕ is
true. We have shown above that ∆(||ϕ||) can be interpreted as the
extent to which the agent desires that ϕ is true. Therefore, we can
define the intensity of the hope about ϕ and the intensity of the
fear about ϕ as follows8 where N and ∆ are associated with two
distinct possibility distributions modeling epistemic uncertainty and
desirability respectively). If N (||ϕ||) < 1 then,

N (||ϕ ∨ ψ||) ≥ α
N (||¬ϕ ∨ χ||) ≥ β
——————————
N (||ψ ∨ χ||) ≥ min(α, β)
which is the basic inference rule in standard possibilistic logic, and
of the pattern [4]:
N (||ϕ ∨ ψ||) ≥ α
Π(||¬ϕ ∨ χ||) ≥ β
——————————
Π(||ψ ∨ χ||) ≥ α ∗ β
with α ∗ β = α if α > 1 − β and α ∗ β = 0 if 1 − β ≥ α.

Hope(||ϕ||) = merge(N (||ϕ||), ∆(||ϕ||))

They are themselves the graded counterparts of two inference rules
well-known in modal logic [9, 4].

5

7

In the preceding two definitions of hope and fear, the strength of
the belief is supposed to be less than 1 in order to distinguish hope
and fear, which imply some form of uncertainty, from happiness and
distress which are based on certainty (i.e., N (||ϕ||) = 1). This is
consistent with OCC psychological model of emotions [15] according to which, while joy and distress are triggered by actual consequences, hope and fear are triggered by prospective consequences
(or prospects).9

Conclusive remarks: towards emotions

In the previous sections, we have shown that possibility theory offers
a unified logical framework in which both epistemic attitudes such
as beliefs and motivational attitudes such as desires can be modeled.
While the operators of weak possibility Π and strong necessity N
have a clear epistemic interpretation, the operators of strong possibility ∆ and weak necessity ∇ can be interpreted respectively as an
operator of desire and as an operator of admissibleness.
In this conclusion, we want to discuss how these two components,
the epistemic one and the motivational one, can be combined in order
to model basic emotion types such as hope and fear. Similar ideas on
the logic of emotion intensity have been recently presented in [2]
without making a connection with possibility theory.
According to psychological models and computational models of
emotions (see, e.g., [16, 13, 15, 10, 2]), the intensity of hope with
respect to a given event ϕ is a monotonically increasing function
of the degree to which the event is desirable and the likelihood of
the event (i.e., the strength of the belief that ϕ is true). That is, the
higher is the desirability of ϕ, and the higher is the intensity of the
agent’s hope that ϕ will occur; the higher is the likelihood of ϕ, and
the higher is the intensity of the agent’s hope that ϕ will occur. 6
Analogously, the intensity of fear with respect to a given event ϕ is
a monotonically increasing function of the degree to which the event
is undesirable and the likelihood of the event (i.e., the strength of the
belief that ϕ is true).
There are several possible merging functions which satisfy these
properties. For example, we could define the merging function
merge as an average function, according to which the intensity of
hope about a certain event ϕ is the average of the strength of the belief that ϕ will occur and the strength of the desire that ϕ will occur.
Another possibility is to define merge as a product function (also
used in [10, 16]), according to which the intensity of hope about ϕ
is the product of the strength of the belief that ϕ will occur and the
strength of the desire that ϕ will occur. Here we do not choose a
specific merging function, as we leave this issue for future research7 .
6

Fear (||ϕ||) = merge(N (||ϕ||), ∆(||¬ϕ||))

REFERENCES
[1] A. Casali, L. Godo, C. Sierra. A graded BDI agent model to represent
and reason about preferences. Artif. Intell.,175, 1468–1478, 2011.
[2] M. Dastani, E. Lorini. A logic of emotions: from appraisal to coping.
Proc. of AAMAS 2012, ACM Press, 1133–1140, 2012.
[3] D. Dubois, P. Hajek, H. Prade. Knowledge-driven versus data-driven
logics. J. of Logic, Language, and Information, 9, 65–89, 2000.
[4] D. Dubois and H. Prade. Resolution principles in possibilistic logic. Int.
J. Approx. Reasoning, 4, 1–21, 1990.
[5] D. Dubois and H. Prade. Epistemic entrenchment and possibilistic
logic. Artif. Intell. 50, 223–239,1991.
[6] D. Dubois, H. Prade. Possibility theory: qualitative and quantitative aspects. In: Quantified Representation of Uncertainty and Imprecision,
(D. Gabbay, P. Smets, eds.), Handbook of Defeasible Reasoning and
Uncertainty Management Systems, Kluwer Acad. Publ., Vol.1, 169–
226, 1998.
[7] D. Dubois and H. Prade. From Blanch´es hexagonal organization of concepts to formal concept analysis and possibility theory. Logica Universalis: 6 (1), 149–169, 2012.
[8] D. Dubois and H. Prade. Possibilistic logic: a retrospective and prospective view. Fuzzy Sets and Systems 144, 3–23, 2004
[9] L. Fari˜nas del Cerro. Resolution modal logic. Logique et Analyse, vol.
110-111, 153-172, 1985.
[10] J. Gratch and S. Marsella. A domain independent framework for modeling emotion. Cognitive Systems Research, 5(4):269–306, 2004.

8

According to Ortony et al. [15] the intensity of hope and fear is determined
by a third parameter called the (temporal and spatial) proximity to the expected event (the higher is the proximity to the expected event, and the
higher is the intensity of hope/fear.) This third dimension is not considered
in the present analysis.
The use of average or product here is however not fully in the spirit of the
kind of ordinal modeling proposed here, and minimum may be a more suitable merging operator. Although the minimum-based ordering of pairs of

9

102

evaluations may be refined for differentiating between (α, β) and (α� , β � ),
when min(α, β) = min(α� , β � ), we may still need a scalar global evaluation.
Here we assume that if an agent desires ϕ to be true, then the situation in
which ϕ is false is undesirable for him. One might object that the undesirability of an event ϕ does not always coincide with the desirability of
its negation. For example, an agent might desire ‘to gain 100 euros’, even
though ‘not gaining 100 euros’ is not undesirable for him. (The agent is
simply indifferent about this result.) In order to model a notion of undesirability, which is independent from the desirability of the logical negation,
two possibility distributions over the set of possible worlds W are required,
one for modeling desirability and the other one for modeling undesirability
(as the negative counterpart of desirability).
Like [10], we here interpret the term ‘prospect’ as synonymous of ‘uncertain consequence’ (in contrast with ‘actual consequence’ as synonymous of
‘certain consequence’).

ECAI-2012 Workshop WL4AI

[11] M. Goldszmidt and J. Pearl. Qualitative probability for default reasoning, belief revision and causal modeling. Artificial Intelligence, 84:52–
112, 1996.
[12] D. Hume. A Treatise of Human Nature. Ed. L. A. Selby-Bigge, P. H.
Nidditch, Clarendon Press, Oxford, 1978.
[13] R. S. Lazarus. Emotion and adaptation. Oxford University Press, 1991.
[14] E. Lorini. A dynamic logic of knowledge, graded beliefs and graded
goals and its application to emotion modelling. Proc. of LORI 2011,
vol. 6953, LNCS, Springer-Verlag, 165–178, 2011.
[15] A. Ortony, G. L. Clore, and A. Collins. The cognitive structure of emotions. Cambridge University Press, 1988.
[16] R. Reisenzein. Emotions as metarepresentational states of mind: naturalizing the belief-desire theory of emotion. Cognitive Systems Research, 10:6–20, 2009.
[17] G. L. S. Shackle. Decision, Order, and Time in Human Affairs. Cambridge University Press, UK, 1961.
[18] W. Spohn. Ordinal conditional functions: a dynamic theory of epistemic
states. In Causation in Decision, Belief Change and Statistics, pages
105–134. Kluwer, 1988.
[19] L. A. Zadeh. Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets
and Systems, 1, 3–28, 1978.

103

