Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138
Available Online at www.ijcsmc.com

International Journal of Computer Science and Mobile Computing
A Monthly Journal of Computer Science and Information Technology

ISSN 2320–088X
IJCSMC, Vol. 4, Issue. 6, June 2015, pg.1121 – 1138
RESEARCH ARTICLE

Computer-Aided Diagnosis for Lung Diseases based on
Artificial Intelligence: A Review to Comparison of TwoWays: BP Training and PSO Optimization
Assistant Lecturer: Eman

Saleem Ibrahem Harba

University Of Baghdad / College Of Arts / Media Unit and Informatics
Email: emanharba_1212@yahoo.com

Abstract: An intelligent computer-aided diagnosis system can be help doctors to diagnose and determine the
type of disease from medical imaging like diagnosis disease from X-ray image of chest. This paper study
some method of integration of neural network like backpropagation neural network and particle swarm
optimizing (PSO) to recognition the X-Ray of chest for some lung disease cases (like Tuberculosis, TB. etc.)
along with the normal case. The aim of this paper to investigated computer-aided diagnosis (CAD) schemes
to determine the probability for the presence of TB or Tuberculosis in lung using artificial neural networks
(ANN) that were trained by a Backpropagation (BP) algorithm or by a particle swarm optimization (PSO).
The experiments show that CAD based on used backpropagation for training neural network is much
effective than the optimization with PSO for recognition side which appeared that BP achieved a good result
reached to 96.4% compared with 84.254% for PSO for 64x64 image input size. The efficiency and
recognition testes for training method was performed and reported in this paper.
Keywords: computer-aided diagnosis, X-ray chest diagnosis; Medical images; Recognition; Neural network.

© 2015, IJCSMC All Rights Reserved

1121

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

1. Introduction
CAD are one of the main subjects in diagnostic radiology and medical imaging
researches. In recent years, the concept of computer-aided diagnosis has been the subject
of much research and not a little controversy. Recently CAD has beginning widely applied
in the field of medical imaging for diagnosis and detection many different types of
abnormalities by use of different imaging modalities.
The early effort for used computerized analysis for medical images were made in
the 1960s, while the systematic and serious investigation on CAD has begun in 1980s with
a change of fundamental in the concept for utilization of the computer output, from
automated computer diagnosis to computer-aided diagnosis [1].
Neural networks are well known for their good performance in classification and
function approximation, and have been used with success in medical image processing
over the past years, particularly in the case of pre-processing (e.g. construction and
restoration), segmentation, and recognition. The Backpropagation poses most places in
pattern recognition field. The other neural techniques, i.e. Hopfield, Adaptive resonance
theory, radial basis function, Probabilistic, convolution, and fuzzy, have also found their
position in medical image detection and recognition [2].
The backpropagation algorithm BP is one of the popular learning algorithms to
train self-learning feed forward neural networks. The BP algorithm involves the gradual
reduction of the error between model output and the target output. It develops the input to
output, by minimizing a cost gained measured over a set of training. The backpropagation
algorithm is applied in feed-forward artificial neural networks ANNs. The aim of the
backpropagation algorithm is to reduce the error, until the ANN learns the training data [3].
Optimization has been applied on neural network to optimized pattern recognition.
There are many types of optimization for ANN like Genetic Algorithms, Swarm
Intelligence (SI) etc. SI is an intelligent paradigm used to optimized solving problems that
took its inspiration from the biological examples by flocking, swarming, and herding
phenomena in vertebrates; it is one of the scientific fields that are closely related to natural
swarms existing in nature, such as ant colonies, bee colonies, and rivers. Particle Swarm
Optimization (PSO) incorporates swarming behaviours observed in flocks of birds, schools
© 2015, IJCSMC All Rights Reserved

1122

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

of fish, or swarms of bees, and even human social behaviour, from which the idea is
emerged. PSO is a population-based optimization tool, which could be implemented and
applied easily to solve various function optimization problems, or the problems that can be
transformed to function optimization problems. As an algorithm, the main strength of PSO
is its fast convergence, which compares favorably with many global optimization
algorithms like Genetic Algorithms (GA), Simulated Annealing (SA) and other global
optimization algorithms; for that we used PSO as a comparison optimization method to
compare its recognition result with the with recognition based on BP [4].
This paper organized as follows. Section 1 generate training data matrix, which is
input and output nodes. true X-Ray images for three lung cases taken (normal, TB, and
Tuberculosis) has been used as input data and 3 output labeling, pre-processing operation
for X-Ray chest images has been applied on that images; It consist of three parts, first part
image enhancement to removed noise and not useful texture (ribs, windpipe, dusts, etc.),
and the second part is to segment each part of lungs. Part 3 resized image to desired neural
input size that should be equally in dimension (i.e. 8x8, 32x32, 64x64, etc.). After
preprocessing operation done it combined it in one data matrix, which represents the input
layer units and labeling. Section2 prepared Feedforward neural network and initialized
weight. Section3 training neural network by two methods: Backpropagation and PSO for
different input sizes, then getting weight updated for each method to used it in recognition
process. Section4 recognition process to recognized x-ray images, the recognition has been
applied on trained and non-trained images by used weights gotten from section3. Finally,
compared the recognition results for each methods and the percentage of correction in
recognition process to verify what is the best method in training process for computeraided diagnosis can be using.

2. NN Training Data
The images used for training ANN are taken from true X-ray chest images to two
cases of lung disease (Tuberculosis TB and tumor) beside the normal case and be used for
building program data matrix.

© 2015, IJCSMC All Rights Reserved

1123

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Table 1: X-ray images for lung Cases and its numbers
Type of Images

Number Of Images

Tuberculosis X-ray

172

TB

X-ray

163

Normal X-ray

122

3. X-ray Image Pre-Processing
Pre-Processing are applied on X-Ray images to removed not useful texture like
(windpipe, or ribs, etc.) and separated effective region i.e. lungs tissue; it consist of two
parts: Image enhancement part that used the morphological filtering algorithm type “Area
Openings”, and segmentation part that used Connected-component algorithm.

3.1 Image Enhancement for X-ray Images
This method consist of multiple operations. Firstly, the x-ray image has been
converted to gray-scale to remove colour, secondly it converted to binary image, finally
applying filter type Area Openings to remove unwanted feathers, as shown in figure 1.

3.2 Segmentation Method
After applying enhancement process, the Connected Components algorithm used to detect
lungs region in X-ray images to separate it from whole image, as shown in figure 1.

(a)

(b)

Figure 1: (a) Original X-Ray Image for chest with gray scale
(b) After applying pre-processing operations

© 2015, IJCSMC All Rights Reserved

1124

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Input Data Generation Algorithm
Input:

Chest X-Ray

Output:

Inputs arrays and Outputs Labeling

Step 1:

Start.

Step 2:

Request Images from folders for each case of lung (TB, tumors and normal).

Step 3:

Convert to gray scaled.

Step 4:

Convert to binary.

Step 5:

Given the threshold value that used in area opening filter.

Step 6:

Enhance X-ray images by used Area Opening algorithm to remove unuseful
features and pass it to segmentation process.

Step 7:

Extract lungs area by used connected component algorithm to remove
unwanted region.

Step 8:

Reshape Lungs and recombined it.

Step 9:

Saved preprocessed images in 3 folders that represent 3 lung cases

Step 10: End.

Figures 2 have shown the image process result with samples of three lung cases.

(a)

© 2015, IJCSMC All Rights Reserved

1125

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

(b)

Figure 2: Image processing result for sample of:
a. Tuberculosis X-ray lung image
b. Normal X-ray lung image
c. TB X-ray lung image

4. Training Neural Network
The neural network prepared and optimized by used two ways: BP algorithm and
PSO algorithm. The model is multi-layer perceptrons (MLP) which consists of an input
layer, hidden layer and an output layer. Inputs are X-ray images that pre-processed as
specified previously. Output layers are three labels represent lung cases (TB, tumours and
normal). Initially random images are used as initial weight, after that a transfer function
applied on the weighted, which transfers the output to next layer, which is the hidden layer,
then, the neurons of hidden layer and input value is compared to threshold value and its
result compared to original one which were found. If the results do not match,
backpropagation algorithm is applied by which weights of previous connections are
© 2015, IJCSMC All Rights Reserved

1126

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

adjusted. Particle swarm optimization applied to Integrate back propagation neural network
for optimizing.

4.1 Preparing the Data
Befor training process it need to generate data matrix that includes input layers and
output labels. At first the preprocessed images are loaded and resized to required size, in
this paper we generate 3 data matrix for three sizes (8x8, 16x16 and 64x64). The 8×8,
16×16 and 32×32 grid of pixels is unrolled respectively into a 64, 256 and 1024
dimensional vectors. Each of these training images becomes a single row in data matrix.
This gives an A by B matrix where every row is a training image for an X-ray lung digit
image.

... (1)
The second parameter need for training NN is to determine the best number of
hidden neurons. According to a Jeff Heaton of Heaton research, the best number be used in
NN training should be 2/3 the size of the input layer, plus the size of the output layer [5]
Input Layers = I = A * B, Output layers = y
Number of Neurons = (Input Layers + Output Layers) * 2/3
= (I + y) * 2/3
The Number of Neurons for 8×8

= (64+3) * 2/3

= 44~ 50

The Number of Neurons for 16×16 = (256+3) * 2/3 = 172 ~ 170
The Number of Neurons for 32×32 = (1024+3) * 2/3 = 684 ~ 700

4.2 Implementation Feedforward neural network
The first part of training is to implement Feedforward NN to optimize it by
BP or by PSO.
The sigmoid function is a mathematical function having an "S" shape (sigmoid curve) [6].
... (2)
© 2015, IJCSMC All Rights Reserved

1127

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Where:

:

,

: can be a scalar, a vector, or a matrix

When training neural networks, it is important to randomly initialize the parameters
for symmetry breaking. One effective strategy for random initialization is to randomly
select values for
(

uniformly in the range

. The learning rate epsilon

has been used with value of 0.12, because this range of values ensures that the

parameters are kept small and makes the learning more efficient. Having too many
features, the learned hypothesis may fit the training set very well, the cost function J(θ),
but fails to generalize to new testing data. To address this over fitting problem, one can
reduce the number of features by manually selecting features to keep, but sometimes each
of these features contributes a bit to predict the output and this method affects the
classification accuracy. Regularization solves this problem by keeping all features but
reducing magnitude values of parameter and by doing so, the cost function

for neural

networks with regularization is given by: [7]

… (3)
Where:

: the number of training examples,

lambda,

: the number of training examples,

input units,

: number of output labels,
Sigmoid function,

For the matrices Theta1 (

: total number of possible labels,
: number of hidden unit,

:

: number of

iscomputed for every example i, where:
: theta one,

) and Theta2 (

: theta two.

) this corresponds to the first

column of each matrix. This will add regularization to cost function.

4.3 Backpropagation Algorithm
This part implements the backpropagation algorithm. The procedure for this BP
algorithm can be summarized as follows: [8]

© 2015, IJCSMC All Rights Reserved

1128

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Figure (3): Backpropagation Updates [8].

The gradient for the sigmoid function can be computed as
... (4)
Where:

:

For large values (both positive and negative) of z, the gradient should be close to 0. When
z = 0, the gradient should be exactly 0.25

1.

Setting the input layer’s values

to the t-th training example

forward pass (Figure 8), computing the activations (
2 and 3. It needing to add
layers

and

. Perform a feed
) for layers

+1 term to ensure that the vectors of activations for

also include the bias unit.

Where:
Unit

in layer 1 (the input layer)

Sigmoid (

)

Sigmoid (

)

© 2015, IJCSMC All Rights Reserved

1129

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

For each output unit

in layer 3 (the output layer), set

=

... (5)

Where:

{0, 1} indicates whether the current training Image matrix

belongs to class

(

= 1), or if it belongs to a different class (

=

0).

2.

For the hidden layer

= 2,

=

3.

... (6)

Accumulating gradient from using the following formula:
=

... (7)

After successful implemented of backpropagation algorithm, regularization is added to
the gradient. To account for regularization, it turns out that this can be added as an
additional term after computing the gradients using backpropagation.

After has been computed

using backpropagation, then it should to adding

regularization using this formula:

=

=

=

for

=

... (8)

for

... (9)

4.4 Training Neural Network by PSO Swarm Optimization
When the PSO algorithm is used in evolving weights of feed forward neural
network, every particle represent a set of weights, there are three encoding strategy for
every particle, the equation used for PSO optimization is shown in follows: [9]

... (10)
© 2015, IJCSMC All Rights Reserved

1130

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Where: c1, c2 are the acceleration constants with positive values; rand () is a
random number between 0 and 1; w is the inertia weight. In addition to the parameters c1,
and c2 parameters, the implementation of the original algorithm also requires placing a
limit on the velocity (vmax). After adjusting the parameters w and vmax, the PSO can
achieve the best search ability.
In particle swarm intelligence, a number of simple entities the particles are put in the
search space of some function or problem, and each participle at current location estimate
the objective function at this location. Each one of particle determines its movement over
the search space through summation some aspect of its current history and best-fitness
locations with those one or more members of the swarm. After all particles have been
moved, the next iteration takes place. Finally, the swarm work as a whole, similar to a flock
of birds that collectively foraging for food, is likely to move close to an optimum of the
fitness function. Each individual in the particle swarm is composed of three D-dimensional
vectors, where D is the dimensionality of the search space. These are the current
position

, the previous best position

, and the velocity

.

Current position is evaluated as a problem solution. If that position is better than
any that has been found so far, then the coordinates are stored in the second vector,

.

The value of the best function result so far is stored in a variable that can be called pbesti
(for “previous best”), for comparison on later iterations. The objective, of course, is to
find the best positions and then updating
adding

to

and pbesti. The new points are select by

, and the algorithm has been operate by adjusting

, which

can effectively be seen as a step size.

© 2015, IJCSMC All Rights Reserved

1131

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

The procedure for this PSO algorithm can be summarized as follows:
1. Step 1: Initialize a population array of particles with random positions and velocities
on D-dimensions in the search space.
2. Step 2: loop.
3. Step 3: For each particle, evaluate the desired optimization fitness function in Dvariables.
4. Step 4: Compare particle’s fitness evaluation with its pbesti. If current value is better
than pbesti ,then set pbesti equal to the current value, and
location

equal to the current

in D-dimensional space.

5. Step 5: Identify the particle in the neighborhood with the best success so far, and
assign its index to the variable g.
6. Step 6: Change the velocity and position of the particle according to the equation
(10)
7. Step 7: If a criterion is met (usually a sufficiently good fitness or a maximum
number of iterations), exit loop.
8. Step 8: end loop.
The parameter w, in the above PSO algorithm also reduces gradually as the iterative
generation increases, just like the PSO algorithm. The flow chart of PSO program is
shown in Figure (9)
The iteration value used for trained ANN has been set to value of (1000) to get the
best performance, the value of variable between -1 and 1, R are random number , the
values of c1=1.5, c2 = 2.5 and the maximum velocity vmax to be (0.1).

© 2015, IJCSMC All Rights Reserved

1132

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Start

Randomly initialize all particle position and velocities
Next Particle
Evaluate the fitness function for each particle

Stopping Criterion
satisfied

Yes

If fitness of particle
> Pbest

Modify Pbest

No
If fitness of
particle >
Pbest

No

Update velocity and position of particle
Yes
Modify Gbest

If Max. No. of
Iteration > Pbest

No

Satisfactory Gbest
Yes

End

Figure 4: PSO Algorithm Scheme

The tests was tested the efficiency of weights generated for different values of
population size taken (100, 250 and 500). The weight efficiency, memory and
computational time that have been achieved for each input have been classified in table (2).

© 2015, IJCSMC All Rights Reserved

1133

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

Table 2: Consumption of system resources and efficiency of weight generated for 1000
iteration, R1= (0.8), R2= (0.2), c1=1.5, c2=2.5, and vmax = 0.1.
Data Matrix

Consumption of system resources
Hidden

Input layers

Population
size

layer

Net
CPU

units

Requiremen
t of memory

Efficiency of

Computational

the weight

time / Sec

generated

PSO

64

100

50

44%

90MB

64

85.359 %

PSO

64

250

50

46%

100 MB

171

86.188 %

PSO

64

500

50

60%

150 MB

343

86.188 %

PSO

256

100

170

51%

130 MB

445

84.53 %

PSO

256

250

170

42%

350 MB

1126

85.912 %

PSO

256

500

170

41%

2400 MB

2240

83.149 %

PSO

1024

100

700

51%

3600 MB

6987

86.74 %

PSO

1024

250

700

50%

8400 MB

17905

87.293 %

PSO

1024

500

700

56%

17250MB

63475

88.398 %

(a)

© 2015, IJCSMC All Rights Reserved

(b)

1134

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

(c)

(d)

Figure 5: Cost gained with epochs of PSO with 100 population size for:
a) 8x8 images matrix, b) 16x16images matrix,
c) 32x32 images matrix, d) 64x64 images matrix.

5. X-ray Images Recognition Test (Practical Tests)
Recognition has been tested using recognition program to identify lung case for
each input image. First program has been tested on images that train used to train NN and
then it been tested with images that are not trained. The program tested by used different
weights that produced from two training method (backpropagation and the integrated way)
for same iteration value of (1000), the backpropagation recognition results and PSO
recognition results have been classified in table (4) and table (5).
Table 4.6: Recognition Results for trained X-Ray images
Type of
Recognition

X-Ray lung image Cases

Image
matrix

Cancer (147)

TB (96)

Normal (119)

size

Detect

Failed

Detect

Failed

Detect

Failed

1

BP

8x8

123

24

86

10

110

9

2

PSO

8x8

122

25

84

12

108

11

3

BP

16x16

134

13

91

5

114

5

4

PSO

16x16

122

25

88

8

100

19

5

BP

32x32

141

6

93

3

116

3

© 2015, IJCSMC All Rights Reserved

1135

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

6

PSO

32x32

134

13

86

10

110

9

7

BP

64x64

138

9

95

1

116

3

8

PSO

64x64

133

14

82

14

90

29

Table 4.7: Recognition Results for non-trained X-Ray images

Cancer (24)

size

TB (15)

Normal (22)

Detect

Failed

Detect

Failed

Detect

Failed

1

PSO

100

16

8

2

13

22

0

2

PSO

250

13

11

11

4

22

0

3

PSO

500

14

10

14

1

21

1

4

BP

----

16

8

8

7

22

0

5

PSO

100

14

10

5

10

21

1

6

PSO

250

18

6

6

9

16

6

7

PSO

500

14

10

5

10

19

5

8

BP

----

15

9

9

6

21

1

9

PSO

100

15

9

4

11

18

4

10

PSO

250

15

9

9

6

21

1

11

PSO

500

18

6

14

1

19

5

12

BP

----

16

8

8

7

19

3

13

PSO

100

19

5

9

6

20

2

BP

-----

15

9

11

4

20

2

64

64 x

32 x 32

16 x 16

8x8

Type of Recognition

X-Ray lung image Cases

Population

14

6. Conclusion
From the conducted experiments, we can get conclusions that for the following points:


The emphasis of this paper is to develop a neural network training method used
for building a program for X-Ray lung diagnosis that may help doctors in their
diagnosis.

© 2015, IJCSMC All Rights Reserved

1136

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138



The PSO-BP training results shown that the efficiency of weight updated
increased depending on increasing of population size and number of iteration.



The computational requirement especially memory have been increased rapidly
as the input layer size increased and when the population size increased.



The applying of image processing on X-ray images before trained it with
neural network given advantage that reduce the error and increasing the
efficiency that due to the removing un useful features that may be dispersal the
NN and it made be possible to reduce the input layer (resized image to small
size about 8x8) without fearing from data loses.



PSO-BP recognition results of trained and non-trained images shown relatively
reducing in recognition errors as the input size and population increased, for
Tuberculosis images detection (that total number 147 images), the tested have
been appeared an increased in correction detection from (122 images) for 64
input size to be raised to (133 images) for 4096 input size which improved
about (7.47%), and four non-trained Tuberculosis images detection (that total
number 24 images), the tested have been appeared an increased in correction
detection from (16 images) for 64 input size to be raised to (19 images) for
4096 input size for same population size which improved about (12.5%). For
the same input size of 64 with different population sizes, the tested have been
appeared an increased in correction detection of TB images from (2 images) for
100 population size to be rise to (11 images) for 250 population size and to (14
images) for 500 population sized which improved about (80 %).

References
1- Kunio Doi, “Computer aided diagnosis in medical imaging: Historical review, current
status and future potential”, Computerized Medical Imaging and Graphics, Vol.31,
No.4-5 198–211, (June 2007).
2- Zhenghao S., Lifeng H., Tsuyoshi N., Kenji S. and Hidenori I., “Survey on Neural
Networks Used for Medical Image Processing”, International Journal of
Computational Science, Vol.3, No.1, pp.011-68 , ISSN: 1992-6669, (2009).

© 2015, IJCSMC All Rights Reserved

1137

Eman Saleem Ibrahem Harba, International Journal of Computer Science & Mobile Computing, Vol.4 Iss.6, June- 2015, pg. 1121-1138

3- Dike U. I., Adoghe U. A., “Computer-aided diagnosis in medical imaging: Historical
review, current status and future potential”, International Journal of Computers and
Distributed Systems, Vol. No.3, Issue 2, ISSN: 2278-5183, (Jun-July 2013).
4- Abraham A., Grosan C. and Ramos V., “Swarm Intelligence in Data Mining”, SpringerVerlag Berlin Heidelberg, ISBN: 978-3-540-34955-6, (2006).
5- Jeff H. “Introduction to Neural Networks with Java”, First Edition, ISBN: 097732060X,
(2005).
6- Balaji S. A. and Baskaran K., “Design and Development of ANN System Using
Sigmoid Activation Function to Predict Annual Rice Production in Tamilnadu”,
IJCSEIT International Journal of Computer Science, Engineering and Information
Technology), Vol.3, No.1, February 2013.
7- Ilunga M. and Stephenson D. “Infilling stream flow data using FF-BP ANN Application
of standard BP and pseudo Mac Laurin power series BP techniques”, Water SA Vol.
31 No. 2, ISSN 0378-4738, (April 2005).
8- Ra´ul Rojas, “Neural Networks A Systematic Introduction”, Book, Springer-Verlag,
Berlin, 1996.
9- Jing-Ru Zhang, Jun Zhang, Tat-Ming Lok and Michael R. Lyu, “A Hybrid Particle
Swarm Optimization–Back-Propagation Algorithm for Feedforward Neural Network
Training”, Elsevier Inc., Applied Mathematics and Computation 185, 2007.

© 2015, IJCSMC All Rights Reserved

1138

