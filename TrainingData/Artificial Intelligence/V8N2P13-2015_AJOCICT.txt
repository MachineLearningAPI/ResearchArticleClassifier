Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

An Investigation into the Conceptual Controversies between Artificial
Intelligence and Computational Intelligence
K.T. Igulu
Department of Computer Science
Rivers State Polytechnic,Bori
Rivers State, Nigeria.
E-mail: igulukt@gmail.com,
Phone: +2347018827522
Z.P. Piah
Department of Computer Science
Rivers State Polytechnic, Bori
Rivers State, Nigeria.
P.O Asagba PhD
Department of Computer Science
University of Port Harcourt
Rivers State, Nigeria.

ABSTRACT
Artificial intelligence (AI) is one of the oldest and best known research fields in computer science which is aimed at giving
intelligence in machines. In spite of enormous effort geared towards AI, its boundary and interference to other fields are yet
undefined. The controversy in AI’s boundary has bred some concepts which are in no practical sense different from the goal of
AI. Most of these concepts are; computational intelligence (CI), soft computing (SC), natural computing (NC), machine learning
(ML), approximating reasoning (AR), fuzzy logic (FL) and adaptive computing (AC). There is still not an objective boundary of
these concepts. This paper investigates the conceptual controversies between AI and CI. AI and CI are major contending concepts
that have posed confusions to researchers and students. We have cited some definitions and comments about AI and CI from
trusted sources. After thorough analysis of the definitions and comments, our own view of what AI and CI are is presented. This
paper does not give extensive information about AI and CI approaches, tools and applications. Our emphasis is in distinguishing
AI from CI. An extensive bibliography is given for references.
Keywords: artificial intelligence; computational intelligence; soft computing; nature-inspired; controversies.
African Journal of Computing & ICT Reference Format:
K.T. Igulu, Z.P. Piah & P.O. Asagba (2015). An Investigation into the Conceptual Controversies between Artificial Intelligence and
Computational Intelligence. Afr J. of Comp & ICTs. Vol 8, No. 2. Pp 115-120.

solving[1]. Another school of thought segments intelligence
into;
a. Rational thought and reasoning-The ability to act
purposefully in an environment.
b. The ability to deal with situations, in an effective
manner, within an environment.
c. Cognitive – Examples of cognitive ability:
memory, perception, concept formation, problem
solving, mental imagery, action, association,
language and attention.
d. The ability to learning from experience.
e.
The ability to live and cope with the demands of
daily life [20].

I. INTRODUCTION
What exactly are these terms Artificial intelligence (AI) and
computational intelligence (CI) and how are they the most
fascinating research areas in the computing discipline? To
provide qualitative answer to this question, it is
consequential to highlight the concept of intelligence.
Although intelligence is not the goal of this paper but any
paper about AI and CI cannot do away with the concept of
intelligence. The main controversy in giving a precise
definition to AI and CI is the inclusion of intelligence. The
study of (human) intelligence has a rich history over three
millenniums [4]. In spite of the ages it has undergone, the
definition of intelligence is still debatable. Intelligence has
been defined in different ways, including the abilities, but
not limited to, abstract thought, understanding, being selfaware, communication, reasoning, learning, having
emotional knowledge, retaining, planning, and problem

In this paper, we will also adapt the rational agent approach
of intelligence in [19].

115

Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

AI is primarily the science of creating intelligent systems
one of the largest scientific communities. AI has been
established already in circa 1950, working on problems that
require intelligence to be solved. Its evolution has been
summarized in the 25th anniversary issue of the AI
Magazine by Mackworth[2]: “In AI’s youth, we worked
hard to establish our paradigm by vigorously attacking and
excluding apparent pretenders to the throne of intelligence,
pretenders such as pattern recognition, behaviourism,
neural networks, and even probability theory. Now that we
are established, such ideological purity is no longer a
concern. We are more catholic, focusing on problems, not
on hammers. Given that we do have a comprehensive
toolbox; issues of architecture and integration emerge as
central [5].”

we observe in the organization of the former may be quite
instructive in our thinking and planning of the latter; and
conversely a good deal of our experiences and difficulties
with our artificial automata can be to some extent
projected on our interpretations of natural organism ” [5].
He envisaged what is seen today as Soft computing (SC) a
term used interchangeably as CI.
With much effort invested than noticed, a new wave of AI
came into picture at a conference on the campus of
Dartmouth College in the summer of 1956. The attendees,
including John McCarthy, Marvin Minsky, Allen Newell
and Herbert Simon, became the leaders of AI research for
many decades. Parallel to what is known as rule-based AI
was the advancement of the nature-inspired techniques
grouped under the name CI.

IEEE Computational Intelligence Society defines CI as
consisting of neural computing (NC), fuzzy Computing
(FC) and evolutionary computation (EC). The approach
taken by researchers and book authors is to treat
computational intelligence as an umbrella under which
more and more methods will be added. A good definition
of the field is therefore impossible, because different
people include or exclude different methods under the same
CI heading [5].

A belief in the efficacy of stepping through simple rules,
combined with a belief that the operations of the Turing
machine accurately model human behaviour, led to claims
for behaviour achievable in digital computers which could
not be substantiated. The turning point in this phase seems
to have been the project for automatic translation of
languages. This failed so badly that it provoked a complete
cessation of funding for AI research in Great Britain and a
severe reduction in the United States. The unsatisfactory
outcome of projects undertaken in the 1950’s caused the
whole field of AI research to become relatively dormant
until the mid-1960. Soon after its renascence, impressive
machine behaviour was achieved, especially in problem
solving and diagnostic assistance. The ability to reflect the
behaviour of an expert was impressive, even though the
range of behaviour was quite limited. Landmarks of this
period include:
a. development by McCarthy [9] of the LIst
Processing (Lisp) language, which focuses on
recursive processing of arbitrary lists;
b. the “blocks world,” from Understanding Natural
Language, by Terry Winograd [21], which
demonstrates limited communication with a robot
in natural English and with automated planning;
c. The Eliza program, which mimics a Rogerian
psychotherapist, by Weizenbaum [10];
d. The Semantic Organization of Memory, by
Quillian [14], which outlines a system of world
linkages reflecting concept linkages in natural
language;
e. The MYCIN program [7], which demonstrated
the utility of rule sets and confidence factors in
developing a diagnostic adviser for physicians.

2. ARTIFICIAL INTELLIGENCE(AI)
2.1 Brief History of AI
In spite of the wide usage and applications, journal papers
and books written about AI, there is still not simple and allencompassing meaning of AI. Before exploring into the
concept of AI, we will highlight its origin and intercepting
fields of AI. As fuzzy as its definition so is the origin of AI.
Some scholars attribute the origin of AI to Aristotle for his
works on logic and deductive reasoning (syllogism).
Though his works on logic has great impact in AI but
deductive reasoning alone does not imply intelligence.
Another School of thought attributes the origin of AI to
Alan Turing for his work on Turing machine. Turing
defined intelligent behavior as the ability to achieve
human-level performance in all cognitive tasks, sufficient
to fool an interrogator.
Roughly speaking, the test he proposed is that the computer
should be interrogated by a human via a teletype, and
passes the test if the interrogator cannot tell if there is a
computer or a human at the other end [19]. Although
formidable, but has not got necessary qualities of
intelligence as defined above. His work was a major
motivation to researchers. His work could be viewed as
machine that acts humanly [19]. Most AI literatures ignore
the influence of Von John Neumann works of automata on
AI. One of his noted comments is that “Natural organisms
are, as a rule, much more complicated and subtle and
therefore much less well understood in detail, than are
artificial automata. Nevertheless, some regularities which

The subject of AI has evolved, and continues to evolve,
from the intersection of research from such fields as
cognitive science, philosophy, psychology, mathematics,
linguistics, statistics, physics, biology, engineering,
ontology, finance, economics and natural sciences. AI is
forecasted to have applications and interferences to almost
all fields of study in few decades.

116

Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

A system is rational if it does the right thing [19]. The right
thing is usually the one which best (or at least well) helps
the system in achieving its goals.[19]. In [19], intelligence
or rationality is based on subjective and dynamic reasoning
rather than the ability to correctly solve problems
irrespective of complexity. The definitions posited by
McCarthy and IEEE seem to be the basis from which all
other views originate but this is also ephemeral. Although
not yet pragmatic, the actualization of strong AI will
contradict the IEEE, 1996 view of AI. The future of AI is
not deterministic. It is quite difficult to extend this
definition, because the definition of what factors describe
human intelligence is not clear.

2.2 Cited Definitions and Commentaries of AI.
The phrase AI, which was coined by John McCarthy about
five decades ago, sidesteps a concise and formal definition
to date. This is ephemeral. One representative definition is
pivoted around the comparison of intelligence of
computing machines with human beings. Another
definition is concerned with the performance of machines
which “historically have been judged to lie within the
domain of intelligence”. None of these definitions or the
like has been universally accepted, perhaps because of their
references to the word “intelligence”, which at present is an
abstract and immeasurable quantity. A better definition of
AI, therefore, calls for formalization of the term
“intelligence”. Psychologist and Cognitive theorists are of
the opinion that intelligence helps in identifying the right
piece of knowledge at the appropriate instances of decision
making. The phrase “AI” thus can be defined as the
simulation of human intelligence on a machine, so as to
make the machine efficient to identify and use the right
piece of “Knowledge” at a given step of solving a problem.
A system capable of planning and executing the right task
at the right time is generally called rational. Thus, AI
alternatively may be stated as a subject dealing with
computational models that can think and act
rationally[19][3].

Two types of methodology have become dominant in AI.
The first is concerned only with sets of rules and their
activation. The second is concerned with more general
problems of the organization of knowledge, plus a need for
cooperation between various sources of knowledge in a
synergistic way. Systems using only the rule-based
approach focus on capture of appropriate rules, the facts
used, and proper rule execution in a limited, specific
situation. These are the kinds of systems properly referred
to as expert systems, since they focus on capturing the
insights of an expert in a small domain, and coding these
insights. The second type of system encompasses a larger
domain than just facts and rules for one situation. The latter
type of system is better referred to as a knowledge-based
system.

Another paradigm in the definition of AI was proposed in
[19] which seem to be simplistic but much more
complicated than expected. Here AI is segmented into four
intersecting categories;
a. thinking humanly
b. acting humanly
c. thinking rationally and
d. Acting rationally.

3. COMPUTATIONAL INTELLIGENCE(CI)
Parallel to what is known as rule-based AI was the
advancement of the nature-inspired techniques grouped
under the name CI. Although used fairly widespread [3],
there is no (yet) on what CI exactly is, but there is a widely
accepted view on which areas belong to it: EC, FC and NC.
The World Congress on CI held every four years (1994
Orlando, 1998 Anchorage, and 2002 Honolulu) consists of
three tracks, the IEEE International Conference on EC, FC,
and NC [4].

The following definitions were the motivation for the
categorization in[19]; "The exciting new effort to make
computers think . . . machines with minds, in the full and
literal sense", "[The automation of] activities that we
associate with human thinking, activities such as decisionmaking, problem solving, learning ...", "The art of creating
machines that perform functions that require intelligence
when performed by people, "The study of how to make
computers do things at which, at the moment, people are
better", "The study of mental faculties through the use of
computational models", "The study of the computations
that make it possible to perceive, reason, and act", "A field
of study that seeks to explain and emulate intelligent
behaviour in terms of computational processes", "The
branch of computer science that is concerned with the
automation of intelligent behaviour”. The two approaches
emphasized in [19] is human-centred and rationalist
approaches. Much emphasis was laid on the latter.

From 1956 to 1969 much research was done in modeling
biological neurons. Most notable were the work on
perceptrons by Rosenblatt, and the adaline by Widrow and
Hoff. In 1969, Minsky and Papert caused a major setback
to NC research. With their book, called Perceptrons, they
concluded that, in their "intuitive judgment", the extension
of simple perceptrons to multilayer perceptrons "is sterile".
This caused research in NC to go into hibernation until the
mid-1980s. During this period of hibernation a few
researchers, most notably Grossberg, Carpenter, Amari,
Kohonen and Fukushima, continued their research efforts.

117

Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

The resurrection of NC research came with landmark
publications from Hopfield, Hinton, and Rumelhart and
McLelland in the early and mid-1980s. From the late 1980s
research in NC started to explode, and is today one of the
largest research areas in Computer Science.
The
development of evolutionary computing (EC) started with
genetic algorithms in the 1950s with the work of Fraser.
However, it is John Holland who is generally viewed as the
father of EC, most specifically of genetic algorithms. In
these works, elements of Darwin's theory of evolution were
modeled algorithmically. In the 1960s, Rechenberg
developed evolutionary strategies (ES). Research in EC
was not a stormy path as was the case for NC.

As cited in [4], one common denominator in the definitions
of CI is adaptation. [4] puts it in perspective as “Any
system... that generates adaptive behavior to meet goals in a
range of environments can be said to be intelligent. In
contrast, any system that cannot generate adaptive behavior
and can only perform in a single limited environment
demonstrates no intelligence.” It exceeds the scope of this
paper to go into the investigation of all the aspects of CI
such as NC, FC and EC. Extensive references have been
provided to aid readers.

In 1920 Lukasiewicz published the first deviation from
two-valued logic in his work on three-valued logic - later
expanded to an arbitrary number of values. The quantum
philosopher Max Black was the first to introduce quasifuzzy Sets wherein degrees of membership to sets were
assigned to elements. It was Lotfi Zadeh who contributed
most to the field of fuzzy logic, being the developer of
fuzzy sets in 1965[12][13].

Contrast to traditional hard computing, SC exploits the
tolerance for imprecision, uncertainty, and partial truth to
achieve tractability [2], robustness, low solution-cost and
better rapport with reality”. SC as coined by Zadeh [13] [14]
was intended to differentiate all techniques that mimic the
human mind from the crisp computing. There is no
difference in goal between CI and SC both is umbrella
concept for nature-inspired problem solving techniques.
Nevertheless, the slight difference between CI and SC is the
composition of techniques. CI is a composition of EC, NC
and FC whereas SC extends to some other techniques to
probabilistic computing and rough set. In fact there is no
boundary for SC techniques. CI is a subset of SC. Therefore
we do not interchangeably use SC and CI in this paper.
Figure 1 depicts this distinction.

3.1 Computational Intelligence versus Soft Computing

A key player in the field of CI is J.C. Bezdek who was the
first researcher to publish a paper on the definition of CI. In
one of his paper, he posited that: “… (strictly)
computational systems depend on numerical data supplied
by the manufactured sensors and do not rely upon
“knowledge”.” Later in 1994, Bezdek offers CI as a” lowlevel computation in the style of the mind” and AI as “midlevel computation in the style of the mind”. He outlined
that mid-level system include knowledge whereas low-level
does not [11][4]. This school of thought implies that CI
systems employ sensor data and the AI should be reserved
for architectures that have a clearly identifiable nonnumerical component or knowledge. Here CI systems are
identified by the fact that: “It deals only with numerical
(low-level) data, has a pattern recognition component, and
does not use knowledge in the AI sense; and additionally,
when it (begins to) exhibit (i) computational adaptively; (ii)
computational fault tolerance; (iii) speed approaching
human-like turnaround, and (iv) error rates that
approximate human performance.” [4].

4. COMPUTATIONAL INTELLIGENCE VERSUS
ARTIFICIAL INTELLIGENCE
This section is the major motivation of this paper. The
relationship between CI and AI has formed a frequently
discussed issue during the development of CI. The huge
majority of CI/AI researchers concerned with the subject
sees them as different areas, where either [3]
•
CI forms an alternative to AI
•
AI subsumes CI
•
CI subsumes AI
Supporting information to the first point could be found in
Mark 1993[4]: “Although seeking similar goals, CI has
emerged as a sovereign field whose research community is
virtually distinct from AI”. Another school of thought that
lays emphasis on point 2 above is the publication of Bazdek
of 1994. He depicted CI to be a subset of AI. Bezdek
summarized the relationships among components of
intelligent systems with a figure, after Bezdek’s elaboration
on his first definition in 1994. He describes three levels of
system complexity, level A, B and C. Level A stands for
artificial or symbolic, level B for biological or organic, and
level C stands for computational or numeric systems [4].
He confirms his view positing that NC, FC and EC are AI
enabling techniques.

Another notion related to Bazdek philosophy but differs
with the introduction of adaptation views CI as thus; “...
Computational intelligence is defined as a methodology
involving computing (whether with a computer, wetware,
etc.) that exhibits an ability to learn and/or deal with new
situations such that the system is perceived to possess one
or more attributes of reason, such as generalization,
discovery, association and abstraction. The output of a
computationally intelligent often includes predictions
and/or decisions…”

118

Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

Another notion that contradicts Bezdek’s view is proposed
by Fogel in 1995 who posited that the basis of this
distinction between AI and CI is the identification of
adaptation as the key feature of intelligence. His argument
could be summarized in the comments in [4]. Fogel[6]
observes that the central focus in traditional AI research has
been on emulating human behavior by extracting rules and
knowledge from human experts. Furthermore, the vast
majority of AI programs has nothing to do with learning.
Traditional symbolic AI systems do not adapt to new
problems in new ways, therefore they emphasize
“artificial” and not the “intelligence”. They may play
excellent chess, but in essence they are but complicated
calculators. In contrast, CI techniques model natural
processes or end-products associated with intelligent
behaviors, either at the level of neuronal activity and
function, human behavior, or evolutionary learning in the
terms of adaptive behavior or adaptive genetics. Pushing it
to the extreme, from these premises it may be implied that
(traditional) AI systems are not intelligent, while CI
systems are.
5. DISCUSSION

•

Figure 1. shows the categorization of the concepts. The AI
is primarily a discipline oriented to creating intelligent
systems. By this, any discipline that deals also with
machine intelligence is subsumed by AI. We view the
traditional AI approaches or techniques as deductive.
Precisely, they follow the famous bottom-up approach.
Techniques under this category cannot efficiently deal
with acute and nondeterministic problems. They cannot
deal with uncertainty and vagueness. Another
categorization is the nature-inspired techniques. These
techniques are believed to deal with the limitations of the
counterpart category naturally. SC is seen as a super set
which contains all techniques categorized as CI and more.

uncertainty, partial truths, ambiquities and
imprecisions that model the nonlinearity and
nondeterminism of the natural world, CI is the
need of AI. CI techniques are inductive in
nature(bottom-top) whereas the traditional AI
techniques are deductive(top-down). Tradtional
AI also known as the rule-based AI employs
crisp techniques and thus will pose difficulties in
dealling with acute problems that require
flexibility. These points imply that CI majors in
solving
complex
or non-algorithmizable
problems.
We can vividly differentiate CI and AI from the
view point that CI is an independent umbrella of
techniques that can be used to realize AI systems
whose intelligence could compete or/and outrun
human intelligence. This also gives viability to
the concept of strong AI. We should note that just
as rule of thumb, heuristics and if…then
approaches are techniques to achieve intelligence
in a deductive manner so are CI techniques which
employ the principle of inductive procedure.

As future research, investigation of the CI and AI
constituent techniques with respect to practical works
should be made to give direction to researchers and
students delving into this area of machine intelligence.
Detailed definition of terms and discussion on these
concepts from an application perspective should also be
included in such investigation.

6. CONCLUDING REMARKS/FUTURE RESEARCH
The CI discipline is apparently at its infancy with respect to
practical application of its constituent technologies. Any
notion given at this stage will have to pass through a test of
time. Below are our views of what CI should be and its
relationship to other concepts.
•

•

AI: In our view, AI is the umbrella discipline of
all disciplines that have to do with simulation of
intelligence of any degree in machines.
CI: We define CI as an umbrella name for
natured-inspired problem-solving techniques
that could be used to simulate intelligence into
machine or make a machine more intelligent
or could be used in solving nonalgorithmizable
problems. In our view, CI is a discipline of its
own
whose
constituent
problem-solving
techniques could be utilised to achieve a more
efficient, error-tollerance, robust and economic
AI entities. Having techniques that can handle

Figure 1. Categorization Of The Concepts
Acknowledgment
We acknowledge the researchers whose works were cited
in this piece.

119

Vol 8. No. 2 June, 2015
African Journal of Computing & ICT
© 2015 Afr J Comp & ICT – All Rights Reserved - ISSN 2006-1781
www.ajocict.net

[17] R. Eberhart, P. Simpson, and R. Dobbins,
Computational Intelligence PC Tools, Boston:
Academic Press, 1996.
[18] R.J. Marks 11, "Intelligence: Computational Versus
Artificial", IEEE Transactions on Neural Networks,
vo1.4, no.5, September 1993.
[19] S. J. Russell, P. Norvig, Artificial Intelligence:
Mordern Approach., New Jersey 07632: Prentice
Hall,1995.
[20] Shazwellyn,
“Psychology
101-What
Is
Intelligence,”
[online].
Available:
www.hugPages.com
[21] T. Winograd, Understanding Natural Language.
New York: Academic Press, 1972 (this is the world
of “shrdlu” and the blocks, so often cited in AI
literature).

REFERENCES
[1] “Artificial Intelligence,” [online]. Available:
www.en.wikipedia.org/wiki/Category:
artificial_intelligence.
[2] A.K. Mackworth, “The Coevolution of AI and
AAAI,” AI Magazine, vol.26 no.4, pp. 51-52,
2005.
[3] Amit Konar, Artificial Intelligence and Soft
Computing: Behavioral and Cognitive Modeling of
the Human Brain, Florida, USA: CRC Press LLC,
2000.
[4] B.G.W. Craenen, A.E. Eiben, “Computational
Intelligence,” Encyclopedia of Life Support
System, EOLSS Co. Ltd., http://www.eolss.net,
2003.
[5] C. L. Mumford, L. C. Jain, Computational
Intelligence: Collaboration, Fusion and Emergence,
Intelligent System Library, Verlag- Berlin:
Springer, 2009.
[6] D. Fogel, “Review of Computational Intelligence
Imitating life,” IEEE Transactions on Neural
Networks, Vol. 6, pp. 156-165, 1995.
[7] E. Charniak and D. McDermott, Introduction to
Artificial Intelligence. Reading, MA: AddisonWesley, 1985.
[8] J. C. Bezdek, What is computational intelligence?
In: Computational Intelligence Imitating Life, pp.
1–12, New York: IEEE Press, 1994.
[9] J. McCarthy, “Recursive Functions of Symbolic
Expressions and Their Computation by Machine,”
Commun. Ass. Comput. Mach., vol. 7, pp. 184195, Apr. 1960.
[10] J. Weizenbaum, Computer Power and Human
Reason. San Francisco: W. H. Freeman & Co.,
1976 (the inside story from the creator of the Eliza
program cited in the literature, with cogent
comments on some of the “reasoning” programs
now available, such as the Macsyma program of
Symbolics).
[11] J. C. Bezdek, "What ... Is Computational
Intelligence?", a chapter in this book.
[12] L.A. Zadeh, “Fuzzy Logic and Soft Computing:
Issues, Contentions and Perspectives,” Proc. Third
International Conference on Fuzzy Logic, Neural
Nets and Soft Computing (IIZUKA’94), Japan, pp.
1-2, 1994.
[13] L.A. Zadeh, “Fuzzy Logic, Neural Networks, and
Soft Computing,” Communications of the ACM,
vol. 37, pp. 77-84, 1994.
[14] M. Minsky, Ed., Semantic Information Processing.
Cambridge, MA: MIT Press, 1968.
[15] P. Schmutter, “a taxonomy for Artificial
Intelligence and Computational Intelligence,”
[online]. Available: http://www.schmutter.de
[16] R.C. Eberhart and Y. Shui, Computational
Intelligence - Concepts to Implementations,
Elsevier, 2007.

120

