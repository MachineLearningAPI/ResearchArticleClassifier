Home

Search

Collections

Journals

About

Contact us

My IOPscience

Entropic uncertainty relations—a survey

This content has been downloaded from IOPscience. Please scroll down to see the full text.
2010 New J. Phys. 12 025009
(http://iopscience.iop.org/1367-2630/12/2/025009)
View the table of contents for this issue, or go to the journal homepage for more

Download details:
IP Address: 202.78.175.199
This content was downloaded on 25/09/2015 at 20:50

Please note that terms and conditions apply.

New Journal of Physics
The open–access journal for physics

Entropic uncertainty relations—a survey
Stephanie Wehner1,3 and Andreas Winter2,3,4
1
Institute for Quantum Information, Caltech, Pasadena, CA 91125, USA
2
Department of Mathematics, University of Bristol, Bristol BS8 1TW, UK
3
Centre for Quantum Technologies, National University of Singapore,
2 Science Drive 3, Singapore 117542, Singapore
E-mail: wehner@caltech.edu and a.j.winter@bris.ac.uk
New Journal of Physics 12 (2010) 025009 (22pp)

Received 27 July 2009
Published 26 February 2010
Online at http://www.njp.org/
doi:10.1088/1367-2630/12/2/025009

Abstract. Uncertainty relations play a central role in quantum mechanics.
Entropic uncertainty relations in particular have gained significant importance
within quantum information, providing the foundation for the security of many
quantum cryptographic protocols. Yet, little is known about entropic uncertainty
relations with more than two measurement settings. In the present survey, we
review known results and open questions.

4

Authors to whom any correspondence should be addressed.

New Journal of Physics 12 (2010) 025009
1367-2630/10/025009+22$30.00

© IOP Publishing Ltd and Deutsche Physikalische Gesellschaft

2
Contents

1. Preliminaries
1.1. Entropic quantities . . . . . . . . . . . .
1.2. Maximally strong uncertainty relations . .
1.3. Mutually unbiased bases . . . . . . . . .
2. Two measurements
2.1. History . . . . . . . . . . . . . . . . . .
2.2. Measurements in different bases . . . . .
2.3. General measurements . . . . . . . . . .
2.4. Quantum side information . . . . . . . .
3. More than two measurements
3.1. Random choice of bases . . . . . . . . .
3.2. Mutually unbiased bases . . . . . . . . .
3.3. Anti-commuting observables . . . . . . .
4. Applications
5. Open problems
Acknowledgments
Appendix. A bound for mutually unbiased bases
References

. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

.
.
.
.

. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .

4
4
5
5
8
8
9
10
11
12
12
12
14
16
17
18
18
21

The uncertainty principle is one of the fundamental ideas of quantum mechanics. Since
Heisenberg’s uncertainty relations for canonically conjugate variables, they have been one
of the most prominent examples of how quantum mechanics differs from the classical
world (Heisenberg 1927). Uncertainty relations today are probably best known in the form
given by Robertson (1929), who extended Heisenberg’s result to two arbitrary observables A
and B. Robertson’s relation states that if we prepare many copies of the state |ψ , and measure
each copy individually using either A or B, we have
A B

1
|
2

ψ|[A, B]|ψ |,

(1)

where X = ψ|X 2 |ψ − ψ|X |ψ 2 for X ∈ {A, B} is the standard deviation resulting from
measuring |ψ with observable X . The consequence is the complementarity of quantum
mechanics: there is no way to simultaneously specify definite values of non-commuting
observables. This, and later, formulations concern themselves with the tradeoff between the
‘uncertainties’ in the value of non-commuting observables on the same state preparation. In
other words, they are comparing counterfactual situations.
It was eventually realized that other measures of ‘spread’ of the distribution on
measurement outcomes can be used to capture the essence of uncertainty relations, which
can be advantageous. Arguably the universal measure is the entropy of the distribution,
which led Hirschmann to propose the first entropic uncertainty relation for position and
momentum observables (Hirschmann 1957). His results were later improved by the inequalities
of Beckner (1975) and the uncertainty relations of Białynicki-Birula and Mycielski (1975),
which we will review below. In Białynicki-Birula and Mycielski (1975) it is shown that this
relation implies the Heisenberg uncertainty relation (1), and thus entropic uncertainty relations
provide us with a more general framework of quantifying ‘uncertainty’.
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

3
That entropic uncertainty relations are indeed desirable was pointed out by Deutsch (1983),
who emphasized the fact that the lower bound given by Robertson’s uncertainty relation
depends on the state |ψ . In particular, this lower bound is trivial when |ψ happens to
give zero expectation on [A, B]—which in finite dimension is always possible. He addressed
this problem by proving a first entropic uncertainty relation in terms of the Shannon
entropy for any two non-degenerate observables, which gives a bound that is independent
of the state to be measured. His uncertainty relation was later improved by Maassen and
Uffink (1988), following a conjecture by Kraus (1987), which we will discuss in detail
below. Apart from placing universal lower bounds on uncertainty even in finite dimension,
another side effect of considering entropy uncertainty relations is a conceptual liberation.
Indeed, Robertson’s inequality (1) is best when the right hand side is 1, i.e. A and B are
canonically conjugate which happens if and only if they are related by a Fourier transform.
In the finite-dimensional case, Maassen and Uffink (1988) show that the largest uncertainty is
obtained more generally for so-called mutually unbiased observables, which opens the way
for uncertainty tradeoffs of more than two observables. Even though entropic uncertainty
relations thus play an important role in our understanding of quantum mechanics, and have
interesting applications ranging from quantum cryptography (Damgaard et al 2005, Koashi
2005), information locking (DiVincenzo et al 2004), atomic systems (Srikanth and Banerjee
2009), to the question of separability (Guehne 2004), very little is known about them. Indeed,
only in the case of two measurement settings do we have a reasonable understanding of such
relations. The purpose of this review is to present what is known about entropic uncertainty
relations for a number of different entropic quantities, where we focus on Shannon and Rényi
entropies. Other relations are known for a wide range of entropic quantities such as the
Fisher information (Gibilisco et al 2009), the Tsallis entropy (Majernik and Majernikova 2001,
Rajagopal 1995, Tsallis 1988) and other entropies with special properties (Hall 2008). A general
survey on uncertainty relations predating most of the results mentioned here can be found in
Dodonov and Man’ko (1989).
Let us first consider the general form of an entropic uncertainty relation more formally. Let
M j = {M xj | M xj ∈ B (H)} be a measurement on the space H with a (finite) set of outcomes
x
x ∈ X , that is, for all x we have M xj 0 and
x M j = 1. For any quantum state ρ, the
measurement M j induces a distribution P j over the outcomes given by P j (x) = Tr(M xj ρ).
We will write Hα (M j |ρ) for an entropy Hα of the resulting distribution. For example, for the
Shannon entropy we have
H (M j |ρ) = −

Tr(M xj ρ) log Tr(M xj ρ).
x

An entropic uncertainty relation captures the incompatibility of several measurements
M1 , . . . , M L . In particular, any such relation takes the form
for all ρ ∈ S (H)

1
L

L

Hα (M j |ρ)

c{M j } ,

(2)

j=1

where c{M j } is a constant depending solely on our choice of measurements, and not on the
state ρ. It is a particularly interesting question to find measurements for which c{M j } is as large
as possible.
In section 1, we first provide an overview of the entropic quantities we will use throughout
this text. We also introduce the concept of maximally strong uncertainty relations and discuss
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

4
mutually unbiased bases, which play a special role in the study of uncertainty relations. We then
consider the case of two measurement settings (L = 2) in section 2 which is the only case well
understood. In section 3, we then present an overview of the few results known for multiple
measurements. We conclude in section 4 with some applications of uncertainty relations in
cryptography.
1. Preliminaries

1.1. Entropic quantities
We begin by introducing all entropic quantities used in this text. The expert reader may safely
skip this section. Let PX be a distribution over a set X , where we write PX (x) for the probability
of choosing a particular element x ∈ X . The Rényi entropy (Rényi 1960) of this distribution is
defined as
Hα (PX ) =

1
log
1−α

PX (x)α ,
x∈X

for any α 0. It will be useful to note that the Rényi entropy is in fact related to the α-norm of
the vector v of probabilities
1/α

v

α

PX (x)α

=
x∈X

by taking the logarithm
Hα (PX ) =

α
log v α .
1−α

A special case of the Rényi entropy is the well-known Shannon entropy (Shannon 1948)
obtained by taking the limit
H (PX ) = lim Hα (PX ) = −
α→1

PX (x) log PX (x).
x∈X

We are especially interested in the so-called collision entropy, that is, the Rényi entropy of order
α = 2 given by
H2 (PX ) = − log

PX (x)2 ,
x∈X

and the min-entropy given by the limit α → ∞ as
H∞ (PX ) = − log maxx∈X PX (x).
The Rényi entropies are monotonically decreasing in α, i.e.
Hα (·)

Hβ (·),

for α β. In particular, we thus have H∞ (·) H2 (·) H (·). Note that any such entropies can
take on values in the interval 0 Hα (·) log |X |, where the lower bound is clearly attained
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

5
if the distribution is sharply defined with PX (x) = 1 for some x ∈ X , and the upper bound is
attained when PX (x) = 1/|X | is the uniform distribution.
In the following, we will write
Hα (B|ρ) := Hα ({|x x|}|ρ)
to denote the entropy arising from a measurement in an orthonormal basis B = {|x | x ∈ [d]}
where [d] := {1, . . . , d} and use
Hα (A|ρ) := Hα ({A x }|ρ)
to denote the entropy arising from measuring with observables A given by the projectors {A x }.
1.2. Maximally strong uncertainty relations
An intriguing question is to find measurements which are very incompatible, in the sense that
the rhs of (2) is very large. We will refer to this as a strong uncertainty relation. Note that given
any set of projective measurements M1 , . . . , M L , we can always find a state ρ such that
Hα (M j |ρ) = 0
for one of the measurements M j , namely by choosing ρ to be an eigenstate of one of the
measurement operators. We thus know that the rhs of (2) can never exceed
log |X |(1 − 1/L)

c{M j }

0.

If for any choice of measurements the lower bound is given by c{M j } = log |X |(1 − 1/L), we
know that if ρ has zero entropy for one of the measurements, the entropy is maximal for all
others. We call a set of measurements that satisfy this property maximally incompatible, and
refer to the corresponding uncertainty relation as being maximally strong. Below, we will define
a special relationship between two bases called mutually unbiased. Such pairs of bases have the
property that when we measure any vector from the first basis in the second basis, the outcome
over measurement outcomes will be uniform. Indeed, when we consider measurements in L
different bases, all bases must be mutually unbiased to each other in order for us to obtain strong
uncertainty relations: suppose that two of the L bases B1 and B2 are not mutually unbiased, so
there exist two basis vectors |x ∈ B1 and |y ∈ B2 that have higher overlap | x|y |2 > 1/d. Then
choosing ρ = |x x| to be a projector onto a vector of the first basis yields zero entropy when
measured in basis B1 and less than full entropy when measured in the basis B2 . As outlined
below, mutually unbiased bases do indeed lead to maximally strong uncertainty relations for
L = 2 measurements. This however does not hold in general for the case of L > 2. We will
also see that maximally incompatible measurements can be found for any L if we only consider
|X | = 2 outcomes.
1.3. Mutually unbiased bases
Since mutually unbiased bases play an important role in the study of uncertainty relations,
we briefly review two well-known constructions for which particular uncertainty relations are
known to hold.

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

6

1

2

3

1

2

3

2

3

1

3

1

2

3

1

2

2

3

1

Figure 1. Mutually orthogonal Latin squares.

Definition 1.1 (MUBs). Let B1 = {|b11 , . . . , |bd1 } and B2 = {|b12 , . . . , |bd2 } be
√ two orthod
1 2
normal bases in C . They are said to be mutually unbiased if | bk |bl | = 1/ d, for every
k, l ∈ [d] A set {B1 , . . . , Bm } of orthonormal bases in Cd is called a set of mutually unbiased
bases if each pair of bases is mutually unbiased.
For example, the well-known computational and Hadamard basis are mutually unbiased.
We use N (d) to denote the maximal number of MUBs in dimension d. In any dimension d, we
have that N(d) d + 1 (Bandyopadhyay et al 2002). If d = p k is a prime power, we have that
N(d) = d + 1 and explicit constructions are known (Bandyopadhyay et al 2002, Wootters and
Fields 1989). If d = s 2 is a square, N(d) MOLS(s) where MOLS(s) denotes the number of
mutually orthogonal s × s Latin squares (Wocjan and Beth 2005). In general, we have N(nm)
min{N(n), N(m)} for all n, m ∈ N (Klappenecker and Rötteler 2004, Zauner 1999). From this
it follows that in any dimension, there is an explicit construction for 3 MUBs (Grassl 2004).
Unfortunately, not much else is known. For example, it is still an open problem whether there
exists a set of 7 (or even 4!) MUBs in dimension d = 6. In this text, we refer to two specific
constructions of mutually unbiased bases. There exists a third construction based on Galois
rings (Klappenecker and Rötteler 2004), which we do not consider here, since we do not know
of any specific uncertainty relations in this setting.
1.3.1. Latin squares. First, we consider MUBs based on mutually orthogonal Latin
squares (Wocjan and Beth 2005) which can be constructed in square dimensions d = s 2 with
s ∈ N. Informally, an s × s Latin square over the symbol set [s] is an arrangement of elements
of [s] into an s × s square such that in each row and each column every element occurs exactly
once. Let L i j denote the entry in a Latin square in row i and column j. Two Latin squares L
and L are called mutually orthogonal if and only if {(L i, j , L i, j )|i, j ∈ [s]} = {(u, v)|u, v ∈ [s]}.
Intuitively, this means that if we place one square on top of the other, and look at all pairs
generated by the overlaying elements, all possible pairs occur. An example is given in figure 1
below. From any s × s Latin square we can obtain a basis for Cs ⊗ Cs . Firstly, we construct s of
the basis vectors from the entries of the Latin square itself. Let
1
|v1, = √
s

E i,L j ( )|i, j ,
i, j∈[s]

where E L is a predicate such that E i,L j ( ) = 1 if and only if L i, j = . Note that for each
we have exactly s pairs i, j such that E i, j ( ) = 1, because each element of [s] occurs exactly
s times in the Latin square. Secondly, from each such vector we obtain s − 1 additional vectors
by adding successive rows of an s × s complex Hadamard matrix H = (h i j ) as coefficients to
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

7
obtain the remaining |vt, j for t ∈ [s], where h i j = ωi j with i, j ∈ {0, . . . , s − 1} and ω = e2π i/s .
Two additional MUBs can then be obtained in the same way from the two non-Latin squares
where each element occurs for an entire row or column, respectively. From each mutually
orthogonal Latin square and these two extra squares which also satisfy the above orthogonality
condition, we obtain one basis. This construction therefore gives MOLS(s) + 2 many MUBs,
where MOLS(s) is the number of s × s mutually orthogonal
Latin squares. It is known that
√
k
k
if s = p is a prime power itself, we obtain p + 1 ≈ d MUBs from this construction. Note,
however, that there do exist many more MUBs in prime power dimensions, namely d + 1. If s is
not a prime power, it is merely known that MOLS(s) s 1/14.8 (Wocjan and Beth 2005).
As an example, consider the first 3 × 3 Latin square depicted in figure 1 and the 3 × 3
complex Hadamard matrix


1 1 1


H = 1 ω ω2 ,
1 ω2 ω
where ω = e2πi/3 . First, we obtain vectors
1
|v1,1 = √ (|1, 1 + |2, 3 + |3, 2 ),
3
1
|v1,2 = √ (|1, 2 + |2, 1 + |3, 3 ),
3
1
|v1,3 = √ (|1, 3 + |2, 2 + |3, 1 ).
3
With the help of H we obtain three additional vectors from the ones above. From the vector
|v1,1 , for example, we obtain
1
|v1,1 = √ (|1, 1 + |2, 3 + |3, 2 ),
3
1
|v2,1 = √ (|1, 1 + ω|2, 3 + ω2 |3, 2 ),
3
1
|v3,1 = √ (|1, 1 + ω2 |2, 3 + ω|3, 2 ).
3
This gives us basis B = {|vt, |t, ∈ [s]} for s = 3. The construction of another basis follows
in exactly the same way from a mutually orthogonal Latin square. The fact that two such
squares L and L are mutually orthogonal ensures that the resulting bases will be mutually
unbiased. Suppose we are given another such basis, B = {|u t, |t, ∈ [s]} belonging to L . We
then have for any , ∈ [s] that | u 1, |v1, |2 = |(1/s) i, j∈[s] E i,L j ( )E i,L j ( )|2 = 1/s 2 , as there
exists exactly only one pair , ∈ [s] such that E i,L j ( )E i,L j ( ) = 1. Clearly, the same argument
holds for the additional vectors derived from the complex Hadamard matrix.
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

8
1.3.2. Generalized Pauli matrices. The second construction we consider is based on the
generalized Pauli matrices X d and Z d (Bandyopadhyay et al 2002), defined by their actions
on the computational basis C = {|0 , . . . , |d − 1 } as follows:
X d |k = |k + 1 mod d ,
Z d |k = ωk |k ,

∀ |k ∈ C,

where ω = e2πi/d . We say that (X d )a 1 (Z d )b1 ⊗ · · · ⊗ (X d )a N (Z d )b N for ak , bk ∈ {0, . . . , d − 1}
and k ∈ [N ] is a string of Pauli matrices. Note that for d = 2 these are just the usual Pauli
matrices.
If d is a prime, it is known that the d + 1 MUBs constructed first by Wootters and
Fields (Wootters and Fields 1989) can also be obtained as the eigenvectors of the matrices
Z d , X d , X d Z d , X d Z d2 , . . . , X d Z dd−1 (Bandyopadhyay et al 2002). If d = p k is a prime power,
consider all d 2 − 1 possible strings of Pauli matrices excluding the identity and group them
into sets C1 , . . . , Cd+1 such that |Ci | = d − 1 and Ci ∩ C j = ∅ for i = j and all elements of
Ci commute. Let Bi be the common eigenbasis of all elements of Ci . Then B1 , . . . , Bd+1
are MUBs (Bandyopadhyay et al 2002). A similar result for d = 2k has also been shown in
Lawrence et al (2002). A special case of this construction are the three mutually unbiased bases
in dimension d = 2k given by the unitaries 1⊗k , H ⊗k and K ⊗k√applied to the computational
basis, where H is the Hadamard transform and K = (1 + iσx )/ 2. A simple example of this
construction are the mutually unbiased bases in dimension d = 2, which are given by the
eigenvectors of the Pauli matrices X , Z and Y . A very interesting aspect of such mutually
unbiased bases is that there exists an ordering B1 , . . . , Bd+1 and a unitary U that cyclically
permutes all bases, that is, U B j = B j+1 for all j, where U Bd+1 = B1 (Wootters and Sussman
2007).
2. Two measurements

The case of two measurements (L = 2) is reasonably well understood in any dimension, and
for any number of outcomes. This case was of particular interest as is directly inspired by the
two measurements for which Heisenberg had originally formulated his uncertainty relation, i.e.
position and momentum. We begin by recalling some of the history of this fascinating problem,
before reviewing the currently relevant results.
2.1. History
The first entropic uncertainty relation was given by Hirschmann (1957) for position and
momentum observables, which was improved by the inequalities of Beckner (1975) and
the entropic uncertainty relations of Białynicki-Birula and Mycielski (1975) to an entropic
uncertainty relation for systems of n canonical pairs of position and momentum coordinates
X i and Pi :
H (X 1 . . . X n |ρ) + H (P1 . . . Pn |ρ)

n log(eπ)

where H (Q 1 . . . Q n |ϕ) refers to the (differential) Shannon entropy of the joint distribution of
the coordinates Q 1 , . . . , Q n when measured on the state ρ. Recall that the differential entropy

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

9
of a probability density p (with respect to Lebesgue measure) on Rn is defined as
H ( p) = − dx p(x) log p(x),
see Cover and Thomas (1991).
That entropic uncertainty relations are of great importance also in finite dimension was
pointed out by Deutsch (1983), who proved that for measurements in two bases A and B we
have
1
1 + c(A, B)
(H (A|ρ) + H (B|ρ)) − log
,
2
2
where c(A, B) := max{| a|b | | |a ∈ A, |b ∈ B}. We will see later that the same bound holds
for the min-entropies H∞ (·). His results were extended to a continuous setting for angle–angular
momentum and position and momentum by Partovi (1983), which in turn was improved by
Białynicki-Birula (1984). Different relations for particular angular momentum observables were
later also derived by Białynicki-Birula and Madajczyk (1985). A Rényi entropic version of such
an uncertainty relation may be found in Białynicki-Birula (2006).
2.2. Measurements in different bases
2.2.1. Any choice of bases. Following a conjecture by Kraus (1987), Maassen and
Uffink (1988) improved Deutsch’s uncertainty relation for measurements in two different bases.
In particular, they showed that if we measure any state ρ ∈ H with dim H = d using observables
with orthonormal eigenbases A = {|a1 , . . . , |ad } and B = {|b1 , . . . , |bd }, respectively, we
have
1
(H (A||ψ
2

) + H (B||ψ ))

− log c(A, B),

(3)

where c(A, B) := max{| a|b | | |a ∈ A, |b ∈ B}. Since H (·) is concave in |ψ , this result also
applies to mixed states ρ. What is the strongest possible relation we could obtain? That is, which
choices of A and B maximize the rhs of equation (3)? It turns out that the maximum is reached
when the two bases are mutually
√ unbiased (see section 1.3), i.e. when all the inner products
on the rhs above are equal to 1/ d. We then obtain that the entropy sum is lower bounded by
1
log d. This is tight, as the example of |ϕ = |a1 shows. Note that for general observables, this
2
lower bound is not necessarily tight, but its usefulness lies in the fact that it is in terms of very
simple geometric information of the relative position of the bases.
2.2.2. Improved bounds for specific bases. For dimension d = 2 optimal uncertainty relations
have been obtained for two observables A = a · σ and B = b · σ where σ = (X, Y, Z ), for some
angles of the Bloch vectors a · b analytically, and for others numerically (Ghirardi et al 2003).
Uncertainty relations that give improved bounds for a large class of measurements in two
different bases A and B have also been obtained in de Vicente and Sanchez-Ruiz√(2008) for
the case that the overlap between two basis vectors is large, that is, c(A, B) 1/ 2. Letting
c := c(A, B), the following analytical bound is shown for this regime:
1
(H (A|ρ)H (B|ρ))
2

1+c
1+c
1−c
1−c
log
−
log
,
2
2
2
2
√
and a numerical bound is provided that is slightly better for 1/ 2 c 0.834.
−

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

10
2.2.3. Relations for Rényi entropies. It is an often overlooked fact that Maassen and Uffink
also show uncertainty relations in terms of the Rényi entropies. In particular, they extend a
result by Landau and Pollack (1961) to show that for any |ψ
1
(H∞ (A||ψ ) + H∞ (B||ψ ))
2

− log

1 + c(A, B)
.
2

To see that this bound can be tight for some choices of A and B, consider two mutually unbiased
bases in dimension d = 2. For example, the computational A = {|0 , √
|1 } and the Hadamard
basis B = {|+ , |− }. The lower bound then becomes − log(1/2 + 1/(2 2)), which is attained
for |ψ = cos(π/8)|0 + sin(π/8)|1 . Furthermore they use a result for α-norms (Riesz 1929) to
show that the following relation holds in terms for Rényi entropies of order α and β satisfying
α > 1 and β = α/(2α − 1) < 1
1
(Hα (A||ψ
2

) + Hβ (B||ψ )) − log c(A, B),

for any state |ψ , which gave the result for the Shannon entropy above in the limit of α, β → 1.
Another uncertainty relation is known for the min-entropy, which has specific cryptographic
applications which we will investigate in section 4.
2.3. General measurements
2.3.1. Shannon entropy. The result by Maassen and Uffink (1988) has been extended to the
case of a general POVM. The first such result was given by Hall (1997), who pointed out
that their result can be easily extended to the case of rank one POVMs. His result was
subsequently strengthened (Massar 2007, Rastegin 2008a) by noting that any two POVMS
M1 = {|x 1 x 1 | | |x 1 ∈ H} and M2 = {|x 2 x 2 | | |x 2 ∈ H} acting on the Hilbert space H have
a Naimark extension to an ancillary space Hanc such that U |x˜ 1 = |x1 + U |x˜ 1 , and U |x˜ 2 =
|x2 + U |xˆ 2 for any unitary U = (1H ⊕ Vanc ) acting only on Hanc , where {|xˆ 1 , |xˆ 2 ∈ Hanc } form
an orthonormal bases on the ancillary system. Maximizing over such unitaries, that is, possible
extensions of the POVM, one obtains the bound
1
(H (M1 |ρ) +
2

H (M2 |ρ))

maxU − log maxx,y | x˜ 1 |U | y˜ 2 |

any state ρ ∈ B(H). The general setting was analyzed by Krishna and Parthasarathy (2002) who
showed that
1
(H (M1 |ρ) +
2

H (M2 |ρ))

(y)

− log maxx,y ||(M1(x) )1/2 (M2 )1/2 ||∞
(y)

(y)

for any POVMS M1 = {M1(x) | M1(x) ∈ B(H)} and M2 = {M2 | M2 ∈ B(H)} and any state
ρ ∈ B(H).
2.3.2. Rényi entropy. Entropic uncertainty relations for Rényi entropies have also been
obtained for the case of POVMs; however, such bounds depend on the state and thus differ
in spirit from the other uncertainty relations we consider. In particular, it has been shown by
Rastegin (2008b, c) that for any two POVMS M1 and M2 and any state
ρ=

λ j |ψ j ψ j |,
j

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

11
we have
1
(Hα (M1 |ρ) + Hβ (M2 |ρ))
2

(y)

− log max j,x,y

| ψ j |M1(x) M2 |ψ j |
(y)

||(M1(x) )1/2 |ψ j ||2 ||(M2 )1/2 |ψ j ||2

,

for 1/α + 1/β = 2.
2.4. Quantum side information
In the context of quantum information theoretical applications some other uncertainty relations
were discovered, which are entropic in spirit, but lie outside of the formalism introduced above.
Here, we quote two that can be viewed as extensions of the inequality of Maassen and
Uffink (1988) in the case of two measurement bases related by the Fourier transform, to
multipartite quantum systems and involving the von Neumann entropy S(ρ) = −Tr ρ log ρ.
With this entropy, one can formally construct a mutual information and a conditional entropy,
respectively, for bipartite states ρ AB with marginals ρ A = Tr B ρ AB and ρ B = Tr A ρ AB :
I (A : B) = I (A : B)ρ := S(ρ A ) + S(ρ B ) − S(ρ AB ),
S(A|B) = S(A|B)ρ := S(ρ AB ) − S(ρ B ).
Both inequalities compare two conjugate bases, i.e. without loss of generality, one
is the standard basis {|z : z = 0, . . . , d − 1}, the other one its Fourier transform
|xˆ = z e2πix z/d |z : x = 0, . . . , d − 1 . (These are just the eigenbases of the generalized
Z - and X -Pauli operators.) Denote the projections onto these bases by Z and X , respectively:
Z (ρ) =

|z z|ρ|z z|,
z

X (ρ) =

|xˆ xˆ |ρ|xˆ xˆ |.
x

The first uncertainty relation is by Christandl and Winter (2005): for a bipartite quantum
state ρ AB such that ρ A is maximally mixed,
I (A : B)Z ⊗id(ρ) + I (A : B)X ⊗id(ρ)

I (A : B)ρ ,

(4)

where id refers to the identity map on the second system (B), while on the first (A) one of the
basis projections Z or X acts.
The second is by Renes and Boileau (2009), who show similarly that for any tripartite state
ρ ABC ,
S(A|B)Z ⊗id(ρ) + S(A|C)X ⊗id(ρ)

log d.

(5)

Note that this directly reduces to (3) for trivial systems B and C—which is why Renes and
Boileau (2009) conjectured the following inequality when Z and X are more generally the
projections onto two arbitrary bases A and B, respectively:
S(A|B)Z ⊗id(ρ) + S(A|C)X ⊗id(ρ)

− log c(A, B).

This relation has indeed been proven recently by Berta et al (2009).

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

12
3. More than two measurements

We now review the known results for entropic uncertainty relations for more than two
measurement settings. Little is known in this scenario, except for a number of special cases. In
particular, it is an interesting open question whether strong uncertainty relations even exist for a
small constant number of measurement settings and more than two measurement outcomes. As
pointed out already, this is conceivable because unlike canonically conjugate variables, which
come in pairs, there are generally more than two mutually unbiased observables.
3.1. Random choice of bases
First of all, it may not be at all obvious that strong uncertainty relations can even be obtained
at all for more than two measurement settings, independent of the number of measurement
outcomes. We will use B j = {U j |x | x ∈ {0, . . . , d − 1}} where |x forms an orthonormal basis
for H to denote the basis obtained by rotating the standard basis into the basis determined by
the unitary U j . It was shown in Hayden et al (2004) that L = (log d)4 unitaries U j chosen from
the Haar measure randomly and independently obey
1
L

L

H (B j |ρ)

log d − O(1) = (log d) 1 − O

j=1

1
log d

with high probability, and for sufficiently large dimension d. It is important to note that the
number of measurement settings is not constant but depends on the dimension.
3.2. Mutually unbiased bases
Now that we know that it is in principle possible to obtain reasonably strong uncertainty
relations, can we construct explicit measurements for which we obtain such relations? Recall
that it is a necessary condition for bases to be mutually unbiased in order to obtain a maximally
strong uncertainty relation in the first place. Given the fact that if we have two measurement
settings, choosing the measurement bases to be mutually unbiased leads to maximally strong
uncertainty relations, it may be tempting to conclude that choosing our measurements to be
mutually unbiased is in general also a sufficient condition. Perhaps surprisingly, this is not the
case.
3.2.1. For d + 1 mutually unbiased bases. We first consider the case of all d + 1 mutually
unbiased bases, for which we can obtain strong uncertainty relations. In particular,
Ivanovic (1992) and Sanchez (1993) have shown that for the mutually unbiased bases
B1 , . . . , Bd+1 we have for any state ρ
1
d +1

d+1

H (B j |ρ)

log(d + 1) − 1.

(6)

j=1

If the dimension d is even, this can further be improved to (Sanchez-Ruiz 1995)
1
d +1

d+1

H (B j |ρ)
j=1

1
d
d
d
d
log
+
+ 1 log + 1
d +1 2
2
2
2

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

.

13
In dimension d = 2, the latter bound gives 2/3, which is tight for the mutually unbiased bases
given by the eigenvectors of the Pauli matrices X , Z and Y . The case of d = 2 was also addressed
separately in Sanchez-Ruiz (1998).
It is worth noting that the first bound (6) is in fact obtained by first lower bounding the
Shannon entropy H (·) by the collision entropy H2 (·), and then one proves that
1
d +1

d+1

H2 (B j |ρ)

log(d + 1) − 1.

(7)

j=1

This inequality can also be proven using the fact that a full set of mutually unbiased bases
forms a two-design (Ballester and Wehner 2007), and we provide a completely elementary
proof of this inequality in the appendix. Interestingly, it has been shown (Wootters and Sussman
2007) that the states ρ minimizing the lhs of (7) are states, which are invariant under a unitary
transformation that permutes the mutually unbiased bases as discussed in section 1.3.
3.2.2. For less than d + 1 mutually unbiased bases. What about less than d + 1 mutually
unbiased bases? First of all, note that it is easy to see that we do not always obtain a
maximally strong uncertainty relation in this setting. Consider dimension d = 3 and three
mutually unbiased bases B1 , B2 and B3 given by the eigenvectors of X 3 , Z 3 and X 3 Z 3 ,
respectively.
Then a simple calculation shows that for example for the state |ψ = (|1 −
√
|2 )/ 2 we have H (B j ||ψ ) = 1 for all bases j ∈ {1, 2, 3} and hence
1
3

3

H (B j ||ψ ) = 1 <
j=1

2
log 3.
3

In DiVincenzo et al (2004) (see the eprint version), numerical work on three and more mutually
unbiased bases in prime dimensions up to 29 is reported, which are consistent with a behavior
of (1 − O(1/k))(log d) of the average entropy lower bound. The mutually unbiased bases are
taken as a subset of the MUBs constructed via the generalized Pauli matrices in prime power
dimension.
Trivial bounds for more than two and less than d + 1 can be derived quite easily. For
example, for any number of mutually unbiased bases B1 , . . . , B L we obtain by combining (3)
for each pair of bases Bi and B j that
1
L

L

H (B j |ρ)
j=1

log d
.
2

(8)

As shown in the appendix, it is also easy to see that
1
L

L

H (B j |ρ)
j=1

− log

L +d −1
.
dL

Curiously, it turns out (Ballester and Wehner 2007) that in square prime power dimensions
d = p 2 there exist up to L = p + 1 MUBs derived from the generalized Pauli matrices for

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

14
which we obtain extremely weak uncertainty relations! In particular, we have for any such set
of MUBs that the lower bound of (8) can be attained5 , that is,
min
ρ

1
L

H (B j |ρ) =
j

log d
.
2

Furthermore, the same is true for all mutually unbiased bases derived from Latin squares.
These results clearly show that mutual unbiasedness is not enough to obtain strong uncertainty
relations. Combined with the numerical results from above, we also note that the dimension d,
as well as the choice of mutually unbiased bases may indeed matter. In Ballester and
Wehner (2007) it was noted that the set of mutually unbiased bases derived from the generalized
Pauli matrices for which we obtain weak uncertainty relations are exactly those which are
separable across the space C p ⊗ C p . However, we can now conclude from the results of
Wootters and Sussman (2007) that there is nothing inherently special about these separable
bases, since there exists a unitary U that maps them to a set of entangled (i.e. non-product)
bases (see section 1.3). It has also been shown by Ambainis (2006) that for any three bases from
the ‘standard’ mutually unbiased bases construction in prime dimension the lower bound cannot
exceed 21 + o(1) log d, for large dimensions. For dimensions of the form 4k + 3 and 8k + 5 no
further assumption is needed, but the proof assumes the generalized Riemann hypothesis for
dimensions of the form 8k + 1. Furthermore, for any 0
1/2, there always exist k = d
many of these bases such that the lower bound cannot be larger than ( 12 + + o(1)) log d.
Tight uncertainty relations for the min-entropy have also been shown recently for O(log d)
MUBs with special symmetry properties in dimension d = 2n (Mandayam and Wehner 2009).
It remains an interesting open question to show tight uncertainty relations for all mutually
unbiased bases.
3.3. Anti-commuting observables
Maximally strong uncertainty relations are known to exist for any number of measurement
settings L, if we limit ourselves to 2 outcomes. These uncertainty relations are derived for
generators of a Clifford algebra (Dietz 2006, Lounesto 2001), which has many beautiful
geometrical properties. For any integer n, the free real associative algebra generated by
1 , . . . , 2n , subject to the anti-commutation relations
{

j,

k}

=

j

k

+

k

j

= 2δ jk 1,

(9)

is called a Clifford algebra. It has a unique representation by Hermitian matrices on n qubits
(up to unitary equivalence). This representation can be obtained via the famous Jordan–Wigner
transformation (Jordan and Wigner 1928):
2 j−1

= Z ⊗( j−1) ⊗ X ⊗ 1⊗(n− j) ,

2j

= Z ⊗( j−1) ⊗ Y ⊗ 1⊗(n− j) ,

for j = 1, . . . , n, where we use X , Y and Z to denote the Pauli matrices. An additional such
matrix can be found by taking the product 0 := 1 2 . . . 2n , which is sometimes known as
the pseudo-scalar. To see how such operators are observables with two measurement outcomes,
5

And many more if one relaxes the condition of mutual unbiasedness to approximate unbiasedness, using the
techniques of Hayden et al (2004).
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

15
note that the eigenvalues of i always come in pairs: Let |η be an eigenvector of i with
eigenvalue λ. From i2 = we have that λ2 = 1. Note that both ±1 occur since we have
i ( j |η ) = −λ j |η . We can therefore express each i as
i

0
i

=

1
i,

−

where i0 and i1 are projectors onto the positive and negative eigenspace of
Furthermore, note that we have for i = j
Tr(

i

j)

= 12 Tr(

i

j

+

j

i)

i,

respectively.

= 0.

That is, all such operators are orthogonal. To gain some intuition of why such operators may
give good uncertainty relations, we also note that the two eigenspaces are equally large, i.e.,
rank( i0 ) = rank( i1 ) for all i, and that the positive and negative eigenspaces of such operators
are mutually unbiased (analogous to bases), since for all i = j, and an arbitrary eigenvector |ψi
of i ,
ψi |

j |ψi

= ψi |

0
j |ψi

− ψi |

1
j |ψi

= 0.

Hence, if we were to measure the maximally mixed state on the positive eigenspace of j with
any of the other observables, the probability of obtaining a measurement outcome of 0 is the
same as for obtaining outcome 1. For simplicity, we will write Hα ( j |ρ) := Hα ({ 0j , 1j }|ρ).
It was shown (Wehner and Winter 2008) that the following maximally strong uncertainty
relation holds for any set of anti-commuting observables S ⊆ { j | j ∈ {0, . . . , 2n}}
min
ρ

1
|S |

H(

j |ρ)

= 1−

j ∈S

1
.
|S |

For dimension d = 2, this reduces to an uncertainty relation for the mutually unbiased bases
given by the eigenvectors of X , Z and Y , respectively. This result is based on a form of
‘meta-uncertainty relation’ which has also been shown in a different context in Toth and
Guehne (2005). For the collision entropy, the bound becomes
min
ρ

1
|S |

H2

j |ρ

= 1 − log 1 +

j ∈S

1
log e
∼ 1−
,
|S |
|S |

and for the min-entropy we have
min
ρ

1
|S |

H∞
j ∈S

j |ρ

1
= 1 − log 1 + √
.
|S |

(10)

Interestingly, uncertainty relations for anti-commuting observables can also be used to prove
Tsirelson’s bound (Ver Steeg and Wehner 2009).
It is not known how to extend this result to more than two measurement outcomes. One
may conjecture that the generalized Clifford algebra generated by operators 1 , . . . , n , where
for all i = j we have
i

j

=ω

j

i,

with ω = e2 i/ may give strong uncertainty relations for measurements with measurement
outcomes. However, the example for X 3 , Z 3 and X 3 Z 3 given above, and numerical evidence for
higher dimensions refute this conjecture.
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

16
4. Applications

Uncertainty relations for measurements in different bases have recently played an important role
in proving security of cryptographic protocols in the bounded (Damgaard et al 2007) and noisystorage model (König et al 2009, Wehner et al 2008), respectively. Here, uncertainty relations
are used to bound the information that a cheating party has about bits which are encoded into
several possible bases, where the choice of basis is initially unknown to him. The simplest
example is an encoding of a single bit x j ∈ {0, 1} into either the computational (as |xi ) or
Hadamard basis (as H |x j ). Suppose we choose the bit x j , as well as the basis uniformly at
random, and suppose further that the cheating party is allowed to perform any measurement on
the encoded qubit giving him some classical information K . After his measurement, we provide
him with the basis information . It can be shown using a purification argument, that we can
turn the uncertainty relation for the min-entropy for the computational B1 and Hadamard basis
B2 (see (10))
1
(H∞ (B1 |ρ) + H∞ (B2 |ρ))
2

− log

1
1
+ √ ,
2 2 2

into the following bound for the adversary’s knowledge about the bit X j given K and the basis
information
1
1
H∞ (X j |K ) − log
+ √ .
2 2 2
Intuitively, the idea behind such a purification argument is to imagine that we send half of an
EPR pair to the cheating party instead of one of the BB84 states. By performing a measurement,
the cheating party then prepares a state on our end which we then measure in the different
bases, bringing us back to our original setting. The conditional min-entropy thereby has a
very intuitive interpretation as H∞ (X j |K ) = −log Pguess (X j |K ), where Pguess (X j |K ) is
the average probability that the cheating party can guess X j given K and , maximized over all
strategies (König et al 2008).
In a cryptographic setting, we are especially interested in the case where we repeat the
encoding above many times. Suppose we choose an n-bit string X 1 , . . . , X n uniformly at
random, and encode each bit in either the computational or Hadamard basis, also chosen
uniformly and independently at random. Using the semidefinite programming formalism of
Ballester et al (2008) it is easily seen (Wehner et al 2008) that this gives us
H∞ (X 1 , . . . , X n |K , )

−n log

1
1
+ √ ,
2 2 2

where the measurement that minimizes the min-entropy is a product measurement, resulting in
the final state to be a product state. In the limit of large n, it is known that for independent states,
the min-entropy behaves approximately like the Shannon entropy (Renes 2005, Tomamichel
et al 2008). This allows one to turn the uncertainty relation of Maassen and Uffink (1988) for
the Shannon entropy into a better bound on the adversaries knowledge about the long string
X 1 , . . . , X n in terms of the min-entropy. More precisely, it is known (Damgaard et al 2007) that
H∞ (X 1 , . . . , X n |K , )

1
− 2δ n
2

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

17
for = exp(−δ 2 n/(32(2 + log (1/δ))2 )), where H∞ is the -smooth min-entropy defined in
Renes (2005). Intuitively, this quantity behaves like the min-entropy, except with probability
. We refer to König et al (2009) for more information, where this uncertainty relation was
recently used to prove security in the noisy-storage model.
5. Open problems

Since a full set of mutually unbiased bases form a so-called two-design, it may be interesting
to consider sets of bases forming a t-design for any t > 2. (A t-design of states is any set such
that the average of any degree-t polynomial in the matrix elements of the states equals the
Haar measure average of the same polynomial, see Ambainis and Emerson (2007).) Using the
result of Klappenecker and Rötteler (2005) and the technique of Ballester and Wehner (2007)
it is straightforward to prove an incredibly weak uncertainty relation for the Rényi entropy of
order t, where the lower bound obeys 1/(1 − t)log ((t!d!)/(t + d − 1)!). Evidently, this lower
bound becomes weaker for higher values of t, which is exactly the opposite of what one would
hope for. It is an interesting open question, whether one can find good uncertainty relations for
higher designs.
The most interesting open problem, however, is to find any sets of measurements at all
for which we do obtain maximally strong uncertainty relations for more than two measurement
settings, and a constant number of measurement outcomes |X | > 2. Note that always
1
0 c{M j }
1−
log |X |,
(11)
L
for any set of measurements {M j } with outcomes in the set X . The problem of the entropic
uncertainty relations at its most general is to find an expression, or at least a lower bound, for
the quantity c{M j } in ‘simple’ terms of the geometry of the measurements M j .
For measurements in different bases, which are of special interest for example in locking
applications (DiVincenzo et al 2004), one is interested in the quantity
1
h(d; L) := maxB1 ,...,BL min
ρ L

L

H (B j |ρ),
j=1

where the maximization is taken over bases B1 , . . . , B L . Note that if in dimension d there exist
L mutually unbiased bases, then by virtue of (8) and the above (11),
1
1
log d h(d; L)
1−
log d,
2
L
and one would like to have a characterization of the sets of bases attaining the maximum.
Seeing thus the scaling of h(d; L) with log d, and assuming an asymptotic viewpoint of
large dimension, we finally consider the quantity6
1
h(L) := lim
h(d; L)
d→∞ log d
which depends now only on the number of bases L. For example, h(2) = 1/2, and it is clear that
h(L + L )
6

L
L
h(L) +
h(L ),
L+L
L+L

If the limit exists; otherwise take the lim inf or lim sup, giving rise to h(L) and h(L), respectively.

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

18
but we do not know if h(L) actually strictly grows with L. If so, does it approach the value
1 − 1/L suggested by the upper bound, or at least 1 − 1/ f (L) with some growing function f
of L?
Finally, since the existence of uncertainty relations is an intriguing aspect separating
quantum theory from the classical world, it would be interesting to know whether entropic
uncertainty relations can lead to an experimental test distinguishing the two settings.
Acknowledgments

We thank Andris Ambainis, Otfried Guehne, Michael Hall, Denes Petz, R Srikanth and Ronald
de Wolf for useful comments and pointers. AW is supported by the UK EPSRC, by the
Royal Society, the Leverhulme Trust, and by the European Commission through IP ‘QAP’ and
STREP ‘QICS’. The Centre for Quantum Technologies is funded by the Singapore Ministry of
Education and the National Research Foundation as part of the Research Centres of Excellence
programme. SW is supported by NSF grants PHY-04056720 and PHY-0803371.
Appendix. A bound for mutually unbiased bases

Here, we provide an alternative proof of an entropic uncertainty relation for a full set of mutually
unbiased bases in dimension d = 2n . This has previously been proved in Ivanovic (1992) and
Sanchez (1993). We already provided an alternative proof using the fact that the set of all
mutually unbiased bases forms a two-design (Ballester and Wehner 2007). The present a very
simple alternative proof for dimension d = 2n , which has the advantage that it neither requires
the introduction of two-designs, nor the results of Larsen (1990) that were used in the previous
proof by Sanchez-Ruiz (Sanchez 1993). Instead, our proof (Wehner 2008) is elementary: after
choosing a convenient parametrization of quantum states, the statement follows immediately
from Fourier analysis.
For the parameterization, we first introduce a basis for the space of 2n × 2n matrices with
the help of mutually unbiased bases. Recall that in dimension 2n , we can find exactly 2n + 1
MUBs. Below, we will always think of an integer j ∈ [d − 1] as a bit string j = j1 , . . . , jn ∈
{0, 1}n in the usual sense. The inner product of j ∈ [d − 1] and a string x = x1 , . . . , xn ∈ {0, 1}n
is then the bit wise inner product of the two bit strings modulo two j · x = k jk xk mod 2. We
will also write j ⊕ j to denote the bitwise x or of strings j and j . Suppose now that we are
given a set of d + 1 MUBs
Z = {B1 , . . . , Bd+1 },

with Bb = {|xb | x ∈ {0, 1}n }. We can then construct an orthogonal basis of the d × d Hermitian
matrices as follows:
Lemma A.1. Consider the Hermitian matrices
(−1) j·x |xb xb |,

j

Sb =
x∈{0,1}n

for b ∈ [d + 1], j ∈ [d − 1] and for all x, x ∈ {0, 1}n and b = b ∈ [d + 1] we have | xb |xb |2 =
j
1/d. Then the set {1 ∪ {Sb |b ∈ [d + 1], j ∈ [d − 1]} forms a basis for the space of d × d
j
j
matrices, where for all j and b, Sb is traceless and (Sb )2 = 1.
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

19
Proof. First, note that we have (d + 1)(d − 1) + 1 = d 2 matrices. We now show that they are all
orthogonal. Note that
Tr(Sb ) =

(−1) j·x = 0,

j

x∈{0,1}n

since j = 0, and hence Sb is traceless. Hence Tr(1Sb ) = 0. Furthermore,
j

j

Tr(Sb Sb ) =
j

(−1) j·x (−1) j ·x | xb |xb |2 .

j

(A.1)

x,x ∈{0,1}n
j·x
j ·x
For b = b , equation (A.1) gives us Tr(Sb Sb ) = (1/d)
= 0, since
x (−1)
x (−1)
j j
( j⊕ j )·x
j, j = 0. For b = b , but j = j , we get Tr(Sb Sb ) = x (−1)
= 0 since j ⊕ j = 0.
j 2
j·x
j·x
Finally, (Sb ) = x x (−1) (−1) |xb xb ||xb xb | = 1.
j

j

Since {1, Sb } form a basis for the d × d matrices, we can thus express the state ρ of a
d-dimensional system as


1
j j
ρ = 1 +
sb Sb ,
d
b∈[d+1] j∈[d−1]
j

j

for some coefficients sb ∈ R. It is now easy to see that
Lemma A.2. Let ρ be a pure state parameterized as above. Then
(sb )2 = d − 1.
j

b∈[d+1] j∈[d−1]

Proof. If ρ is a pure state, we have Tr(ρ 2 ) = 1. Hence




1 
j
Tr(1) +
(sb )2 Tr(1)
2
d
b∈[d+1] j∈[d−1]


1
j
(sb )2  = 1,
= 1 +
d
b
j

Tr(ρ 2 ) =

from which the claim follows.
Lemma A.3. Let |xb be the xth basis vector of the bth MUB. Then for any state ρ

Tr(|xb xb |ρ) =



1
j
1+
(−1) j·x sb .
d
j∈[d−1

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

20
Proof. We have

Tr(|xb xb |ρ) =



1
Tr(|xb xb |) +
d

sb Tr(Sb |xb xb |).
j

j

b ,j

Suppose b = b . Then Tr(Sb |xb xb |) = (1/d) x (−1) j·x = 0, since j = 0. Suppose b = b .
j
Then Tr(Sb |xb xb |) = x (−1) j·x | xb |xb |2 = (−1) j·x , from which the claim follows.
j

We are now ready to prove an entropic uncertainty relation for L mutually unbiased bases.
Theorem A.4. Let S = {B1 , . . . , B L } ⊆ Z be a set of mutually unbiased bases in dimension
d = 2n . Then
1
L +d −1
.
H2 (Bb , | ) − log
L b∈[L]
dL
Proof. First,√note that we can define functions f b ( j) = sb for j ∈ [d − 1] and f b (0)
√ = 1. Then
ˆf b (x) = (1/ d)( j∈{0,...,d−1} (−1) j·x sbj ) is the Fourier transform of f b and (1/ d) ˆf b (x) =
Tr(|xb xb |ρ) = | xb | |2 by lemma A.3. Thus
1
1
H2 (Bb , | ) = −
log
| x b | |4
L b∈[L]
L b∈[L]
n
j

x∈{0,1}

− log

1
dL

ˆf b (x)2
x

b


= − log

1
dL


(sb )2 
j

1 +
b

j

1
(L + d − 1),
dL
where the first inequality follows from Jensen’s inequality and the concavity of log. The next
equality follows from Parseval’s equality, and the last follows from the fact that |
is a pure
state and lemma A.2.
= − log

Corollary A.5. Let S = {B1 , . . . , B L } be a set of mutually unbiased bases. Then
1
L

H (Bb ||
b∈[L]

)

− log

L +d −1
.
dL

In particular, for a full set of L = d + 1 MUBs we obtain

1
L

b

H (Bb ||

)

Proof. This follows immediately from theorem A.4 and the fact that H (·)

log(d + 1) − 1.
H2 (·).

It is interesting to note that this bound is the same that arises from interpolating between the
results of Sanchez-Ruiz (1993) and Maassen and Uffink (1988) as was done by Azarchs (2004).
This bound has more recently been rediscovered by Wu et al (2009).
New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

21
References
Ambainis A 2009 Limits on entropic uncertainty relations for 3 and more MUBs arXiv:0909.3720
Ambainis A and Emerson J 2007 Proc. 22nd Annu. IEEE Conf. on Computational Complexity (CCC’07)
pp 129–40 arXiv:quant-ph/0701126
Azarchs A 2004 Entropic uncertainty relations for incomplete sets of mutually unbiased observables. arXiv:quantph/0412083
Ballester M and Wehner S 2007 Phys. Rev. A 75 022319
Ballester M, Wehner S and Winter A 2008 IEEE Trans. Inf. Theory 54 4183
Bandyopadhyay S, Boykin P, Roychowdhury V and Vatan F 2002 Algorithmica 34 512
Beckner W 1975 Ann. Math. 102 159
Berta M, Christandl M, Colbeck R, Renes J and Renner R 2009 An entropic uncertainty relation with quantum side
information. arXiv:0909.0950
Białynicki-Birula I 1984 Phys. Lett. A 103 253
Białynicki-Birula I 2006 Phys. Rev. A 74 052102
Białynicki-Birula I and Madajczyk J L 1985 Phys. Lett. A 108 384
Białynicki-Birula I and Mycielski J 1975 Commun. Math. Phys. 44 129
Christandl M and Winter A 2005 Uncertainty, monogamy and locking of quantum correlations. arXiv:quantph/0501090
Cover T M and Thomas J A 1991 Elements of Information Theory (New York: Wiley)
Damgaard I, Fehr S, Renner R, Salvail L and Schaffner C 2007 A tight high-order entropic uncertainty relation
with applications in the bounded quantum-storage model Proc. CRYPTO 2007
Damgaard I, Fehr S, Salvail L and Schaffner C 2005 Proc. 46th IEEE FOCS pp 449–58
Deutsch D 1983 Phys. Rev. Lett. 50 631
Dietz K 2006 J. Phys. A: Math. Gen. 36 1433
DiVincenzo D, Horodecki M, Leung D, Smolin J and Terhal B 2004 Phys. Rev. Lett. 92 067902
Dodonov V V and Man’ko V I 1989 Invariants and the evolution of nonstationary quantum Systems Proc. Lebedev
Physics Institute vol 183 ed M A Markov (Commack, NY: Nova Science) pp 3–101
Ghirardi G, Marinatto L and Romano R 2003 Phys. Lett. A 317 32
Gibilisco P, Hiai F and Petz D 2009 IEEE Trans. Inf. Theory 55 439
Grassl M 2004 Proc. ERATO Conf. Quantum Information Science pp 60–1 (arXiv:quant-ph/0406175)
Guehne O 2004 Phys. Rev. Lett. 92 117903
Hall M J W 1997 Phys. Rev. A 55 100
Hall M J W 2008 J. Phys. A: Math. Gen. 41 255301
Hayden P, Leung D, Shor P and Winter A 2004 Commun. Math. Phys. 250 371
Heisenberg W 1927 Z. Phys. 43 172
Hirschmann I I 1957 Am. J. Math. 79 152
Ivanovic I D 1992 J. Phys. A: Math. Gen. 25 363
Jordan P and Wigner E 1928 Z. Phys. 47 631
Klappenecker A and Rötteler M 2004 Int. Conf. on Finite Fields and Applications (Fq7) (Lecture Notes in
Computer Science vol 2948) (New York: Springer) pp 137–44
Klappenecker A and Rötteler M 2005 Proc. IEEE Int. Symp. on Information Theory pp 1740–4
Koashi M 2005 Simple security proof of quantum key distribution via uncertainty principle arXiv: quantph/0505108
König R, Renner R and Schaffner C 2008 The operational meaning of min- and max-entropy arXiv:0807.1338
König R, Wehner S and Wullschleger J 2009 Unconditional security in the noisy-storage model arXiv:0906.1030
Kraus K 1987 Phys. Rev. D 35 3070
Krishna M and Parthasarathy K R 2002 Ind. J. Stat. A 64 (arXiv:quant-ph/0110025)
Landau H J and Pollack H O 1961 Bell Syst. Tech. J. 40 65

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

22
Larsen U 1990 J. Phys. A: Math. Gen. 23 1041
Lawrence J, Brukner C and Zeilinger A 2002 Phys. Rev. A 65 032320
Lounesto P 2001 Clifford Algebras and Spinors (Cambridge: Cambridge University Press)
Maassen H and Uffink J 1988 Phys. Rev. Lett. 60 1103
Majernik V and Majernikova E 2001 Rep. Math. Phys. 47 381
Mandayam P and Wehner S 2009 in preparation
Massar S 2007 Phys. Rev. A 76 042114
Partovi M H 1983 Phys. Rev. Lett. 50 24
Rajagopal A K 1995 Phys. Lett. A 205 32
Rastegin A E 2008a Comment on ‘uncertainty relations for positive-operator-valued measures’ arXiv:0810.0038
Rastegin A E 2008b arXiv:0807.2691
Rastegin A E 2008c arXiv:0805.1777
Renes J M and Boileau J-C 2009 Phys. Rev. Lett. 103 020402
Renner R 2005 Security of quantum key distribution PhD Thesis ETH Zurich (arXiv:quant-ph/0512258)
Rényi A 1960 Proc. 4th Berkeley Symp. on Mathematics, Statistics and Probability pp 547–61
Riesz M 1929 Acta Math. 49 465
Robertson H 1929 Phys. Rev. 34 163
Sanchez J 1993 Phys. Lett. A 173 233
Sanchez-Ruiz J 1995 Phys. Lett. A 201 125
Sanchez-Ruiz J 1998 Phys. Lett. A 244 189
Shannon C E 1948 Bell Syst. Tech. J. 27 379
Srikanth R and Banerjee S 2009 Eur. Phys. J. D 53 217
Tomamichel M, Colbeck R and Renner R 2008 A fully quantum asymptotic equipartition property.
arXiv:0811.1221
Toth G and Guehne O 2005 Phys. Rev. A 72 022340
Tsallis C 1988 J. Stat. Phys. 51 479
Ver Steeg G and Wehner S 2009 Quantum Inf. Comput. 9 801
de Vicente J I and Sanchez-Ruiz J 2008 Phys. Rev. A 77 042110
Wehner S 2008 Cryptography in a quantum world PhD Thesis University of Amsterdam (arXiv:0806.3483)
Wehner S, Schaffner C and Terhal B M 2008 Phys. Rev. Lett. 100 220502
Wehner S and Winter A 2008 J. Math. Phys. 49 062105
Wocjan P and Beth T 2005 Quantum Inf. and Comput. 5 93
Wootters W and Fields B 1989 Ann. Phys. 191 368
Wootters W K and Sussman D M 2007 arXiv:0704.1277
Wu S, Yu S and Molmer K 2009 Phys. Rev. A 79 022104
Zauner G 1999 Quantendesigns—Grundzüge einer nichtkommutativen designtheorie PhD Thesis Universität Wien

New Journal of Physics 12 (2010) 025009 (http://www.njp.org/)

